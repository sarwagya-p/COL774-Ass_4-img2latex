{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, layers, hparams):\n",
    "        '''\n",
    "        Args:\n",
    "            layers: Description of all layers in the Encoder: [(layer_type, {layer_params})]\n",
    "                - layer types - ['conv1d', 'conv2d', 'maxpool1d', 'maxpool2d', 'avgpool2d', 'avgpool2d', 'linear', 'dropout']\n",
    "                - layer_params - dict of parameters for the layer\n",
    "\n",
    "            hparams: Hyperparameters for the model\n",
    "        '''\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hp = hparams\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for layer_type, layer_params in layers:\n",
    "            if layer_type == 'conv1d':\n",
    "                self.layers.append(nn.Conv1d(**layer_params))\n",
    "            elif layer_type == 'conv2d':\n",
    "                self.layers.append(nn.Conv2d(**layer_params))\n",
    "            elif layer_type == 'maxpool1d':\n",
    "                self.layers.append(nn.MaxPool1d(**layer_params))\n",
    "            elif layer_type == 'maxpool2d':\n",
    "                self.layers.append(nn.MaxPool2d(**layer_params))\n",
    "            elif layer_type == 'avgpool1d':\n",
    "                self.layers.append(nn.AvgPool1d(**layer_params))\n",
    "            elif layer_type == 'avgpool2d':\n",
    "                self.layers.append(nn.AvgPool2d(**layer_params))\n",
    "            elif layer_type == 'linear':\n",
    "                self.layers.append(nn.Linear(**layer_params))\n",
    "            elif layer_type == 'dropout':\n",
    "                self.layers.append(nn.Dropout(**layer_params))\n",
    "            else:\n",
    "                raise ValueError(f'Invalid layer type: {layer_type}')\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers:\n",
    "            input = layer(input)\n",
    "        return input\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab, vocab_dict, input_size, embedding_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        '''\n",
    "        Args:\n",
    "            vocabulary_size: Size of the vocabulary\n",
    "            embedding_size: Size of the embedding vector\n",
    "        '''\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_dict = vocab_dict\n",
    "\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm = nn.LSTM(input_size+embedding_size, embedding_size, batch_first=True)\n",
    "        self.output = nn.Linear(embedding_size, len(vocab))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "        Args:\n",
    "            input: Input to the decoder\n",
    "            hidden: Hidden state of the previous time step\n",
    "        '''\n",
    "        # prev_embed = self.embedding(prev_tokens)\n",
    "        # concated_inp = torch.cat((input, prev_embed), dim=1)\n",
    "        if hidden is None:\n",
    "            output, hidden = self.lstm(input)\n",
    "        else:\n",
    "            output, hidden = self.lstm(input, hidden)\n",
    "        output = self.output(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PAD = \"<pad>\"\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\"\n",
    "\n",
    "def load_img(path, size = (224, 224)):\n",
    "    img = (Image.open(path))\n",
    "    transform = transforms.Compose([transforms.Resize(size, antialias=True), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "    im = transform(img).detach()\n",
    "    im = 1 - im\n",
    "    return im\n",
    "\n",
    "class Img2LatexDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, formula_path, img_size = (224, 224)):\n",
    "        self.data_frame = pd.read_csv(formula_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.token_to_idx = {}\n",
    "        self.tokens = []\n",
    "\n",
    "        for row in self.data_frame[\"formula\"]:\n",
    "            row = row.split()\n",
    "\n",
    "            for token in row:\n",
    "                if token not in self.token_to_idx:\n",
    "                    self.token_to_idx[token] = len(self.token_to_idx)\n",
    "                    self.tokens.append(token)\n",
    "        \n",
    "        for special_token in [SOS, EOS, PAD]:\n",
    "            self.token_to_idx[special_token] = len(self.token_to_idx)\n",
    "            self.tokens.append(special_token)\n",
    "\n",
    "        max_len = max([len(row.split()) for row in self.data_frame[\"formula\"]])+2\n",
    "        def indexer(row):\n",
    "            index_list = [self.token_to_idx[SOS]]\n",
    "            index_list.extend([self.token_to_idx[token] for token in row.split()])\n",
    "            index_list.append(self.token_to_idx[EOS])\n",
    "            index_list.extend([self.token_to_idx[PAD]] * (max_len - len(index_list)))\n",
    "\n",
    "            return index_list\n",
    "        \n",
    "        self.data_frame[\"IndexList\"] = self.data_frame[\"formula\"].apply(indexer)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = load_img(self.img_dir + self.data_frame[\"image\"][index], self.img_size)\n",
    "        return img, torch.tensor(self.data_frame[\"IndexList\"][index], requires_grad=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.token_to_idx, self.tokens\n",
    "\n",
    "img_dir = \"../data/SyntheticData/images/\"\n",
    "formula_dir = \"../data/SyntheticData/train.csv\"\n",
    "\n",
    "dataset = Img2LatexDataset(img_dir, formula_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"lr\" : 0.001,\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 10\n",
    "}\n",
    "\n",
    "channel_seq = [3, 32, 64, 128, 256, 512]\n",
    "num_conv_pool = 5\n",
    "\n",
    "enc_layers = []\n",
    "\n",
    "for i in range(num_conv_pool):\n",
    "    enc_layers.append(('conv2d', {'in_channels': channel_seq[i], 'out_channels': channel_seq[i+1], 'kernel_size': 5}))\n",
    "    enc_layers.append(('maxpool2d', {'kernel_size': 2}))\n",
    "\n",
    "enc_layers.append(('avgpool2d', {'kernel_size': (3,3)}))\n",
    "\n",
    "enc = EncoderCNN(enc_layers, hparams).to(device)\n",
    "dec = DecoderRNN(dataset.tokens, dataset.token_to_idx, 512, 512).to(device)\n",
    "\n",
    "model = EncoderDecoder(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([32, 3, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([128, 64, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([256, 128, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([512, 256, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 1024])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([549])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED MODEL to cuda\n",
      "torch.Size([31, 512])\n",
      "tensor([[546,   0,  36,  ..., 548, 548, 548],\n",
      "        [546,   0, 169,  ..., 548, 548, 548],\n",
      "        [546,   0,  61,  ..., 548, 548, 548],\n",
      "        ...,\n",
      "        [546,   0,  10,  ..., 548, 548, 548],\n",
      "        [546,   0,   3,  ..., 548, 548, 548],\n",
      "        [546,   0,  10,  ..., 548, 548, 548]], device='cuda:0')\n",
      "torch.Size([31, 143])\n",
      "torch.Size([31, 143, 512])\n",
      "torch.Size([31, 143, 512])\n",
      "torch.Size([31, 143, 549])\n",
      "H\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]], device='cuda:0')\n",
      "torch.Size([2516, 549])\n",
      "torch.Size([2516, 549])\n",
      "h\n",
      "torch.Size([31, 143, 549])\n",
      "['$', '{', '_', '{', 'a', '}', '=', '\\\\frac', '\\\\frac', '{', '1', '}', '{', '2', '}', '\\\\left(', '_', '{', '\\\\mu', '}', '^', '_', '{', '\\\\mu', '}', '^', '^', '{', '\\\\mu', '}', '}', '+', '_', '{', '\\\\alpha', '}', '^', '\\\\frac', '{', '1', '}', '{', '2', '}', '}', '{', '2', '}', '}', '_', '{', '\\\\mu', '}', '^', '\\\\partial', '_', '{', '\\\\mu', '}', '^', '^', '{', '\\\\alpha', '}', '\\\\right)', '\\\\frac', '{', '1', '}', '{', '2', '}', '\\\\right)', '_', '{', '\\\\alpha', '}', '^', '^', '{', '\\\\alpha', '}', '\\\\right)', '^', ',', '$', '<eos>', '^', '{', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{']\n",
      "['$', 'f', '_', '{', '\\\\mu', '}', '=', '-', '\\\\frac', '{', '1', '}', '{', '2', '}', 'p', '_', '{', '\\\\alpha', '}', '\\\\partial', '_', '{', '\\\\mu', '}', 'g', '^', '{', '\\\\alpha', '\\\\beta', '}', 'p', '_', '{', '\\\\beta', '}', '-', '\\\\frac', '{', '\\\\hbar', '^', '{', '2', '}', '}', '{', '4', '}', '\\\\partial', '_', '{', '\\\\mu', '}', '\\\\left(', '\\\\partial', '_', '{', '\\\\alpha', '}', '\\\\Gamma', '^', '{', '\\\\alpha', '}', '+', '\\\\frac', '{', '1', '}', '{', '2', '}', '\\\\Gamma', '_', '{', '\\\\alpha', '}', '\\\\Gamma', '^', '{', '\\\\alpha', '}', '\\\\right)', '\\\\,', ',', '$', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0]\n",
    "   \n",
    "   return labels[:, :len(non_pad_cols)]\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = 31, shuffle = True)\n",
    "\n",
    "model_path = \"./models/model.pt\"\n",
    "current_params_path = \"./models/current_params.txt\"\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "labels = remove_trailing_pads(labels)\n",
    "context_vec = model.encoder(images).squeeze()\n",
    "if len(context_vec.shape) == 1:\n",
    "    context_vec = context_vec.unsqueeze(0)\n",
    "print(context_vec.shape)\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "print(context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1).shape)\n",
    "print(model.decoder.embedding(labels).shape)\n",
    "target = nn.functional.one_hot(labels, num_classes=len(dataset.tokens)).float().to(device)\n",
    "inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2)\n",
    "\n",
    "output, _ = model.decoder(inputs, None)\n",
    "print(output.shape)\n",
    "print(\"H\")\n",
    "mask = labels == PAD_IDX\n",
    "print(mask)\n",
    "print(output[labels == PAD_IDX].shape)\n",
    "print(target[labels == PAD_IDX].shape)\n",
    "# output[labels == PAD_IDX] = 0\n",
    "# target[labels == PAD_IDX] = 0\n",
    "print(\"h\")\n",
    "print(output.shape)\n",
    "output = output.argmax(dim=2)\n",
    "output_tokens = [dataset.tokens[token_idx] for token_idx in output[0].tolist()]\n",
    "print(output_tokens)\n",
    "print([dataset.tokens[token_idx] for token_idx in labels[0, 1:].tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '{', '_', '{', '1', '}', '}', '}', '=', '{', '2', '}', '=', '=', '\\\\frac', '\\\\,', '^', '{', '2', '}', '}', '{', '1', '}', '}', '}', '}', '{', '2', '}', '}', '{', '.', '\\\\frac', '{', '1', '}', '}', '{', '\\\\frac', '}', '{', '{', '\\\\frac', '}', '{', '1', '}', '}', '}', '}', '{', '{', '\\\\frac', '1', '}', '_', '{', '1', '}', '}', '}', '}', '{', '{', '\\\\frac', '}', '^', '{', '\\\\right)', '$', '.', '\\\\frac', '}', '}', '^', '.', '_', '\\\\,', '\\\\frac', '{', '}', '^', '{', 'i', '}', '}', '}', '=', '.', '\\\\frac', '}', '}', '^', '{', '$', '<eos>', '_', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{']\n",
      "['$', 'S', '_', '{', '[', '1', ']', '}', '^', '{', 'c', '}', '\\\\,', '=', '\\\\,', 'e', '^', '{', 'i', '\\\\vartheta', '_', '{', '[', '1', ']', '}', '^', '{', 'c', '}', '}', '\\\\,', '\\\\left(', '\\\\begin{array}', '{', 'c', 'c', '}', '{', '0', '}', '&', '{', '\\\\Theta', '_', '{', '[', '1', ']', '}', '}', '\\\\\\\\', '{', '-', '\\\\,', '\\\\Theta', '_', '{', '[', '1', ']', '}', '}', '&', '{', '0', '}', '\\\\\\\\', '\\\\end{array}', '\\\\right)', '\\\\,', '{', '\\\\cal', 'K', '}', '\\\\,', '\\\\equiv', '\\\\,', '{', '\\\\cal', 'C', '}', '_', '{', '[', '1', ']', '}', '\\\\,', '{', '\\\\cal', 'K', '}', '\\\\quad', '.', '$', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "t = 27\n",
    "output_tokens = [dataset.tokens[token_idx] for token_idx in output[t].tolist()]\n",
    "print(output_tokens)\n",
    "print([dataset.tokens[token_idx] for token_idx in labels[t, 1:].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1734.1604, 2072.4707,  252.6192,  215.5585,  217.3692, 1952.0667,\n",
       "        2512.1045,  230.7138,  220.1318, 2070.3169, 1944.1429, 1655.5834,\n",
       "         178.0718,  213.9041, 1245.3400, 2149.6555, 1944.7310, 1942.9019,\n",
       "         374.3238, 1622.1216,  504.0812,  623.3975,  214.0963,  230.4600,\n",
       "        1964.6390,  205.6519,  273.4448,  226.8584, 1580.5632, 1955.5258,\n",
       "         233.6819,  261.7012, 1666.2042, 1623.9436, 1670.8289, 1598.0292,\n",
       "         243.2216,  220.0372, 1949.1882,  222.4726, 1978.6477, 1937.8784,\n",
       "         302.8336,  217.6581, 1967.6904, 2024.3748, 1591.1747, 1569.5627,\n",
       "        3150.0876,  218.5603,  216.4439, 1637.1022,  217.0717,  164.1452,\n",
       "        1994.8130, 1587.9167, 1956.4849,  203.3632,  200.6049,  311.7800,\n",
       "        1585.7943, 1646.0098, 1944.4889, 1584.9890, 1602.2743,  194.7858,\n",
       "        1958.3536,  444.8534, 1958.7516, 1928.8143, 1658.7949, 1406.0608,\n",
       "        2660.7786,  210.7152, 1591.8102, 2446.9768, 1605.8856,  199.1292,\n",
       "        2092.7134, 1621.6423, 1997.4701, 1983.5083,  127.8232, 1623.2202,\n",
       "         216.8455, 1962.4543, 1954.1826,  187.6516, 1621.3401, 2014.3300,\n",
       "        1957.6008,  191.0217,  191.1535, 1600.9648, 2047.5240, 2084.0117,\n",
       "         596.5546,  427.6954,  186.0078, 2033.2334,  252.3554,  202.0293,\n",
       "        2997.4033,  197.2981,  434.3950,  293.5649,  237.2772,  224.1999,\n",
       "         457.6664, 2262.9783, 1693.0026, 2410.2734,  197.4115, 1592.4750,\n",
       "        1970.9547,  193.9722,  184.9067,  254.1237, 1633.4939, 2135.2590,\n",
       "        1954.0312,  143.6440, 1654.4922,  260.6284,  660.1451,  220.8467,\n",
       "         275.7413, 1656.5624,  326.6652, 2053.4548,  489.3335,  211.4370,\n",
       "         210.0995, 1600.3053, 1986.4924,  257.4280, 1656.0171,  221.8414,\n",
       "        1904.7816, 1942.3429,  350.0374, 1698.0880, 1608.9603,  170.6849,\n",
       "        1905.1019,  175.4389,  236.3952, 2042.0354,  180.6770,  276.5999,\n",
       "         210.3500, 1630.9027,  296.2735,  270.6233,  287.8549, 1930.0306,\n",
       "         179.7047, 1615.0706, 1913.7118,  220.5714, 1606.8412,  219.2022,\n",
       "         224.0030, 1612.9659, 1963.9802, 1995.6904,  341.5000, 1996.7992,\n",
       "         280.9182,  182.0666,  212.9470, 1999.7909, 2237.5674,  284.1943,\n",
       "         229.0126, 1615.1609,  352.6448,  231.7483, 1615.8104,  183.1380,\n",
       "        1903.6360,  198.7336,  239.4345, 2035.6760, 1948.4421,  201.7550,\n",
       "         195.5453,  252.0621, 1964.9448, 1969.8561, 1975.3533, 1573.4799,\n",
       "         278.8395,  160.1132,  234.5703,  255.2583, 1580.6890, 1598.9462,\n",
       "         216.5594,  281.7617,  300.2778,  310.9838,  201.7132, 2000.8759,\n",
       "         187.0771,  239.2932, 1633.9376, 2002.5046, 1924.4427, 2041.4528,\n",
       "        1674.7043, 1596.1301, 1971.5276, 1646.3850, 1068.6462,  499.2125,\n",
       "        1956.6387,  195.0397,  273.5725,  309.4285, 1932.1053, 1588.7468,\n",
       "        2145.7773, 2261.4785, 1608.4501,  236.5504, 1583.7577,  311.1363,\n",
       "        2049.3237, 2011.7802,  192.1308, 1921.7302,  268.8392, 1950.3091,\n",
       "         173.7306, 2005.2140,  206.0701, 1648.5768,  188.5606,  230.8860,\n",
       "        2000.9061, 1984.2583,  347.5899, 1988.8890, 1967.6396,  644.2937,\n",
       "         258.9025, 1613.5847, 1651.6487,  364.4552, 2047.6095, 1570.0747,\n",
       "        1587.5488, 1970.2157,  202.4970,  280.9392,  202.2704,  190.3976,\n",
       "         225.4185,  200.4203,  208.5917, 2009.9338,  224.4762, 4569.9067,\n",
       "         423.1777, 1644.3097, 1942.4427, 1955.7203, 1974.6141, 1796.5012,\n",
       "         248.9073,  488.0496, 1656.0861,  191.5478, 2042.2671,  240.9355,\n",
       "         186.1632, 1647.5021, 2260.1650, 1714.2384, 1575.4177,  183.9545,\n",
       "         192.3472,  200.6792,  166.9894, 2009.4886, 1627.3657, 2088.8611,\n",
       "         215.7912,  774.7803, 1598.7474, 1589.1320,  193.3688, 2024.5272,\n",
       "        2098.5830, 1585.9939,  397.1557,  432.8669, 1608.4352,  309.5633,\n",
       "         202.0742,  400.2130, 1620.9495, 1621.5957,  184.6101,  206.5536,\n",
       "         871.9304,  182.4277, 1666.3333,  199.0614, 1616.5613, 1556.1440,\n",
       "        1573.0159,  217.5089,  296.8964, 1590.5460, 1959.8009,  337.9868,\n",
       "        1604.2197,  243.6858, 1271.1904,  221.0852,  234.0467,  922.7005,\n",
       "         189.6839,  208.5311, 2032.6685,  199.8118,  255.8303, 1625.4421,\n",
       "        1595.7190,  264.0386, 1948.3800,  197.5587,  676.3924,  262.6884,\n",
       "         168.0467,  213.9640, 1909.7777, 1964.1355,  341.0035, 1673.7520,\n",
       "         279.3752,  226.8567, 2021.3323, 1938.8298, 1638.5282, 1598.3329,\n",
       "         195.7118, 1940.8397, 1613.6488, 1788.4526,  192.1172,  205.3209,\n",
       "         251.6318, 1701.4252, 1577.5911,  262.5567,  232.5106,  177.3625,\n",
       "         195.4280,  193.2348,  249.3349,  274.9368,  282.2879, 1604.0216,\n",
       "        1164.4341,  565.3531,  215.2836, 1601.9108,  384.2124,  218.2679,\n",
       "        1981.3826,  202.1303,  217.4909,  245.9351,  180.1619, 1735.5958,\n",
       "        1608.0222, 1957.9697, 1989.3956,  217.0219,  206.2852,  572.1429,\n",
       "        1949.5433,  230.8943, 1945.0614, 1578.7367,  228.0712,  237.0225,\n",
       "        1699.8555,  237.2258,  208.8014,  716.2084,  185.5689, 1583.0133,\n",
       "         210.2700,  197.6865,  186.6133,  216.6513,  202.8001, 2007.8718,\n",
       "         169.8273,  214.3681, 1576.4351,  747.1990,  187.3885, 1594.2982,\n",
       "         162.8309, 1832.7198, 1998.2679,  221.3087, 2120.2012,  318.1745,\n",
       "        1952.2078,  252.9600, 1624.9001,  336.4955, 2034.1910, 1918.5045,\n",
       "        1957.5343, 1587.2185, 2072.5522,  198.9888, 1655.5243, 1959.6846,\n",
       "        1984.4221,  492.6928, 1621.0078,  382.8004, 2007.0024,  192.6567,\n",
       "         244.5722,  248.8508,  228.8720, 2229.2964, 1608.3446, 1750.4524,\n",
       "        1954.3434, 2035.5227,  223.3970,  257.9302, 2102.2068, 1948.6073,\n",
       "        1582.8583, 2081.0557,  240.8204, 1981.9331,  168.1885, 1968.4082,\n",
       "        2084.1875,  192.1631,  300.5800, 1681.0970,  321.0082,  409.7813,\n",
       "         213.5170, 1627.8812, 1799.4857, 1649.5261, 2227.0337,  174.8162,\n",
       "        2361.0955, 2042.4928,  259.7658, 1614.0079,  202.4066, 1948.9478,\n",
       "         976.3595, 1148.4910, 1598.1044, 1908.5385, 1869.3066, 1628.8390,\n",
       "         236.7710, 1629.0590, 2080.3176,  308.9594, 1939.0974,  202.1614,\n",
       "        1622.5856, 1999.2720,  212.7152, 1600.1041,  143.3778, 1666.7505,\n",
       "         231.9697, 1988.7133, 2083.0850, 1673.0609, 1723.6432,  492.1842,\n",
       "        1959.5184,  398.2504, 1677.1144, 1612.9453, 1955.3766,  215.6329,\n",
       "         230.3894, 1571.2089,  218.8087,  216.5171,  251.5740, 1643.3228,\n",
       "        1677.5233,  380.0384, 1813.4005, 1727.1516,  230.0147, 1568.5699,\n",
       "        2024.5148, 2251.0034], device='cuda:0', grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context_vec.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n",
      "LOADED MODEL to cuda\n",
      "Running Batch 0, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6380321979522705\n",
      "Running Batch 1, Epoch 0, Total Tokens: 139\n",
      "Loss: 3.3033957481384277\n",
      "Running Batch 2, Epoch 0, Total Tokens: 134\n",
      "Loss: 3.7399842739105225\n",
      "Running Batch 3, Epoch 0, Total Tokens: 128\n",
      "Loss: 3.9308242797851562\n",
      "Running Batch 4, Epoch 0, Total Tokens: 144\n",
      "Loss: 5.509815216064453\n",
      "Running Batch 5, Epoch 0, Total Tokens: 169\n",
      "Loss: 4.406740188598633\n",
      "Running Batch 6, Epoch 0, Total Tokens: 130\n",
      "Loss: 3.4961729049682617\n",
      "Running Batch 7, Epoch 0, Total Tokens: 129\n",
      "Loss: 3.103196620941162\n",
      "Running Batch 8, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.8560688495635986\n",
      "Running Batch 9, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.7728872299194336\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 9, Loss: 2.7728872299194336\n",
      "Running Batch 10, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.7598319053649902\n",
      "Running Batch 11, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.786576986312866\n",
      "Running Batch 12, Epoch 0, Total Tokens: 100\n",
      "Loss: 2.631941556930542\n",
      "Running Batch 13, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.6460752487182617\n",
      "Running Batch 14, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.446037530899048\n",
      "Running Batch 15, Epoch 0, Total Tokens: 190\n",
      "Loss: 2.5055229663848877\n",
      "Running Batch 16, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2903034687042236\n",
      "Running Batch 17, Epoch 0, Total Tokens: 188\n",
      "Loss: 2.4484081268310547\n",
      "Running Batch 18, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2423501014709473\n",
      "Running Batch 19, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.2786505222320557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 19, Loss: 2.2786505222320557\n",
      "Running Batch 20, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.338090658187866\n",
      "Running Batch 21, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.252739429473877\n",
      "Running Batch 22, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.252088785171509\n",
      "Running Batch 23, Epoch 0, Total Tokens: 186\n",
      "Loss: 2.1796464920043945\n",
      "Running Batch 24, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.166935920715332\n",
      "Running Batch 25, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.138202428817749\n",
      "Running Batch 26, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.0816659927368164\n",
      "Running Batch 27, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.224586248397827\n",
      "Running Batch 28, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.12583327293396\n",
      "Running Batch 29, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.0293736457824707\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 29, Loss: 2.0293736457824707\n",
      "Running Batch 30, Epoch 0, Total Tokens: 164\n",
      "Loss: 2.0543482303619385\n",
      "Running Batch 31, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.0664186477661133\n",
      "Running Batch 32, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.0091474056243896\n",
      "Running Batch 33, Epoch 0, Total Tokens: 629\n",
      "Loss: 1.990800142288208\n",
      "Running Batch 34, Epoch 0, Total Tokens: 158\n",
      "Loss: 2.057197332382202\n",
      "Running Batch 35, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.0402350425720215\n",
      "Running Batch 36, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.0266780853271484\n",
      "Running Batch 37, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.9584585428237915\n",
      "Running Batch 38, Epoch 0, Total Tokens: 158\n",
      "Loss: 1.8985034227371216\n",
      "Running Batch 39, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.9839487075805664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 39, Loss: 1.9839487075805664\n",
      "Running Batch 40, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.9427560567855835\n",
      "Running Batch 41, Epoch 0, Total Tokens: 287\n",
      "Loss: 1.9783316850662231\n",
      "Running Batch 42, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.9461004734039307\n",
      "Running Batch 43, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.9819835424423218\n",
      "Running Batch 44, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.000201940536499\n",
      "Running Batch 45, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.8835656642913818\n",
      "Running Batch 46, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.883311152458191\n",
      "Running Batch 47, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.8945001363754272\n",
      "Running Batch 48, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.900886058807373\n",
      "Running Batch 49, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.9464826583862305\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 49, Loss: 1.9464826583862305\n",
      "Running Batch 50, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.9131325483322144\n",
      "Running Batch 51, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.9565136432647705\n",
      "Running Batch 52, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.8967809677124023\n",
      "Running Batch 53, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.8840224742889404\n",
      "Running Batch 54, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.8714475631713867\n",
      "Running Batch 55, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7870652675628662\n",
      "Running Batch 56, Epoch 0, Total Tokens: 115\n",
      "Loss: 1.8302096128463745\n",
      "Running Batch 57, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.911731481552124\n",
      "Running Batch 58, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.920302391052246\n",
      "Running Batch 59, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.8797427415847778\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 59, Loss: 1.8797427415847778\n",
      "Running Batch 60, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.8180842399597168\n",
      "Running Batch 61, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.8347115516662598\n",
      "Running Batch 62, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.8356496095657349\n",
      "Running Batch 63, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.7935253381729126\n",
      "Running Batch 64, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7984023094177246\n",
      "Running Batch 65, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.8184865713119507\n",
      "Running Batch 66, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.8444870710372925\n",
      "Running Batch 67, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.8612968921661377\n",
      "Running Batch 68, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.8079540729522705\n",
      "Running Batch 69, Epoch 0, Total Tokens: 372\n",
      "Loss: 1.8439677953720093\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 69, Loss: 1.8439677953720093\n",
      "Running Batch 70, Epoch 0, Total Tokens: 203\n",
      "Loss: 1.8587127923965454\n",
      "Running Batch 71, Epoch 0, Total Tokens: 187\n",
      "Loss: 1.9081859588623047\n",
      "Running Batch 72, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.767570972442627\n",
      "Running Batch 73, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.8042714595794678\n",
      "Running Batch 74, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.8505480289459229\n",
      "Running Batch 75, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.8474115133285522\n",
      "Running Batch 76, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.8109943866729736\n",
      "Running Batch 77, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.8268564939498901\n",
      "Running Batch 78, Epoch 0, Total Tokens: 210\n",
      "Loss: 1.811942219734192\n",
      "Running Batch 79, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.8183344602584839\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 79, Loss: 1.8183344602584839\n",
      "Running Batch 80, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.8281426429748535\n",
      "Running Batch 81, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.8408886194229126\n",
      "Running Batch 82, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.867725133895874\n",
      "Running Batch 83, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.8316850662231445\n",
      "Running Batch 84, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.8379369974136353\n",
      "Running Batch 85, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7236652374267578\n",
      "Running Batch 86, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.8455805778503418\n",
      "Running Batch 87, Epoch 0, Total Tokens: 116\n",
      "Loss: 1.8358908891677856\n",
      "Running Batch 88, Epoch 0, Total Tokens: 197\n",
      "Loss: 1.7979485988616943\n",
      "Running Batch 89, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.8342243432998657\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 89, Loss: 1.8342243432998657\n",
      "Running Batch 90, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.8848778009414673\n",
      "Running Batch 91, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.6927951574325562\n",
      "Running Batch 92, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.893649935722351\n",
      "Running Batch 93, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.706940770149231\n",
      "Running Batch 94, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.8309544324874878\n",
      "Running Batch 95, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7175050973892212\n",
      "Running Batch 96, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7945040464401245\n",
      "Running Batch 97, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7693367004394531\n",
      "Running Batch 98, Epoch 0, Total Tokens: 250\n",
      "Loss: 1.7266806364059448\n",
      "Running Batch 99, Epoch 0, Total Tokens: 295\n",
      "Loss: 1.8177154064178467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 99, Loss: 1.8177154064178467\n",
      "Running Batch 100, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.8778069019317627\n",
      "Running Batch 101, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7492868900299072\n",
      "Running Batch 102, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7498950958251953\n",
      "Running Batch 103, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7931101322174072\n",
      "Running Batch 104, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.759474515914917\n",
      "Running Batch 105, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.8011536598205566\n",
      "Running Batch 106, Epoch 0, Total Tokens: 284\n",
      "Loss: 1.8699029684066772\n",
      "Running Batch 107, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.8100639581680298\n",
      "Running Batch 108, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7911368608474731\n",
      "Running Batch 109, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.69855797290802\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 109, Loss: 1.69855797290802\n",
      "Running Batch 110, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7389625310897827\n",
      "Running Batch 111, Epoch 0, Total Tokens: 293\n",
      "Loss: 1.7083971500396729\n",
      "Running Batch 112, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6922252178192139\n",
      "Running Batch 113, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.697735071182251\n",
      "Running Batch 114, Epoch 0, Total Tokens: 384\n",
      "Loss: 1.8448604345321655\n",
      "Running Batch 115, Epoch 0, Total Tokens: 237\n",
      "Loss: 1.7660497426986694\n",
      "Running Batch 116, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.8597922325134277\n",
      "Running Batch 117, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7909884452819824\n",
      "Running Batch 118, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.716116189956665\n",
      "Running Batch 119, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7553468942642212\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 119, Loss: 1.7553468942642212\n",
      "Running Batch 120, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.7384880781173706\n",
      "Running Batch 121, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7495958805084229\n",
      "Running Batch 122, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.669059157371521\n",
      "Running Batch 123, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6963074207305908\n",
      "Running Batch 124, Epoch 0, Total Tokens: 178\n",
      "Loss: 1.7199779748916626\n",
      "Running Batch 125, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7176264524459839\n",
      "Running Batch 126, Epoch 0, Total Tokens: 237\n",
      "Loss: 1.731743335723877\n",
      "Running Batch 127, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.8832385540008545\n",
      "Running Batch 128, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.744939923286438\n",
      "Running Batch 129, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.8272137641906738\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 129, Loss: 1.8272137641906738\n",
      "Running Batch 130, Epoch 0, Total Tokens: 192\n",
      "Loss: 1.721692681312561\n",
      "Running Batch 131, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.8013306856155396\n",
      "Running Batch 132, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7532082796096802\n",
      "Running Batch 133, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6978063583374023\n",
      "Running Batch 134, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7701070308685303\n",
      "Running Batch 135, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.789107322692871\n",
      "Running Batch 136, Epoch 0, Total Tokens: 231\n",
      "Loss: 1.7787206172943115\n",
      "Running Batch 137, Epoch 0, Total Tokens: 111\n",
      "Loss: 1.7458988428115845\n",
      "Running Batch 138, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7305314540863037\n",
      "Running Batch 139, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7562474012374878\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 139, Loss: 1.7562474012374878\n",
      "Running Batch 140, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.891866683959961\n",
      "Running Batch 141, Epoch 0, Total Tokens: 231\n",
      "Loss: 1.802452802658081\n",
      "Running Batch 142, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7609180212020874\n",
      "Running Batch 143, Epoch 0, Total Tokens: 178\n",
      "Loss: 1.6916406154632568\n",
      "Running Batch 144, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7762608528137207\n",
      "Running Batch 145, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6798489093780518\n",
      "Running Batch 146, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7003206014633179\n",
      "Running Batch 147, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.8356107473373413\n",
      "Running Batch 148, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.653762698173523\n",
      "Running Batch 149, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.70753812789917\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 149, Loss: 1.70753812789917\n",
      "Running Batch 150, Epoch 0, Total Tokens: 177\n",
      "Loss: 1.641793966293335\n",
      "Running Batch 151, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.645001769065857\n",
      "Running Batch 152, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.7522845268249512\n",
      "Running Batch 153, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7234283685684204\n",
      "Running Batch 154, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7371803522109985\n",
      "Running Batch 155, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7439093589782715\n",
      "Running Batch 156, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6767024993896484\n",
      "Running Batch 157, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.705033540725708\n",
      "Running Batch 158, Epoch 0, Total Tokens: 286\n",
      "Loss: 1.6565043926239014\n",
      "Running Batch 159, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.80282723903656\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 159, Loss: 1.80282723903656\n",
      "Running Batch 160, Epoch 0, Total Tokens: 170\n",
      "Loss: 1.7771296501159668\n",
      "Running Batch 161, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.634275197982788\n",
      "Running Batch 162, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7141737937927246\n",
      "Running Batch 163, Epoch 0, Total Tokens: 106\n",
      "Loss: 1.80112886428833\n",
      "Running Batch 164, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7137259244918823\n",
      "Running Batch 165, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7329955101013184\n",
      "Running Batch 166, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7982503175735474\n",
      "Running Batch 167, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7351641654968262\n",
      "Running Batch 168, Epoch 0, Total Tokens: 236\n",
      "Loss: 1.736216425895691\n",
      "Running Batch 169, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6633652448654175\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 169, Loss: 1.6633652448654175\n",
      "Running Batch 170, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.902471899986267\n",
      "Running Batch 171, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6984518766403198\n",
      "Running Batch 172, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7362332344055176\n",
      "Running Batch 173, Epoch 0, Total Tokens: 193\n",
      "Loss: 1.7144213914871216\n",
      "Running Batch 174, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7532074451446533\n",
      "Running Batch 175, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.778030514717102\n",
      "Running Batch 176, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6988518238067627\n",
      "Running Batch 177, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7564561367034912\n",
      "Running Batch 178, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7367929220199585\n",
      "Running Batch 179, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6602277755737305\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 179, Loss: 1.6602277755737305\n",
      "Running Batch 180, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.760087251663208\n",
      "Running Batch 181, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7497087717056274\n",
      "Running Batch 182, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7101826667785645\n",
      "Running Batch 183, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6956199407577515\n",
      "Running Batch 184, Epoch 0, Total Tokens: 356\n",
      "Loss: 1.722046136856079\n",
      "Running Batch 185, Epoch 0, Total Tokens: 281\n",
      "Loss: 1.7448339462280273\n",
      "Running Batch 186, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.8192884922027588\n",
      "Running Batch 187, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.8146287202835083\n",
      "Running Batch 188, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.7349636554718018\n",
      "Running Batch 189, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7210949659347534\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 189, Loss: 1.7210949659347534\n",
      "Running Batch 190, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7071211338043213\n",
      "Running Batch 191, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6961827278137207\n",
      "Running Batch 192, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6764405965805054\n",
      "Running Batch 193, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.7077670097351074\n",
      "Running Batch 194, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6815448999404907\n",
      "Running Batch 195, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6913020610809326\n",
      "Running Batch 196, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.6390050649642944\n",
      "Running Batch 197, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7448351383209229\n",
      "Running Batch 198, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.726967453956604\n",
      "Running Batch 199, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.7711246013641357\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 199, Loss: 1.7711246013641357\n",
      "Running Batch 200, Epoch 0, Total Tokens: 285\n",
      "Loss: 1.8704222440719604\n",
      "Running Batch 201, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7715933322906494\n",
      "Running Batch 202, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7175651788711548\n",
      "Running Batch 203, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7001712322235107\n",
      "Running Batch 204, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6220287084579468\n",
      "Running Batch 205, Epoch 0, Total Tokens: 428\n",
      "Loss: 1.724518060684204\n",
      "Running Batch 206, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6847866773605347\n",
      "Running Batch 207, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.8053979873657227\n",
      "Running Batch 208, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6777088642120361\n",
      "Running Batch 209, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6951011419296265\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 209, Loss: 1.6951011419296265\n",
      "Running Batch 210, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6930842399597168\n",
      "Running Batch 211, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.7285236120224\n",
      "Running Batch 212, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.7562648057937622\n",
      "Running Batch 213, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7094354629516602\n",
      "Running Batch 214, Epoch 0, Total Tokens: 111\n",
      "Loss: 1.6331064701080322\n",
      "Running Batch 215, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.688132643699646\n",
      "Running Batch 216, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7502416372299194\n",
      "Running Batch 217, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6866650581359863\n",
      "Running Batch 218, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7269413471221924\n",
      "Running Batch 219, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7371796369552612\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 219, Loss: 1.7371796369552612\n",
      "Running Batch 220, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7136857509613037\n",
      "Running Batch 221, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7886615991592407\n",
      "Running Batch 222, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7860060930252075\n",
      "Running Batch 223, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.754467248916626\n",
      "Running Batch 224, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7595757246017456\n",
      "Running Batch 225, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.738764762878418\n",
      "Running Batch 226, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.705432653427124\n",
      "Running Batch 227, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6930121183395386\n",
      "Running Batch 228, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7492973804473877\n",
      "Running Batch 229, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6756905317306519\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 229, Loss: 1.6756905317306519\n",
      "Running Batch 230, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6855157613754272\n",
      "Running Batch 231, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7128825187683105\n",
      "Running Batch 232, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.641782283782959\n",
      "Running Batch 233, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.8264789581298828\n",
      "Running Batch 234, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.5950902700424194\n",
      "Running Batch 235, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.725321888923645\n",
      "Running Batch 236, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.6600648164749146\n",
      "Running Batch 237, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7055373191833496\n",
      "Running Batch 238, Epoch 0, Total Tokens: 94\n",
      "Loss: 1.8092023134231567\n",
      "Running Batch 239, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7017226219177246\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 239, Loss: 1.7017226219177246\n",
      "Running Batch 240, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.673701524734497\n",
      "Running Batch 241, Epoch 0, Total Tokens: 116\n",
      "Loss: 1.6934075355529785\n",
      "Running Batch 242, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.7908542156219482\n",
      "Running Batch 243, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7146081924438477\n",
      "Running Batch 244, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.7940130233764648\n",
      "Running Batch 245, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.6555980443954468\n",
      "Running Batch 246, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7308013439178467\n",
      "Running Batch 247, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6604723930358887\n",
      "Running Batch 248, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7412598133087158\n",
      "Running Batch 249, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.64707350730896\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 249, Loss: 1.64707350730896\n",
      "Running Batch 250, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6799556016921997\n",
      "Running Batch 251, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.7531265020370483\n",
      "Running Batch 252, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.7093995809555054\n",
      "Running Batch 253, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.671406865119934\n",
      "Running Batch 254, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6679115295410156\n",
      "Running Batch 255, Epoch 0, Total Tokens: 174\n",
      "Loss: 1.7694157361984253\n",
      "Running Batch 256, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.786529779434204\n",
      "Running Batch 257, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6680115461349487\n",
      "Running Batch 258, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7399415969848633\n",
      "Running Batch 259, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.6719121932983398\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 259, Loss: 1.6719121932983398\n",
      "Running Batch 260, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6919517517089844\n",
      "Running Batch 261, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6371642351150513\n",
      "Running Batch 262, Epoch 0, Total Tokens: 274\n",
      "Loss: 1.7144124507904053\n",
      "Running Batch 263, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.6470873355865479\n",
      "Running Batch 264, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.796523094177246\n",
      "Running Batch 265, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7443654537200928\n",
      "Running Batch 266, Epoch 0, Total Tokens: 190\n",
      "Loss: 1.7219047546386719\n",
      "Running Batch 267, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7086931467056274\n",
      "Running Batch 268, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6612952947616577\n",
      "Running Batch 269, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.7563501596450806\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 269, Loss: 1.7563501596450806\n",
      "Running Batch 270, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.6001834869384766\n",
      "Running Batch 271, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7817920446395874\n",
      "Running Batch 272, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7053228616714478\n",
      "Running Batch 273, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7339253425598145\n",
      "Running Batch 274, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7431550025939941\n",
      "Running Batch 275, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.732678771018982\n",
      "Running Batch 276, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6388707160949707\n",
      "Running Batch 277, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7644354104995728\n",
      "Running Batch 278, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.7348685264587402\n",
      "Running Batch 279, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7224863767623901\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 279, Loss: 1.7224863767623901\n",
      "Running Batch 280, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6867800951004028\n",
      "Running Batch 281, Epoch 0, Total Tokens: 174\n",
      "Loss: 1.6581535339355469\n",
      "Running Batch 282, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7720998525619507\n",
      "Running Batch 283, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6835625171661377\n",
      "Running Batch 284, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7345452308654785\n",
      "Running Batch 285, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.7975529432296753\n",
      "Running Batch 286, Epoch 0, Total Tokens: 244\n",
      "Loss: 1.6680585145950317\n",
      "Running Batch 287, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.722705364227295\n",
      "Running Batch 288, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6785218715667725\n",
      "Running Batch 289, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.7389689683914185\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 289, Loss: 1.7389689683914185\n",
      "Running Batch 290, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.8100078105926514\n",
      "Running Batch 291, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.707395315170288\n",
      "Running Batch 292, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.741951584815979\n",
      "Running Batch 293, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7152349948883057\n",
      "Running Batch 294, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6750562191009521\n",
      "Running Batch 295, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6819477081298828\n",
      "Running Batch 296, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6655319929122925\n",
      "Running Batch 297, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7541241645812988\n",
      "Running Batch 298, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7200697660446167\n",
      "Running Batch 299, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7341561317443848\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 299, Loss: 1.7341561317443848\n",
      "Running Batch 300, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.7294281721115112\n",
      "Running Batch 301, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6804461479187012\n",
      "Running Batch 302, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7336536645889282\n",
      "Running Batch 303, Epoch 0, Total Tokens: 367\n",
      "Loss: 1.691506266593933\n",
      "Running Batch 304, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7188066244125366\n",
      "Running Batch 305, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.7303638458251953\n",
      "Running Batch 306, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.722022294998169\n",
      "Running Batch 307, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7690315246582031\n",
      "Running Batch 308, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.6155232191085815\n",
      "Running Batch 309, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.7170673608779907\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 309, Loss: 1.7170673608779907\n",
      "Running Batch 310, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6486700773239136\n",
      "Running Batch 311, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.7026475667953491\n",
      "Running Batch 312, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7567697763442993\n",
      "Running Batch 313, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.687622308731079\n",
      "Running Batch 314, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7656241655349731\n",
      "Running Batch 315, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6248506307601929\n",
      "Running Batch 316, Epoch 0, Total Tokens: 104\n",
      "Loss: 1.6307717561721802\n",
      "Running Batch 317, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5911515951156616\n",
      "Running Batch 318, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.629751443862915\n",
      "Running Batch 319, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6851006746292114\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 319, Loss: 1.6851006746292114\n",
      "Running Batch 320, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.8009803295135498\n",
      "Running Batch 321, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.768878698348999\n",
      "Running Batch 322, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.681386113166809\n",
      "Running Batch 323, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.751235008239746\n",
      "Running Batch 324, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.681374192237854\n",
      "Running Batch 325, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7079997062683105\n",
      "Running Batch 326, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7919570207595825\n",
      "Running Batch 327, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.6699256896972656\n",
      "Running Batch 328, Epoch 0, Total Tokens: 624\n",
      "Loss: 1.6561685800552368\n",
      "Running Batch 329, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7377299070358276\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 329, Loss: 1.7377299070358276\n",
      "Running Batch 330, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6667981147766113\n",
      "Running Batch 331, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6861960887908936\n",
      "Running Batch 332, Epoch 0, Total Tokens: 168\n",
      "Loss: 1.6790753602981567\n",
      "Running Batch 333, Epoch 0, Total Tokens: 337\n",
      "Loss: 1.5744959115982056\n",
      "Running Batch 334, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6372404098510742\n",
      "Running Batch 335, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7667737007141113\n",
      "Running Batch 336, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.636346459388733\n",
      "Running Batch 337, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6611565351486206\n",
      "Running Batch 338, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6820451021194458\n",
      "Running Batch 339, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.5839954614639282\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 339, Loss: 1.5839954614639282\n",
      "Running Batch 340, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.666872501373291\n",
      "Running Batch 341, Epoch 0, Total Tokens: 258\n",
      "Loss: 1.604181170463562\n",
      "Running Batch 342, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6764742136001587\n",
      "Running Batch 343, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7988759279251099\n",
      "Running Batch 344, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7229773998260498\n",
      "Running Batch 345, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.670932412147522\n",
      "Running Batch 346, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7091491222381592\n",
      "Running Batch 347, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6493499279022217\n",
      "Running Batch 348, Epoch 0, Total Tokens: 361\n",
      "Loss: 1.6729851961135864\n",
      "Running Batch 349, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.682278037071228\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 349, Loss: 1.682278037071228\n",
      "Running Batch 350, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.727057933807373\n",
      "Running Batch 351, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7242614030838013\n",
      "Running Batch 352, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6630851030349731\n",
      "Running Batch 353, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7227404117584229\n",
      "Running Batch 354, Epoch 0, Total Tokens: 261\n",
      "Loss: 1.7917832136154175\n",
      "Running Batch 355, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6777194738388062\n",
      "Running Batch 356, Epoch 0, Total Tokens: 299\n",
      "Loss: 1.7680268287658691\n",
      "Running Batch 357, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6089491844177246\n",
      "Running Batch 358, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.603641152381897\n",
      "Running Batch 359, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7819050550460815\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 359, Loss: 1.7819050550460815\n",
      "Running Batch 360, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.70093834400177\n",
      "Running Batch 361, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7181758880615234\n",
      "Running Batch 362, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7106181383132935\n",
      "Running Batch 363, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6979262828826904\n",
      "Running Batch 364, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7609349489212036\n",
      "Running Batch 365, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6165339946746826\n",
      "Running Batch 366, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.6658258438110352\n",
      "Running Batch 367, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.645450472831726\n",
      "Running Batch 368, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.6795059442520142\n",
      "Running Batch 369, Epoch 0, Total Tokens: 175\n",
      "Loss: 1.7969757318496704\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 369, Loss: 1.7969757318496704\n",
      "Running Batch 370, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.659693956375122\n",
      "Running Batch 371, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6493695974349976\n",
      "Running Batch 372, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.7434526681900024\n",
      "Running Batch 373, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6656872034072876\n",
      "Running Batch 374, Epoch 0, Total Tokens: 294\n",
      "Loss: 1.737483263015747\n",
      "Running Batch 375, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.6863503456115723\n",
      "Running Batch 376, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.658801555633545\n",
      "Running Batch 377, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6739203929901123\n",
      "Running Batch 378, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6710618734359741\n",
      "Running Batch 379, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7748559713363647\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 379, Loss: 1.7748559713363647\n",
      "Running Batch 380, Epoch 0, Total Tokens: 160\n",
      "Loss: 1.6491526365280151\n",
      "Running Batch 381, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6665600538253784\n",
      "Running Batch 382, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.7402100563049316\n",
      "Running Batch 383, Epoch 0, Total Tokens: 158\n",
      "Loss: 1.6821738481521606\n",
      "Running Batch 384, Epoch 0, Total Tokens: 224\n",
      "Loss: 1.6875836849212646\n",
      "Running Batch 385, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7304078340530396\n",
      "Running Batch 386, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.5897505283355713\n",
      "Running Batch 387, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6713502407073975\n",
      "Running Batch 388, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.669743299484253\n",
      "Running Batch 389, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6539323329925537\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 389, Loss: 1.6539323329925537\n",
      "Running Batch 390, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7463337182998657\n",
      "Running Batch 391, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6453654766082764\n",
      "Running Batch 392, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7808688879013062\n",
      "Running Batch 393, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7575514316558838\n",
      "Running Batch 394, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6634788513183594\n",
      "Running Batch 395, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7714934349060059\n",
      "Running Batch 396, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.710755467414856\n",
      "Running Batch 397, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6030274629592896\n",
      "Running Batch 398, Epoch 0, Total Tokens: 221\n",
      "Loss: 1.7103971242904663\n",
      "Running Batch 399, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6866836547851562\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 399, Loss: 1.6866836547851562\n",
      "Running Batch 400, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7129921913146973\n",
      "Running Batch 401, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.6471129655838013\n",
      "Running Batch 402, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7634892463684082\n",
      "Running Batch 403, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.720345139503479\n",
      "Running Batch 404, Epoch 0, Total Tokens: 228\n",
      "Loss: 1.6461808681488037\n",
      "Running Batch 405, Epoch 0, Total Tokens: 273\n",
      "Loss: 1.7847813367843628\n",
      "Running Batch 406, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.751152515411377\n",
      "Running Batch 407, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6634186506271362\n",
      "Running Batch 408, Epoch 0, Total Tokens: 234\n",
      "Loss: 1.7266838550567627\n",
      "Running Batch 409, Epoch 0, Total Tokens: 334\n",
      "Loss: 1.64871346950531\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 409, Loss: 1.64871346950531\n",
      "Running Batch 410, Epoch 0, Total Tokens: 209\n",
      "Loss: 1.6804146766662598\n",
      "Running Batch 411, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6470848321914673\n",
      "Running Batch 412, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.62050461769104\n",
      "Running Batch 413, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7390069961547852\n",
      "Running Batch 414, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.749239206314087\n",
      "Running Batch 415, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7604399919509888\n",
      "Running Batch 416, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6509968042373657\n",
      "Running Batch 417, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.6835709810256958\n",
      "Running Batch 418, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7095333337783813\n",
      "Running Batch 419, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7073315382003784\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 419, Loss: 1.7073315382003784\n",
      "Running Batch 420, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7211419343948364\n",
      "Running Batch 421, Epoch 0, Total Tokens: 170\n",
      "Loss: 1.6371397972106934\n",
      "Running Batch 422, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6653497219085693\n",
      "Running Batch 423, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.672993779182434\n",
      "Running Batch 424, Epoch 0, Total Tokens: 188\n",
      "Loss: 1.6603569984436035\n",
      "Running Batch 425, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6552746295928955\n",
      "Running Batch 426, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6613250970840454\n",
      "Running Batch 427, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7008416652679443\n",
      "Running Batch 428, Epoch 0, Total Tokens: 114\n",
      "Loss: 1.746381402015686\n",
      "Running Batch 429, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7245392799377441\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 429, Loss: 1.7245392799377441\n",
      "Running Batch 430, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6283622980117798\n",
      "Running Batch 431, Epoch 0, Total Tokens: 220\n",
      "Loss: 1.6817278861999512\n",
      "Running Batch 432, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.769529104232788\n",
      "Running Batch 433, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6651020050048828\n",
      "Running Batch 434, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6107810735702515\n",
      "Running Batch 435, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6631217002868652\n",
      "Running Batch 436, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7998895645141602\n",
      "Running Batch 437, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6206835508346558\n",
      "Running Batch 438, Epoch 0, Total Tokens: 494\n",
      "Loss: 1.520471453666687\n",
      "Running Batch 439, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6531246900558472\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 439, Loss: 1.6531246900558472\n",
      "Running Batch 440, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.653632640838623\n",
      "Running Batch 441, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.813634991645813\n",
      "Running Batch 442, Epoch 0, Total Tokens: 282\n",
      "Loss: 1.7009117603302002\n",
      "Running Batch 443, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7473342418670654\n",
      "Running Batch 444, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.642796516418457\n",
      "Running Batch 445, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6774089336395264\n",
      "Running Batch 446, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6460272073745728\n",
      "Running Batch 447, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7093631029129028\n",
      "Running Batch 448, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.720136046409607\n",
      "Running Batch 449, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7081605195999146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 449, Loss: 1.7081605195999146\n",
      "Running Batch 450, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.5944947004318237\n",
      "Running Batch 451, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6115899085998535\n",
      "Running Batch 452, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.625558614730835\n",
      "Running Batch 453, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7483190298080444\n",
      "Running Batch 454, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.668400764465332\n",
      "Running Batch 455, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6756144762039185\n",
      "Running Batch 456, Epoch 0, Total Tokens: 202\n",
      "Loss: 1.7372479438781738\n",
      "Running Batch 457, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6739214658737183\n",
      "Running Batch 458, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6455426216125488\n",
      "Running Batch 459, Epoch 0, Total Tokens: 184\n",
      "Loss: 1.6492875814437866\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 459, Loss: 1.6492875814437866\n",
      "Running Batch 460, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6597894430160522\n",
      "Running Batch 461, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.701416254043579\n",
      "Running Batch 462, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.577764630317688\n",
      "Running Batch 463, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.7071664333343506\n",
      "Running Batch 464, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7131305932998657\n",
      "Running Batch 465, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6361057758331299\n",
      "Running Batch 466, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6584199666976929\n",
      "Running Batch 467, Epoch 0, Total Tokens: 266\n",
      "Loss: 1.5847305059432983\n",
      "Running Batch 468, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6973605155944824\n",
      "Running Batch 469, Epoch 0, Total Tokens: 288\n",
      "Loss: 1.6117295026779175\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 469, Loss: 1.6117295026779175\n",
      "Running Batch 470, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6701152324676514\n",
      "Running Batch 471, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7297056913375854\n",
      "Running Batch 472, Epoch 0, Total Tokens: 114\n",
      "Loss: 1.7500437498092651\n",
      "Running Batch 473, Epoch 0, Total Tokens: 109\n",
      "Loss: 1.6793906688690186\n",
      "Running Batch 474, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.5399937629699707\n",
      "Running Batch 475, Epoch 0, Total Tokens: 111\n",
      "Loss: 1.744752049446106\n",
      "Running Batch 476, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6400537490844727\n",
      "Running Batch 477, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6382955312728882\n",
      "Running Batch 478, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6715811491012573\n",
      "Running Batch 479, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7150945663452148\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 479, Loss: 1.7150945663452148\n",
      "Running Batch 480, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6564728021621704\n",
      "Running Batch 481, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.5884480476379395\n",
      "Running Batch 482, Epoch 0, Total Tokens: 108\n",
      "Loss: 1.7283469438552856\n",
      "Running Batch 483, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6769154071807861\n",
      "Running Batch 484, Epoch 0, Total Tokens: 183\n",
      "Loss: 1.6051371097564697\n",
      "Running Batch 485, Epoch 0, Total Tokens: 258\n",
      "Loss: 1.6388128995895386\n",
      "Running Batch 486, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.6450215578079224\n",
      "Running Batch 487, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6552919149398804\n",
      "Running Batch 488, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6631925106048584\n",
      "Running Batch 489, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5737292766571045\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 489, Loss: 1.5737292766571045\n",
      "Running Batch 490, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7164766788482666\n",
      "Running Batch 491, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.699625015258789\n",
      "Running Batch 492, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6336358785629272\n",
      "Running Batch 493, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7097078561782837\n",
      "Running Batch 494, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.714734435081482\n",
      "Running Batch 495, Epoch 0, Total Tokens: 164\n",
      "Loss: 1.6679028272628784\n",
      "Running Batch 496, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6144994497299194\n",
      "Running Batch 497, Epoch 0, Total Tokens: 188\n",
      "Loss: 1.6911842823028564\n",
      "Running Batch 498, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.6767325401306152\n",
      "Running Batch 499, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7134716510772705\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 499, Loss: 1.7134716510772705\n",
      "Running Batch 500, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6388627290725708\n",
      "Running Batch 501, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.584118127822876\n",
      "Running Batch 502, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.6296035051345825\n",
      "Running Batch 503, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6397442817687988\n",
      "Running Batch 504, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.653209924697876\n",
      "Running Batch 505, Epoch 0, Total Tokens: 214\n",
      "Loss: 1.6290380954742432\n",
      "Running Batch 506, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.779218077659607\n",
      "Running Batch 507, Epoch 0, Total Tokens: 169\n",
      "Loss: 1.560060977935791\n",
      "Running Batch 508, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.604990005493164\n",
      "Running Batch 509, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.5426369905471802\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 509, Loss: 1.5426369905471802\n",
      "Running Batch 510, Epoch 0, Total Tokens: 527\n",
      "Loss: 1.7075682878494263\n",
      "Running Batch 511, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6787303686141968\n",
      "Running Batch 512, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.698490858078003\n",
      "Running Batch 513, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6301031112670898\n",
      "Running Batch 514, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6163450479507446\n",
      "Running Batch 515, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.571928858757019\n",
      "Running Batch 516, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6987411975860596\n",
      "Running Batch 517, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.587418794631958\n",
      "Running Batch 518, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6192349195480347\n",
      "Running Batch 519, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6906332969665527\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 519, Loss: 1.6906332969665527\n",
      "Running Batch 520, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.647170066833496\n",
      "Running Batch 521, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6081879138946533\n",
      "Running Batch 522, Epoch 0, Total Tokens: 241\n",
      "Loss: 1.654599666595459\n",
      "Running Batch 523, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6529828310012817\n",
      "Running Batch 524, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7037283182144165\n",
      "Running Batch 525, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.632539987564087\n",
      "Running Batch 526, Epoch 0, Total Tokens: 187\n",
      "Loss: 1.7388707399368286\n",
      "Running Batch 527, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6907031536102295\n",
      "Running Batch 528, Epoch 0, Total Tokens: 244\n",
      "Loss: 1.5634084939956665\n",
      "Running Batch 529, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7467619180679321\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 529, Loss: 1.7467619180679321\n",
      "Running Batch 530, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6777174472808838\n",
      "Running Batch 531, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6508044004440308\n",
      "Running Batch 532, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.660327434539795\n",
      "Running Batch 533, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6530444622039795\n",
      "Running Batch 534, Epoch 0, Total Tokens: 254\n",
      "Loss: 1.5336135625839233\n",
      "Running Batch 535, Epoch 0, Total Tokens: 163\n",
      "Loss: 1.7403427362442017\n",
      "Running Batch 536, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7551605701446533\n",
      "Running Batch 537, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6691700220108032\n",
      "Running Batch 538, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7337557077407837\n",
      "Running Batch 539, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6797181367874146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 539, Loss: 1.6797181367874146\n",
      "Running Batch 540, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6317343711853027\n",
      "Running Batch 541, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7523653507232666\n",
      "Running Batch 542, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6741851568222046\n",
      "Running Batch 543, Epoch 0, Total Tokens: 418\n",
      "Loss: 1.6698887348175049\n",
      "Running Batch 544, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.614079236984253\n",
      "Running Batch 545, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6386688947677612\n",
      "Running Batch 546, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6360682249069214\n",
      "Running Batch 547, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6119214296340942\n",
      "Running Batch 548, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.605331301689148\n",
      "Running Batch 549, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7316527366638184\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 549, Loss: 1.7316527366638184\n",
      "Running Batch 550, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6988065242767334\n",
      "Running Batch 551, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.659579873085022\n",
      "Running Batch 552, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.679840326309204\n",
      "Running Batch 553, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7456488609313965\n",
      "Running Batch 554, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.584535002708435\n",
      "Running Batch 555, Epoch 0, Total Tokens: 170\n",
      "Loss: 1.5789830684661865\n",
      "Running Batch 556, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6094748973846436\n",
      "Running Batch 557, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6901530027389526\n",
      "Running Batch 558, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6843856573104858\n",
      "Running Batch 559, Epoch 0, Total Tokens: 160\n",
      "Loss: 1.6310632228851318\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 559, Loss: 1.6310632228851318\n",
      "Running Batch 560, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6716364622116089\n",
      "Running Batch 561, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.7312750816345215\n",
      "Running Batch 562, Epoch 0, Total Tokens: 170\n",
      "Loss: 1.5528780221939087\n",
      "Running Batch 563, Epoch 0, Total Tokens: 211\n",
      "Loss: 1.6489341259002686\n",
      "Running Batch 564, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6114596128463745\n",
      "Running Batch 565, Epoch 0, Total Tokens: 116\n",
      "Loss: 1.643974781036377\n",
      "Running Batch 566, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.739363193511963\n",
      "Running Batch 567, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6262930631637573\n",
      "Running Batch 568, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.7251551151275635\n",
      "Running Batch 569, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.8154250383377075\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 569, Loss: 1.8154250383377075\n",
      "Running Batch 570, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.62369966506958\n",
      "Running Batch 571, Epoch 0, Total Tokens: 118\n",
      "Loss: 1.6428725719451904\n",
      "Running Batch 572, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5767334699630737\n",
      "Running Batch 573, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6485881805419922\n",
      "Running Batch 574, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6640241146087646\n",
      "Running Batch 575, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7012661695480347\n",
      "Running Batch 576, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.639365315437317\n",
      "Running Batch 577, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6421092748641968\n",
      "Running Batch 578, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.668755054473877\n",
      "Running Batch 579, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.482450246810913\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 579, Loss: 1.482450246810913\n",
      "Running Batch 580, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6798778772354126\n",
      "Running Batch 581, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6003633737564087\n",
      "Running Batch 582, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.569425106048584\n",
      "Running Batch 583, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6655243635177612\n",
      "Running Batch 584, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.745821237564087\n",
      "Running Batch 585, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6863391399383545\n",
      "Running Batch 586, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.7493878602981567\n",
      "Running Batch 587, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.5866544246673584\n",
      "Running Batch 588, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6792807579040527\n",
      "Running Batch 589, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.667655348777771\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 589, Loss: 1.667655348777771\n",
      "Running Batch 590, Epoch 0, Total Tokens: 196\n",
      "Loss: 1.7891528606414795\n",
      "Running Batch 591, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6083863973617554\n",
      "Running Batch 592, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7416443824768066\n",
      "Running Batch 593, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.654890775680542\n",
      "Running Batch 594, Epoch 0, Total Tokens: 568\n",
      "Loss: 1.5602047443389893\n",
      "Running Batch 595, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6773273944854736\n",
      "Running Batch 596, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5748661756515503\n",
      "Running Batch 597, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.5493847131729126\n",
      "Running Batch 598, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6018738746643066\n",
      "Running Batch 599, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7020273208618164\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 599, Loss: 1.7020273208618164\n",
      "Running Batch 600, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6140754222869873\n",
      "Running Batch 601, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6203805208206177\n",
      "Running Batch 602, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6145750284194946\n",
      "Running Batch 603, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7425624132156372\n",
      "Running Batch 604, Epoch 0, Total Tokens: 188\n",
      "Loss: 1.5737322568893433\n",
      "Running Batch 605, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.7139830589294434\n",
      "Running Batch 606, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.736910104751587\n",
      "Running Batch 607, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.5368798971176147\n",
      "Running Batch 608, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.631106972694397\n",
      "Running Batch 609, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6141488552093506\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 609, Loss: 1.6141488552093506\n",
      "Running Batch 610, Epoch 0, Total Tokens: 224\n",
      "Loss: 1.7518075704574585\n",
      "Running Batch 611, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.630896806716919\n",
      "Running Batch 612, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6806294918060303\n",
      "Running Batch 613, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7453547716140747\n",
      "Running Batch 614, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6511304378509521\n",
      "Running Batch 615, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6780619621276855\n",
      "Running Batch 616, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6855822801589966\n",
      "Running Batch 617, Epoch 0, Total Tokens: 242\n",
      "Loss: 1.639013409614563\n",
      "Running Batch 618, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7242363691329956\n",
      "Running Batch 619, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.519519567489624\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 619, Loss: 1.519519567489624\n",
      "Running Batch 620, Epoch 0, Total Tokens: 106\n",
      "Loss: 1.7338773012161255\n",
      "Running Batch 621, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6429619789123535\n",
      "Running Batch 622, Epoch 0, Total Tokens: 115\n",
      "Loss: 1.6488115787506104\n",
      "Running Batch 623, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.6175284385681152\n",
      "Running Batch 624, Epoch 0, Total Tokens: 228\n",
      "Loss: 1.695741891860962\n",
      "Running Batch 625, Epoch 0, Total Tokens: 191\n",
      "Loss: 1.6447229385375977\n",
      "Running Batch 626, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.5481969118118286\n",
      "Running Batch 627, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6643669605255127\n",
      "Running Batch 628, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.664353847503662\n",
      "Running Batch 629, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.5858654975891113\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 629, Loss: 1.5858654975891113\n",
      "Running Batch 630, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6592530012130737\n",
      "Running Batch 631, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6571428775787354\n",
      "Running Batch 632, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6626203060150146\n",
      "Running Batch 633, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.699571967124939\n",
      "Running Batch 634, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6630077362060547\n",
      "Running Batch 635, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.6161950826644897\n",
      "Running Batch 636, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7443510293960571\n",
      "Running Batch 637, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6291170120239258\n",
      "Running Batch 638, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.5204256772994995\n",
      "Running Batch 639, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.7004715204238892\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 639, Loss: 1.7004715204238892\n",
      "Running Batch 640, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6167863607406616\n",
      "Running Batch 641, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.666048288345337\n",
      "Running Batch 642, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6492456197738647\n",
      "Running Batch 643, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.6906174421310425\n",
      "Running Batch 644, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6180720329284668\n",
      "Running Batch 645, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6714341640472412\n",
      "Running Batch 646, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.5726935863494873\n",
      "Running Batch 647, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6643606424331665\n",
      "Running Batch 648, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6692620515823364\n",
      "Running Batch 649, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6272996664047241\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 649, Loss: 1.6272996664047241\n",
      "Running Batch 650, Epoch 0, Total Tokens: 114\n",
      "Loss: 1.6628401279449463\n",
      "Running Batch 651, Epoch 0, Total Tokens: 108\n",
      "Loss: 1.5740221738815308\n",
      "Running Batch 652, Epoch 0, Total Tokens: 180\n",
      "Loss: 1.7070754766464233\n",
      "Running Batch 653, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6818376779556274\n",
      "Running Batch 654, Epoch 0, Total Tokens: 179\n",
      "Loss: 1.6416001319885254\n",
      "Running Batch 655, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.635854721069336\n",
      "Running Batch 656, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6132291555404663\n",
      "Running Batch 657, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6284493207931519\n",
      "Running Batch 658, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.5639798641204834\n",
      "Running Batch 659, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6831315755844116\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 659, Loss: 1.6831315755844116\n",
      "Running Batch 660, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7071398496627808\n",
      "Running Batch 661, Epoch 0, Total Tokens: 205\n",
      "Loss: 1.620781660079956\n",
      "Running Batch 662, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6601455211639404\n",
      "Running Batch 663, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.634246587753296\n",
      "Running Batch 664, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.621435284614563\n",
      "Running Batch 665, Epoch 0, Total Tokens: 262\n",
      "Loss: 1.5661487579345703\n",
      "Running Batch 666, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6491433382034302\n",
      "Running Batch 667, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6684199571609497\n",
      "Running Batch 668, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6464442014694214\n",
      "Running Batch 669, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.5736006498336792\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 669, Loss: 1.5736006498336792\n",
      "Running Batch 670, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6186530590057373\n",
      "Running Batch 671, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6490291357040405\n",
      "Running Batch 672, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7018380165100098\n",
      "Running Batch 673, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.657623529434204\n",
      "Running Batch 674, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6488224267959595\n",
      "Running Batch 675, Epoch 0, Total Tokens: 257\n",
      "Loss: 1.6383792161941528\n",
      "Running Batch 676, Epoch 0, Total Tokens: 114\n",
      "Loss: 1.639567255973816\n",
      "Running Batch 677, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.5787996053695679\n",
      "Running Batch 678, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6006298065185547\n",
      "Running Batch 679, Epoch 0, Total Tokens: 214\n",
      "Loss: 1.61586332321167\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 679, Loss: 1.61586332321167\n",
      "Running Batch 680, Epoch 0, Total Tokens: 202\n",
      "Loss: 1.6118083000183105\n",
      "Running Batch 681, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6259747743606567\n",
      "Running Batch 682, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6167916059494019\n",
      "Running Batch 683, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6929961442947388\n",
      "Running Batch 684, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6574145555496216\n",
      "Running Batch 685, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6069519519805908\n",
      "Running Batch 686, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.622829794883728\n",
      "Running Batch 687, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.5861197710037231\n",
      "Running Batch 688, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.568772554397583\n",
      "Running Batch 689, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6385319232940674\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 689, Loss: 1.6385319232940674\n",
      "Running Batch 690, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6283460855484009\n",
      "Running Batch 691, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6528620719909668\n",
      "Running Batch 692, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.73650324344635\n",
      "Running Batch 693, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6414748430252075\n",
      "Running Batch 694, Epoch 0, Total Tokens: 225\n",
      "Loss: 1.7031086683273315\n",
      "Running Batch 695, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.6817432641983032\n",
      "Running Batch 696, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6433662176132202\n",
      "Running Batch 697, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6962785720825195\n",
      "Running Batch 698, Epoch 0, Total Tokens: 267\n",
      "Loss: 1.6781789064407349\n",
      "Running Batch 699, Epoch 0, Total Tokens: 174\n",
      "Loss: 1.642443060874939\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 699, Loss: 1.642443060874939\n",
      "Running Batch 700, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7016382217407227\n",
      "Running Batch 701, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.6357393264770508\n",
      "Running Batch 702, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.5905969142913818\n",
      "Running Batch 703, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.623351812362671\n",
      "Running Batch 704, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5924209356307983\n",
      "Running Batch 705, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6092140674591064\n",
      "Running Batch 706, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6458851099014282\n",
      "Running Batch 707, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.5886282920837402\n",
      "Running Batch 708, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.594373345375061\n",
      "Running Batch 709, Epoch 0, Total Tokens: 168\n",
      "Loss: 1.6906408071517944\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 709, Loss: 1.6906408071517944\n",
      "Running Batch 710, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.6666834354400635\n",
      "Running Batch 711, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.7439546585083008\n",
      "Running Batch 712, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6385879516601562\n",
      "Running Batch 713, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5952485799789429\n",
      "Running Batch 714, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.6568540334701538\n",
      "Running Batch 715, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7074335813522339\n",
      "Running Batch 716, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.589367389678955\n",
      "Running Batch 717, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6741214990615845\n",
      "Running Batch 718, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6147083044052124\n",
      "Running Batch 719, Epoch 0, Total Tokens: 185\n",
      "Loss: 1.6622447967529297\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 719, Loss: 1.6622447967529297\n",
      "Running Batch 720, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.5530091524124146\n",
      "Running Batch 721, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.6714457273483276\n",
      "Running Batch 722, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.6016428470611572\n",
      "Running Batch 723, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6844878196716309\n",
      "Running Batch 724, Epoch 0, Total Tokens: 266\n",
      "Loss: 1.5211529731750488\n",
      "Running Batch 725, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.705405354499817\n",
      "Running Batch 726, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7000240087509155\n",
      "Running Batch 727, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6856602430343628\n",
      "Running Batch 728, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.656631588935852\n",
      "Running Batch 729, Epoch 0, Total Tokens: 163\n",
      "Loss: 1.6884106397628784\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 729, Loss: 1.6884106397628784\n",
      "Running Batch 730, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.4939284324645996\n",
      "Running Batch 731, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.6260600090026855\n",
      "Running Batch 732, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6699800491333008\n",
      "Running Batch 733, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.5659369230270386\n",
      "Running Batch 734, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6457618474960327\n",
      "Running Batch 735, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6362138986587524\n",
      "Running Batch 736, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.6310746669769287\n",
      "Running Batch 737, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6148077249526978\n",
      "Running Batch 738, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.579638123512268\n",
      "Running Batch 739, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6494834423065186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 739, Loss: 1.6494834423065186\n",
      "Running Batch 740, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.5766335725784302\n",
      "Running Batch 741, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6541301012039185\n",
      "Running Batch 742, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6306064128875732\n",
      "Running Batch 743, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6121470928192139\n",
      "Running Batch 744, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6373465061187744\n",
      "Running Batch 745, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6285098791122437\n",
      "Running Batch 746, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.543514370918274\n",
      "Running Batch 747, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6304951906204224\n",
      "Running Batch 748, Epoch 0, Total Tokens: 452\n",
      "Loss: 1.688150405883789\n",
      "Running Batch 749, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5879520177841187\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 749, Loss: 1.5879520177841187\n",
      "Running Batch 750, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6188433170318604\n",
      "Running Batch 751, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.621573567390442\n",
      "Running Batch 752, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.5727410316467285\n",
      "Running Batch 753, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6103830337524414\n",
      "Running Batch 754, Epoch 0, Total Tokens: 171\n",
      "Loss: 1.5328868627548218\n",
      "Running Batch 755, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.559252381324768\n",
      "Running Batch 756, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6901220083236694\n",
      "Running Batch 757, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6102359294891357\n",
      "Running Batch 758, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6241635084152222\n",
      "Running Batch 759, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7207880020141602\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 759, Loss: 1.7207880020141602\n",
      "Running Batch 760, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.5568526983261108\n",
      "Running Batch 761, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6183053255081177\n",
      "Running Batch 762, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.621867299079895\n",
      "Running Batch 763, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.6622955799102783\n",
      "Running Batch 764, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6294853687286377\n",
      "Running Batch 765, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7046403884887695\n",
      "Running Batch 766, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6168711185455322\n",
      "Running Batch 767, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.6794557571411133\n",
      "Running Batch 768, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6573973894119263\n",
      "Running Batch 769, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.580085039138794\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 769, Loss: 1.580085039138794\n",
      "Running Batch 770, Epoch 0, Total Tokens: 171\n",
      "Loss: 1.663075566291809\n",
      "Running Batch 771, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.6920244693756104\n",
      "Running Batch 772, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6762727499008179\n",
      "Running Batch 773, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6435654163360596\n",
      "Running Batch 774, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6111515760421753\n",
      "Running Batch 775, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6166681051254272\n",
      "Running Batch 776, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.636906623840332\n",
      "Running Batch 777, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6341804265975952\n",
      "Running Batch 778, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.581414818763733\n",
      "Running Batch 779, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.680321216583252\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 779, Loss: 1.680321216583252\n",
      "Running Batch 780, Epoch 0, Total Tokens: 229\n",
      "Loss: 1.5457884073257446\n",
      "Running Batch 781, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.6242034435272217\n",
      "Running Batch 782, Epoch 0, Total Tokens: 186\n",
      "Loss: 1.5404661893844604\n",
      "Running Batch 783, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.5420180559158325\n",
      "Running Batch 784, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6114836931228638\n",
      "Running Batch 785, Epoch 0, Total Tokens: 110\n",
      "Loss: 1.5480194091796875\n",
      "Running Batch 786, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6150436401367188\n",
      "Running Batch 787, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.5428097248077393\n",
      "Running Batch 788, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6476645469665527\n",
      "Running Batch 789, Epoch 0, Total Tokens: 169\n",
      "Loss: 1.6088142395019531\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 789, Loss: 1.6088142395019531\n",
      "Running Batch 790, Epoch 0, Total Tokens: 169\n",
      "Loss: 1.6347659826278687\n",
      "Running Batch 791, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7587854862213135\n",
      "Running Batch 792, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.5833914279937744\n",
      "Running Batch 793, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5908101797103882\n",
      "Running Batch 794, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5860782861709595\n",
      "Running Batch 795, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.682131290435791\n",
      "Running Batch 796, Epoch 0, Total Tokens: 201\n",
      "Loss: 1.6763114929199219\n",
      "Running Batch 797, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6072196960449219\n",
      "Running Batch 798, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.5643727779388428\n",
      "Running Batch 799, Epoch 0, Total Tokens: 179\n",
      "Loss: 1.6366066932678223\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 799, Loss: 1.6366066932678223\n",
      "Running Batch 800, Epoch 0, Total Tokens: 182\n",
      "Loss: 1.575439691543579\n",
      "Running Batch 801, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5473966598510742\n",
      "Running Batch 802, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.6092437505722046\n",
      "Running Batch 803, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.5552027225494385\n",
      "Running Batch 804, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6164987087249756\n",
      "Running Batch 805, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.656732439994812\n",
      "Running Batch 806, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.718620777130127\n",
      "Running Batch 807, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6441426277160645\n",
      "Running Batch 808, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6881297826766968\n",
      "Running Batch 809, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7208729982376099\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 809, Loss: 1.7208729982376099\n",
      "Running Batch 810, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.6150190830230713\n",
      "Running Batch 811, Epoch 0, Total Tokens: 322\n",
      "Loss: 1.6492269039154053\n",
      "Running Batch 812, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.57370924949646\n",
      "Running Batch 813, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6024253368377686\n",
      "Running Batch 814, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6740039587020874\n",
      "Running Batch 815, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.6434133052825928\n",
      "Running Batch 816, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.5840140581130981\n",
      "Running Batch 817, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.6801789999008179\n",
      "Running Batch 818, Epoch 0, Total Tokens: 380\n",
      "Loss: 1.6352512836456299\n",
      "Running Batch 819, Epoch 0, Total Tokens: 205\n",
      "Loss: 1.630562663078308\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 819, Loss: 1.630562663078308\n",
      "Running Batch 820, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5650055408477783\n",
      "Running Batch 821, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.6168859004974365\n",
      "Running Batch 822, Epoch 0, Total Tokens: 217\n",
      "Loss: 1.645414113998413\n",
      "Running Batch 823, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.6433706283569336\n",
      "Running Batch 824, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6791672706604004\n",
      "Running Batch 825, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.7065258026123047\n",
      "Running Batch 826, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6388920545578003\n",
      "Running Batch 827, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.5984067916870117\n",
      "Running Batch 828, Epoch 0, Total Tokens: 190\n",
      "Loss: 1.638961911201477\n",
      "Running Batch 829, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6553821563720703\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 829, Loss: 1.6553821563720703\n",
      "Running Batch 830, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6126315593719482\n",
      "Running Batch 831, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6776683330535889\n",
      "Running Batch 832, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.5305677652359009\n",
      "Running Batch 833, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.5988012552261353\n",
      "Running Batch 834, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6080007553100586\n",
      "Running Batch 835, Epoch 0, Total Tokens: 158\n",
      "Loss: 1.6361548900604248\n",
      "Running Batch 836, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6452635526657104\n",
      "Running Batch 837, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.5597748756408691\n",
      "Running Batch 838, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.600267767906189\n",
      "Running Batch 839, Epoch 0, Total Tokens: 107\n",
      "Loss: 1.4980231523513794\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 839, Loss: 1.4980231523513794\n",
      "Running Batch 840, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6518096923828125\n",
      "Running Batch 841, Epoch 0, Total Tokens: 351\n",
      "Loss: 1.6250190734863281\n",
      "Running Batch 842, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6052393913269043\n",
      "Running Batch 843, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.7311815023422241\n",
      "Running Batch 844, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6521031856536865\n",
      "Running Batch 845, Epoch 0, Total Tokens: 163\n",
      "Loss: 1.6133418083190918\n",
      "Running Batch 846, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.615673542022705\n",
      "Running Batch 847, Epoch 0, Total Tokens: 267\n",
      "Loss: 1.6740436553955078\n",
      "Running Batch 848, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.678553819656372\n",
      "Running Batch 849, Epoch 0, Total Tokens: 103\n",
      "Loss: 1.6562650203704834\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 849, Loss: 1.6562650203704834\n",
      "Running Batch 850, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.5906699895858765\n",
      "Running Batch 851, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6640268564224243\n",
      "Running Batch 852, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.532753348350525\n",
      "Running Batch 853, Epoch 0, Total Tokens: 110\n",
      "Loss: 1.6498019695281982\n",
      "Running Batch 854, Epoch 0, Total Tokens: 219\n",
      "Loss: 1.614216685295105\n",
      "Running Batch 855, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6635918617248535\n",
      "Running Batch 856, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.687125325202942\n",
      "Running Batch 857, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6647119522094727\n",
      "Running Batch 858, Epoch 0, Total Tokens: 285\n",
      "Loss: 1.5909970998764038\n",
      "Running Batch 859, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.552983045578003\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 859, Loss: 1.552983045578003\n",
      "Running Batch 860, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6373586654663086\n",
      "Running Batch 861, Epoch 0, Total Tokens: 178\n",
      "Loss: 1.6553219556808472\n",
      "Running Batch 862, Epoch 0, Total Tokens: 203\n",
      "Loss: 1.578914761543274\n",
      "Running Batch 863, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7134220600128174\n",
      "Running Batch 864, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.6375017166137695\n",
      "Running Batch 865, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6189404726028442\n",
      "Running Batch 866, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.668640375137329\n",
      "Running Batch 867, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6082948446273804\n",
      "Running Batch 868, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7186484336853027\n",
      "Running Batch 869, Epoch 0, Total Tokens: 326\n",
      "Loss: 1.610613226890564\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 869, Loss: 1.610613226890564\n",
      "Running Batch 870, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.5931473970413208\n",
      "Running Batch 871, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.547163724899292\n",
      "Running Batch 872, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6593819856643677\n",
      "Running Batch 873, Epoch 0, Total Tokens: 185\n",
      "Loss: 1.5854215621948242\n",
      "Running Batch 874, Epoch 0, Total Tokens: 116\n",
      "Loss: 1.676236629486084\n",
      "Running Batch 875, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6125879287719727\n",
      "Running Batch 876, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.7152073383331299\n",
      "Running Batch 877, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6385151147842407\n",
      "Running Batch 878, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.639950156211853\n",
      "Running Batch 879, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.5470062494277954\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 879, Loss: 1.5470062494277954\n",
      "Running Batch 880, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.575722575187683\n",
      "Running Batch 881, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.5678129196166992\n",
      "Running Batch 882, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5527503490447998\n",
      "Running Batch 883, Epoch 0, Total Tokens: 196\n",
      "Loss: 1.5775885581970215\n",
      "Running Batch 884, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6171033382415771\n",
      "Running Batch 885, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.536690592765808\n",
      "Running Batch 886, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.6247193813323975\n",
      "Running Batch 887, Epoch 0, Total Tokens: 179\n",
      "Loss: 1.6672414541244507\n",
      "Running Batch 888, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6836587190628052\n",
      "Running Batch 889, Epoch 0, Total Tokens: 204\n",
      "Loss: 1.5805928707122803\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 889, Loss: 1.5805928707122803\n",
      "Running Batch 890, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.5916774272918701\n",
      "Running Batch 891, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.603657841682434\n",
      "Running Batch 892, Epoch 0, Total Tokens: 185\n",
      "Loss: 1.6417661905288696\n",
      "Running Batch 893, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6091415882110596\n",
      "Running Batch 894, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.5597138404846191\n",
      "Running Batch 895, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6846978664398193\n",
      "Running Batch 896, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6264597177505493\n",
      "Running Batch 897, Epoch 0, Total Tokens: 192\n",
      "Loss: 1.584118127822876\n",
      "Running Batch 898, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6688894033432007\n",
      "Running Batch 899, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.5830812454223633\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 899, Loss: 1.5830812454223633\n",
      "Running Batch 900, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5893361568450928\n",
      "Running Batch 901, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6781282424926758\n",
      "Running Batch 902, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6608092784881592\n",
      "Running Batch 903, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6021978855133057\n",
      "Running Batch 904, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5317238569259644\n",
      "Running Batch 905, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6735366582870483\n",
      "Running Batch 906, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.4966267347335815\n",
      "Running Batch 907, Epoch 0, Total Tokens: 360\n",
      "Loss: 1.7106292247772217\n",
      "Running Batch 908, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.61923086643219\n",
      "Running Batch 909, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6196680068969727\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 909, Loss: 1.6196680068969727\n",
      "Running Batch 910, Epoch 0, Total Tokens: 114\n",
      "Loss: 1.6134170293807983\n",
      "Running Batch 911, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6380910873413086\n",
      "Running Batch 912, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.747757077217102\n",
      "Running Batch 913, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6095032691955566\n",
      "Running Batch 914, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6747967004776\n",
      "Running Batch 915, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.5718876123428345\n",
      "Running Batch 916, Epoch 0, Total Tokens: 158\n",
      "Loss: 1.5756797790527344\n",
      "Running Batch 917, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.5849272012710571\n",
      "Running Batch 918, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6165213584899902\n",
      "Running Batch 919, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.5835251808166504\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 919, Loss: 1.5835251808166504\n",
      "Running Batch 920, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6254031658172607\n",
      "Running Batch 921, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.5375111103057861\n",
      "Running Batch 922, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.664461374282837\n",
      "Running Batch 923, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.559975028038025\n",
      "Running Batch 924, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6157673597335815\n",
      "Running Batch 925, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.651158094406128\n",
      "Running Batch 926, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6144487857818604\n",
      "Running Batch 927, Epoch 0, Total Tokens: 210\n",
      "Loss: 1.6762160062789917\n",
      "Running Batch 928, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.5961694717407227\n",
      "Running Batch 929, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.5593695640563965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 929, Loss: 1.5593695640563965\n",
      "Running Batch 930, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6757577657699585\n",
      "Running Batch 931, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.578018307685852\n",
      "Running Batch 932, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6250278949737549\n",
      "Running Batch 933, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.51873779296875\n",
      "Running Batch 934, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6205482482910156\n",
      "Running Batch 935, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6181365251541138\n",
      "Running Batch 936, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6315113306045532\n",
      "Running Batch 937, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.5876232385635376\n",
      "Running Batch 938, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6393988132476807\n",
      "Running Batch 939, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.6753864288330078\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 939, Loss: 1.6753864288330078\n",
      "Running Batch 940, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.6282575130462646\n",
      "Running Batch 941, Epoch 0, Total Tokens: 203\n",
      "Loss: 1.5768417119979858\n",
      "Running Batch 942, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.6057227849960327\n",
      "Running Batch 943, Epoch 0, Total Tokens: 99\n",
      "Loss: 1.6988489627838135\n",
      "Running Batch 944, Epoch 0, Total Tokens: 219\n",
      "Loss: 1.6017183065414429\n",
      "Running Batch 945, Epoch 0, Total Tokens: 107\n",
      "Loss: 1.58072829246521\n",
      "Running Batch 946, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.5413038730621338\n",
      "Running Batch 947, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.5531948804855347\n",
      "Running Batch 948, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.4963124990463257\n",
      "Running Batch 949, Epoch 0, Total Tokens: 254\n",
      "Loss: 1.6333895921707153\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 949, Loss: 1.6333895921707153\n",
      "Running Batch 950, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.524160385131836\n",
      "Running Batch 951, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.5887335538864136\n",
      "Running Batch 952, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.5854359865188599\n",
      "Running Batch 953, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6291476488113403\n",
      "Running Batch 954, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6499395370483398\n",
      "Running Batch 955, Epoch 0, Total Tokens: 224\n",
      "Loss: 1.53780996799469\n",
      "Running Batch 956, Epoch 0, Total Tokens: 572\n",
      "Loss: 1.6574136018753052\n",
      "Running Batch 957, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6345576047897339\n",
      "Running Batch 958, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6145954132080078\n",
      "Running Batch 959, Epoch 0, Total Tokens: 174\n",
      "Loss: 1.6040923595428467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 959, Loss: 1.6040923595428467\n",
      "Running Batch 960, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.583372950553894\n",
      "Running Batch 961, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.5900567770004272\n",
      "Running Batch 962, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.5779414176940918\n",
      "Running Batch 963, Epoch 0, Total Tokens: 105\n",
      "Loss: 1.6059483289718628\n",
      "Running Batch 964, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6021173000335693\n",
      "Running Batch 965, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.5433907508850098\n",
      "Running Batch 966, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.5008958578109741\n",
      "Running Batch 967, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.61317777633667\n",
      "Running Batch 968, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6390140056610107\n",
      "Running Batch 969, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.587407112121582\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 969, Loss: 1.587407112121582\n",
      "Running Batch 970, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.592396855354309\n",
      "Running Batch 971, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6525864601135254\n",
      "Running Batch 972, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.5798017978668213\n",
      "Running Batch 973, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.5796852111816406\n",
      "Running Batch 974, Epoch 0, Total Tokens: 202\n",
      "Loss: 1.5194929838180542\n",
      "Running Batch 975, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.6302261352539062\n",
      "Running Batch 976, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6169991493225098\n",
      "Running Batch 977, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6335948705673218\n",
      "Running Batch 978, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.573166847229004\n",
      "Running Batch 979, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6160552501678467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 979, Loss: 1.6160552501678467\n",
      "Running Batch 980, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.5268151760101318\n",
      "Running Batch 981, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.5626219511032104\n",
      "Running Batch 982, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.509060263633728\n",
      "Running Batch 983, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.6387975215911865\n",
      "Running Batch 984, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6011394262313843\n",
      "Running Batch 985, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.5646319389343262\n",
      "Running Batch 986, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.575817584991455\n",
      "Running Batch 987, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.5725828409194946\n",
      "Running Batch 988, Epoch 0, Total Tokens: 230\n",
      "Loss: 1.6727644205093384\n",
      "Running Batch 989, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.5363984107971191\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 989, Loss: 1.5363984107971191\n",
      "Running Batch 990, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6312105655670166\n",
      "Running Batch 991, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.6024035215377808\n",
      "Running Batch 992, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6149312257766724\n",
      "Running Batch 993, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.6987812519073486\n",
      "Running Batch 994, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.5959070920944214\n",
      "Running Batch 995, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.5821385383605957\n",
      "Running Batch 996, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6115422248840332\n",
      "Running Batch 997, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.5774781703948975\n",
      "Running Batch 998, Epoch 0, Total Tokens: 109\n",
      "Loss: 1.5128909349441528\n",
      "Running Batch 999, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.5726885795593262\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 999, Loss: 1.5726885795593262\n",
      "Running Batch 1000, Epoch 0, Total Tokens: 190\n",
      "Loss: 1.649478554725647\n",
      "Running Batch 1001, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6559522151947021\n",
      "Running Batch 1002, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.6401342153549194\n",
      "Running Batch 1003, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5810850858688354\n",
      "Running Batch 1004, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.599294900894165\n",
      "Running Batch 1005, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5217887163162231\n",
      "Running Batch 1006, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.683875560760498\n",
      "Running Batch 1007, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.5825755596160889\n",
      "Running Batch 1008, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.608854055404663\n",
      "Running Batch 1009, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.5898040533065796\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1009, Loss: 1.5898040533065796\n",
      "Running Batch 1010, Epoch 0, Total Tokens: 108\n",
      "Loss: 1.532275915145874\n",
      "Running Batch 1011, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.4981005191802979\n",
      "Running Batch 1012, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.685086965560913\n",
      "Running Batch 1013, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.5909111499786377\n",
      "Running Batch 1014, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.5617352724075317\n",
      "Running Batch 1015, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.63805091381073\n",
      "Running Batch 1016, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.5713071823120117\n",
      "Running Batch 1017, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7055363655090332\n",
      "Running Batch 1018, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5853266716003418\n",
      "Running Batch 1019, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.5471490621566772\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1019, Loss: 1.5471490621566772\n",
      "Running Batch 1020, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.5470918416976929\n",
      "Running Batch 1021, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6096879243850708\n",
      "Running Batch 1022, Epoch 0, Total Tokens: 186\n",
      "Loss: 1.5886019468307495\n",
      "Running Batch 1023, Epoch 0, Total Tokens: 281\n",
      "Loss: 1.552961826324463\n",
      "Running Batch 1024, Epoch 0, Total Tokens: 171\n",
      "Loss: 1.5883831977844238\n",
      "Running Batch 1025, Epoch 0, Total Tokens: 324\n",
      "Loss: 1.6357754468917847\n",
      "Running Batch 1026, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6439611911773682\n",
      "Running Batch 1027, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6055737733840942\n",
      "Running Batch 1028, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.5776499509811401\n",
      "Running Batch 1029, Epoch 0, Total Tokens: 187\n",
      "Loss: 1.5284847021102905\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1029, Loss: 1.5284847021102905\n",
      "Running Batch 1030, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6094087362289429\n",
      "Running Batch 1031, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6990094184875488\n",
      "Running Batch 1032, Epoch 0, Total Tokens: 251\n",
      "Loss: 1.560595989227295\n",
      "Running Batch 1033, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5515624284744263\n",
      "Running Batch 1034, Epoch 0, Total Tokens: 160\n",
      "Loss: 1.5445960760116577\n",
      "Running Batch 1035, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.573021650314331\n",
      "Running Batch 1036, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.638418436050415\n",
      "Running Batch 1037, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.5662739276885986\n",
      "Running Batch 1038, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.5940812826156616\n",
      "Running Batch 1039, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.6460587978363037\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1039, Loss: 1.6460587978363037\n",
      "Running Batch 1040, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.5378036499023438\n",
      "Running Batch 1041, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6902706623077393\n",
      "Running Batch 1042, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.5808205604553223\n",
      "Running Batch 1043, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.524235725402832\n",
      "Running Batch 1044, Epoch 0, Total Tokens: 182\n",
      "Loss: 1.7035537958145142\n",
      "Running Batch 1045, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6393284797668457\n",
      "Running Batch 1046, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6516247987747192\n",
      "Running Batch 1047, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.613843321800232\n",
      "Running Batch 1048, Epoch 0, Total Tokens: 357\n",
      "Loss: 1.7064476013183594\n",
      "Running Batch 1049, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.5703277587890625\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1049, Loss: 1.5703277587890625\n",
      "Running Batch 1050, Epoch 0, Total Tokens: 211\n",
      "Loss: 1.6411734819412231\n",
      "Running Batch 1051, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6794387102127075\n",
      "Running Batch 1052, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6303349733352661\n",
      "Running Batch 1053, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6028631925582886\n",
      "Running Batch 1054, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6470695734024048\n",
      "Running Batch 1055, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6317532062530518\n",
      "Running Batch 1056, Epoch 0, Total Tokens: 107\n",
      "Loss: 1.6138092279434204\n",
      "Running Batch 1057, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6301658153533936\n",
      "Running Batch 1058, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.5353373289108276\n",
      "Running Batch 1059, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5822029113769531\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1059, Loss: 1.5822029113769531\n",
      "Running Batch 1060, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.6007739305496216\n",
      "Running Batch 1061, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.5686479806900024\n",
      "Running Batch 1062, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7555737495422363\n",
      "Running Batch 1063, Epoch 0, Total Tokens: 117\n",
      "Loss: 1.6100152730941772\n",
      "Running Batch 1064, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6291718482971191\n",
      "Running Batch 1065, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.569205403327942\n",
      "Running Batch 1066, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.5486342906951904\n",
      "Running Batch 1067, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.6415576934814453\n",
      "Running Batch 1068, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.5312272310256958\n",
      "Running Batch 1069, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5535298585891724\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1069, Loss: 1.5535298585891724\n",
      "Running Batch 1070, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.586418867111206\n",
      "Running Batch 1071, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.526097297668457\n",
      "Running Batch 1072, Epoch 0, Total Tokens: 133\n",
      "Loss: 1.4698750972747803\n",
      "Running Batch 1073, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5811994075775146\n",
      "Running Batch 1074, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.579254388809204\n",
      "Running Batch 1075, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.647491693496704\n",
      "Running Batch 1076, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5389511585235596\n",
      "Running Batch 1077, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.6050735712051392\n",
      "Running Batch 1078, Epoch 0, Total Tokens: 178\n",
      "Loss: 1.6158099174499512\n",
      "Running Batch 1079, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6854681968688965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1079, Loss: 1.6854681968688965\n",
      "Running Batch 1080, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6838629245758057\n",
      "Running Batch 1081, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.5463720560073853\n",
      "Running Batch 1082, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.5639361143112183\n",
      "Running Batch 1083, Epoch 0, Total Tokens: 182\n",
      "Loss: 1.5345414876937866\n",
      "Running Batch 1084, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.5909148454666138\n",
      "Running Batch 1085, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6071200370788574\n",
      "Running Batch 1086, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.6993522644042969\n",
      "Running Batch 1087, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.561657190322876\n",
      "Running Batch 1088, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5672876834869385\n",
      "Running Batch 1089, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.6141579151153564\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1089, Loss: 1.6141579151153564\n",
      "Running Batch 1090, Epoch 0, Total Tokens: 187\n",
      "Loss: 1.6369799375534058\n",
      "Running Batch 1091, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.564200520515442\n",
      "Running Batch 1092, Epoch 0, Total Tokens: 183\n",
      "Loss: 1.5844184160232544\n",
      "Running Batch 1093, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.5880849361419678\n",
      "Running Batch 1094, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6422662734985352\n",
      "Running Batch 1095, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6062357425689697\n",
      "Running Batch 1096, Epoch 0, Total Tokens: 195\n",
      "Loss: 1.608467936515808\n",
      "Running Batch 1097, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.6315549612045288\n",
      "Running Batch 1098, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6251537799835205\n",
      "Running Batch 1099, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.5878965854644775\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1099, Loss: 1.5878965854644775\n",
      "Running Batch 1100, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.59054696559906\n",
      "Running Batch 1101, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.5077341794967651\n",
      "Running Batch 1102, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6049349308013916\n",
      "Running Batch 1103, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.5555179119110107\n",
      "Running Batch 1104, Epoch 0, Total Tokens: 121\n",
      "Loss: 1.5518720149993896\n",
      "Running Batch 1105, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6554080247879028\n",
      "Running Batch 1106, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.6317987442016602\n",
      "Running Batch 1107, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.4825981855392456\n",
      "Running Batch 1108, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6258941888809204\n",
      "Running Batch 1109, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6833288669586182\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1109, Loss: 1.6833288669586182\n",
      "Running Batch 1110, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.5736056566238403\n",
      "Running Batch 1111, Epoch 0, Total Tokens: 299\n",
      "Loss: 1.5817298889160156\n",
      "Running Batch 1112, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.5890508890151978\n",
      "Running Batch 1113, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.614867091178894\n",
      "Running Batch 1114, Epoch 0, Total Tokens: 296\n",
      "Loss: 1.5979902744293213\n",
      "Running Batch 1115, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.6691291332244873\n",
      "Running Batch 1116, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.5782155990600586\n",
      "Running Batch 1117, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.5590717792510986\n",
      "Running Batch 1118, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.5419360399246216\n",
      "Running Batch 1119, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6136443614959717\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1119, Loss: 1.6136443614959717\n",
      "Running Batch 1120, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6482549905776978\n",
      "Running Batch 1121, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6001811027526855\n",
      "Running Batch 1122, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.5130064487457275\n",
      "Running Batch 1123, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.5940862894058228\n",
      "Running Batch 1124, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6958330869674683\n",
      "Running Batch 1125, Epoch 0, Total Tokens: 105\n",
      "Loss: 1.5705739259719849\n",
      "Running Batch 1126, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6109827756881714\n",
      "Running Batch 1127, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6189929246902466\n",
      "Running Batch 1128, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.5448801517486572\n",
      "Running Batch 1129, Epoch 0, Total Tokens: 195\n",
      "Loss: 1.6088947057724\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1129, Loss: 1.6088947057724\n",
      "Running Batch 1130, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.573269009590149\n",
      "Running Batch 1131, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.5708332061767578\n",
      "Running Batch 1132, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.6743791103363037\n",
      "Running Batch 1133, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.5335594415664673\n",
      "Running Batch 1134, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.559997320175171\n",
      "Running Batch 1135, Epoch 0, Total Tokens: 164\n",
      "Loss: 1.5774998664855957\n",
      "Running Batch 1136, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.5956687927246094\n",
      "Running Batch 1137, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.6200789213180542\n",
      "Running Batch 1138, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.620615005493164\n",
      "Running Batch 1139, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.5790702104568481\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1139, Loss: 1.5790702104568481\n",
      "Running Batch 1140, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.5659645795822144\n",
      "Running Batch 1141, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.643160343170166\n",
      "Running Batch 1142, Epoch 0, Total Tokens: 184\n",
      "Loss: 1.599873423576355\n",
      "Running Batch 1143, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6026668548583984\n",
      "Running Batch 1144, Epoch 0, Total Tokens: 223\n",
      "Loss: 1.618421196937561\n",
      "Running Batch 1145, Epoch 0, Total Tokens: 220\n",
      "Loss: 1.62678062915802\n",
      "Running Batch 1146, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5423669815063477\n",
      "Running Batch 1147, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.589700698852539\n",
      "Running Batch 1148, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.5968987941741943\n",
      "Running Batch 1149, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.5181926488876343\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1149, Loss: 1.5181926488876343\n",
      "Running Batch 1150, Epoch 0, Total Tokens: 254\n",
      "Loss: 1.556652545928955\n",
      "Running Batch 1151, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.5787557363510132\n",
      "Running Batch 1152, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.58341646194458\n",
      "Running Batch 1153, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.636185646057129\n",
      "Running Batch 1154, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.576500415802002\n",
      "Running Batch 1155, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.5597195625305176\n",
      "Running Batch 1156, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.5320680141448975\n",
      "Running Batch 1157, Epoch 0, Total Tokens: 108\n",
      "Loss: 1.590285301208496\n",
      "Running Batch 1158, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.608291506767273\n",
      "Running Batch 1159, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.5932918787002563\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1159, Loss: 1.5932918787002563\n",
      "Running Batch 1160, Epoch 0, Total Tokens: 236\n",
      "Loss: 1.4938573837280273\n",
      "Running Batch 1161, Epoch 0, Total Tokens: 340\n",
      "Loss: 1.5639872550964355\n",
      "Running Batch 1162, Epoch 0, Total Tokens: 249\n",
      "Loss: 1.5241047143936157\n",
      "Running Batch 1163, Epoch 0, Total Tokens: 234\n",
      "Loss: 1.5260069370269775\n",
      "Running Batch 1164, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6340161561965942\n",
      "Running Batch 1165, Epoch 0, Total Tokens: 111\n",
      "Loss: 1.559191346168518\n",
      "Running Batch 1166, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6047970056533813\n",
      "Running Batch 1167, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.5601937770843506\n",
      "Running Batch 1168, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.6543034315109253\n",
      "Running Batch 1169, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6217023134231567\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1169, Loss: 1.6217023134231567\n",
      "Running Batch 1170, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.5991783142089844\n",
      "Running Batch 1171, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.6346831321716309\n",
      "AVG LOSS: 1.6940683578061568, Epoch: 1\n",
      "Running Batch 0, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.5602949857711792\n",
      "Running Batch 1, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5470912456512451\n",
      "Running Batch 2, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.4585731029510498\n",
      "Running Batch 3, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5518392324447632\n",
      "Running Batch 4, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.6160414218902588\n",
      "Running Batch 5, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4927217960357666\n",
      "Running Batch 6, Epoch 1, Total Tokens: 242\n",
      "Loss: 1.5515518188476562\n",
      "Running Batch 7, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5478332042694092\n",
      "Running Batch 8, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5056413412094116\n",
      "Running Batch 9, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4540752172470093\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 9, Loss: 1.4540752172470093\n",
      "Running Batch 10, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4974809885025024\n",
      "Running Batch 11, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5994821786880493\n",
      "Running Batch 12, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5051063299179077\n",
      "Running Batch 13, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5342304706573486\n",
      "Running Batch 14, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4166772365570068\n",
      "Running Batch 15, Epoch 1, Total Tokens: 337\n",
      "Loss: 1.4496514797210693\n",
      "Running Batch 16, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4677058458328247\n",
      "Running Batch 17, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.560347318649292\n",
      "Running Batch 18, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4539530277252197\n",
      "Running Batch 19, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.522692322731018\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 19, Loss: 1.522692322731018\n",
      "Running Batch 20, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4505279064178467\n",
      "Running Batch 21, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5700660943984985\n",
      "Running Batch 22, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.5121018886566162\n",
      "Running Batch 23, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6116784811019897\n",
      "Running Batch 24, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.518320083618164\n",
      "Running Batch 25, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.5430173873901367\n",
      "Running Batch 26, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4969159364700317\n",
      "Running Batch 27, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5652880668640137\n",
      "Running Batch 28, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.5045442581176758\n",
      "Running Batch 29, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4800986051559448\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 29, Loss: 1.4800986051559448\n",
      "Running Batch 30, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5316619873046875\n",
      "Running Batch 31, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5314936637878418\n",
      "Running Batch 32, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5276612043380737\n",
      "Running Batch 33, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.5579183101654053\n",
      "Running Batch 34, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.472477912902832\n",
      "Running Batch 35, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.556212067604065\n",
      "Running Batch 36, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.566057801246643\n",
      "Running Batch 37, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5071871280670166\n",
      "Running Batch 38, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.6261804103851318\n",
      "Running Batch 39, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4949418306350708\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 39, Loss: 1.4949418306350708\n",
      "Running Batch 40, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.502646565437317\n",
      "Running Batch 41, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5057730674743652\n",
      "Running Batch 42, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6494451761245728\n",
      "Running Batch 43, Epoch 1, Total Tokens: 217\n",
      "Loss: 1.4404233694076538\n",
      "Running Batch 44, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.584216594696045\n",
      "Running Batch 45, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5385147333145142\n",
      "Running Batch 46, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.4895875453948975\n",
      "Running Batch 47, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.6011406183242798\n",
      "Running Batch 48, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6409462690353394\n",
      "Running Batch 49, Epoch 1, Total Tokens: 281\n",
      "Loss: 1.4939149618148804\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 49, Loss: 1.4939149618148804\n",
      "Running Batch 50, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4854437112808228\n",
      "Running Batch 51, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.61651611328125\n",
      "Running Batch 52, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5850781202316284\n",
      "Running Batch 53, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4756020307540894\n",
      "Running Batch 54, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4287409782409668\n",
      "Running Batch 55, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.528538465499878\n",
      "Running Batch 56, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5590344667434692\n",
      "Running Batch 57, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5300593376159668\n",
      "Running Batch 58, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5888606309890747\n",
      "Running Batch 59, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.469902515411377\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 59, Loss: 1.469902515411377\n",
      "Running Batch 60, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5071791410446167\n",
      "Running Batch 61, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.5495226383209229\n",
      "Running Batch 62, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.585450530052185\n",
      "Running Batch 63, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.54293692111969\n",
      "Running Batch 64, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4886071681976318\n",
      "Running Batch 65, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.4661550521850586\n",
      "Running Batch 66, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4872702360153198\n",
      "Running Batch 67, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.5744389295578003\n",
      "Running Batch 68, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6187328100204468\n",
      "Running Batch 69, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.464089274406433\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 69, Loss: 1.464089274406433\n",
      "Running Batch 70, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5412923097610474\n",
      "Running Batch 71, Epoch 1, Total Tokens: 210\n",
      "Loss: 1.5018951892852783\n",
      "Running Batch 72, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4605209827423096\n",
      "Running Batch 73, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.497206687927246\n",
      "Running Batch 74, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.579671859741211\n",
      "Running Batch 75, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.6502751111984253\n",
      "Running Batch 76, Epoch 1, Total Tokens: 201\n",
      "Loss: 1.51852285861969\n",
      "Running Batch 77, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.466270089149475\n",
      "Running Batch 78, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.6040679216384888\n",
      "Running Batch 79, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5973724126815796\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 79, Loss: 1.5973724126815796\n",
      "Running Batch 80, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.4850598573684692\n",
      "Running Batch 81, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5761806964874268\n",
      "Running Batch 82, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.4980354309082031\n",
      "Running Batch 83, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.6021391153335571\n",
      "Running Batch 84, Epoch 1, Total Tokens: 418\n",
      "Loss: 1.5076085329055786\n",
      "Running Batch 85, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.4819501638412476\n",
      "Running Batch 86, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.5701898336410522\n",
      "Running Batch 87, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.585801362991333\n",
      "Running Batch 88, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.5714573860168457\n",
      "Running Batch 89, Epoch 1, Total Tokens: 267\n",
      "Loss: 1.4547398090362549\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 89, Loss: 1.4547398090362549\n",
      "Running Batch 90, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5676627159118652\n",
      "Running Batch 91, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5616124868392944\n",
      "Running Batch 92, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5017626285552979\n",
      "Running Batch 93, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5316270589828491\n",
      "Running Batch 94, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5025311708450317\n",
      "Running Batch 95, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.4869160652160645\n",
      "Running Batch 96, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5379767417907715\n",
      "Running Batch 97, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.5116199254989624\n",
      "Running Batch 98, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.4777302742004395\n",
      "Running Batch 99, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.536356806755066\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 99, Loss: 1.536356806755066\n",
      "Running Batch 100, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.5042585134506226\n",
      "Running Batch 101, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4884597063064575\n",
      "Running Batch 102, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5913548469543457\n",
      "Running Batch 103, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.525894045829773\n",
      "Running Batch 104, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.499578833580017\n",
      "Running Batch 105, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5208632946014404\n",
      "Running Batch 106, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.543683409690857\n",
      "Running Batch 107, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.510524868965149\n",
      "Running Batch 108, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.574169397354126\n",
      "Running Batch 109, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.540083646774292\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 109, Loss: 1.540083646774292\n",
      "Running Batch 110, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5582762956619263\n",
      "Running Batch 111, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5193365812301636\n",
      "Running Batch 112, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5410155057907104\n",
      "Running Batch 113, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4945013523101807\n",
      "Running Batch 114, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.532163381576538\n",
      "Running Batch 115, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5122075080871582\n",
      "Running Batch 116, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.421108603477478\n",
      "Running Batch 117, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5345319509506226\n",
      "Running Batch 118, Epoch 1, Total Tokens: 183\n",
      "Loss: 1.4530274868011475\n",
      "Running Batch 119, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4673422574996948\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 119, Loss: 1.4673422574996948\n",
      "Running Batch 120, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.5474742650985718\n",
      "Running Batch 121, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.3668147325515747\n",
      "Running Batch 122, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6149938106536865\n",
      "Running Batch 123, Epoch 1, Total Tokens: 527\n",
      "Loss: 1.5456618070602417\n",
      "Running Batch 124, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5693694353103638\n",
      "Running Batch 125, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.523032307624817\n",
      "Running Batch 126, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5328435897827148\n",
      "Running Batch 127, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5421159267425537\n",
      "Running Batch 128, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5536013841629028\n",
      "Running Batch 129, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.4445085525512695\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 129, Loss: 1.4445085525512695\n",
      "Running Batch 130, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5743221044540405\n",
      "Running Batch 131, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5393579006195068\n",
      "Running Batch 132, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5669628381729126\n",
      "Running Batch 133, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.577195644378662\n",
      "Running Batch 134, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.4337928295135498\n",
      "Running Batch 135, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5663630962371826\n",
      "Running Batch 136, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.614347219467163\n",
      "Running Batch 137, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.6073119640350342\n",
      "Running Batch 138, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.5331993103027344\n",
      "Running Batch 139, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5523358583450317\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 139, Loss: 1.5523358583450317\n",
      "Running Batch 140, Epoch 1, Total Tokens: 109\n",
      "Loss: 1.5907180309295654\n",
      "Running Batch 141, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4536793231964111\n",
      "Running Batch 142, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.6233899593353271\n",
      "Running Batch 143, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5161683559417725\n",
      "Running Batch 144, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5141321420669556\n",
      "Running Batch 145, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.49264657497406\n",
      "Running Batch 146, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5122339725494385\n",
      "Running Batch 147, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.572974443435669\n",
      "Running Batch 148, Epoch 1, Total Tokens: 360\n",
      "Loss: 1.5713415145874023\n",
      "Running Batch 149, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4790347814559937\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 149, Loss: 1.4790347814559937\n",
      "Running Batch 150, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.494016408920288\n",
      "Running Batch 151, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5248613357543945\n",
      "Running Batch 152, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5840718746185303\n",
      "Running Batch 153, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5734286308288574\n",
      "Running Batch 154, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5097345113754272\n",
      "Running Batch 155, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5750346183776855\n",
      "Running Batch 156, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.5055574178695679\n",
      "Running Batch 157, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.5913256406784058\n",
      "Running Batch 158, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4865094423294067\n",
      "Running Batch 159, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.6150351762771606\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 159, Loss: 1.6150351762771606\n",
      "Running Batch 160, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.4221233129501343\n",
      "Running Batch 161, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4718263149261475\n",
      "Running Batch 162, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5473071336746216\n",
      "Running Batch 163, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6062147617340088\n",
      "Running Batch 164, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5758761167526245\n",
      "Running Batch 165, Epoch 1, Total Tokens: 174\n",
      "Loss: 1.629125714302063\n",
      "Running Batch 166, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.480183482170105\n",
      "Running Batch 167, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5663994550704956\n",
      "Running Batch 168, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4831675291061401\n",
      "Running Batch 169, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.592219591140747\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 169, Loss: 1.592219591140747\n",
      "Running Batch 170, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.56474769115448\n",
      "Running Batch 171, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.4487552642822266\n",
      "Running Batch 172, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.588321328163147\n",
      "Running Batch 173, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.5159714221954346\n",
      "Running Batch 174, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5512710809707642\n",
      "Running Batch 175, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5065220594406128\n",
      "Running Batch 176, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.514692783355713\n",
      "Running Batch 177, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6143654584884644\n",
      "Running Batch 178, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.60917067527771\n",
      "Running Batch 179, Epoch 1, Total Tokens: 220\n",
      "Loss: 1.5878374576568604\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 179, Loss: 1.5878374576568604\n",
      "Running Batch 180, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.541025996208191\n",
      "Running Batch 181, Epoch 1, Total Tokens: 236\n",
      "Loss: 1.5570967197418213\n",
      "Running Batch 182, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.551883578300476\n",
      "Running Batch 183, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.5082876682281494\n",
      "Running Batch 184, Epoch 1, Total Tokens: 258\n",
      "Loss: 1.5434679985046387\n",
      "Running Batch 185, Epoch 1, Total Tokens: 106\n",
      "Loss: 1.5065191984176636\n",
      "Running Batch 186, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5189179182052612\n",
      "Running Batch 187, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5939884185791016\n",
      "Running Batch 188, Epoch 1, Total Tokens: 250\n",
      "Loss: 1.5470445156097412\n",
      "Running Batch 189, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5944032669067383\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 189, Loss: 1.5944032669067383\n",
      "Running Batch 190, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4750726222991943\n",
      "Running Batch 191, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.6033178567886353\n",
      "Running Batch 192, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.571010708808899\n",
      "Running Batch 193, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5307443141937256\n",
      "Running Batch 194, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.655351161956787\n",
      "Running Batch 195, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.6087206602096558\n",
      "Running Batch 196, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5769938230514526\n",
      "Running Batch 197, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4950367212295532\n",
      "Running Batch 198, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.6131556034088135\n",
      "Running Batch 199, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5242273807525635\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 199, Loss: 1.5242273807525635\n",
      "Running Batch 200, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.547549843788147\n",
      "Running Batch 201, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5532193183898926\n",
      "Running Batch 202, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4208654165267944\n",
      "Running Batch 203, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.607470989227295\n",
      "Running Batch 204, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5633624792099\n",
      "Running Batch 205, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.48991060256958\n",
      "Running Batch 206, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5510435104370117\n",
      "Running Batch 207, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.4819376468658447\n",
      "Running Batch 208, Epoch 1, Total Tokens: 367\n",
      "Loss: 1.5284063816070557\n",
      "Running Batch 209, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.5599671602249146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 209, Loss: 1.5599671602249146\n",
      "Running Batch 210, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.5896825790405273\n",
      "Running Batch 211, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4930922985076904\n",
      "Running Batch 212, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.4905285835266113\n",
      "Running Batch 213, Epoch 1, Total Tokens: 257\n",
      "Loss: 1.4264650344848633\n",
      "Running Batch 214, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4784184694290161\n",
      "Running Batch 215, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5365577936172485\n",
      "Running Batch 216, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4920728206634521\n",
      "Running Batch 217, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4972703456878662\n",
      "Running Batch 218, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5544620752334595\n",
      "Running Batch 219, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5354673862457275\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 219, Loss: 1.5354673862457275\n",
      "Running Batch 220, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5308337211608887\n",
      "Running Batch 221, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5635654926300049\n",
      "Running Batch 222, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5009461641311646\n",
      "Running Batch 223, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5250476598739624\n",
      "Running Batch 224, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.480295181274414\n",
      "Running Batch 225, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5948325395584106\n",
      "Running Batch 226, Epoch 1, Total Tokens: 210\n",
      "Loss: 1.606217622756958\n",
      "Running Batch 227, Epoch 1, Total Tokens: 261\n",
      "Loss: 1.550511360168457\n",
      "Running Batch 228, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5841293334960938\n",
      "Running Batch 229, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.4748404026031494\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 229, Loss: 1.4748404026031494\n",
      "Running Batch 230, Epoch 1, Total Tokens: 168\n",
      "Loss: 1.523315668106079\n",
      "Running Batch 231, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.555489420890808\n",
      "Running Batch 232, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.467887043952942\n",
      "Running Batch 233, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5108762979507446\n",
      "Running Batch 234, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6218292713165283\n",
      "Running Batch 235, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.4488095045089722\n",
      "Running Batch 236, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5936342477798462\n",
      "Running Batch 237, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.467267632484436\n",
      "Running Batch 238, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5897326469421387\n",
      "Running Batch 239, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4857840538024902\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 239, Loss: 1.4857840538024902\n",
      "Running Batch 240, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.5256400108337402\n",
      "Running Batch 241, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5422135591506958\n",
      "Running Batch 242, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.6079037189483643\n",
      "Running Batch 243, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.537550687789917\n",
      "Running Batch 244, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.4851831197738647\n",
      "Running Batch 245, Epoch 1, Total Tokens: 220\n",
      "Loss: 1.525067687034607\n",
      "Running Batch 246, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.6215418577194214\n",
      "Running Batch 247, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5489970445632935\n",
      "Running Batch 248, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5322695970535278\n",
      "Running Batch 249, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.540563702583313\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 249, Loss: 1.540563702583313\n",
      "Running Batch 250, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5488132238388062\n",
      "Running Batch 251, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.480737566947937\n",
      "Running Batch 252, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.5071340799331665\n",
      "Running Batch 253, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.4161319732666016\n",
      "Running Batch 254, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.4450993537902832\n",
      "Running Batch 255, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5223979949951172\n",
      "Running Batch 256, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.4138766527175903\n",
      "Running Batch 257, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.4912084341049194\n",
      "Running Batch 258, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4818551540374756\n",
      "Running Batch 259, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.4804364442825317\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 259, Loss: 1.4804364442825317\n",
      "Running Batch 260, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.5768388509750366\n",
      "Running Batch 261, Epoch 1, Total Tokens: 106\n",
      "Loss: 1.5303233861923218\n",
      "Running Batch 262, Epoch 1, Total Tokens: 191\n",
      "Loss: 1.5300096273422241\n",
      "Running Batch 263, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5265027284622192\n",
      "Running Batch 264, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.4670132398605347\n",
      "Running Batch 265, Epoch 1, Total Tokens: 351\n",
      "Loss: 1.5567963123321533\n",
      "Running Batch 266, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.5628465414047241\n",
      "Running Batch 267, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.528995156288147\n",
      "Running Batch 268, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5168672800064087\n",
      "Running Batch 269, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.4763727188110352\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 269, Loss: 1.4763727188110352\n",
      "Running Batch 270, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5649034976959229\n",
      "Running Batch 271, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.4746776819229126\n",
      "Running Batch 272, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5280418395996094\n",
      "Running Batch 273, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.5502289533615112\n",
      "Running Batch 274, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.468042016029358\n",
      "Running Batch 275, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.517354965209961\n",
      "Running Batch 276, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.541937232017517\n",
      "Running Batch 277, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4460703134536743\n",
      "Running Batch 278, Epoch 1, Total Tokens: 185\n",
      "Loss: 1.5071660280227661\n",
      "Running Batch 279, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.503676414489746\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 279, Loss: 1.503676414489746\n",
      "Running Batch 280, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5249583721160889\n",
      "Running Batch 281, Epoch 1, Total Tokens: 356\n",
      "Loss: 1.6121034622192383\n",
      "Running Batch 282, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5558260679244995\n",
      "Running Batch 283, Epoch 1, Total Tokens: 282\n",
      "Loss: 1.4368504285812378\n",
      "Running Batch 284, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.504072904586792\n",
      "Running Batch 285, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4466408491134644\n",
      "Running Batch 286, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5730022192001343\n",
      "Running Batch 287, Epoch 1, Total Tokens: 214\n",
      "Loss: 1.562016248703003\n",
      "Running Batch 288, Epoch 1, Total Tokens: 293\n",
      "Loss: 1.5075063705444336\n",
      "Running Batch 289, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.4627399444580078\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 289, Loss: 1.4627399444580078\n",
      "Running Batch 290, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5377405881881714\n",
      "Running Batch 291, Epoch 1, Total Tokens: 110\n",
      "Loss: 1.4761369228363037\n",
      "Running Batch 292, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5501213073730469\n",
      "Running Batch 293, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.485497236251831\n",
      "Running Batch 294, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4742296934127808\n",
      "Running Batch 295, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.579676866531372\n",
      "Running Batch 296, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.5073009729385376\n",
      "Running Batch 297, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5398781299591064\n",
      "Running Batch 298, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.466448187828064\n",
      "Running Batch 299, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5643671751022339\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 299, Loss: 1.5643671751022339\n",
      "Running Batch 300, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.4581620693206787\n",
      "Running Batch 301, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5421525239944458\n",
      "Running Batch 302, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.5325473546981812\n",
      "Running Batch 303, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.545000672340393\n",
      "Running Batch 304, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5159295797348022\n",
      "Running Batch 305, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5185437202453613\n",
      "Running Batch 306, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5519919395446777\n",
      "Running Batch 307, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4531630277633667\n",
      "Running Batch 308, Epoch 1, Total Tokens: 234\n",
      "Loss: 1.5338141918182373\n",
      "Running Batch 309, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.582245945930481\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 309, Loss: 1.582245945930481\n",
      "Running Batch 310, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5822142362594604\n",
      "Running Batch 311, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.551200270652771\n",
      "Running Batch 312, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.589727759361267\n",
      "Running Batch 313, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5254548788070679\n",
      "Running Batch 314, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5818017721176147\n",
      "Running Batch 315, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5847610235214233\n",
      "Running Batch 316, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5420546531677246\n",
      "Running Batch 317, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.572380781173706\n",
      "Running Batch 318, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5384724140167236\n",
      "Running Batch 319, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.622557282447815\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 319, Loss: 1.622557282447815\n",
      "Running Batch 320, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5870922803878784\n",
      "Running Batch 321, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.6240661144256592\n",
      "Running Batch 322, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.435201644897461\n",
      "Running Batch 323, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5063164234161377\n",
      "Running Batch 324, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.501773476600647\n",
      "Running Batch 325, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5579549074172974\n",
      "Running Batch 326, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4415397644042969\n",
      "Running Batch 327, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.5327234268188477\n",
      "Running Batch 328, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5808321237564087\n",
      "Running Batch 329, Epoch 1, Total Tokens: 202\n",
      "Loss: 1.4901479482650757\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 329, Loss: 1.4901479482650757\n",
      "Running Batch 330, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5236862897872925\n",
      "Running Batch 331, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5201067924499512\n",
      "Running Batch 332, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.4392446279525757\n",
      "Running Batch 333, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4844491481781006\n",
      "Running Batch 334, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.4891448020935059\n",
      "Running Batch 335, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5307302474975586\n",
      "Running Batch 336, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.5357487201690674\n",
      "Running Batch 337, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5623770952224731\n",
      "Running Batch 338, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.6063034534454346\n",
      "Running Batch 339, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.551842212677002\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 339, Loss: 1.551842212677002\n",
      "Running Batch 340, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5819826126098633\n",
      "Running Batch 341, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.463646650314331\n",
      "Running Batch 342, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5225169658660889\n",
      "Running Batch 343, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.498652458190918\n",
      "Running Batch 344, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.548412561416626\n",
      "Running Batch 345, Epoch 1, Total Tokens: 267\n",
      "Loss: 1.5826901197433472\n",
      "Running Batch 346, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.5040537118911743\n",
      "Running Batch 347, Epoch 1, Total Tokens: 184\n",
      "Loss: 1.54069185256958\n",
      "Running Batch 348, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.502311110496521\n",
      "Running Batch 349, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4800182580947876\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 349, Loss: 1.4800182580947876\n",
      "Running Batch 350, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5900883674621582\n",
      "Running Batch 351, Epoch 1, Total Tokens: 107\n",
      "Loss: 1.510107398033142\n",
      "Running Batch 352, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5223698616027832\n",
      "Running Batch 353, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4844048023223877\n",
      "Running Batch 354, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5447698831558228\n",
      "Running Batch 355, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5417431592941284\n",
      "Running Batch 356, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5658035278320312\n",
      "Running Batch 357, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.461037278175354\n",
      "Running Batch 358, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5337858200073242\n",
      "Running Batch 359, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.597740888595581\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 359, Loss: 1.597740888595581\n",
      "Running Batch 360, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.543012022972107\n",
      "Running Batch 361, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5125199556350708\n",
      "Running Batch 362, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5532029867172241\n",
      "Running Batch 363, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.526601791381836\n",
      "Running Batch 364, Epoch 1, Total Tokens: 237\n",
      "Loss: 1.6233313083648682\n",
      "Running Batch 365, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5537737607955933\n",
      "Running Batch 366, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.6150312423706055\n",
      "Running Batch 367, Epoch 1, Total Tokens: 274\n",
      "Loss: 1.4717705249786377\n",
      "Running Batch 368, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5254732370376587\n",
      "Running Batch 369, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5497559309005737\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 369, Loss: 1.5497559309005737\n",
      "Running Batch 370, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5244228839874268\n",
      "Running Batch 371, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5292271375656128\n",
      "Running Batch 372, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.6975191831588745\n",
      "Running Batch 373, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5354584455490112\n",
      "Running Batch 374, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5003950595855713\n",
      "Running Batch 375, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5484684705734253\n",
      "Running Batch 376, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.4936342239379883\n",
      "Running Batch 377, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.527033805847168\n",
      "Running Batch 378, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4912726879119873\n",
      "Running Batch 379, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5251330137252808\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 379, Loss: 1.5251330137252808\n",
      "Running Batch 380, Epoch 1, Total Tokens: 191\n",
      "Loss: 1.4954440593719482\n",
      "Running Batch 381, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5440031290054321\n",
      "Running Batch 382, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.4224629402160645\n",
      "Running Batch 383, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5274587869644165\n",
      "Running Batch 384, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.46759033203125\n",
      "Running Batch 385, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.572228193283081\n",
      "Running Batch 386, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5234110355377197\n",
      "Running Batch 387, Epoch 1, Total Tokens: 107\n",
      "Loss: 1.5802993774414062\n",
      "Running Batch 388, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.4067788124084473\n",
      "Running Batch 389, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.448803186416626\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 389, Loss: 1.448803186416626\n",
      "Running Batch 390, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5560276508331299\n",
      "Running Batch 391, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.5150303840637207\n",
      "Running Batch 392, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5582071542739868\n",
      "Running Batch 393, Epoch 1, Total Tokens: 160\n",
      "Loss: 1.4754395484924316\n",
      "Running Batch 394, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.5117982625961304\n",
      "Running Batch 395, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5859811305999756\n",
      "Running Batch 396, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.5719095468521118\n",
      "Running Batch 397, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4193530082702637\n",
      "Running Batch 398, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.4544793367385864\n",
      "Running Batch 399, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4425827264785767\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 399, Loss: 1.4425827264785767\n",
      "Running Batch 400, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5307328701019287\n",
      "Running Batch 401, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5961514711380005\n",
      "Running Batch 402, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.5804657936096191\n",
      "Running Batch 403, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.5146071910858154\n",
      "Running Batch 404, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4619638919830322\n",
      "Running Batch 405, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.4830695390701294\n",
      "Running Batch 406, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.5025581121444702\n",
      "Running Batch 407, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5747593641281128\n",
      "Running Batch 408, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4722225666046143\n",
      "Running Batch 409, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5237337350845337\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 409, Loss: 1.5237337350845337\n",
      "Running Batch 410, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.6423614025115967\n",
      "Running Batch 411, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.5222898721694946\n",
      "Running Batch 412, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4415278434753418\n",
      "Running Batch 413, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4664944410324097\n",
      "Running Batch 414, Epoch 1, Total Tokens: 249\n",
      "Loss: 1.4691513776779175\n",
      "Running Batch 415, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4273356199264526\n",
      "Running Batch 416, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5233073234558105\n",
      "Running Batch 417, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.6009501218795776\n",
      "Running Batch 418, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.5293928384780884\n",
      "Running Batch 419, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5759817361831665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 419, Loss: 1.5759817361831665\n",
      "Running Batch 420, Epoch 1, Total Tokens: 295\n",
      "Loss: 1.5576605796813965\n",
      "Running Batch 421, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5164268016815186\n",
      "Running Batch 422, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.6127040386199951\n",
      "Running Batch 423, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4471436738967896\n",
      "Running Batch 424, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5078129768371582\n",
      "Running Batch 425, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4940698146820068\n",
      "Running Batch 426, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5598654747009277\n",
      "Running Batch 427, Epoch 1, Total Tokens: 183\n",
      "Loss: 1.5033870935440063\n",
      "Running Batch 428, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.502449870109558\n",
      "Running Batch 429, Epoch 1, Total Tokens: 287\n",
      "Loss: 1.6247847080230713\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 429, Loss: 1.6247847080230713\n",
      "Running Batch 430, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.5427985191345215\n",
      "Running Batch 431, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.4064438343048096\n",
      "Running Batch 432, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.4818928241729736\n",
      "Running Batch 433, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5658951997756958\n",
      "Running Batch 434, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.549402117729187\n",
      "Running Batch 435, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5729748010635376\n",
      "Running Batch 436, Epoch 1, Total Tokens: 106\n",
      "Loss: 1.5239523649215698\n",
      "Running Batch 437, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.5042392015457153\n",
      "Running Batch 438, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.5809913873672485\n",
      "Running Batch 439, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.544845461845398\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 439, Loss: 1.544845461845398\n",
      "Running Batch 440, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6243195533752441\n",
      "Running Batch 441, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.535780906677246\n",
      "Running Batch 442, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4834249019622803\n",
      "Running Batch 443, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4777687788009644\n",
      "Running Batch 444, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5055698156356812\n",
      "Running Batch 445, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4329993724822998\n",
      "Running Batch 446, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.5557361841201782\n",
      "Running Batch 447, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.4884530305862427\n",
      "Running Batch 448, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4965145587921143\n",
      "Running Batch 449, Epoch 1, Total Tokens: 326\n",
      "Loss: 1.4738736152648926\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 449, Loss: 1.4738736152648926\n",
      "Running Batch 450, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6007364988327026\n",
      "Running Batch 451, Epoch 1, Total Tokens: 100\n",
      "Loss: 1.4562605619430542\n",
      "Running Batch 452, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.583361268043518\n",
      "Running Batch 453, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4983880519866943\n",
      "Running Batch 454, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4582754373550415\n",
      "Running Batch 455, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.4920016527175903\n",
      "Running Batch 456, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.4950737953186035\n",
      "Running Batch 457, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5801730155944824\n",
      "Running Batch 458, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.4751696586608887\n",
      "Running Batch 459, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6293164491653442\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 459, Loss: 1.6293164491653442\n",
      "Running Batch 460, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.4568365812301636\n",
      "Running Batch 461, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.479501485824585\n",
      "Running Batch 462, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5784649848937988\n",
      "Running Batch 463, Epoch 1, Total Tokens: 219\n",
      "Loss: 1.5305540561676025\n",
      "Running Batch 464, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.480732798576355\n",
      "Running Batch 465, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5091099739074707\n",
      "Running Batch 466, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.466218113899231\n",
      "Running Batch 467, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5847489833831787\n",
      "Running Batch 468, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.5219690799713135\n",
      "Running Batch 469, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6124019622802734\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 469, Loss: 1.6124019622802734\n",
      "Running Batch 470, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.3965787887573242\n",
      "Running Batch 471, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5702838897705078\n",
      "Running Batch 472, Epoch 1, Total Tokens: 236\n",
      "Loss: 1.4064974784851074\n",
      "Running Batch 473, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5207273960113525\n",
      "Running Batch 474, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.4688996076583862\n",
      "Running Batch 475, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5094949007034302\n",
      "Running Batch 476, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5670254230499268\n",
      "Running Batch 477, Epoch 1, Total Tokens: 357\n",
      "Loss: 1.5762348175048828\n",
      "Running Batch 478, Epoch 1, Total Tokens: 258\n",
      "Loss: 1.4934840202331543\n",
      "Running Batch 479, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5094894170761108\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 479, Loss: 1.5094894170761108\n",
      "Running Batch 480, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5247797966003418\n",
      "Running Batch 481, Epoch 1, Total Tokens: 340\n",
      "Loss: 1.51417875289917\n",
      "Running Batch 482, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5288300514221191\n",
      "Running Batch 483, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5144281387329102\n",
      "Running Batch 484, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5083452463150024\n",
      "Running Batch 485, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5604997873306274\n",
      "Running Batch 486, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.5724265575408936\n",
      "Running Batch 487, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5688145160675049\n",
      "Running Batch 488, Epoch 1, Total Tokens: 163\n",
      "Loss: 1.4275771379470825\n",
      "Running Batch 489, Epoch 1, Total Tokens: 285\n",
      "Loss: 1.4816398620605469\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 489, Loss: 1.4816398620605469\n",
      "Running Batch 490, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.55246102809906\n",
      "Running Batch 491, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4924858808517456\n",
      "Running Batch 492, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5559263229370117\n",
      "Running Batch 493, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6334298849105835\n",
      "Running Batch 494, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5092313289642334\n",
      "Running Batch 495, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.618675708770752\n",
      "Running Batch 496, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5265414714813232\n",
      "Running Batch 497, Epoch 1, Total Tokens: 299\n",
      "Loss: 1.514493703842163\n",
      "Running Batch 498, Epoch 1, Total Tokens: 629\n",
      "Loss: 1.4401471614837646\n",
      "Running Batch 499, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.44986093044281\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 499, Loss: 1.44986093044281\n",
      "Running Batch 500, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5152915716171265\n",
      "Running Batch 501, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.5497642755508423\n",
      "Running Batch 502, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.549270749092102\n",
      "Running Batch 503, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5141841173171997\n",
      "Running Batch 504, Epoch 1, Total Tokens: 102\n",
      "Loss: 1.48972487449646\n",
      "Running Batch 505, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5327883958816528\n",
      "Running Batch 506, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6317447423934937\n",
      "Running Batch 507, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4424405097961426\n",
      "Running Batch 508, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.6013695001602173\n",
      "Running Batch 509, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5966203212738037\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 509, Loss: 1.5966203212738037\n",
      "Running Batch 510, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.489961862564087\n",
      "Running Batch 511, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5562971830368042\n",
      "Running Batch 512, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5517215728759766\n",
      "Running Batch 513, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.476364254951477\n",
      "Running Batch 514, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.535309076309204\n",
      "Running Batch 515, Epoch 1, Total Tokens: 196\n",
      "Loss: 1.5181453227996826\n",
      "Running Batch 516, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5275191068649292\n",
      "Running Batch 517, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.5475069284439087\n",
      "Running Batch 518, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5859452486038208\n",
      "Running Batch 519, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4874815940856934\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 519, Loss: 1.4874815940856934\n",
      "Running Batch 520, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5196202993392944\n",
      "Running Batch 521, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5729049444198608\n",
      "Running Batch 522, Epoch 1, Total Tokens: 205\n",
      "Loss: 1.5868492126464844\n",
      "Running Batch 523, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5071988105773926\n",
      "Running Batch 524, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5454951524734497\n",
      "Running Batch 525, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5340428352355957\n",
      "Running Batch 526, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5633834600448608\n",
      "Running Batch 527, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.56637442111969\n",
      "Running Batch 528, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.5492591857910156\n",
      "Running Batch 529, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.5097768306732178\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 529, Loss: 1.5097768306732178\n",
      "Running Batch 530, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5321191549301147\n",
      "Running Batch 531, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4747306108474731\n",
      "Running Batch 532, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.438808560371399\n",
      "Running Batch 533, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5669097900390625\n",
      "Running Batch 534, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.4893906116485596\n",
      "Running Batch 535, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.6303175687789917\n",
      "Running Batch 536, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4640520811080933\n",
      "Running Batch 537, Epoch 1, Total Tokens: 294\n",
      "Loss: 1.5095568895339966\n",
      "Running Batch 538, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5257952213287354\n",
      "Running Batch 539, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4771449565887451\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 539, Loss: 1.4771449565887451\n",
      "Running Batch 540, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4972705841064453\n",
      "Running Batch 541, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.4119873046875\n",
      "Running Batch 542, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5633395910263062\n",
      "Running Batch 543, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.4999972581863403\n",
      "Running Batch 544, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.6084016561508179\n",
      "Running Batch 545, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4169279336929321\n",
      "Running Batch 546, Epoch 1, Total Tokens: 109\n",
      "Loss: 1.530548095703125\n",
      "Running Batch 547, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.459162712097168\n",
      "Running Batch 548, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.500044822692871\n",
      "Running Batch 549, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5344065427780151\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 549, Loss: 1.5344065427780151\n",
      "Running Batch 550, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4429715871810913\n",
      "Running Batch 551, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4463074207305908\n",
      "Running Batch 552, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4839482307434082\n",
      "Running Batch 553, Epoch 1, Total Tokens: 225\n",
      "Loss: 1.5523681640625\n",
      "Running Batch 554, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5131233930587769\n",
      "Running Batch 555, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4490647315979004\n",
      "Running Batch 556, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5346132516860962\n",
      "Running Batch 557, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.532726526260376\n",
      "Running Batch 558, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.669001817703247\n",
      "Running Batch 559, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5320088863372803\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 559, Loss: 1.5320088863372803\n",
      "Running Batch 560, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.4992116689682007\n",
      "Running Batch 561, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.5376099348068237\n",
      "Running Batch 562, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.612231969833374\n",
      "Running Batch 563, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.547705054283142\n",
      "Running Batch 564, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4036444425582886\n",
      "Running Batch 565, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.5807238817214966\n",
      "Running Batch 566, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5392004251480103\n",
      "Running Batch 567, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.50762140750885\n",
      "Running Batch 568, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.4693667888641357\n",
      "Running Batch 569, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.410256266593933\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 569, Loss: 1.410256266593933\n",
      "Running Batch 570, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4435354471206665\n",
      "Running Batch 571, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4768983125686646\n",
      "Running Batch 572, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.633171558380127\n",
      "Running Batch 573, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.612990379333496\n",
      "Running Batch 574, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.5638020038604736\n",
      "Running Batch 575, Epoch 1, Total Tokens: 205\n",
      "Loss: 1.4463353157043457\n",
      "Running Batch 576, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.589155912399292\n",
      "Running Batch 577, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.511533260345459\n",
      "Running Batch 578, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5082768201828003\n",
      "Running Batch 579, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4788376092910767\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 579, Loss: 1.4788376092910767\n",
      "Running Batch 580, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.491443157196045\n",
      "Running Batch 581, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.5138992071151733\n",
      "Running Batch 582, Epoch 1, Total Tokens: 230\n",
      "Loss: 1.4841852188110352\n",
      "Running Batch 583, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5727683305740356\n",
      "Running Batch 584, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4564833641052246\n",
      "Running Batch 585, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5221449136734009\n",
      "Running Batch 586, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5457956790924072\n",
      "Running Batch 587, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.608717679977417\n",
      "Running Batch 588, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5263803005218506\n",
      "Running Batch 589, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.5219889879226685\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 589, Loss: 1.5219889879226685\n",
      "Running Batch 590, Epoch 1, Total Tokens: 428\n",
      "Loss: 1.3793323040008545\n",
      "Running Batch 591, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.6252632141113281\n",
      "Running Batch 592, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.6683789491653442\n",
      "Running Batch 593, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4875890016555786\n",
      "Running Batch 594, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5394566059112549\n",
      "Running Batch 595, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.486899733543396\n",
      "Running Batch 596, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.4471741914749146\n",
      "Running Batch 597, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.4159878492355347\n",
      "Running Batch 598, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4890326261520386\n",
      "Running Batch 599, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.5856846570968628\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 599, Loss: 1.5856846570968628\n",
      "Running Batch 600, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5379745960235596\n",
      "Running Batch 601, Epoch 1, Total Tokens: 202\n",
      "Loss: 1.4408208131790161\n",
      "Running Batch 602, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.5240498781204224\n",
      "Running Batch 603, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.497108817100525\n",
      "Running Batch 604, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4946372509002686\n",
      "Running Batch 605, Epoch 1, Total Tokens: 163\n",
      "Loss: 1.4622372388839722\n",
      "Running Batch 606, Epoch 1, Total Tokens: 196\n",
      "Loss: 1.4484171867370605\n",
      "Running Batch 607, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.4801959991455078\n",
      "Running Batch 608, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5308979749679565\n",
      "Running Batch 609, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4369961023330688\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 609, Loss: 1.4369961023330688\n",
      "Running Batch 610, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4579282999038696\n",
      "Running Batch 611, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.499485731124878\n",
      "Running Batch 612, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5548664331436157\n",
      "Running Batch 613, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5274416208267212\n",
      "Running Batch 614, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.4640978574752808\n",
      "Running Batch 615, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.6672147512435913\n",
      "Running Batch 616, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5378034114837646\n",
      "Running Batch 617, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4991669654846191\n",
      "Running Batch 618, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4605604410171509\n",
      "Running Batch 619, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.6376419067382812\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 619, Loss: 1.6376419067382812\n",
      "Running Batch 620, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5013505220413208\n",
      "Running Batch 621, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4442657232284546\n",
      "Running Batch 622, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4338088035583496\n",
      "Running Batch 623, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5588011741638184\n",
      "Running Batch 624, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4911829233169556\n",
      "Running Batch 625, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.5040918588638306\n",
      "Running Batch 626, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.472880244255066\n",
      "Running Batch 627, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5431405305862427\n",
      "Running Batch 628, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5210254192352295\n",
      "Running Batch 629, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.5096542835235596\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 629, Loss: 1.5096542835235596\n",
      "Running Batch 630, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.505400538444519\n",
      "Running Batch 631, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5613467693328857\n",
      "Running Batch 632, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4701576232910156\n",
      "Running Batch 633, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.5329738855361938\n",
      "Running Batch 634, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5472406148910522\n",
      "Running Batch 635, Epoch 1, Total Tokens: 185\n",
      "Loss: 1.5347893238067627\n",
      "Running Batch 636, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.5625059604644775\n",
      "Running Batch 637, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.5800049304962158\n",
      "Running Batch 638, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5500633716583252\n",
      "Running Batch 639, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5280661582946777\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 639, Loss: 1.5280661582946777\n",
      "Running Batch 640, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.4958784580230713\n",
      "Running Batch 641, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.4246137142181396\n",
      "Running Batch 642, Epoch 1, Total Tokens: 183\n",
      "Loss: 1.49671471118927\n",
      "Running Batch 643, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.502057671546936\n",
      "Running Batch 644, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5041943788528442\n",
      "Running Batch 645, Epoch 1, Total Tokens: 219\n",
      "Loss: 1.5460246801376343\n",
      "Running Batch 646, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.5378355979919434\n",
      "Running Batch 647, Epoch 1, Total Tokens: 322\n",
      "Loss: 1.4806269407272339\n",
      "Running Batch 648, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.579102873802185\n",
      "Running Batch 649, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4947553873062134\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 649, Loss: 1.4947553873062134\n",
      "Running Batch 650, Epoch 1, Total Tokens: 266\n",
      "Loss: 1.4740493297576904\n",
      "Running Batch 651, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5261406898498535\n",
      "Running Batch 652, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.5173887014389038\n",
      "Running Batch 653, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.504318356513977\n",
      "Running Batch 654, Epoch 1, Total Tokens: 107\n",
      "Loss: 1.553041934967041\n",
      "Running Batch 655, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5410871505737305\n",
      "Running Batch 656, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.4120677709579468\n",
      "Running Batch 657, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5303518772125244\n",
      "Running Batch 658, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4799870252609253\n",
      "Running Batch 659, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5179437398910522\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 659, Loss: 1.5179437398910522\n",
      "Running Batch 660, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.5492233037948608\n",
      "Running Batch 661, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.434436321258545\n",
      "Running Batch 662, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.531614899635315\n",
      "Running Batch 663, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.3977537155151367\n",
      "Running Batch 664, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5232036113739014\n",
      "Running Batch 665, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5111044645309448\n",
      "Running Batch 666, Epoch 1, Total Tokens: 285\n",
      "Loss: 1.507939100265503\n",
      "Running Batch 667, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5629026889801025\n",
      "Running Batch 668, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5690890550613403\n",
      "Running Batch 669, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5569409132003784\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 669, Loss: 1.5569409132003784\n",
      "Running Batch 670, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5092369318008423\n",
      "Running Batch 671, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.4204862117767334\n",
      "Running Batch 672, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5605686902999878\n",
      "Running Batch 673, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4698580503463745\n",
      "Running Batch 674, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4923535585403442\n",
      "Running Batch 675, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4812976121902466\n",
      "Running Batch 676, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.524408221244812\n",
      "Running Batch 677, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4767122268676758\n",
      "Running Batch 678, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.4909968376159668\n",
      "Running Batch 679, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.4117764234542847\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 679, Loss: 1.4117764234542847\n",
      "Running Batch 680, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5249954462051392\n",
      "Running Batch 681, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4287432432174683\n",
      "Running Batch 682, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.606469750404358\n",
      "Running Batch 683, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.4694645404815674\n",
      "Running Batch 684, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5580017566680908\n",
      "Running Batch 685, Epoch 1, Total Tokens: 452\n",
      "Loss: 1.5845770835876465\n",
      "Running Batch 686, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.43116295337677\n",
      "Running Batch 687, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.516312837600708\n",
      "Running Batch 688, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.4647550582885742\n",
      "Running Batch 689, Epoch 1, Total Tokens: 197\n",
      "Loss: 1.470609426498413\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 689, Loss: 1.470609426498413\n",
      "Running Batch 690, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5066001415252686\n",
      "Running Batch 691, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.5390067100524902\n",
      "Running Batch 692, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.4893572330474854\n",
      "Running Batch 693, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4541208744049072\n",
      "Running Batch 694, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4716545343399048\n",
      "Running Batch 695, Epoch 1, Total Tokens: 223\n",
      "Loss: 1.4873970746994019\n",
      "Running Batch 696, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5230686664581299\n",
      "Running Batch 697, Epoch 1, Total Tokens: 281\n",
      "Loss: 1.4896142482757568\n",
      "Running Batch 698, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.4952577352523804\n",
      "Running Batch 699, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5089352130889893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 699, Loss: 1.5089352130889893\n",
      "Running Batch 700, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.503024935722351\n",
      "Running Batch 701, Epoch 1, Total Tokens: 273\n",
      "Loss: 1.4648703336715698\n",
      "Running Batch 702, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4342446327209473\n",
      "Running Batch 703, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.5515100955963135\n",
      "Running Batch 704, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4968972206115723\n",
      "Running Batch 705, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.4692639112472534\n",
      "Running Batch 706, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.465093731880188\n",
      "Running Batch 707, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.5062965154647827\n",
      "Running Batch 708, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5468626022338867\n",
      "Running Batch 709, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.496885895729065\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 709, Loss: 1.496885895729065\n",
      "Running Batch 710, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5343149900436401\n",
      "Running Batch 711, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.501549482345581\n",
      "Running Batch 712, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.486528754234314\n",
      "Running Batch 713, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5150474309921265\n",
      "Running Batch 714, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.4531710147857666\n",
      "Running Batch 715, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4877139329910278\n",
      "Running Batch 716, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4753918647766113\n",
      "Running Batch 717, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.4341058731079102\n",
      "Running Batch 718, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5267865657806396\n",
      "Running Batch 719, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.4724984169006348\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 719, Loss: 1.4724984169006348\n",
      "Running Batch 720, Epoch 1, Total Tokens: 266\n",
      "Loss: 1.4343912601470947\n",
      "Running Batch 721, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.4020642042160034\n",
      "Running Batch 722, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4982484579086304\n",
      "Running Batch 723, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.5230027437210083\n",
      "Running Batch 724, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4439045190811157\n",
      "Running Batch 725, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.4989954233169556\n",
      "Running Batch 726, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5333359241485596\n",
      "Running Batch 727, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.4978471994400024\n",
      "Running Batch 728, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.4730976819992065\n",
      "Running Batch 729, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5153998136520386\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 729, Loss: 1.5153998136520386\n",
      "Running Batch 730, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5888686180114746\n",
      "Running Batch 731, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4991445541381836\n",
      "Running Batch 732, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4760873317718506\n",
      "Running Batch 733, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5178498029708862\n",
      "Running Batch 734, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4984021186828613\n",
      "Running Batch 735, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.520082950592041\n",
      "Running Batch 736, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4901212453842163\n",
      "Running Batch 737, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.4711734056472778\n",
      "Running Batch 738, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.417121171951294\n",
      "Running Batch 739, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.501155972480774\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 739, Loss: 1.501155972480774\n",
      "Running Batch 740, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5144555568695068\n",
      "Running Batch 741, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.4917616844177246\n",
      "Running Batch 742, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.576297402381897\n",
      "Running Batch 743, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5630204677581787\n",
      "Running Batch 744, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.5094965696334839\n",
      "Running Batch 745, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.4855319261550903\n",
      "Running Batch 746, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5003002882003784\n",
      "Running Batch 747, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5404044389724731\n",
      "Running Batch 748, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.495069146156311\n",
      "Running Batch 749, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4830445051193237\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 749, Loss: 1.4830445051193237\n",
      "Running Batch 750, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5792251825332642\n",
      "Running Batch 751, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4899919033050537\n",
      "Running Batch 752, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.434278964996338\n",
      "Running Batch 753, Epoch 1, Total Tokens: 296\n",
      "Loss: 1.4673799276351929\n",
      "Running Batch 754, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.5579246282577515\n",
      "Running Batch 755, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.537515640258789\n",
      "Running Batch 756, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.533110499382019\n",
      "Running Batch 757, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.6152423620224\n",
      "Running Batch 758, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5426920652389526\n",
      "Running Batch 759, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5308678150177002\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 759, Loss: 1.5308678150177002\n",
      "Running Batch 760, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.497377872467041\n",
      "Running Batch 761, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.484326720237732\n",
      "Running Batch 762, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.569790244102478\n",
      "Running Batch 763, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5662866830825806\n",
      "Running Batch 764, Epoch 1, Total Tokens: 185\n",
      "Loss: 1.5993565320968628\n",
      "Running Batch 765, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.575026273727417\n",
      "Running Batch 766, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.5680782794952393\n",
      "Running Batch 767, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4853020906448364\n",
      "Running Batch 768, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4776028394699097\n",
      "Running Batch 769, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.551854133605957\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 769, Loss: 1.551854133605957\n",
      "Running Batch 770, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.483489990234375\n",
      "Running Batch 771, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5177773237228394\n",
      "Running Batch 772, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4795587062835693\n",
      "Running Batch 773, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.5688639879226685\n",
      "Running Batch 774, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.477818250656128\n",
      "Running Batch 775, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4193720817565918\n",
      "Running Batch 776, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.5290567874908447\n",
      "Running Batch 777, Epoch 1, Total Tokens: 186\n",
      "Loss: 1.4924399852752686\n",
      "Running Batch 778, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5116790533065796\n",
      "Running Batch 779, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4334819316864014\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 779, Loss: 1.4334819316864014\n",
      "Running Batch 780, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4674330949783325\n",
      "Running Batch 781, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.477388858795166\n",
      "Running Batch 782, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.470687985420227\n",
      "Running Batch 783, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.4764866828918457\n",
      "Running Batch 784, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5055289268493652\n",
      "Running Batch 785, Epoch 1, Total Tokens: 220\n",
      "Loss: 1.6048270463943481\n",
      "Running Batch 786, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.531374454498291\n",
      "Running Batch 787, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5390479564666748\n",
      "Running Batch 788, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.477327823638916\n",
      "Running Batch 789, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.5504028797149658\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 789, Loss: 1.5504028797149658\n",
      "Running Batch 790, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5334798097610474\n",
      "Running Batch 791, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5102202892303467\n",
      "Running Batch 792, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5318996906280518\n",
      "Running Batch 793, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.437821388244629\n",
      "Running Batch 794, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4377779960632324\n",
      "Running Batch 795, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5157885551452637\n",
      "Running Batch 796, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4743931293487549\n",
      "Running Batch 797, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.489278793334961\n",
      "Running Batch 798, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.548278570175171\n",
      "Running Batch 799, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.504207730293274\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 799, Loss: 1.504207730293274\n",
      "Running Batch 800, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5175821781158447\n",
      "Running Batch 801, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.4894979000091553\n",
      "Running Batch 802, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.568297028541565\n",
      "Running Batch 803, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4925878047943115\n",
      "Running Batch 804, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5989618301391602\n",
      "Running Batch 805, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4992094039916992\n",
      "Running Batch 806, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4738750457763672\n",
      "Running Batch 807, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4268158674240112\n",
      "Running Batch 808, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4633479118347168\n",
      "Running Batch 809, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5173099040985107\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 809, Loss: 1.5173099040985107\n",
      "Running Batch 810, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5333105325698853\n",
      "Running Batch 811, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.4619102478027344\n",
      "Running Batch 812, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5039947032928467\n",
      "Running Batch 813, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.4596537351608276\n",
      "Running Batch 814, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.555654525756836\n",
      "Running Batch 815, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5910756587982178\n",
      "Running Batch 816, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4469810724258423\n",
      "Running Batch 817, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5192798376083374\n",
      "Running Batch 818, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.452765941619873\n",
      "Running Batch 819, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.4764788150787354\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 819, Loss: 1.4764788150787354\n",
      "Running Batch 820, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.5224977731704712\n",
      "Running Batch 821, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4482638835906982\n",
      "Running Batch 822, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.580693006515503\n",
      "Running Batch 823, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5054088830947876\n",
      "Running Batch 824, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4286423921585083\n",
      "Running Batch 825, Epoch 1, Total Tokens: 163\n",
      "Loss: 1.4964286088943481\n",
      "Running Batch 826, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5248832702636719\n",
      "Running Batch 827, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5110204219818115\n",
      "Running Batch 828, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5615501403808594\n",
      "Running Batch 829, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.4143222570419312\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 829, Loss: 1.4143222570419312\n",
      "Running Batch 830, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.52837336063385\n",
      "Running Batch 831, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5252515077590942\n",
      "Running Batch 832, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5375412702560425\n",
      "Running Batch 833, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5417606830596924\n",
      "Running Batch 834, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4965496063232422\n",
      "Running Batch 835, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.390661597251892\n",
      "Running Batch 836, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.3384164571762085\n",
      "Running Batch 837, Epoch 1, Total Tokens: 168\n",
      "Loss: 1.5157772302627563\n",
      "Running Batch 838, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.4553500413894653\n",
      "Running Batch 839, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5356340408325195\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 839, Loss: 1.5356340408325195\n",
      "Running Batch 840, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.4340473413467407\n",
      "Running Batch 841, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4897269010543823\n",
      "Running Batch 842, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.436384916305542\n",
      "Running Batch 843, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.5826361179351807\n",
      "Running Batch 844, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.4417791366577148\n",
      "Running Batch 845, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.5214753150939941\n",
      "Running Batch 846, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6328564882278442\n",
      "Running Batch 847, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.3976906538009644\n",
      "Running Batch 848, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.554321050643921\n",
      "Running Batch 849, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5144983530044556\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 849, Loss: 1.5144983530044556\n",
      "Running Batch 850, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5304034948349\n",
      "Running Batch 851, Epoch 1, Total Tokens: 324\n",
      "Loss: 1.4639815092086792\n",
      "Running Batch 852, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5524648427963257\n",
      "Running Batch 853, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4343621730804443\n",
      "Running Batch 854, Epoch 1, Total Tokens: 624\n",
      "Loss: 1.528753399848938\n",
      "Running Batch 855, Epoch 1, Total Tokens: 572\n",
      "Loss: 1.6278289556503296\n",
      "Running Batch 856, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4864249229431152\n",
      "Running Batch 857, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5137962102890015\n",
      "Running Batch 858, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.5530542135238647\n",
      "Running Batch 859, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5261033773422241\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 859, Loss: 1.5261033773422241\n",
      "Running Batch 860, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4831550121307373\n",
      "Running Batch 861, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.516588568687439\n",
      "Running Batch 862, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5920592546463013\n",
      "Running Batch 863, Epoch 1, Total Tokens: 209\n",
      "Loss: 1.5701558589935303\n",
      "Running Batch 864, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.4549578428268433\n",
      "Running Batch 865, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4813172817230225\n",
      "Running Batch 866, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.4572433233261108\n",
      "Running Batch 867, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.58756685256958\n",
      "Running Batch 868, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5923606157302856\n",
      "Running Batch 869, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5029377937316895\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 869, Loss: 1.5029377937316895\n",
      "Running Batch 870, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4675774574279785\n",
      "Running Batch 871, Epoch 1, Total Tokens: 494\n",
      "Loss: 1.4464607238769531\n",
      "Running Batch 872, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.5437870025634766\n",
      "Running Batch 873, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.551121473312378\n",
      "Running Batch 874, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5733332633972168\n",
      "Running Batch 875, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5403051376342773\n",
      "Running Batch 876, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5478242635726929\n",
      "Running Batch 877, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5374644994735718\n",
      "Running Batch 878, Epoch 1, Total Tokens: 228\n",
      "Loss: 1.3963505029678345\n",
      "Running Batch 879, Epoch 1, Total Tokens: 193\n",
      "Loss: 1.5844043493270874\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 879, Loss: 1.5844043493270874\n",
      "Running Batch 880, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.4716682434082031\n",
      "Running Batch 881, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.4621378183364868\n",
      "Running Batch 882, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4762126207351685\n",
      "Running Batch 883, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.494444727897644\n",
      "Running Batch 884, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5091509819030762\n",
      "Running Batch 885, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.457560420036316\n",
      "Running Batch 886, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.523553490638733\n",
      "Running Batch 887, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.5153988599777222\n",
      "Running Batch 888, Epoch 1, Total Tokens: 174\n",
      "Loss: 1.4698649644851685\n",
      "Running Batch 889, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.4517868757247925\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 889, Loss: 1.4517868757247925\n",
      "Running Batch 890, Epoch 1, Total Tokens: 160\n",
      "Loss: 1.562713623046875\n",
      "Running Batch 891, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5751817226409912\n",
      "Running Batch 892, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5437759160995483\n",
      "Running Batch 893, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5213661193847656\n",
      "Running Batch 894, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4862686395645142\n",
      "Running Batch 895, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.5887525081634521\n",
      "Running Batch 896, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.496211290359497\n",
      "Running Batch 897, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.45720636844635\n",
      "Running Batch 898, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5084478855133057\n",
      "Running Batch 899, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.5079389810562134\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 899, Loss: 1.5079389810562134\n",
      "Running Batch 900, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.5450540781021118\n",
      "Running Batch 901, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.5061508417129517\n",
      "Running Batch 902, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.516935110092163\n",
      "Running Batch 903, Epoch 1, Total Tokens: 231\n",
      "Loss: 1.5327755212783813\n",
      "Running Batch 904, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.4851229190826416\n",
      "Running Batch 905, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4678020477294922\n",
      "Running Batch 906, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.388802170753479\n",
      "Running Batch 907, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.4919769763946533\n",
      "Running Batch 908, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.401281714439392\n",
      "Running Batch 909, Epoch 1, Total Tokens: 109\n",
      "Loss: 1.413246512413025\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 909, Loss: 1.413246512413025\n",
      "Running Batch 910, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5093077421188354\n",
      "Running Batch 911, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.3986992835998535\n",
      "Running Batch 912, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.4738938808441162\n",
      "Running Batch 913, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4613176584243774\n",
      "Running Batch 914, Epoch 1, Total Tokens: 110\n",
      "Loss: 1.6079260110855103\n",
      "Running Batch 915, Epoch 1, Total Tokens: 262\n",
      "Loss: 1.4874128103256226\n",
      "Running Batch 916, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.512796401977539\n",
      "Running Batch 917, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4654308557510376\n",
      "Running Batch 918, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4712697267532349\n",
      "Running Batch 919, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4561681747436523\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 919, Loss: 1.4561681747436523\n",
      "Running Batch 920, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4458987712860107\n",
      "Running Batch 921, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.513654351234436\n",
      "Running Batch 922, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5231561660766602\n",
      "Running Batch 923, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5575716495513916\n",
      "Running Batch 924, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.441137671470642\n",
      "Running Batch 925, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.5148696899414062\n",
      "Running Batch 926, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.5057554244995117\n",
      "Running Batch 927, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.473888874053955\n",
      "Running Batch 928, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5035831928253174\n",
      "Running Batch 929, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.507392168045044\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 929, Loss: 1.507392168045044\n",
      "Running Batch 930, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5366405248641968\n",
      "Running Batch 931, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5472784042358398\n",
      "Running Batch 932, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.4973328113555908\n",
      "Running Batch 933, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.4086809158325195\n",
      "Running Batch 934, Epoch 1, Total Tokens: 237\n",
      "Loss: 1.4384169578552246\n",
      "Running Batch 935, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.458869457244873\n",
      "Running Batch 936, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4395229816436768\n",
      "Running Batch 937, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.492404580116272\n",
      "Running Batch 938, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4988058805465698\n",
      "Running Batch 939, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.503273367881775\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 939, Loss: 1.503273367881775\n",
      "Running Batch 940, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5238124132156372\n",
      "Running Batch 941, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.5417054891586304\n",
      "Running Batch 942, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4952515363693237\n",
      "Running Batch 943, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5220454931259155\n",
      "Running Batch 944, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5416816473007202\n",
      "Running Batch 945, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.4803436994552612\n",
      "Running Batch 946, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5754033327102661\n",
      "Running Batch 947, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4452036619186401\n",
      "Running Batch 948, Epoch 1, Total Tokens: 380\n",
      "Loss: 1.6068964004516602\n",
      "Running Batch 949, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.5051343441009521\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 949, Loss: 1.5051343441009521\n",
      "Running Batch 950, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4982986450195312\n",
      "Running Batch 951, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4452013969421387\n",
      "Running Batch 952, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.456253170967102\n",
      "Running Batch 953, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.4911810159683228\n",
      "Running Batch 954, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4839413166046143\n",
      "Running Batch 955, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4679702520370483\n",
      "Running Batch 956, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.461118459701538\n",
      "Running Batch 957, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.3991494178771973\n",
      "Running Batch 958, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5708458423614502\n",
      "Running Batch 959, Epoch 1, Total Tokens: 184\n",
      "Loss: 1.490809440612793\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 959, Loss: 1.490809440612793\n",
      "Running Batch 960, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.5059669017791748\n",
      "Running Batch 961, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.4997105598449707\n",
      "Running Batch 962, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.459856390953064\n",
      "Running Batch 963, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4513919353485107\n",
      "Running Batch 964, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4489398002624512\n",
      "Running Batch 965, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4661985635757446\n",
      "Running Batch 966, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.5179433822631836\n",
      "Running Batch 967, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.557711124420166\n",
      "Running Batch 968, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.502966284751892\n",
      "Running Batch 969, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.408679485321045\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 969, Loss: 1.408679485321045\n",
      "Running Batch 970, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4517827033996582\n",
      "Running Batch 971, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5200906991958618\n",
      "Running Batch 972, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.4916467666625977\n",
      "Running Batch 973, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4599164724349976\n",
      "Running Batch 974, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4474081993103027\n",
      "Running Batch 975, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.4984668493270874\n",
      "Running Batch 976, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.39175283908844\n",
      "Running Batch 977, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.6299426555633545\n",
      "Running Batch 978, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.4629957675933838\n",
      "Running Batch 979, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.5620465278625488\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 979, Loss: 1.5620465278625488\n",
      "Running Batch 980, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4258918762207031\n",
      "Running Batch 981, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4707890748977661\n",
      "Running Batch 982, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.5767782926559448\n",
      "Running Batch 983, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.449148416519165\n",
      "Running Batch 984, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.5133278369903564\n",
      "Running Batch 985, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5626718997955322\n",
      "Running Batch 986, Epoch 1, Total Tokens: 299\n",
      "Loss: 1.4629156589508057\n",
      "Running Batch 987, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4464472532272339\n",
      "Running Batch 988, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.5146801471710205\n",
      "Running Batch 989, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5814132690429688\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 989, Loss: 1.5814132690429688\n",
      "Running Batch 990, Epoch 1, Total Tokens: 228\n",
      "Loss: 1.5270763635635376\n",
      "Running Batch 991, Epoch 1, Total Tokens: 174\n",
      "Loss: 1.4634052515029907\n",
      "Running Batch 992, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.5659494400024414\n",
      "Running Batch 993, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.4831129312515259\n",
      "Running Batch 994, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.5348095893859863\n",
      "Running Batch 995, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5283750295639038\n",
      "Running Batch 996, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.503674030303955\n",
      "Running Batch 997, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.4473239183425903\n",
      "Running Batch 998, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4936168193817139\n",
      "Running Batch 999, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.517349123954773\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 999, Loss: 1.517349123954773\n",
      "Running Batch 1000, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4224607944488525\n",
      "Running Batch 1001, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.5158274173736572\n",
      "Running Batch 1002, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4852290153503418\n",
      "Running Batch 1003, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.4915310144424438\n",
      "Running Batch 1004, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.461302638053894\n",
      "Running Batch 1005, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.4912911653518677\n",
      "Running Batch 1006, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.4443249702453613\n",
      "Running Batch 1007, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.443625569343567\n",
      "Running Batch 1008, Epoch 1, Total Tokens: 175\n",
      "Loss: 1.5150353908538818\n",
      "Running Batch 1009, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.4884573221206665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1009, Loss: 1.4884573221206665\n",
      "Running Batch 1010, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.4590777158737183\n",
      "Running Batch 1011, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.489052414894104\n",
      "Running Batch 1012, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5050528049468994\n",
      "Running Batch 1013, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4627346992492676\n",
      "Running Batch 1014, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.3685715198516846\n",
      "Running Batch 1015, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.5424748659133911\n",
      "Running Batch 1016, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5629171133041382\n",
      "Running Batch 1017, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.5068219900131226\n",
      "Running Batch 1018, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.3816200494766235\n",
      "Running Batch 1019, Epoch 1, Total Tokens: 214\n",
      "Loss: 1.4497781991958618\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1019, Loss: 1.4497781991958618\n",
      "Running Batch 1020, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.512117862701416\n",
      "Running Batch 1021, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.5282280445098877\n",
      "Running Batch 1022, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4532155990600586\n",
      "Running Batch 1023, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4950931072235107\n",
      "Running Batch 1024, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5291095972061157\n",
      "Running Batch 1025, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.4667778015136719\n",
      "Running Batch 1026, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.445570468902588\n",
      "Running Batch 1027, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5044466257095337\n",
      "Running Batch 1028, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5298676490783691\n",
      "Running Batch 1029, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.53415048122406\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1029, Loss: 1.53415048122406\n",
      "Running Batch 1030, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5640722513198853\n",
      "Running Batch 1031, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4893525838851929\n",
      "Running Batch 1032, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.571860671043396\n",
      "Running Batch 1033, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4056955575942993\n",
      "Running Batch 1034, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.4213547706604004\n",
      "Running Batch 1035, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.4289671182632446\n",
      "Running Batch 1036, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.491024374961853\n",
      "Running Batch 1037, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.4858477115631104\n",
      "Running Batch 1038, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4890198707580566\n",
      "Running Batch 1039, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.551512598991394\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1039, Loss: 1.551512598991394\n",
      "Running Batch 1040, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4252071380615234\n",
      "Running Batch 1041, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4193953275680542\n",
      "Running Batch 1042, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.435213565826416\n",
      "Running Batch 1043, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.4175649881362915\n",
      "Running Batch 1044, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.5905972719192505\n",
      "Running Batch 1045, Epoch 1, Total Tokens: 202\n",
      "Loss: 1.4565907716751099\n",
      "Running Batch 1046, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4717774391174316\n",
      "Running Batch 1047, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.4030665159225464\n",
      "Running Batch 1048, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.4795386791229248\n",
      "Running Batch 1049, Epoch 1, Total Tokens: 231\n",
      "Loss: 1.4455807209014893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1049, Loss: 1.4455807209014893\n",
      "Running Batch 1050, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.5484340190887451\n",
      "Running Batch 1051, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4812606573104858\n",
      "Running Batch 1052, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4363019466400146\n",
      "Running Batch 1053, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.439925193786621\n",
      "Running Batch 1054, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.5213608741760254\n",
      "Running Batch 1055, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4978578090667725\n",
      "Running Batch 1056, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.5103797912597656\n",
      "Running Batch 1057, Epoch 1, Total Tokens: 229\n",
      "Loss: 1.3711405992507935\n",
      "Running Batch 1058, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5459551811218262\n",
      "Running Batch 1059, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.4456806182861328\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1059, Loss: 1.4456806182861328\n",
      "Running Batch 1060, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4212770462036133\n",
      "Running Batch 1061, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.4749581813812256\n",
      "Running Batch 1062, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.4882986545562744\n",
      "Running Batch 1063, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.4496724605560303\n",
      "Running Batch 1064, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.5016839504241943\n",
      "Running Batch 1065, Epoch 1, Total Tokens: 384\n",
      "Loss: 1.5256072282791138\n",
      "Running Batch 1066, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.47065007686615\n",
      "Running Batch 1067, Epoch 1, Total Tokens: 288\n",
      "Loss: 1.4975932836532593\n",
      "Running Batch 1068, Epoch 1, Total Tokens: 334\n",
      "Loss: 1.569784164428711\n",
      "Running Batch 1069, Epoch 1, Total Tokens: 251\n",
      "Loss: 1.4615468978881836\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1069, Loss: 1.4615468978881836\n",
      "Running Batch 1070, Epoch 1, Total Tokens: 372\n",
      "Loss: 1.5288594961166382\n",
      "Running Batch 1071, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.391188621520996\n",
      "Running Batch 1072, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4741106033325195\n",
      "Running Batch 1073, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.5892524719238281\n",
      "Running Batch 1074, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.4509516954421997\n",
      "Running Batch 1075, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.4547563791275024\n",
      "Running Batch 1076, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4440973997116089\n",
      "Running Batch 1077, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.463923692703247\n",
      "Running Batch 1078, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.580774188041687\n",
      "Running Batch 1079, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.55739164352417\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1079, Loss: 1.55739164352417\n",
      "Running Batch 1080, Epoch 1, Total Tokens: 177\n",
      "Loss: 1.3980216979980469\n",
      "Running Batch 1081, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.540893316268921\n",
      "Running Batch 1082, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.4086977243423462\n",
      "Running Batch 1083, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4517524242401123\n",
      "Running Batch 1084, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.4772366285324097\n",
      "Running Batch 1085, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.565117597579956\n",
      "Running Batch 1086, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4330745935440063\n",
      "Running Batch 1087, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4846653938293457\n",
      "Running Batch 1088, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.463938593864441\n",
      "Running Batch 1089, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.498328685760498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1089, Loss: 1.498328685760498\n",
      "Running Batch 1090, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.4453297853469849\n",
      "Running Batch 1091, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.5863063335418701\n",
      "Running Batch 1092, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.481287956237793\n",
      "Running Batch 1093, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.515855312347412\n",
      "Running Batch 1094, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5279771089553833\n",
      "Running Batch 1095, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.480474591255188\n",
      "Running Batch 1096, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5313934087753296\n",
      "Running Batch 1097, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.514114499092102\n",
      "Running Batch 1098, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.5849205255508423\n",
      "Running Batch 1099, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.508508563041687\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1099, Loss: 1.508508563041687\n",
      "Running Batch 1100, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4903546571731567\n",
      "Running Batch 1101, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.413077473640442\n",
      "Running Batch 1102, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4714070558547974\n",
      "Running Batch 1103, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.4926408529281616\n",
      "Running Batch 1104, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.4370040893554688\n",
      "Running Batch 1105, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5513256788253784\n",
      "Running Batch 1106, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5386710166931152\n",
      "Running Batch 1107, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.507258415222168\n",
      "Running Batch 1108, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.5708523988723755\n",
      "Running Batch 1109, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.4193860292434692\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1109, Loss: 1.4193860292434692\n",
      "Running Batch 1110, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.498214840888977\n",
      "Running Batch 1111, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.5311572551727295\n",
      "Running Batch 1112, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4085183143615723\n",
      "Running Batch 1113, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.491463303565979\n",
      "Running Batch 1114, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.477814793586731\n",
      "Running Batch 1115, Epoch 1, Total Tokens: 568\n",
      "Loss: 1.4817426204681396\n",
      "Running Batch 1116, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.5052330493927002\n",
      "Running Batch 1117, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.4854706525802612\n",
      "Running Batch 1118, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.5322223901748657\n",
      "Running Batch 1119, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4159066677093506\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1119, Loss: 1.4159066677093506\n",
      "Running Batch 1120, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.3708738088607788\n",
      "Running Batch 1121, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.4972432851791382\n",
      "Running Batch 1122, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.572966456413269\n",
      "Running Batch 1123, Epoch 1, Total Tokens: 186\n",
      "Loss: 1.5384920835494995\n",
      "Running Batch 1124, Epoch 1, Total Tokens: 241\n",
      "Loss: 1.4301848411560059\n",
      "Running Batch 1125, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.533382534980774\n",
      "Running Batch 1126, Epoch 1, Total Tokens: 361\n",
      "Loss: 1.4385192394256592\n",
      "Running Batch 1127, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.4935355186462402\n",
      "Running Batch 1128, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.446780800819397\n",
      "Running Batch 1129, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.4907143115997314\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1129, Loss: 1.4907143115997314\n",
      "Running Batch 1130, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.5623564720153809\n",
      "Running Batch 1131, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6150535345077515\n",
      "Running Batch 1132, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.365099549293518\n",
      "Running Batch 1133, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.4489747285842896\n",
      "Running Batch 1134, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.4339438676834106\n",
      "Running Batch 1135, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.5247902870178223\n",
      "Running Batch 1136, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.4298932552337646\n",
      "Running Batch 1137, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.4375447034835815\n",
      "Running Batch 1138, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.4634567499160767\n",
      "Running Batch 1139, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.4335665702819824\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1139, Loss: 1.4335665702819824\n",
      "Running Batch 1140, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5414698123931885\n",
      "Running Batch 1141, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.5499976873397827\n",
      "Running Batch 1142, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.5120620727539062\n",
      "Running Batch 1143, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.5186837911605835\n",
      "Running Batch 1144, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4134312868118286\n",
      "Running Batch 1145, Epoch 1, Total Tokens: 221\n",
      "Loss: 1.5599159002304077\n",
      "Running Batch 1146, Epoch 1, Total Tokens: 286\n",
      "Loss: 1.5035958290100098\n",
      "Running Batch 1147, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.4654536247253418\n",
      "Running Batch 1148, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.476593255996704\n",
      "Running Batch 1149, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5241740942001343\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1149, Loss: 1.5241740942001343\n",
      "Running Batch 1150, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5785309076309204\n",
      "Running Batch 1151, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.442250370979309\n",
      "Running Batch 1152, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.5225533246994019\n",
      "Running Batch 1153, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.3761823177337646\n",
      "Running Batch 1154, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.3750289678573608\n",
      "Running Batch 1155, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.4067955017089844\n",
      "Running Batch 1156, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.5141420364379883\n",
      "Running Batch 1157, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.4818190336227417\n",
      "Running Batch 1158, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.4992268085479736\n",
      "Running Batch 1159, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.4813340902328491\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1159, Loss: 1.4813340902328491\n",
      "Running Batch 1160, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.3984202146530151\n",
      "Running Batch 1161, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.448016881942749\n",
      "Running Batch 1162, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.5426243543624878\n",
      "Running Batch 1163, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.5161583423614502\n",
      "Running Batch 1164, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.6134084463119507\n",
      "Running Batch 1165, Epoch 1, Total Tokens: 284\n",
      "Loss: 1.5895380973815918\n",
      "Running Batch 1166, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.5661407709121704\n",
      "Running Batch 1167, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.5805233716964722\n",
      "Running Batch 1168, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.5335131883621216\n",
      "Running Batch 1169, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.562029242515564\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1169, Loss: 1.562029242515564\n",
      "Running Batch 1170, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.3755974769592285\n",
      "Running Batch 1171, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.522616982460022\n",
      "AVG LOSS: 1.5125213547167924, Epoch: 2\n",
      "Running Batch 0, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.418874979019165\n",
      "Running Batch 1, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.4693306684494019\n",
      "Running Batch 2, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4386868476867676\n",
      "Running Batch 3, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.464736819267273\n",
      "Running Batch 4, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.4080088138580322\n",
      "Running Batch 5, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.411779522895813\n",
      "Running Batch 6, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4079859256744385\n",
      "Running Batch 7, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3726749420166016\n",
      "Running Batch 8, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4176592826843262\n",
      "Running Batch 9, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3396072387695312\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 9, Loss: 1.3396072387695312\n",
      "Running Batch 10, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4465153217315674\n",
      "Running Batch 11, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.3827482461929321\n",
      "Running Batch 12, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3475748300552368\n",
      "Running Batch 13, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.360484004020691\n",
      "Running Batch 14, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3941649198532104\n",
      "Running Batch 15, Epoch 2, Total Tokens: 231\n",
      "Loss: 1.4592361450195312\n",
      "Running Batch 16, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3601738214492798\n",
      "Running Batch 17, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.4687235355377197\n",
      "Running Batch 18, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.3796486854553223\n",
      "Running Batch 19, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3677542209625244\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 19, Loss: 1.3677542209625244\n",
      "Running Batch 20, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4446064233779907\n",
      "Running Batch 21, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.4223227500915527\n",
      "Running Batch 22, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3907638788223267\n",
      "Running Batch 23, Epoch 2, Total Tokens: 254\n",
      "Loss: 1.3371177911758423\n",
      "Running Batch 24, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3633095026016235\n",
      "Running Batch 25, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.3501571416854858\n",
      "Running Batch 26, Epoch 2, Total Tokens: 230\n",
      "Loss: 1.3895187377929688\n",
      "Running Batch 27, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3728108406066895\n",
      "Running Batch 28, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.411327600479126\n",
      "Running Batch 29, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.3712425231933594\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 29, Loss: 1.3712425231933594\n",
      "Running Batch 30, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4579367637634277\n",
      "Running Batch 31, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4352411031723022\n",
      "Running Batch 32, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4042980670928955\n",
      "Running Batch 33, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4105634689331055\n",
      "Running Batch 34, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3729497194290161\n",
      "Running Batch 35, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3708149194717407\n",
      "Running Batch 36, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.403742790222168\n",
      "Running Batch 37, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3123271465301514\n",
      "Running Batch 38, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.502994179725647\n",
      "Running Batch 39, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.4198507070541382\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 39, Loss: 1.4198507070541382\n",
      "Running Batch 40, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.5174295902252197\n",
      "Running Batch 41, Epoch 2, Total Tokens: 251\n",
      "Loss: 1.4088257551193237\n",
      "Running Batch 42, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4982967376708984\n",
      "Running Batch 43, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.3704761266708374\n",
      "Running Batch 44, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.4319679737091064\n",
      "Running Batch 45, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4948869943618774\n",
      "Running Batch 46, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3437334299087524\n",
      "Running Batch 47, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.4343159198760986\n",
      "Running Batch 48, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3492084741592407\n",
      "Running Batch 49, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.3427156209945679\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 49, Loss: 1.3427156209945679\n",
      "Running Batch 50, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4301906824111938\n",
      "Running Batch 51, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.406437873840332\n",
      "Running Batch 52, Epoch 2, Total Tokens: 105\n",
      "Loss: 1.3607702255249023\n",
      "Running Batch 53, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.332627296447754\n",
      "Running Batch 54, Epoch 2, Total Tokens: 241\n",
      "Loss: 1.3895761966705322\n",
      "Running Batch 55, Epoch 2, Total Tokens: 284\n",
      "Loss: 1.417144775390625\n",
      "Running Batch 56, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3853780031204224\n",
      "Running Batch 57, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4135069847106934\n",
      "Running Batch 58, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.4049663543701172\n",
      "Running Batch 59, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.317192554473877\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 59, Loss: 1.317192554473877\n",
      "Running Batch 60, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.5248031616210938\n",
      "Running Batch 61, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4445631504058838\n",
      "Running Batch 62, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3078382015228271\n",
      "Running Batch 63, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4002087116241455\n",
      "Running Batch 64, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4099313020706177\n",
      "Running Batch 65, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.3725464344024658\n",
      "Running Batch 66, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.412436842918396\n",
      "Running Batch 67, Epoch 2, Total Tokens: 184\n",
      "Loss: 1.4027308225631714\n",
      "Running Batch 68, Epoch 2, Total Tokens: 254\n",
      "Loss: 1.4683266878128052\n",
      "Running Batch 69, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.3807644844055176\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 69, Loss: 1.3807644844055176\n",
      "Running Batch 70, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.3978499174118042\n",
      "Running Batch 71, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4851124286651611\n",
      "Running Batch 72, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.5136520862579346\n",
      "Running Batch 73, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.476719856262207\n",
      "Running Batch 74, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3848772048950195\n",
      "Running Batch 75, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4250887632369995\n",
      "Running Batch 76, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4197704792022705\n",
      "Running Batch 77, Epoch 2, Total Tokens: 168\n",
      "Loss: 1.316498875617981\n",
      "Running Batch 78, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4835262298583984\n",
      "Running Batch 79, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4010169506072998\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 79, Loss: 1.4010169506072998\n",
      "Running Batch 80, Epoch 2, Total Tokens: 360\n",
      "Loss: 1.4601869583129883\n",
      "Running Batch 81, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4952391386032104\n",
      "Running Batch 82, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.3851211071014404\n",
      "Running Batch 83, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4856396913528442\n",
      "Running Batch 84, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4009599685668945\n",
      "Running Batch 85, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.3919199705123901\n",
      "Running Batch 86, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3323404788970947\n",
      "Running Batch 87, Epoch 2, Total Tokens: 367\n",
      "Loss: 1.3726565837860107\n",
      "Running Batch 88, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4453797340393066\n",
      "Running Batch 89, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3806456327438354\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 89, Loss: 1.3806456327438354\n",
      "Running Batch 90, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4628986120224\n",
      "Running Batch 91, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.3600083589553833\n",
      "Running Batch 92, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4210094213485718\n",
      "Running Batch 93, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3909533023834229\n",
      "Running Batch 94, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3833177089691162\n",
      "Running Batch 95, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3721964359283447\n",
      "Running Batch 96, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3783164024353027\n",
      "Running Batch 97, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3065887689590454\n",
      "Running Batch 98, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.3168175220489502\n",
      "Running Batch 99, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4811978340148926\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 99, Loss: 1.4811978340148926\n",
      "Running Batch 100, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.2911027669906616\n",
      "Running Batch 101, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.3758752346038818\n",
      "Running Batch 102, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4354100227355957\n",
      "Running Batch 103, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.3137918710708618\n",
      "Running Batch 104, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.387237787246704\n",
      "Running Batch 105, Epoch 2, Total Tokens: 110\n",
      "Loss: 1.45412015914917\n",
      "Running Batch 106, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3895777463912964\n",
      "Running Batch 107, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.3729887008666992\n",
      "Running Batch 108, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3959732055664062\n",
      "Running Batch 109, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.4799017906188965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 109, Loss: 1.4799017906188965\n",
      "Running Batch 110, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3747533559799194\n",
      "Running Batch 111, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.445339322090149\n",
      "Running Batch 112, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4086182117462158\n",
      "Running Batch 113, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.4376695156097412\n",
      "Running Batch 114, Epoch 2, Total Tokens: 568\n",
      "Loss: 1.3891340494155884\n",
      "Running Batch 115, Epoch 2, Total Tokens: 258\n",
      "Loss: 1.4387646913528442\n",
      "Running Batch 116, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4289661645889282\n",
      "Running Batch 117, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3928287029266357\n",
      "Running Batch 118, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3674942255020142\n",
      "Running Batch 119, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4228202104568481\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 119, Loss: 1.4228202104568481\n",
      "Running Batch 120, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4257875680923462\n",
      "Running Batch 121, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.3791135549545288\n",
      "Running Batch 122, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.4626530408859253\n",
      "Running Batch 123, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3988533020019531\n",
      "Running Batch 124, Epoch 2, Total Tokens: 109\n",
      "Loss: 1.3986178636550903\n",
      "Running Batch 125, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.3859401941299438\n",
      "Running Batch 126, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.532279133796692\n",
      "Running Batch 127, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3325690031051636\n",
      "Running Batch 128, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.4575194120407104\n",
      "Running Batch 129, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3889116048812866\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 129, Loss: 1.3889116048812866\n",
      "Running Batch 130, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.392158031463623\n",
      "Running Batch 131, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4359952211380005\n",
      "Running Batch 132, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.395970106124878\n",
      "Running Batch 133, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.4556818008422852\n",
      "Running Batch 134, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.368623971939087\n",
      "Running Batch 135, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4084084033966064\n",
      "Running Batch 136, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4332834482192993\n",
      "Running Batch 137, Epoch 2, Total Tokens: 211\n",
      "Loss: 1.5130770206451416\n",
      "Running Batch 138, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4686161279678345\n",
      "Running Batch 139, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.4402775764465332\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 139, Loss: 1.4402775764465332\n",
      "Running Batch 140, Epoch 2, Total Tokens: 274\n",
      "Loss: 1.4570834636688232\n",
      "Running Batch 141, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.4793822765350342\n",
      "Running Batch 142, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4393254518508911\n",
      "Running Batch 143, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4135469198226929\n",
      "Running Batch 144, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4179686307907104\n",
      "Running Batch 145, Epoch 2, Total Tokens: 229\n",
      "Loss: 1.4758360385894775\n",
      "Running Batch 146, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4185134172439575\n",
      "Running Batch 147, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4238014221191406\n",
      "Running Batch 148, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.4036921262741089\n",
      "Running Batch 149, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4168299436569214\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 149, Loss: 1.4168299436569214\n",
      "Running Batch 150, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.404646635055542\n",
      "Running Batch 151, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3947486877441406\n",
      "Running Batch 152, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4400888681411743\n",
      "Running Batch 153, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4014959335327148\n",
      "Running Batch 154, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4865360260009766\n",
      "Running Batch 155, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4849283695220947\n",
      "Running Batch 156, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.351029634475708\n",
      "Running Batch 157, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.3171285390853882\n",
      "Running Batch 158, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.3469295501708984\n",
      "Running Batch 159, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.3472118377685547\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 159, Loss: 1.3472118377685547\n",
      "Running Batch 160, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.3801906108856201\n",
      "Running Batch 161, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.344511866569519\n",
      "Running Batch 162, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.454347014427185\n",
      "Running Batch 163, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.4467253684997559\n",
      "Running Batch 164, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4163391590118408\n",
      "Running Batch 165, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.373236894607544\n",
      "Running Batch 166, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.536696195602417\n",
      "Running Batch 167, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.472285270690918\n",
      "Running Batch 168, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3174978494644165\n",
      "Running Batch 169, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4455801248550415\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 169, Loss: 1.4455801248550415\n",
      "Running Batch 170, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.400033712387085\n",
      "Running Batch 171, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3910027742385864\n",
      "Running Batch 172, Epoch 2, Total Tokens: 286\n",
      "Loss: 1.3876688480377197\n",
      "Running Batch 173, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.405857801437378\n",
      "Running Batch 174, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3863286972045898\n",
      "Running Batch 175, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3836491107940674\n",
      "Running Batch 176, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.3230564594268799\n",
      "Running Batch 177, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3841259479522705\n",
      "Running Batch 178, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4718436002731323\n",
      "Running Batch 179, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.3731752634048462\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 179, Loss: 1.3731752634048462\n",
      "Running Batch 180, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3375910520553589\n",
      "Running Batch 181, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4297422170639038\n",
      "Running Batch 182, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4172238111495972\n",
      "Running Batch 183, Epoch 2, Total Tokens: 380\n",
      "Loss: 1.3743479251861572\n",
      "Running Batch 184, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4182066917419434\n",
      "Running Batch 185, Epoch 2, Total Tokens: 357\n",
      "Loss: 1.5339843034744263\n",
      "Running Batch 186, Epoch 2, Total Tokens: 266\n",
      "Loss: 1.2996174097061157\n",
      "Running Batch 187, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3884456157684326\n",
      "Running Batch 188, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.357132911682129\n",
      "Running Batch 189, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4036654233932495\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 189, Loss: 1.4036654233932495\n",
      "Running Batch 190, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.3894623517990112\n",
      "Running Batch 191, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4040204286575317\n",
      "Running Batch 192, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3945432901382446\n",
      "Running Batch 193, Epoch 2, Total Tokens: 384\n",
      "Loss: 1.4811851978302002\n",
      "Running Batch 194, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3735429048538208\n",
      "Running Batch 195, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.38495671749115\n",
      "Running Batch 196, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.423571228981018\n",
      "Running Batch 197, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4166367053985596\n",
      "Running Batch 198, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.3435360193252563\n",
      "Running Batch 199, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.416601538658142\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 199, Loss: 1.416601538658142\n",
      "Running Batch 200, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4208118915557861\n",
      "Running Batch 201, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3938881158828735\n",
      "Running Batch 202, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.4443190097808838\n",
      "Running Batch 203, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.395864725112915\n",
      "Running Batch 204, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.4162440299987793\n",
      "Running Batch 205, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.397660255432129\n",
      "Running Batch 206, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.3739628791809082\n",
      "Running Batch 207, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.4481475353240967\n",
      "Running Batch 208, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3433600664138794\n",
      "Running Batch 209, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4235501289367676\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 209, Loss: 1.4235501289367676\n",
      "Running Batch 210, Epoch 2, Total Tokens: 572\n",
      "Loss: 1.3987019062042236\n",
      "Running Batch 211, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.5303244590759277\n",
      "Running Batch 212, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4256576299667358\n",
      "Running Batch 213, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3512738943099976\n",
      "Running Batch 214, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4422214031219482\n",
      "Running Batch 215, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.381742000579834\n",
      "Running Batch 216, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3865671157836914\n",
      "Running Batch 217, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.3070498704910278\n",
      "Running Batch 218, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4781256914138794\n",
      "Running Batch 219, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.3985129594802856\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 219, Loss: 1.3985129594802856\n",
      "Running Batch 220, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.468723177909851\n",
      "Running Batch 221, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4625166654586792\n",
      "Running Batch 222, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.4473925828933716\n",
      "Running Batch 223, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.33871328830719\n",
      "Running Batch 224, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4717274904251099\n",
      "Running Batch 225, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.3936762809753418\n",
      "Running Batch 226, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4452624320983887\n",
      "Running Batch 227, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.499682903289795\n",
      "Running Batch 228, Epoch 2, Total Tokens: 293\n",
      "Loss: 1.4235764741897583\n",
      "Running Batch 229, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4107145071029663\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 229, Loss: 1.4107145071029663\n",
      "Running Batch 230, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.432509183883667\n",
      "Running Batch 231, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.415513515472412\n",
      "Running Batch 232, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4700913429260254\n",
      "Running Batch 233, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.4274365901947021\n",
      "Running Batch 234, Epoch 2, Total Tokens: 109\n",
      "Loss: 1.4958733320236206\n",
      "Running Batch 235, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4495465755462646\n",
      "Running Batch 236, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4907878637313843\n",
      "Running Batch 237, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.5070019960403442\n",
      "Running Batch 238, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4074803590774536\n",
      "Running Batch 239, Epoch 2, Total Tokens: 196\n",
      "Loss: 1.4118143320083618\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 239, Loss: 1.4118143320083618\n",
      "Running Batch 240, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.4224494695663452\n",
      "Running Batch 241, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.4329615831375122\n",
      "Running Batch 242, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.3978129625320435\n",
      "Running Batch 243, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3533618450164795\n",
      "Running Batch 244, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.3745239973068237\n",
      "Running Batch 245, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4237253665924072\n",
      "Running Batch 246, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.455572485923767\n",
      "Running Batch 247, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.4237570762634277\n",
      "Running Batch 248, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.407694697380066\n",
      "Running Batch 249, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.552372694015503\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 249, Loss: 1.552372694015503\n",
      "Running Batch 250, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.3410816192626953\n",
      "Running Batch 251, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4139695167541504\n",
      "Running Batch 252, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.424918293952942\n",
      "Running Batch 253, Epoch 2, Total Tokens: 299\n",
      "Loss: 1.3755568265914917\n",
      "Running Batch 254, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4160642623901367\n",
      "Running Batch 255, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4320379495620728\n",
      "Running Batch 256, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4339832067489624\n",
      "Running Batch 257, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3751330375671387\n",
      "Running Batch 258, Epoch 2, Total Tokens: 214\n",
      "Loss: 1.435354471206665\n",
      "Running Batch 259, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4612222909927368\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 259, Loss: 1.4612222909927368\n",
      "Running Batch 260, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.4226549863815308\n",
      "Running Batch 261, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4841257333755493\n",
      "Running Batch 262, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4945588111877441\n",
      "Running Batch 263, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.5130399465560913\n",
      "Running Batch 264, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.3442414999008179\n",
      "Running Batch 265, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.453992247581482\n",
      "Running Batch 266, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.406853437423706\n",
      "Running Batch 267, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4757938385009766\n",
      "Running Batch 268, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.3629257678985596\n",
      "Running Batch 269, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.3711118698120117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 269, Loss: 1.3711118698120117\n",
      "Running Batch 270, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.4402470588684082\n",
      "Running Batch 271, Epoch 2, Total Tokens: 219\n",
      "Loss: 1.4074797630310059\n",
      "Running Batch 272, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4747400283813477\n",
      "Running Batch 273, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.3828582763671875\n",
      "Running Batch 274, Epoch 2, Total Tokens: 629\n",
      "Loss: 1.2827681303024292\n",
      "Running Batch 275, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.5214862823486328\n",
      "Running Batch 276, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4646215438842773\n",
      "Running Batch 277, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.5301613807678223\n",
      "Running Batch 278, Epoch 2, Total Tokens: 110\n",
      "Loss: 1.3909850120544434\n",
      "Running Batch 279, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4323283433914185\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 279, Loss: 1.4323283433914185\n",
      "Running Batch 280, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.473204493522644\n",
      "Running Batch 281, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.406126618385315\n",
      "Running Batch 282, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3731495141983032\n",
      "Running Batch 283, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.4005208015441895\n",
      "Running Batch 284, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3733044862747192\n",
      "Running Batch 285, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4477522373199463\n",
      "Running Batch 286, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.319980263710022\n",
      "Running Batch 287, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4781700372695923\n",
      "Running Batch 288, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.3952258825302124\n",
      "Running Batch 289, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3707153797149658\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 289, Loss: 1.3707153797149658\n",
      "Running Batch 290, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4465593099594116\n",
      "Running Batch 291, Epoch 2, Total Tokens: 236\n",
      "Loss: 1.4020764827728271\n",
      "Running Batch 292, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4351935386657715\n",
      "Running Batch 293, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4031349420547485\n",
      "Running Batch 294, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4947993755340576\n",
      "Running Batch 295, Epoch 2, Total Tokens: 244\n",
      "Loss: 1.4037437438964844\n",
      "Running Batch 296, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4770152568817139\n",
      "Running Batch 297, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.3591209650039673\n",
      "Running Batch 298, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4573131799697876\n",
      "Running Batch 299, Epoch 2, Total Tokens: 258\n",
      "Loss: 1.4553247690200806\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 299, Loss: 1.4553247690200806\n",
      "Running Batch 300, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.374031901359558\n",
      "Running Batch 301, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.4952855110168457\n",
      "Running Batch 302, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.412001609802246\n",
      "Running Batch 303, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.40620756149292\n",
      "Running Batch 304, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4739737510681152\n",
      "Running Batch 305, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.353412389755249\n",
      "Running Batch 306, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3793253898620605\n",
      "Running Batch 307, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.455240249633789\n",
      "Running Batch 308, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.4793505668640137\n",
      "Running Batch 309, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.4257571697235107\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 309, Loss: 1.4257571697235107\n",
      "Running Batch 310, Epoch 2, Total Tokens: 294\n",
      "Loss: 1.2862017154693604\n",
      "Running Batch 311, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.354465365409851\n",
      "Running Batch 312, Epoch 2, Total Tokens: 254\n",
      "Loss: 1.4335750341415405\n",
      "Running Batch 313, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.402921438217163\n",
      "Running Batch 314, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.2979919910430908\n",
      "Running Batch 315, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.365208387374878\n",
      "Running Batch 316, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.3771508932113647\n",
      "Running Batch 317, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4151687622070312\n",
      "Running Batch 318, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.354520559310913\n",
      "Running Batch 319, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.369931697845459\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 319, Loss: 1.369931697845459\n",
      "Running Batch 320, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4478769302368164\n",
      "Running Batch 321, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.476263403892517\n",
      "Running Batch 322, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3384326696395874\n",
      "Running Batch 323, Epoch 2, Total Tokens: 262\n",
      "Loss: 1.4101005792617798\n",
      "Running Batch 324, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.5079187154769897\n",
      "Running Batch 325, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4169999361038208\n",
      "Running Batch 326, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.449726939201355\n",
      "Running Batch 327, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4105072021484375\n",
      "Running Batch 328, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.2797926664352417\n",
      "Running Batch 329, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.380637288093567\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 329, Loss: 1.380637288093567\n",
      "Running Batch 330, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.388595700263977\n",
      "Running Batch 331, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.4091315269470215\n",
      "Running Batch 332, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4041839838027954\n",
      "Running Batch 333, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.4818522930145264\n",
      "Running Batch 334, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4111577272415161\n",
      "Running Batch 335, Epoch 2, Total Tokens: 282\n",
      "Loss: 1.4631071090698242\n",
      "Running Batch 336, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3912428617477417\n",
      "Running Batch 337, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.3879719972610474\n",
      "Running Batch 338, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.3878819942474365\n",
      "Running Batch 339, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3545407056808472\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 339, Loss: 1.3545407056808472\n",
      "Running Batch 340, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.3898875713348389\n",
      "Running Batch 341, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3716578483581543\n",
      "Running Batch 342, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.3492610454559326\n",
      "Running Batch 343, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.491148591041565\n",
      "Running Batch 344, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.4331015348434448\n",
      "Running Batch 345, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.323663592338562\n",
      "Running Batch 346, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.4392595291137695\n",
      "Running Batch 347, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4500187635421753\n",
      "Running Batch 348, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.5445466041564941\n",
      "Running Batch 349, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4558905363082886\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 349, Loss: 1.4558905363082886\n",
      "Running Batch 350, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4680089950561523\n",
      "Running Batch 351, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.361830234527588\n",
      "Running Batch 352, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.446027159690857\n",
      "Running Batch 353, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.409621238708496\n",
      "Running Batch 354, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.3376445770263672\n",
      "Running Batch 355, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4034779071807861\n",
      "Running Batch 356, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4310176372528076\n",
      "Running Batch 357, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4068135023117065\n",
      "Running Batch 358, Epoch 2, Total Tokens: 107\n",
      "Loss: 1.4281445741653442\n",
      "Running Batch 359, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.442434549331665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 359, Loss: 1.442434549331665\n",
      "Running Batch 360, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.395887017250061\n",
      "Running Batch 361, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.4577879905700684\n",
      "Running Batch 362, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.3552418947219849\n",
      "Running Batch 363, Epoch 2, Total Tokens: 193\n",
      "Loss: 1.4353054761886597\n",
      "Running Batch 364, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.4720767736434937\n",
      "Running Batch 365, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4642422199249268\n",
      "Running Batch 366, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4061347246170044\n",
      "Running Batch 367, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.4939628839492798\n",
      "Running Batch 368, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.411940336227417\n",
      "Running Batch 369, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.417528510093689\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 369, Loss: 1.417528510093689\n",
      "Running Batch 370, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.420920491218567\n",
      "Running Batch 371, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4504717588424683\n",
      "Running Batch 372, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3808002471923828\n",
      "Running Batch 373, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.4577710628509521\n",
      "Running Batch 374, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3518967628479004\n",
      "Running Batch 375, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4057881832122803\n",
      "Running Batch 376, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4475399255752563\n",
      "Running Batch 377, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.324608564376831\n",
      "Running Batch 378, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4214657545089722\n",
      "Running Batch 379, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.4955856800079346\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 379, Loss: 1.4955856800079346\n",
      "Running Batch 380, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3463647365570068\n",
      "Running Batch 381, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.417068362236023\n",
      "Running Batch 382, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.3996998071670532\n",
      "Running Batch 383, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4262958765029907\n",
      "Running Batch 384, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.5147576332092285\n",
      "Running Batch 385, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4888827800750732\n",
      "Running Batch 386, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.401923418045044\n",
      "Running Batch 387, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.3977768421173096\n",
      "Running Batch 388, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4879276752471924\n",
      "Running Batch 389, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4373639822006226\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 389, Loss: 1.4373639822006226\n",
      "Running Batch 390, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.373927116394043\n",
      "Running Batch 391, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.3696194887161255\n",
      "Running Batch 392, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.3847978115081787\n",
      "Running Batch 393, Epoch 2, Total Tokens: 205\n",
      "Loss: 1.3899613618850708\n",
      "Running Batch 394, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.487876296043396\n",
      "Running Batch 395, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4699910879135132\n",
      "Running Batch 396, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4133187532424927\n",
      "Running Batch 397, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.397552490234375\n",
      "Running Batch 398, Epoch 2, Total Tokens: 281\n",
      "Loss: 1.4076799154281616\n",
      "Running Batch 399, Epoch 2, Total Tokens: 494\n",
      "Loss: 1.3524415493011475\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 399, Loss: 1.3524415493011475\n",
      "Running Batch 400, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.36663019657135\n",
      "Running Batch 401, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.476536512374878\n",
      "Running Batch 402, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4139254093170166\n",
      "Running Batch 403, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.373382329940796\n",
      "Running Batch 404, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.4227203130722046\n",
      "Running Batch 405, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.4141242504119873\n",
      "Running Batch 406, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.452703595161438\n",
      "Running Batch 407, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4541993141174316\n",
      "Running Batch 408, Epoch 2, Total Tokens: 108\n",
      "Loss: 1.537490725517273\n",
      "Running Batch 409, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.3951325416564941\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 409, Loss: 1.3951325416564941\n",
      "Running Batch 410, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4939621686935425\n",
      "Running Batch 411, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3988560438156128\n",
      "Running Batch 412, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4343103170394897\n",
      "Running Batch 413, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.403427243232727\n",
      "Running Batch 414, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4611921310424805\n",
      "Running Batch 415, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4551485776901245\n",
      "Running Batch 416, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3890258073806763\n",
      "Running Batch 417, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3962899446487427\n",
      "Running Batch 418, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4105075597763062\n",
      "Running Batch 419, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.4105899333953857\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 419, Loss: 1.4105899333953857\n",
      "Running Batch 420, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.467665433883667\n",
      "Running Batch 421, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.30082368850708\n",
      "Running Batch 422, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4010577201843262\n",
      "Running Batch 423, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.47098970413208\n",
      "Running Batch 424, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4929245710372925\n",
      "Running Batch 425, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3720533847808838\n",
      "Running Batch 426, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3485052585601807\n",
      "Running Batch 427, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3654882907867432\n",
      "Running Batch 428, Epoch 2, Total Tokens: 102\n",
      "Loss: 1.4290907382965088\n",
      "Running Batch 429, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4259400367736816\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 429, Loss: 1.4259400367736816\n",
      "Running Batch 430, Epoch 2, Total Tokens: 340\n",
      "Loss: 1.4649138450622559\n",
      "Running Batch 431, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4592642784118652\n",
      "Running Batch 432, Epoch 2, Total Tokens: 288\n",
      "Loss: 1.4209331274032593\n",
      "Running Batch 433, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4877203702926636\n",
      "Running Batch 434, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4237006902694702\n",
      "Running Batch 435, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4317954778671265\n",
      "Running Batch 436, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.403131127357483\n",
      "Running Batch 437, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4317443370819092\n",
      "Running Batch 438, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.429664969444275\n",
      "Running Batch 439, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4144893884658813\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 439, Loss: 1.4144893884658813\n",
      "Running Batch 440, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.4343395233154297\n",
      "Running Batch 441, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.3007855415344238\n",
      "Running Batch 442, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.411552906036377\n",
      "Running Batch 443, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3160732984542847\n",
      "Running Batch 444, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3835762739181519\n",
      "Running Batch 445, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3052849769592285\n",
      "Running Batch 446, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3623692989349365\n",
      "Running Batch 447, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4448587894439697\n",
      "Running Batch 448, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.4249002933502197\n",
      "Running Batch 449, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.3877203464508057\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 449, Loss: 1.3877203464508057\n",
      "Running Batch 450, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4066689014434814\n",
      "Running Batch 451, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.4923187494277954\n",
      "Running Batch 452, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4692906141281128\n",
      "Running Batch 453, Epoch 2, Total Tokens: 322\n",
      "Loss: 1.3438804149627686\n",
      "Running Batch 454, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3910562992095947\n",
      "Running Batch 455, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4328700304031372\n",
      "Running Batch 456, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4462897777557373\n",
      "Running Batch 457, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.3514381647109985\n",
      "Running Batch 458, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4912461042404175\n",
      "Running Batch 459, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3425570726394653\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 459, Loss: 1.3425570726394653\n",
      "Running Batch 460, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.4298121929168701\n",
      "Running Batch 461, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.415680170059204\n",
      "Running Batch 462, Epoch 2, Total Tokens: 236\n",
      "Loss: 1.3467084169387817\n",
      "Running Batch 463, Epoch 2, Total Tokens: 110\n",
      "Loss: 1.5142863988876343\n",
      "Running Batch 464, Epoch 2, Total Tokens: 108\n",
      "Loss: 1.4627799987792969\n",
      "Running Batch 465, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4709848165512085\n",
      "Running Batch 466, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.341488003730774\n",
      "Running Batch 467, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.442212700843811\n",
      "Running Batch 468, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.3707494735717773\n",
      "Running Batch 469, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3808283805847168\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 469, Loss: 1.3808283805847168\n",
      "Running Batch 470, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.3826614618301392\n",
      "Running Batch 471, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4461631774902344\n",
      "Running Batch 472, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.435157060623169\n",
      "Running Batch 473, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.429912805557251\n",
      "Running Batch 474, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4761720895767212\n",
      "Running Batch 475, Epoch 2, Total Tokens: 299\n",
      "Loss: 1.4187955856323242\n",
      "Running Batch 476, Epoch 2, Total Tokens: 100\n",
      "Loss: 1.4172639846801758\n",
      "Running Batch 477, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3228585720062256\n",
      "Running Batch 478, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.3698441982269287\n",
      "Running Batch 479, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.380887746810913\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 479, Loss: 1.380887746810913\n",
      "Running Batch 480, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.4472990036010742\n",
      "Running Batch 481, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3445141315460205\n",
      "Running Batch 482, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4182275533676147\n",
      "Running Batch 483, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.295552134513855\n",
      "Running Batch 484, Epoch 2, Total Tokens: 191\n",
      "Loss: 1.4203861951828003\n",
      "Running Batch 485, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3598933219909668\n",
      "Running Batch 486, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4270665645599365\n",
      "Running Batch 487, Epoch 2, Total Tokens: 111\n",
      "Loss: 1.4629515409469604\n",
      "Running Batch 488, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4356436729431152\n",
      "Running Batch 489, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.411394715309143\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 489, Loss: 1.411394715309143\n",
      "Running Batch 490, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4476786851882935\n",
      "Running Batch 491, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3481155633926392\n",
      "Running Batch 492, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4560761451721191\n",
      "Running Batch 493, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.4066476821899414\n",
      "Running Batch 494, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.5013765096664429\n",
      "Running Batch 495, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3958382606506348\n",
      "Running Batch 496, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4900445938110352\n",
      "Running Batch 497, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4123777151107788\n",
      "Running Batch 498, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.429031252861023\n",
      "Running Batch 499, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3785160779953003\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 499, Loss: 1.3785160779953003\n",
      "Running Batch 500, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.338849663734436\n",
      "Running Batch 501, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.3403890132904053\n",
      "Running Batch 502, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.4526664018630981\n",
      "Running Batch 503, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.4104965925216675\n",
      "Running Batch 504, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.4306870698928833\n",
      "Running Batch 505, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.4805738925933838\n",
      "Running Batch 506, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4436577558517456\n",
      "Running Batch 507, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.412184238433838\n",
      "Running Batch 508, Epoch 2, Total Tokens: 223\n",
      "Loss: 1.5049766302108765\n",
      "Running Batch 509, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3922138214111328\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 509, Loss: 1.3922138214111328\n",
      "Running Batch 510, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3928775787353516\n",
      "Running Batch 511, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3193786144256592\n",
      "Running Batch 512, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.390166997909546\n",
      "Running Batch 513, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4490253925323486\n",
      "Running Batch 514, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.4589017629623413\n",
      "Running Batch 515, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4682425260543823\n",
      "Running Batch 516, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.414357304573059\n",
      "Running Batch 517, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.3274140357971191\n",
      "Running Batch 518, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.403807282447815\n",
      "Running Batch 519, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.3130484819412231\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 519, Loss: 1.3130484819412231\n",
      "Running Batch 520, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.41170334815979\n",
      "Running Batch 521, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.3629626035690308\n",
      "Running Batch 522, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.3787238597869873\n",
      "Running Batch 523, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3395657539367676\n",
      "Running Batch 524, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.4524166584014893\n",
      "Running Batch 525, Epoch 2, Total Tokens: 102\n",
      "Loss: 1.496856451034546\n",
      "Running Batch 526, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.435455322265625\n",
      "Running Batch 527, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3944644927978516\n",
      "Running Batch 528, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4123302698135376\n",
      "Running Batch 529, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4654549360275269\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 529, Loss: 1.4654549360275269\n",
      "Running Batch 530, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.448428988456726\n",
      "Running Batch 531, Epoch 2, Total Tokens: 219\n",
      "Loss: 1.4193068742752075\n",
      "Running Batch 532, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4375920295715332\n",
      "Running Batch 533, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3560081720352173\n",
      "Running Batch 534, Epoch 2, Total Tokens: 210\n",
      "Loss: 1.3652108907699585\n",
      "Running Batch 535, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4372764825820923\n",
      "Running Batch 536, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.4353244304656982\n",
      "Running Batch 537, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.4159457683563232\n",
      "Running Batch 538, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4956423044204712\n",
      "Running Batch 539, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4309897422790527\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 539, Loss: 1.4309897422790527\n",
      "Running Batch 540, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.4591038227081299\n",
      "Running Batch 541, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3983352184295654\n",
      "Running Batch 542, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.43401038646698\n",
      "Running Batch 543, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.4079341888427734\n",
      "Running Batch 544, Epoch 2, Total Tokens: 249\n",
      "Loss: 1.4131172895431519\n",
      "Running Batch 545, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.409726858139038\n",
      "Running Batch 546, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4357069730758667\n",
      "Running Batch 547, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3850059509277344\n",
      "Running Batch 548, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.3036662340164185\n",
      "Running Batch 549, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4100703001022339\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 549, Loss: 1.4100703001022339\n",
      "Running Batch 550, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4425272941589355\n",
      "Running Batch 551, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.3407682180404663\n",
      "Running Batch 552, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.3748805522918701\n",
      "Running Batch 553, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4887491464614868\n",
      "Running Batch 554, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.414467692375183\n",
      "Running Batch 555, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4434893131256104\n",
      "Running Batch 556, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4531153440475464\n",
      "Running Batch 557, Epoch 2, Total Tokens: 107\n",
      "Loss: 1.3973290920257568\n",
      "Running Batch 558, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.359385371208191\n",
      "Running Batch 559, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.3240188360214233\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 559, Loss: 1.3240188360214233\n",
      "Running Batch 560, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.4610984325408936\n",
      "Running Batch 561, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4849591255187988\n",
      "Running Batch 562, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4758654832839966\n",
      "Running Batch 563, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3888376951217651\n",
      "Running Batch 564, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4512614011764526\n",
      "Running Batch 565, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4224213361740112\n",
      "Running Batch 566, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.384669542312622\n",
      "Running Batch 567, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.37130868434906\n",
      "Running Batch 568, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4745255708694458\n",
      "Running Batch 569, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4017753601074219\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 569, Loss: 1.4017753601074219\n",
      "Running Batch 570, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4324843883514404\n",
      "Running Batch 571, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4109724760055542\n",
      "Running Batch 572, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4030518531799316\n",
      "Running Batch 573, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.387127161026001\n",
      "Running Batch 574, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.3742549419403076\n",
      "Running Batch 575, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3907556533813477\n",
      "Running Batch 576, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4817012548446655\n",
      "Running Batch 577, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4176995754241943\n",
      "Running Batch 578, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.4628968238830566\n",
      "Running Batch 579, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3316477537155151\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 579, Loss: 1.3316477537155151\n",
      "Running Batch 580, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.384436011314392\n",
      "Running Batch 581, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.5152206420898438\n",
      "Running Batch 582, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4245598316192627\n",
      "Running Batch 583, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.392806887626648\n",
      "Running Batch 584, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.4051058292388916\n",
      "Running Batch 585, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.373684287071228\n",
      "Running Batch 586, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4021011590957642\n",
      "Running Batch 587, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.2969937324523926\n",
      "Running Batch 588, Epoch 2, Total Tokens: 184\n",
      "Loss: 1.3980717658996582\n",
      "Running Batch 589, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.3899997472763062\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 589, Loss: 1.3899997472763062\n",
      "Running Batch 590, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3541810512542725\n",
      "Running Batch 591, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.3749257326126099\n",
      "Running Batch 592, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.337005853652954\n",
      "Running Batch 593, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.370636224746704\n",
      "Running Batch 594, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.347057819366455\n",
      "Running Batch 595, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4038736820220947\n",
      "Running Batch 596, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4642372131347656\n",
      "Running Batch 597, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3940472602844238\n",
      "Running Batch 598, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4682139158248901\n",
      "Running Batch 599, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.412238597869873\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 599, Loss: 1.412238597869873\n",
      "Running Batch 600, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3260048627853394\n",
      "Running Batch 601, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.4492695331573486\n",
      "Running Batch 602, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4010424613952637\n",
      "Running Batch 603, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.436442255973816\n",
      "Running Batch 604, Epoch 2, Total Tokens: 285\n",
      "Loss: 1.3799633979797363\n",
      "Running Batch 605, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.350975751876831\n",
      "Running Batch 606, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3671244382858276\n",
      "Running Batch 607, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.496385097503662\n",
      "Running Batch 608, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.3811486959457397\n",
      "Running Batch 609, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.3161847591400146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 609, Loss: 1.3161847591400146\n",
      "Running Batch 610, Epoch 2, Total Tokens: 296\n",
      "Loss: 1.4086130857467651\n",
      "Running Batch 611, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.402284860610962\n",
      "Running Batch 612, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.3611294031143188\n",
      "Running Batch 613, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.350049614906311\n",
      "Running Batch 614, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3618106842041016\n",
      "Running Batch 615, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3242127895355225\n",
      "Running Batch 616, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.4499812126159668\n",
      "Running Batch 617, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4077656269073486\n",
      "Running Batch 618, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4189634323120117\n",
      "Running Batch 619, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4777745008468628\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 619, Loss: 1.4777745008468628\n",
      "Running Batch 620, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.3794358968734741\n",
      "Running Batch 621, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4742088317871094\n",
      "Running Batch 622, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3762904405593872\n",
      "Running Batch 623, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.333370327949524\n",
      "Running Batch 624, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3922053575515747\n",
      "Running Batch 625, Epoch 2, Total Tokens: 624\n",
      "Loss: 1.3524718284606934\n",
      "Running Batch 626, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4165951013565063\n",
      "Running Batch 627, Epoch 2, Total Tokens: 228\n",
      "Loss: 1.385857343673706\n",
      "Running Batch 628, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.4808197021484375\n",
      "Running Batch 629, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4057972431182861\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 629, Loss: 1.4057972431182861\n",
      "Running Batch 630, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.4442466497421265\n",
      "Running Batch 631, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3410931825637817\n",
      "Running Batch 632, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4419149160385132\n",
      "Running Batch 633, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.436724305152893\n",
      "Running Batch 634, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.487923502922058\n",
      "Running Batch 635, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.3887996673583984\n",
      "Running Batch 636, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3230186700820923\n",
      "Running Batch 637, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.4083373546600342\n",
      "Running Batch 638, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.4411360025405884\n",
      "Running Batch 639, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.390280842781067\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 639, Loss: 1.390280842781067\n",
      "Running Batch 640, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4311184883117676\n",
      "Running Batch 641, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3178129196166992\n",
      "Running Batch 642, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.35653555393219\n",
      "Running Batch 643, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4232395887374878\n",
      "Running Batch 644, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3535672426223755\n",
      "Running Batch 645, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3537570238113403\n",
      "Running Batch 646, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.3984426259994507\n",
      "Running Batch 647, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.530644416809082\n",
      "Running Batch 648, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.54916250705719\n",
      "Running Batch 649, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.4515546560287476\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 649, Loss: 1.4515546560287476\n",
      "Running Batch 650, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4042998552322388\n",
      "Running Batch 651, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3142738342285156\n",
      "Running Batch 652, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.470337152481079\n",
      "Running Batch 653, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4158340692520142\n",
      "Running Batch 654, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.445950984954834\n",
      "Running Batch 655, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4020360708236694\n",
      "Running Batch 656, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3985836505889893\n",
      "Running Batch 657, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4307527542114258\n",
      "Running Batch 658, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4235104322433472\n",
      "Running Batch 659, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3744618892669678\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 659, Loss: 1.3744618892669678\n",
      "Running Batch 660, Epoch 2, Total Tokens: 527\n",
      "Loss: 1.4238648414611816\n",
      "Running Batch 661, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.4314699172973633\n",
      "Running Batch 662, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3949579000473022\n",
      "Running Batch 663, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3670196533203125\n",
      "Running Batch 664, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4228723049163818\n",
      "Running Batch 665, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4016578197479248\n",
      "Running Batch 666, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.5592479705810547\n",
      "Running Batch 667, Epoch 2, Total Tokens: 326\n",
      "Loss: 1.4505650997161865\n",
      "Running Batch 668, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4663598537445068\n",
      "Running Batch 669, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4219894409179688\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 669, Loss: 1.4219894409179688\n",
      "Running Batch 670, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.465485692024231\n",
      "Running Batch 671, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.3453288078308105\n",
      "Running Batch 672, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4362980127334595\n",
      "Running Batch 673, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3837655782699585\n",
      "Running Batch 674, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4910449981689453\n",
      "Running Batch 675, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4306780099868774\n",
      "Running Batch 676, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.323789119720459\n",
      "Running Batch 677, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3450758457183838\n",
      "Running Batch 678, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4656440019607544\n",
      "Running Batch 679, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4789823293685913\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 679, Loss: 1.4789823293685913\n",
      "Running Batch 680, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4201717376708984\n",
      "Running Batch 681, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4194825887680054\n",
      "Running Batch 682, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4492874145507812\n",
      "Running Batch 683, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3627432584762573\n",
      "Running Batch 684, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3896112442016602\n",
      "Running Batch 685, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3647239208221436\n",
      "Running Batch 686, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.429089903831482\n",
      "Running Batch 687, Epoch 2, Total Tokens: 180\n",
      "Loss: 1.4036084413528442\n",
      "Running Batch 688, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.476347804069519\n",
      "Running Batch 689, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3209654092788696\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 689, Loss: 1.3209654092788696\n",
      "Running Batch 690, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.43364679813385\n",
      "Running Batch 691, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.504276156425476\n",
      "Running Batch 692, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3922959566116333\n",
      "Running Batch 693, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4129393100738525\n",
      "Running Batch 694, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4695669412612915\n",
      "Running Batch 695, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.449144959449768\n",
      "Running Batch 696, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.397410273551941\n",
      "Running Batch 697, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.4019674062728882\n",
      "Running Batch 698, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3130751848220825\n",
      "Running Batch 699, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.3979612588882446\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 699, Loss: 1.3979612588882446\n",
      "Running Batch 700, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3772696256637573\n",
      "Running Batch 701, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4243453741073608\n",
      "Running Batch 702, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3864758014678955\n",
      "Running Batch 703, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3637231588363647\n",
      "Running Batch 704, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.407820224761963\n",
      "Running Batch 705, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3761111497879028\n",
      "Running Batch 706, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.3653517961502075\n",
      "Running Batch 707, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.459564447402954\n",
      "Running Batch 708, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.365939974784851\n",
      "Running Batch 709, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3304680585861206\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 709, Loss: 1.3304680585861206\n",
      "Running Batch 710, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.3911545276641846\n",
      "Running Batch 711, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.5031713247299194\n",
      "Running Batch 712, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.404832124710083\n",
      "Running Batch 713, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4785404205322266\n",
      "Running Batch 714, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.3879225254058838\n",
      "Running Batch 715, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.3647785186767578\n",
      "Running Batch 716, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4808039665222168\n",
      "Running Batch 717, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3817224502563477\n",
      "Running Batch 718, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3744587898254395\n",
      "Running Batch 719, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3677433729171753\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 719, Loss: 1.3677433729171753\n",
      "Running Batch 720, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.410537838935852\n",
      "Running Batch 721, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.386904239654541\n",
      "Running Batch 722, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4243594408035278\n",
      "Running Batch 723, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.43588125705719\n",
      "Running Batch 724, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.4067836999893188\n",
      "Running Batch 725, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.4417316913604736\n",
      "Running Batch 726, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4024165868759155\n",
      "Running Batch 727, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3532359600067139\n",
      "Running Batch 728, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.3188668489456177\n",
      "Running Batch 729, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.3653895854949951\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 729, Loss: 1.3653895854949951\n",
      "Running Batch 730, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4008594751358032\n",
      "Running Batch 731, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.3195685148239136\n",
      "Running Batch 732, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.3717153072357178\n",
      "Running Batch 733, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4821335077285767\n",
      "Running Batch 734, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3335819244384766\n",
      "Running Batch 735, Epoch 2, Total Tokens: 237\n",
      "Loss: 1.374220848083496\n",
      "Running Batch 736, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3955875635147095\n",
      "Running Batch 737, Epoch 2, Total Tokens: 231\n",
      "Loss: 1.4093377590179443\n",
      "Running Batch 738, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.4490541219711304\n",
      "Running Batch 739, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.451345443725586\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 739, Loss: 1.451345443725586\n",
      "Running Batch 740, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3534512519836426\n",
      "Running Batch 741, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.402366280555725\n",
      "Running Batch 742, Epoch 2, Total Tokens: 324\n",
      "Loss: 1.4434958696365356\n",
      "Running Batch 743, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.436631202697754\n",
      "Running Batch 744, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.366049885749817\n",
      "Running Batch 745, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.471190094947815\n",
      "Running Batch 746, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.422542691230774\n",
      "Running Batch 747, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.356123685836792\n",
      "Running Batch 748, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.350169062614441\n",
      "Running Batch 749, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.336782693862915\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 749, Loss: 1.336782693862915\n",
      "Running Batch 750, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.430558681488037\n",
      "Running Batch 751, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4636446237564087\n",
      "Running Batch 752, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.294508457183838\n",
      "Running Batch 753, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3411377668380737\n",
      "Running Batch 754, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.2933493852615356\n",
      "Running Batch 755, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.4769744873046875\n",
      "Running Batch 756, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.40810227394104\n",
      "Running Batch 757, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.3481504917144775\n",
      "Running Batch 758, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.4618710279464722\n",
      "Running Batch 759, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.5200458765029907\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 759, Loss: 1.5200458765029907\n",
      "Running Batch 760, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.3173373937606812\n",
      "Running Batch 761, Epoch 2, Total Tokens: 210\n",
      "Loss: 1.334497094154358\n",
      "Running Batch 762, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.339894413948059\n",
      "Running Batch 763, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.448883295059204\n",
      "Running Batch 764, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4211571216583252\n",
      "Running Batch 765, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.4969482421875\n",
      "Running Batch 766, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4250562191009521\n",
      "Running Batch 767, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.492031216621399\n",
      "Running Batch 768, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.4385247230529785\n",
      "Running Batch 769, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4130305051803589\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 769, Loss: 1.4130305051803589\n",
      "Running Batch 770, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.4253268241882324\n",
      "Running Batch 771, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.383769154548645\n",
      "Running Batch 772, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4991233348846436\n",
      "Running Batch 773, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4933669567108154\n",
      "Running Batch 774, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.410447597503662\n",
      "Running Batch 775, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.4250702857971191\n",
      "Running Batch 776, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.356297254562378\n",
      "Running Batch 777, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3393465280532837\n",
      "Running Batch 778, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.379218339920044\n",
      "Running Batch 779, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.4380801916122437\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 779, Loss: 1.4380801916122437\n",
      "Running Batch 780, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3769443035125732\n",
      "Running Batch 781, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3852317333221436\n",
      "Running Batch 782, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4041122198104858\n",
      "Running Batch 783, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.3233202695846558\n",
      "Running Batch 784, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.3584296703338623\n",
      "Running Batch 785, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.507184386253357\n",
      "Running Batch 786, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.419496774673462\n",
      "Running Batch 787, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3597856760025024\n",
      "Running Batch 788, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4546000957489014\n",
      "Running Batch 789, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4392832517623901\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 789, Loss: 1.4392832517623901\n",
      "Running Batch 790, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4883739948272705\n",
      "Running Batch 791, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.470306634902954\n",
      "Running Batch 792, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4204832315444946\n",
      "Running Batch 793, Epoch 2, Total Tokens: 267\n",
      "Loss: 1.315930724143982\n",
      "Running Batch 794, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.416797399520874\n",
      "Running Batch 795, Epoch 2, Total Tokens: 261\n",
      "Loss: 1.5119709968566895\n",
      "Running Batch 796, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4604203701019287\n",
      "Running Batch 797, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.359555721282959\n",
      "Running Batch 798, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4275660514831543\n",
      "Running Batch 799, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4576689004898071\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 799, Loss: 1.4576689004898071\n",
      "Running Batch 800, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.46487295627594\n",
      "Running Batch 801, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.3797754049301147\n",
      "Running Batch 802, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.3864740133285522\n",
      "Running Batch 803, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.4466789960861206\n",
      "Running Batch 804, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4206875562667847\n",
      "Running Batch 805, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.3472388982772827\n",
      "Running Batch 806, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4653092622756958\n",
      "Running Batch 807, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4012701511383057\n",
      "Running Batch 808, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4547111988067627\n",
      "Running Batch 809, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.3824455738067627\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 809, Loss: 1.3824455738067627\n",
      "Running Batch 810, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4122322797775269\n",
      "Running Batch 811, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.4649717807769775\n",
      "Running Batch 812, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.460995078086853\n",
      "Running Batch 813, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4720746278762817\n",
      "Running Batch 814, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4471983909606934\n",
      "Running Batch 815, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.3319042921066284\n",
      "Running Batch 816, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.36472487449646\n",
      "Running Batch 817, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3958783149719238\n",
      "Running Batch 818, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4176474809646606\n",
      "Running Batch 819, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4357208013534546\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 819, Loss: 1.4357208013534546\n",
      "Running Batch 820, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4588978290557861\n",
      "Running Batch 821, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4640203714370728\n",
      "Running Batch 822, Epoch 2, Total Tokens: 244\n",
      "Loss: 1.3802130222320557\n",
      "Running Batch 823, Epoch 2, Total Tokens: 109\n",
      "Loss: 1.4486162662506104\n",
      "Running Batch 824, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.368894100189209\n",
      "Running Batch 825, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3117634057998657\n",
      "Running Batch 826, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.4441584348678589\n",
      "Running Batch 827, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.5102672576904297\n",
      "Running Batch 828, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4321300983428955\n",
      "Running Batch 829, Epoch 2, Total Tokens: 418\n",
      "Loss: 1.3742077350616455\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 829, Loss: 1.3742077350616455\n",
      "Running Batch 830, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.4280787706375122\n",
      "Running Batch 831, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3914868831634521\n",
      "Running Batch 832, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.409542202949524\n",
      "Running Batch 833, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4655929803848267\n",
      "Running Batch 834, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4706015586853027\n",
      "Running Batch 835, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3924669027328491\n",
      "Running Batch 836, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.430586814880371\n",
      "Running Batch 837, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.3767372369766235\n",
      "Running Batch 838, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4363157749176025\n",
      "Running Batch 839, Epoch 2, Total Tokens: 452\n",
      "Loss: 1.4554295539855957\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 839, Loss: 1.4554295539855957\n",
      "Running Batch 840, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3745311498641968\n",
      "Running Batch 841, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.456872582435608\n",
      "Running Batch 842, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4325952529907227\n",
      "Running Batch 843, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.332759976387024\n",
      "Running Batch 844, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.461022138595581\n",
      "Running Batch 845, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4585715532302856\n",
      "Running Batch 846, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4471428394317627\n",
      "Running Batch 847, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.466522216796875\n",
      "Running Batch 848, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.4098303318023682\n",
      "Running Batch 849, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4615659713745117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 849, Loss: 1.4615659713745117\n",
      "Running Batch 850, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4124841690063477\n",
      "Running Batch 851, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.4315226078033447\n",
      "Running Batch 852, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.3582819700241089\n",
      "Running Batch 853, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.3718138933181763\n",
      "Running Batch 854, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4500175714492798\n",
      "Running Batch 855, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.422274112701416\n",
      "Running Batch 856, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.4633709192276\n",
      "Running Batch 857, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.3605626821517944\n",
      "Running Batch 858, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.3983466625213623\n",
      "Running Batch 859, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.4270516633987427\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 859, Loss: 1.4270516633987427\n",
      "Running Batch 860, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4107664823532104\n",
      "Running Batch 861, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.5497671365737915\n",
      "Running Batch 862, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.415726900100708\n",
      "Running Batch 863, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.406554937362671\n",
      "Running Batch 864, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.4976682662963867\n",
      "Running Batch 865, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.3861149549484253\n",
      "Running Batch 866, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4223823547363281\n",
      "Running Batch 867, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3006000518798828\n",
      "Running Batch 868, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4492990970611572\n",
      "Running Batch 869, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3988150358200073\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 869, Loss: 1.3988150358200073\n",
      "Running Batch 870, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4534285068511963\n",
      "Running Batch 871, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.4087389707565308\n",
      "Running Batch 872, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.397464632987976\n",
      "Running Batch 873, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.5469114780426025\n",
      "Running Batch 874, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.3505431413650513\n",
      "Running Batch 875, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.443128228187561\n",
      "Running Batch 876, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.37841796875\n",
      "Running Batch 877, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4541858434677124\n",
      "Running Batch 878, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4481438398361206\n",
      "Running Batch 879, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.406611680984497\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 879, Loss: 1.406611680984497\n",
      "Running Batch 880, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4058728218078613\n",
      "Running Batch 881, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.470404028892517\n",
      "Running Batch 882, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.452616572380066\n",
      "Running Batch 883, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3934112787246704\n",
      "Running Batch 884, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4750311374664307\n",
      "Running Batch 885, Epoch 2, Total Tokens: 109\n",
      "Loss: 1.3782222270965576\n",
      "Running Batch 886, Epoch 2, Total Tokens: 225\n",
      "Loss: 1.3163347244262695\n",
      "Running Batch 887, Epoch 2, Total Tokens: 356\n",
      "Loss: 1.4203763008117676\n",
      "Running Batch 888, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4769326448440552\n",
      "Running Batch 889, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4179604053497314\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 889, Loss: 1.4179604053497314\n",
      "Running Batch 890, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.4591009616851807\n",
      "Running Batch 891, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.429736614227295\n",
      "Running Batch 892, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4383763074874878\n",
      "Running Batch 893, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4238349199295044\n",
      "Running Batch 894, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.4425815343856812\n",
      "Running Batch 895, Epoch 2, Total Tokens: 334\n",
      "Loss: 1.3502691984176636\n",
      "Running Batch 896, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.489525318145752\n",
      "Running Batch 897, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3571717739105225\n",
      "Running Batch 898, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4114651679992676\n",
      "Running Batch 899, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3368149995803833\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 899, Loss: 1.3368149995803833\n",
      "Running Batch 900, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3449053764343262\n",
      "Running Batch 901, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4072245359420776\n",
      "Running Batch 902, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3965409994125366\n",
      "Running Batch 903, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.342218279838562\n",
      "Running Batch 904, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.4882060289382935\n",
      "Running Batch 905, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4203523397445679\n",
      "Running Batch 906, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.4670236110687256\n",
      "Running Batch 907, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.4266422986984253\n",
      "Running Batch 908, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3684509992599487\n",
      "Running Batch 909, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4188984632492065\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 909, Loss: 1.4188984632492065\n",
      "Running Batch 910, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.372644305229187\n",
      "Running Batch 911, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.3475879430770874\n",
      "Running Batch 912, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.4052393436431885\n",
      "Running Batch 913, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.347335696220398\n",
      "Running Batch 914, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4353407621383667\n",
      "Running Batch 915, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.4401116371154785\n",
      "Running Batch 916, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3974732160568237\n",
      "Running Batch 917, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3468537330627441\n",
      "Running Batch 918, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.3888746500015259\n",
      "Running Batch 919, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4433331489562988\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 919, Loss: 1.4433331489562988\n",
      "Running Batch 920, Epoch 2, Total Tokens: 205\n",
      "Loss: 1.4578640460968018\n",
      "Running Batch 921, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.3922295570373535\n",
      "Running Batch 922, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4577078819274902\n",
      "Running Batch 923, Epoch 2, Total Tokens: 228\n",
      "Loss: 1.3676409721374512\n",
      "Running Batch 924, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.384956955909729\n",
      "Running Batch 925, Epoch 2, Total Tokens: 372\n",
      "Loss: 1.4789501428604126\n",
      "Running Batch 926, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.415769100189209\n",
      "Running Batch 927, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.443408727645874\n",
      "Running Batch 928, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.367081880569458\n",
      "Running Batch 929, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.369386911392212\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 929, Loss: 1.369386911392212\n",
      "Running Batch 930, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4035162925720215\n",
      "Running Batch 931, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.4073951244354248\n",
      "Running Batch 932, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.3652880191802979\n",
      "Running Batch 933, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4716370105743408\n",
      "Running Batch 934, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4420983791351318\n",
      "Running Batch 935, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4628262519836426\n",
      "Running Batch 936, Epoch 2, Total Tokens: 273\n",
      "Loss: 1.347605586051941\n",
      "Running Batch 937, Epoch 2, Total Tokens: 351\n",
      "Loss: 1.4226585626602173\n",
      "Running Batch 938, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.3774242401123047\n",
      "Running Batch 939, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4441523551940918\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 939, Loss: 1.4441523551940918\n",
      "Running Batch 940, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.3561739921569824\n",
      "Running Batch 941, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.3478447198867798\n",
      "Running Batch 942, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.4236130714416504\n",
      "Running Batch 943, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4739032983779907\n",
      "Running Batch 944, Epoch 2, Total Tokens: 214\n",
      "Loss: 1.342896819114685\n",
      "Running Batch 945, Epoch 2, Total Tokens: 192\n",
      "Loss: 1.404467225074768\n",
      "Running Batch 946, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4617550373077393\n",
      "Running Batch 947, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.3841058015823364\n",
      "Running Batch 948, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.448394775390625\n",
      "Running Batch 949, Epoch 2, Total Tokens: 103\n",
      "Loss: 1.3675795793533325\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 949, Loss: 1.3675795793533325\n",
      "Running Batch 950, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.478637933731079\n",
      "Running Batch 951, Epoch 2, Total Tokens: 196\n",
      "Loss: 1.4049278497695923\n",
      "Running Batch 952, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.436556339263916\n",
      "Running Batch 953, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.3976597785949707\n",
      "Running Batch 954, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4623668193817139\n",
      "Running Batch 955, Epoch 2, Total Tokens: 266\n",
      "Loss: 1.3237428665161133\n",
      "Running Batch 956, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.3848413228988647\n",
      "Running Batch 957, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.361605167388916\n",
      "Running Batch 958, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4811855554580688\n",
      "Running Batch 959, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.378139615058899\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 959, Loss: 1.378139615058899\n",
      "Running Batch 960, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3787860870361328\n",
      "Running Batch 961, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.4279941320419312\n",
      "Running Batch 962, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3694608211517334\n",
      "Running Batch 963, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.354215383529663\n",
      "Running Batch 964, Epoch 2, Total Tokens: 104\n",
      "Loss: 1.536049246788025\n",
      "Running Batch 965, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.3874218463897705\n",
      "Running Batch 966, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.384232521057129\n",
      "Running Batch 967, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.3922773599624634\n",
      "Running Batch 968, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3525677919387817\n",
      "Running Batch 969, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4663084745407104\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 969, Loss: 1.4663084745407104\n",
      "Running Batch 970, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.4125897884368896\n",
      "Running Batch 971, Epoch 2, Total Tokens: 281\n",
      "Loss: 1.4804255962371826\n",
      "Running Batch 972, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4254761934280396\n",
      "Running Batch 973, Epoch 2, Total Tokens: 177\n",
      "Loss: 1.4453157186508179\n",
      "Running Batch 974, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.3521350622177124\n",
      "Running Batch 975, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4649121761322021\n",
      "Running Batch 976, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.5379140377044678\n",
      "Running Batch 977, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.334631085395813\n",
      "Running Batch 978, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4274380207061768\n",
      "Running Batch 979, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.412922978401184\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 979, Loss: 1.412922978401184\n",
      "Running Batch 980, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4794939756393433\n",
      "Running Batch 981, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.3785151243209839\n",
      "Running Batch 982, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4798191785812378\n",
      "Running Batch 983, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.46540367603302\n",
      "Running Batch 984, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.442786455154419\n",
      "Running Batch 985, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3843932151794434\n",
      "Running Batch 986, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.2799813747406006\n",
      "Running Batch 987, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.4135258197784424\n",
      "Running Batch 988, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.3821967840194702\n",
      "Running Batch 989, Epoch 2, Total Tokens: 337\n",
      "Loss: 1.4122593402862549\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 989, Loss: 1.4122593402862549\n",
      "Running Batch 990, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.4582432508468628\n",
      "Running Batch 991, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.4583269357681274\n",
      "Running Batch 992, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3419671058654785\n",
      "Running Batch 993, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.3756095170974731\n",
      "Running Batch 994, Epoch 2, Total Tokens: 428\n",
      "Loss: 1.367214322090149\n",
      "Running Batch 995, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3845252990722656\n",
      "Running Batch 996, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.3736342191696167\n",
      "Running Batch 997, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.419701099395752\n",
      "Running Batch 998, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.3473999500274658\n",
      "Running Batch 999, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3828973770141602\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 999, Loss: 1.3828973770141602\n",
      "Running Batch 1000, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.413859486579895\n",
      "Running Batch 1001, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.506988763809204\n",
      "Running Batch 1002, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.386043906211853\n",
      "Running Batch 1003, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4070930480957031\n",
      "Running Batch 1004, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.3975253105163574\n",
      "Running Batch 1005, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.5146613121032715\n",
      "Running Batch 1006, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4647256135940552\n",
      "Running Batch 1007, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4130489826202393\n",
      "Running Batch 1008, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4881420135498047\n",
      "Running Batch 1009, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.474774956703186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1009, Loss: 1.474774956703186\n",
      "Running Batch 1010, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.4019997119903564\n",
      "Running Batch 1011, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.338139295578003\n",
      "Running Batch 1012, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3646008968353271\n",
      "Running Batch 1013, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.451639175415039\n",
      "Running Batch 1014, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.453958511352539\n",
      "Running Batch 1015, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4149380922317505\n",
      "Running Batch 1016, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4132086038589478\n",
      "Running Batch 1017, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3939390182495117\n",
      "Running Batch 1018, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4785526990890503\n",
      "Running Batch 1019, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.4517078399658203\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1019, Loss: 1.4517078399658203\n",
      "Running Batch 1020, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.419480323791504\n",
      "Running Batch 1021, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4928405284881592\n",
      "Running Batch 1022, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4661941528320312\n",
      "Running Batch 1023, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.4438722133636475\n",
      "Running Batch 1024, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.423227310180664\n",
      "Running Batch 1025, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3904390335083008\n",
      "Running Batch 1026, Epoch 2, Total Tokens: 285\n",
      "Loss: 1.3180313110351562\n",
      "Running Batch 1027, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.392133355140686\n",
      "Running Batch 1028, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4791516065597534\n",
      "Running Batch 1029, Epoch 2, Total Tokens: 197\n",
      "Loss: 1.4463086128234863\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1029, Loss: 1.4463086128234863\n",
      "Running Batch 1030, Epoch 2, Total Tokens: 204\n",
      "Loss: 1.4110524654388428\n",
      "Running Batch 1031, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.441423773765564\n",
      "Running Batch 1032, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.345033049583435\n",
      "Running Batch 1033, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4316644668579102\n",
      "Running Batch 1034, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4187318086624146\n",
      "Running Batch 1035, Epoch 2, Total Tokens: 211\n",
      "Loss: 1.3503886461257935\n",
      "Running Batch 1036, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.432667851448059\n",
      "Running Batch 1037, Epoch 2, Total Tokens: 106\n",
      "Loss: 1.403078556060791\n",
      "Running Batch 1038, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.388756275177002\n",
      "Running Batch 1039, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.498789668083191\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1039, Loss: 1.498789668083191\n",
      "Running Batch 1040, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.3891971111297607\n",
      "Running Batch 1041, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.4482495784759521\n",
      "Running Batch 1042, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.448808193206787\n",
      "Running Batch 1043, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.3544092178344727\n",
      "Running Batch 1044, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4234986305236816\n",
      "Running Batch 1045, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.3795301914215088\n",
      "Running Batch 1046, Epoch 2, Total Tokens: 206\n",
      "Loss: 1.4021329879760742\n",
      "Running Batch 1047, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.428961157798767\n",
      "Running Batch 1048, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4124610424041748\n",
      "Running Batch 1049, Epoch 2, Total Tokens: 206\n",
      "Loss: 1.3506217002868652\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1049, Loss: 1.3506217002868652\n",
      "Running Batch 1050, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.3783684968948364\n",
      "Running Batch 1051, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.356943130493164\n",
      "Running Batch 1052, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3897323608398438\n",
      "Running Batch 1053, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.360581636428833\n",
      "Running Batch 1054, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.429079532623291\n",
      "Running Batch 1055, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3910740613937378\n",
      "Running Batch 1056, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.354943871498108\n",
      "Running Batch 1057, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4502063989639282\n",
      "Running Batch 1058, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.314663052558899\n",
      "Running Batch 1059, Epoch 2, Total Tokens: 361\n",
      "Loss: 1.280325174331665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1059, Loss: 1.280325174331665\n",
      "Running Batch 1060, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3732681274414062\n",
      "Running Batch 1061, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.391364574432373\n",
      "Running Batch 1062, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.3839104175567627\n",
      "Running Batch 1063, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.353680968284607\n",
      "Running Batch 1064, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.3702994585037231\n",
      "Running Batch 1065, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3483507633209229\n",
      "Running Batch 1066, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3429235219955444\n",
      "Running Batch 1067, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4120453596115112\n",
      "Running Batch 1068, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3369951248168945\n",
      "Running Batch 1069, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.4211390018463135\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1069, Loss: 1.4211390018463135\n",
      "Running Batch 1070, Epoch 2, Total Tokens: 242\n",
      "Loss: 1.4226610660552979\n",
      "Running Batch 1071, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.4330943822860718\n",
      "Running Batch 1072, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.4751219749450684\n",
      "Running Batch 1073, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.3914345502853394\n",
      "Running Batch 1074, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4737167358398438\n",
      "Running Batch 1075, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3955955505371094\n",
      "Running Batch 1076, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3273279666900635\n",
      "Running Batch 1077, Epoch 2, Total Tokens: 287\n",
      "Loss: 1.438724160194397\n",
      "Running Batch 1078, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3268046379089355\n",
      "Running Batch 1079, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.3530218601226807\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1079, Loss: 1.3530218601226807\n",
      "Running Batch 1080, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.2914680242538452\n",
      "Running Batch 1081, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.3942450284957886\n",
      "Running Batch 1082, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.393507480621338\n",
      "Running Batch 1083, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3950608968734741\n",
      "Running Batch 1084, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.406028389930725\n",
      "Running Batch 1085, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.4199368953704834\n",
      "Running Batch 1086, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.4154201745986938\n",
      "Running Batch 1087, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.3054360151290894\n",
      "Running Batch 1088, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.4111438989639282\n",
      "Running Batch 1089, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3257160186767578\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1089, Loss: 1.3257160186767578\n",
      "Running Batch 1090, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.382979393005371\n",
      "Running Batch 1091, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4459526538848877\n",
      "Running Batch 1092, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.408998966217041\n",
      "Running Batch 1093, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.3603373765945435\n",
      "Running Batch 1094, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.3651119470596313\n",
      "Running Batch 1095, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.4102849960327148\n",
      "Running Batch 1096, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.370147705078125\n",
      "Running Batch 1097, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.421074628829956\n",
      "Running Batch 1098, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3555482625961304\n",
      "Running Batch 1099, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.3200840950012207\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1099, Loss: 1.3200840950012207\n",
      "Running Batch 1100, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.440659523010254\n",
      "Running Batch 1101, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4428106546401978\n",
      "Running Batch 1102, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.430271863937378\n",
      "Running Batch 1103, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.3960026502609253\n",
      "Running Batch 1104, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.3769676685333252\n",
      "Running Batch 1105, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.4051358699798584\n",
      "Running Batch 1106, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.3030437231063843\n",
      "Running Batch 1107, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3497997522354126\n",
      "Running Batch 1108, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4445997476577759\n",
      "Running Batch 1109, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.436051845550537\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1109, Loss: 1.436051845550537\n",
      "Running Batch 1110, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.398295521736145\n",
      "Running Batch 1111, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4157816171646118\n",
      "Running Batch 1112, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.3530144691467285\n",
      "Running Batch 1113, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.3642774820327759\n",
      "Running Batch 1114, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.342913031578064\n",
      "Running Batch 1115, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.3742610216140747\n",
      "Running Batch 1116, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.400648832321167\n",
      "Running Batch 1117, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.381209373474121\n",
      "Running Batch 1118, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4445980787277222\n",
      "Running Batch 1119, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.4306906461715698\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1119, Loss: 1.4306906461715698\n",
      "Running Batch 1120, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.4594433307647705\n",
      "Running Batch 1121, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.4171782732009888\n",
      "Running Batch 1122, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4074687957763672\n",
      "Running Batch 1123, Epoch 2, Total Tokens: 250\n",
      "Loss: 1.4385896921157837\n",
      "Running Batch 1124, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.4462391138076782\n",
      "Running Batch 1125, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4818999767303467\n",
      "Running Batch 1126, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.4035351276397705\n",
      "Running Batch 1127, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.3850507736206055\n",
      "Running Batch 1128, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.3698123693466187\n",
      "Running Batch 1129, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.3369758129119873\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1129, Loss: 1.3369758129119873\n",
      "Running Batch 1130, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.4301434755325317\n",
      "Running Batch 1131, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4975504875183105\n",
      "Running Batch 1132, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.4050228595733643\n",
      "Running Batch 1133, Epoch 2, Total Tokens: 295\n",
      "Loss: 1.372543215751648\n",
      "Running Batch 1134, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.3763673305511475\n",
      "Running Batch 1135, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.4602152109146118\n",
      "Running Batch 1136, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.4050101041793823\n",
      "Running Batch 1137, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.4856135845184326\n",
      "Running Batch 1138, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.4220726490020752\n",
      "Running Batch 1139, Epoch 2, Total Tokens: 191\n",
      "Loss: 1.414316177368164\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1139, Loss: 1.414316177368164\n",
      "Running Batch 1140, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3830523490905762\n",
      "Running Batch 1141, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.501335620880127\n",
      "Running Batch 1142, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.404305100440979\n",
      "Running Batch 1143, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.3639189004898071\n",
      "Running Batch 1144, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3962304592132568\n",
      "Running Batch 1145, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.416658878326416\n",
      "Running Batch 1146, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.3468681573867798\n",
      "Running Batch 1147, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.4017034769058228\n",
      "Running Batch 1148, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.3342653512954712\n",
      "Running Batch 1149, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.4159505367279053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1149, Loss: 1.4159505367279053\n",
      "Running Batch 1150, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.3856204748153687\n",
      "Running Batch 1151, Epoch 2, Total Tokens: 108\n",
      "Loss: 1.3964346647262573\n",
      "Running Batch 1152, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4246044158935547\n",
      "Running Batch 1153, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.3844119310379028\n",
      "Running Batch 1154, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.3752546310424805\n",
      "Running Batch 1155, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.395154595375061\n",
      "Running Batch 1156, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.4209229946136475\n",
      "Running Batch 1157, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4376431703567505\n",
      "Running Batch 1158, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.4014503955841064\n",
      "Running Batch 1159, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.4263824224472046\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1159, Loss: 1.4263824224472046\n",
      "Running Batch 1160, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.4497319459915161\n",
      "Running Batch 1161, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.4527714252471924\n",
      "Running Batch 1162, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.401212453842163\n",
      "Running Batch 1163, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.4356727600097656\n",
      "Running Batch 1164, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.473929524421692\n",
      "Running Batch 1165, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.451448917388916\n",
      "Running Batch 1166, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.426463007926941\n",
      "Running Batch 1167, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.4118708372116089\n",
      "Running Batch 1168, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.425107717514038\n",
      "Running Batch 1169, Epoch 2, Total Tokens: 257\n",
      "Loss: 1.3862360715866089\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1169, Loss: 1.3862360715866089\n",
      "Running Batch 1170, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.3725407123565674\n",
      "Running Batch 1171, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.3527235984802246\n",
      "AVG LOSS: 1.4108018864950629, Epoch: 3\n",
      "Running Batch 0, Epoch 3, Total Tokens: 254\n",
      "Loss: 1.3859624862670898\n",
      "Running Batch 1, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.2455825805664062\n",
      "Running Batch 2, Epoch 3, Total Tokens: 168\n",
      "Loss: 1.2893800735473633\n",
      "Running Batch 3, Epoch 3, Total Tokens: 236\n",
      "Loss: 1.3304511308670044\n",
      "Running Batch 4, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.3006495237350464\n",
      "Running Batch 5, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.2117646932601929\n",
      "Running Batch 6, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.3217569589614868\n",
      "Running Batch 7, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.288307547569275\n",
      "Running Batch 8, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.2902438640594482\n",
      "Running Batch 9, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.3625247478485107\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 9, Loss: 1.3625247478485107\n",
      "Running Batch 10, Epoch 3, Total Tokens: 214\n",
      "Loss: 1.2587510347366333\n",
      "Running Batch 11, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.345503330230713\n",
      "Running Batch 12, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.320013403892517\n",
      "Running Batch 13, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.2669833898544312\n",
      "Running Batch 14, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.3339033126831055\n",
      "Running Batch 15, Epoch 3, Total Tokens: 182\n",
      "Loss: 1.2572053670883179\n",
      "Running Batch 16, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.2721965312957764\n",
      "Running Batch 17, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.3166712522506714\n",
      "Running Batch 18, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.2962915897369385\n",
      "Running Batch 19, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.360209345817566\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 19, Loss: 1.360209345817566\n",
      "Running Batch 20, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.3700273036956787\n",
      "Running Batch 21, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.346775770187378\n",
      "Running Batch 22, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.3044575452804565\n",
      "Running Batch 23, Epoch 3, Total Tokens: 261\n",
      "Loss: 1.344370722770691\n",
      "Running Batch 24, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.3645704984664917\n",
      "Running Batch 25, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3290759325027466\n",
      "Running Batch 26, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.3340096473693848\n",
      "Running Batch 27, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.2915586233139038\n",
      "Running Batch 28, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.2457365989685059\n",
      "Running Batch 29, Epoch 3, Total Tokens: 180\n",
      "Loss: 1.3261643648147583\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 29, Loss: 1.3261643648147583\n",
      "Running Batch 30, Epoch 3, Total Tokens: 257\n",
      "Loss: 1.2384872436523438\n",
      "Running Batch 31, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.2800766229629517\n",
      "Running Batch 32, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.2848609685897827\n",
      "Running Batch 33, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.3909300565719604\n",
      "Running Batch 34, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.240517497062683\n",
      "Running Batch 35, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.2720649242401123\n",
      "Running Batch 36, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.3005802631378174\n",
      "Running Batch 37, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.304935097694397\n",
      "Running Batch 38, Epoch 3, Total Tokens: 203\n",
      "Loss: 1.2706995010375977\n",
      "Running Batch 39, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.411170244216919\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 39, Loss: 1.411170244216919\n",
      "Running Batch 40, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.3070456981658936\n",
      "Running Batch 41, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.29701566696167\n",
      "Running Batch 42, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.3003997802734375\n",
      "Running Batch 43, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.2649316787719727\n",
      "Running Batch 44, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.2777296304702759\n",
      "Running Batch 45, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.3440253734588623\n",
      "Running Batch 46, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.2840327024459839\n",
      "Running Batch 47, Epoch 3, Total Tokens: 572\n",
      "Loss: 1.2923177480697632\n",
      "Running Batch 48, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.329172134399414\n",
      "Running Batch 49, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.3243175745010376\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 49, Loss: 1.3243175745010376\n",
      "Running Batch 50, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.2927650213241577\n",
      "Running Batch 51, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3545434474945068\n",
      "Running Batch 52, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3558712005615234\n",
      "Running Batch 53, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.3062211275100708\n",
      "Running Batch 54, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.3112598657608032\n",
      "Running Batch 55, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.3260183334350586\n",
      "Running Batch 56, Epoch 3, Total Tokens: 254\n",
      "Loss: 1.2329527139663696\n",
      "Running Batch 57, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.2998385429382324\n",
      "Running Batch 58, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.3418768644332886\n",
      "Running Batch 59, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.2864121198654175\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 59, Loss: 1.2864121198654175\n",
      "Running Batch 60, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.3411047458648682\n",
      "Running Batch 61, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.3173836469650269\n",
      "Running Batch 62, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3506438732147217\n",
      "Running Batch 63, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.312349796295166\n",
      "Running Batch 64, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.3396447896957397\n",
      "Running Batch 65, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.3791862726211548\n",
      "Running Batch 66, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.368554711341858\n",
      "Running Batch 67, Epoch 3, Total Tokens: 205\n",
      "Loss: 1.3193360567092896\n",
      "Running Batch 68, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.2846779823303223\n",
      "Running Batch 69, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.2329012155532837\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 69, Loss: 1.2329012155532837\n",
      "Running Batch 70, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.3688859939575195\n",
      "Running Batch 71, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3438713550567627\n",
      "Running Batch 72, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.3760126829147339\n",
      "Running Batch 73, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.3707157373428345\n",
      "Running Batch 74, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.2677539587020874\n",
      "Running Batch 75, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.3752225637435913\n",
      "Running Batch 76, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.2590759992599487\n",
      "Running Batch 77, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.331778883934021\n",
      "Running Batch 78, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.26246976852417\n",
      "Running Batch 79, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.320387840270996\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 79, Loss: 1.320387840270996\n",
      "Running Batch 80, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.3917417526245117\n",
      "Running Batch 81, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.3115946054458618\n",
      "Running Batch 82, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.3673115968704224\n",
      "Running Batch 83, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.358383297920227\n",
      "Running Batch 84, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.2605478763580322\n",
      "Running Batch 85, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.3251376152038574\n",
      "Running Batch 86, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.323119044303894\n",
      "Running Batch 87, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.3234280347824097\n",
      "Running Batch 88, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.4120451211929321\n",
      "Running Batch 89, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.2767177820205688\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 89, Loss: 1.2767177820205688\n",
      "Running Batch 90, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.310907244682312\n",
      "Running Batch 91, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.3873226642608643\n",
      "Running Batch 92, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.3097411394119263\n",
      "Running Batch 93, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.2909467220306396\n",
      "Running Batch 94, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.3285781145095825\n",
      "Running Batch 95, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.2853500843048096\n",
      "Running Batch 96, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.3211265802383423\n",
      "Running Batch 97, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.3531055450439453\n",
      "Running Batch 98, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.3813824653625488\n",
      "Running Batch 99, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3258594274520874\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 99, Loss: 1.3258594274520874\n",
      "Running Batch 100, Epoch 3, Total Tokens: 281\n",
      "Loss: 1.270443081855774\n",
      "Running Batch 101, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.3481166362762451\n",
      "Running Batch 102, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.3264570236206055\n",
      "Running Batch 103, Epoch 3, Total Tokens: 322\n",
      "Loss: 1.215241551399231\n",
      "Running Batch 104, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.3160197734832764\n",
      "Running Batch 105, Epoch 3, Total Tokens: 262\n",
      "Loss: 1.3630943298339844\n",
      "Running Batch 106, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.3450180292129517\n",
      "Running Batch 107, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.34817373752594\n",
      "Running Batch 108, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.288166880607605\n",
      "Running Batch 109, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.3028854131698608\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 109, Loss: 1.3028854131698608\n",
      "Running Batch 110, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.2846683263778687\n",
      "Running Batch 111, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.2917989492416382\n",
      "Running Batch 112, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.1602946519851685\n",
      "Running Batch 113, Epoch 3, Total Tokens: 360\n",
      "Loss: 1.3470969200134277\n",
      "Running Batch 114, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.3235780000686646\n",
      "Running Batch 115, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.3834285736083984\n",
      "Running Batch 116, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.3557854890823364\n",
      "Running Batch 117, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.2606464624404907\n",
      "Running Batch 118, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.2546559572219849\n",
      "Running Batch 119, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.3342481851577759\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 119, Loss: 1.3342481851577759\n",
      "Running Batch 120, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.3028945922851562\n",
      "Running Batch 121, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.2802138328552246\n",
      "Running Batch 122, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.3503552675247192\n",
      "Running Batch 123, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.4137294292449951\n",
      "Running Batch 124, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.313643455505371\n",
      "Running Batch 125, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.2937041521072388\n",
      "Running Batch 126, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.2119609117507935\n",
      "Running Batch 127, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3765192031860352\n",
      "Running Batch 128, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.3582229614257812\n",
      "Running Batch 129, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3697199821472168\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 129, Loss: 1.3697199821472168\n",
      "Running Batch 130, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.2654526233673096\n",
      "Running Batch 131, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.2961264848709106\n",
      "Running Batch 132, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.2291946411132812\n",
      "Running Batch 133, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.3123953342437744\n",
      "Running Batch 134, Epoch 3, Total Tokens: 293\n",
      "Loss: 1.2573765516281128\n",
      "Running Batch 135, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.3034331798553467\n",
      "Running Batch 136, Epoch 3, Total Tokens: 324\n",
      "Loss: 1.2911509275436401\n",
      "Running Batch 137, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.312274694442749\n",
      "Running Batch 138, Epoch 3, Total Tokens: 326\n",
      "Loss: 1.2713404893875122\n",
      "Running Batch 139, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.2707380056381226\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 139, Loss: 1.2707380056381226\n",
      "Running Batch 140, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.3695677518844604\n",
      "Running Batch 141, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.3069837093353271\n",
      "Running Batch 142, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.365543007850647\n",
      "Running Batch 143, Epoch 3, Total Tokens: 273\n",
      "Loss: 1.3218116760253906\n",
      "Running Batch 144, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.2467763423919678\n",
      "Running Batch 145, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.354872465133667\n",
      "Running Batch 146, Epoch 3, Total Tokens: 210\n",
      "Loss: 1.3384164571762085\n",
      "Running Batch 147, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.2655597925186157\n",
      "Running Batch 148, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.3383678197860718\n",
      "Running Batch 149, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.3833409547805786\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 149, Loss: 1.3833409547805786\n",
      "Running Batch 150, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.4005141258239746\n",
      "Running Batch 151, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.3552825450897217\n",
      "Running Batch 152, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.2378820180892944\n",
      "Running Batch 153, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.2514177560806274\n",
      "Running Batch 154, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.3830801248550415\n",
      "Running Batch 155, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.3771542310714722\n",
      "Running Batch 156, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.2514500617980957\n",
      "Running Batch 157, Epoch 3, Total Tokens: 182\n",
      "Loss: 1.382097840309143\n",
      "Running Batch 158, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.3881648778915405\n",
      "Running Batch 159, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.3056589365005493\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 159, Loss: 1.3056589365005493\n",
      "Running Batch 160, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.332282304763794\n",
      "Running Batch 161, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.3633317947387695\n",
      "Running Batch 162, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.3336448669433594\n",
      "Running Batch 163, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.2876713275909424\n",
      "Running Batch 164, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.2640990018844604\n",
      "Running Batch 165, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.3541953563690186\n",
      "Running Batch 166, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.4081069231033325\n",
      "Running Batch 167, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.35299551486969\n",
      "Running Batch 168, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.3289551734924316\n",
      "Running Batch 169, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.2857484817504883\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 169, Loss: 1.2857484817504883\n",
      "Running Batch 170, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.3379846811294556\n",
      "Running Batch 171, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.401634931564331\n",
      "Running Batch 172, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.4132639169692993\n",
      "Running Batch 173, Epoch 3, Total Tokens: 179\n",
      "Loss: 1.3465023040771484\n",
      "Running Batch 174, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.4090948104858398\n",
      "Running Batch 175, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.2534842491149902\n",
      "Running Batch 176, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.3943248987197876\n",
      "Running Batch 177, Epoch 3, Total Tokens: 234\n",
      "Loss: 1.3695991039276123\n",
      "Running Batch 178, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.329867959022522\n",
      "Running Batch 179, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.3260232210159302\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 179, Loss: 1.3260232210159302\n",
      "Running Batch 180, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.3640320301055908\n",
      "Running Batch 181, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.3471224308013916\n",
      "Running Batch 182, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.326694130897522\n",
      "Running Batch 183, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.3307123184204102\n",
      "Running Batch 184, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.2633957862854004\n",
      "Running Batch 185, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.3527284860610962\n",
      "Running Batch 186, Epoch 3, Total Tokens: 287\n",
      "Loss: 1.3888190984725952\n",
      "Running Batch 187, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3428599834442139\n",
      "Running Batch 188, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.3189460039138794\n",
      "Running Batch 189, Epoch 3, Total Tokens: 299\n",
      "Loss: 1.2731796503067017\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 189, Loss: 1.2731796503067017\n",
      "Running Batch 190, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.4092386960983276\n",
      "Running Batch 191, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.334426760673523\n",
      "Running Batch 192, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.3638699054718018\n",
      "Running Batch 193, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.3846944570541382\n",
      "Running Batch 194, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.3248640298843384\n",
      "Running Batch 195, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.3770312070846558\n",
      "Running Batch 196, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.408996343612671\n",
      "Running Batch 197, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.2624800205230713\n",
      "Running Batch 198, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3313980102539062\n",
      "Running Batch 199, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.3681457042694092\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 199, Loss: 1.3681457042694092\n",
      "Running Batch 200, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.3076475858688354\n",
      "Running Batch 201, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.3416180610656738\n",
      "Running Batch 202, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.3067572116851807\n",
      "Running Batch 203, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.3175524473190308\n",
      "Running Batch 204, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3085263967514038\n",
      "Running Batch 205, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.2823905944824219\n",
      "Running Batch 206, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.3493586778640747\n",
      "Running Batch 207, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.3548873662948608\n",
      "Running Batch 208, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.3259294033050537\n",
      "Running Batch 209, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.2895221710205078\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 209, Loss: 1.2895221710205078\n",
      "Running Batch 210, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.2321503162384033\n",
      "Running Batch 211, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.3214092254638672\n",
      "Running Batch 212, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.4608635902404785\n",
      "Running Batch 213, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.3244097232818604\n",
      "Running Batch 214, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.3036195039749146\n",
      "Running Batch 215, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.3126603364944458\n",
      "Running Batch 216, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.3423984050750732\n",
      "Running Batch 217, Epoch 3, Total Tokens: 428\n",
      "Loss: 1.2971080541610718\n",
      "Running Batch 218, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.3850725889205933\n",
      "Running Batch 219, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.37716543674469\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 219, Loss: 1.37716543674469\n",
      "Running Batch 220, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.3338295221328735\n",
      "Running Batch 221, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.3135892152786255\n",
      "Running Batch 222, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.2908278703689575\n",
      "Running Batch 223, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.4405641555786133\n",
      "Running Batch 224, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3494682312011719\n",
      "Running Batch 225, Epoch 3, Total Tokens: 105\n",
      "Loss: 1.3539149761199951\n",
      "Running Batch 226, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.2584731578826904\n",
      "Running Batch 227, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.3729923963546753\n",
      "Running Batch 228, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.3259098529815674\n",
      "Running Batch 229, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.3098949193954468\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 229, Loss: 1.3098949193954468\n",
      "Running Batch 230, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.337785005569458\n",
      "Running Batch 231, Epoch 3, Total Tokens: 206\n",
      "Loss: 1.3517221212387085\n",
      "Running Batch 232, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.3929095268249512\n",
      "Running Batch 233, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.3232849836349487\n",
      "Running Batch 234, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.3598897457122803\n",
      "Running Batch 235, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.4454604387283325\n",
      "Running Batch 236, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.298824429512024\n",
      "Running Batch 237, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.3952773809432983\n",
      "Running Batch 238, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.3540161848068237\n",
      "Running Batch 239, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.2283728122711182\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 239, Loss: 1.2283728122711182\n",
      "Running Batch 240, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.4716975688934326\n",
      "Running Batch 241, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.3126237392425537\n",
      "Running Batch 242, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.3671870231628418\n",
      "Running Batch 243, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.360211968421936\n",
      "Running Batch 244, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.2905975580215454\n",
      "Running Batch 245, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.3112238645553589\n",
      "Running Batch 246, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.3047306537628174\n",
      "Running Batch 247, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.3505141735076904\n",
      "Running Batch 248, Epoch 3, Total Tokens: 201\n",
      "Loss: 1.29788339138031\n",
      "Running Batch 249, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.359767198562622\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 249, Loss: 1.359767198562622\n",
      "Running Batch 250, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.4250619411468506\n",
      "Running Batch 251, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.472973346710205\n",
      "Running Batch 252, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.2994191646575928\n",
      "Running Batch 253, Epoch 3, Total Tokens: 494\n",
      "Loss: 1.3274638652801514\n",
      "Running Batch 254, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.3434083461761475\n",
      "Running Batch 255, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.3648113012313843\n",
      "Running Batch 256, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.2790621519088745\n",
      "Running Batch 257, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.3365038633346558\n",
      "Running Batch 258, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.2473235130310059\n",
      "Running Batch 259, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.440126657485962\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 259, Loss: 1.440126657485962\n",
      "Running Batch 260, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.299917459487915\n",
      "Running Batch 261, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.4247889518737793\n",
      "Running Batch 262, Epoch 3, Total Tokens: 258\n",
      "Loss: 1.3730474710464478\n",
      "Running Batch 263, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.427992582321167\n",
      "Running Batch 264, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.3328031301498413\n",
      "Running Batch 265, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.4658535718917847\n",
      "Running Batch 266, Epoch 3, Total Tokens: 195\n",
      "Loss: 1.6020115613937378\n",
      "Running Batch 267, Epoch 3, Total Tokens: 203\n",
      "Loss: 1.6367968320846558\n",
      "Running Batch 268, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.1696360111236572\n",
      "Running Batch 269, Epoch 3, Total Tokens: 158\n",
      "Loss: 7.192951679229736\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 269, Loss: 7.192951679229736\n",
      "Running Batch 270, Epoch 3, Total Tokens: 126\n",
      "Loss: 4.935114860534668\n",
      "Running Batch 271, Epoch 3, Total Tokens: 134\n",
      "Loss: 4.420472145080566\n",
      "Running Batch 272, Epoch 3, Total Tokens: 133\n",
      "Loss: 4.48305082321167\n",
      "Running Batch 273, Epoch 3, Total Tokens: 148\n",
      "Loss: 4.384024143218994\n",
      "Running Batch 274, Epoch 3, Total Tokens: 143\n",
      "Loss: 4.387295722961426\n",
      "Running Batch 275, Epoch 3, Total Tokens: 132\n",
      "Loss: 4.194087505340576\n",
      "Running Batch 276, Epoch 3, Total Tokens: 219\n",
      "Loss: 4.1851959228515625\n",
      "Running Batch 277, Epoch 3, Total Tokens: 161\n",
      "Loss: 4.138160228729248\n",
      "Running Batch 278, Epoch 3, Total Tokens: 113\n",
      "Loss: 4.172637462615967\n",
      "Running Batch 279, Epoch 3, Total Tokens: 140\n",
      "Loss: 4.056342124938965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 279, Loss: 4.056342124938965\n",
      "Running Batch 280, Epoch 3, Total Tokens: 142\n",
      "Loss: 4.235626697540283\n",
      "Running Batch 281, Epoch 3, Total Tokens: 137\n",
      "Loss: 4.526768207550049\n",
      "Running Batch 282, Epoch 3, Total Tokens: 131\n",
      "Loss: 4.4615960121154785\n",
      "Running Batch 283, Epoch 3, Total Tokens: 157\n",
      "Loss: 4.682523727416992\n",
      "Running Batch 284, Epoch 3, Total Tokens: 131\n",
      "Loss: 4.782668113708496\n",
      "Running Batch 285, Epoch 3, Total Tokens: 133\n",
      "Loss: 4.686586856842041\n",
      "Running Batch 286, Epoch 3, Total Tokens: 152\n",
      "Loss: 4.789081573486328\n",
      "Running Batch 287, Epoch 3, Total Tokens: 142\n",
      "Loss: 4.7126898765563965\n",
      "Running Batch 288, Epoch 3, Total Tokens: 150\n",
      "Loss: 4.967795372009277\n",
      "Running Batch 289, Epoch 3, Total Tokens: 158\n",
      "Loss: 5.758070945739746\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 289, Loss: 5.758070945739746\n",
      "Running Batch 290, Epoch 3, Total Tokens: 115\n",
      "Loss: 8.102263450622559\n",
      "Running Batch 291, Epoch 3, Total Tokens: 153\n",
      "Loss: 4.591736793518066\n",
      "Running Batch 292, Epoch 3, Total Tokens: 138\n",
      "Loss: 4.388858795166016\n",
      "Running Batch 293, Epoch 3, Total Tokens: 150\n",
      "Loss: 4.302153587341309\n",
      "Running Batch 294, Epoch 3, Total Tokens: 126\n",
      "Loss: 4.2229228019714355\n",
      "Running Batch 295, Epoch 3, Total Tokens: 172\n",
      "Loss: 4.0907816886901855\n",
      "Running Batch 296, Epoch 3, Total Tokens: 127\n",
      "Loss: 4.037426948547363\n",
      "Running Batch 297, Epoch 3, Total Tokens: 149\n",
      "Loss: 4.142695426940918\n",
      "Running Batch 298, Epoch 3, Total Tokens: 120\n",
      "Loss: 4.0448832511901855\n",
      "Running Batch 299, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.969810724258423\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 299, Loss: 3.969810724258423\n",
      "Running Batch 300, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.954366683959961\n",
      "Running Batch 301, Epoch 3, Total Tokens: 162\n",
      "Loss: 3.98210072517395\n",
      "Running Batch 302, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.9565794467926025\n",
      "Running Batch 303, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.980311155319214\n",
      "Running Batch 304, Epoch 3, Total Tokens: 133\n",
      "Loss: 4.07229471206665\n",
      "Running Batch 305, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.953385591506958\n",
      "Running Batch 306, Epoch 3, Total Tokens: 228\n",
      "Loss: 3.9367587566375732\n",
      "Running Batch 307, Epoch 3, Total Tokens: 202\n",
      "Loss: 4.0497846603393555\n",
      "Running Batch 308, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.9154961109161377\n",
      "Running Batch 309, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8983564376831055\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 309, Loss: 3.8983564376831055\n",
      "Running Batch 310, Epoch 3, Total Tokens: 188\n",
      "Loss: 3.922773838043213\n",
      "Running Batch 311, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.901190757751465\n",
      "Running Batch 312, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.9838743209838867\n",
      "Running Batch 313, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.868533134460449\n",
      "Running Batch 314, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8882017135620117\n",
      "Running Batch 315, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.992892265319824\n",
      "Running Batch 316, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.9314751625061035\n",
      "Running Batch 317, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.9127204418182373\n",
      "Running Batch 318, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.942962169647217\n",
      "Running Batch 319, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8533031940460205\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 319, Loss: 3.8533031940460205\n",
      "Running Batch 320, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.90755558013916\n",
      "Running Batch 321, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.9248008728027344\n",
      "Running Batch 322, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8589673042297363\n",
      "Running Batch 323, Epoch 3, Total Tokens: 266\n",
      "Loss: 3.8714654445648193\n",
      "Running Batch 324, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.958037853240967\n",
      "Running Batch 325, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.937822103500366\n",
      "Running Batch 326, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.902329683303833\n",
      "Running Batch 327, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8409242630004883\n",
      "Running Batch 328, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9504544734954834\n",
      "Running Batch 329, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8981707096099854\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 329, Loss: 3.8981707096099854\n",
      "Running Batch 330, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.859290599822998\n",
      "Running Batch 331, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.9041738510131836\n",
      "Running Batch 332, Epoch 3, Total Tokens: 109\n",
      "Loss: 3.898963689804077\n",
      "Running Batch 333, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.892137289047241\n",
      "Running Batch 334, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8606903553009033\n",
      "Running Batch 335, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.9222090244293213\n",
      "Running Batch 336, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.907756805419922\n",
      "Running Batch 337, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.888383626937866\n",
      "Running Batch 338, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8568387031555176\n",
      "Running Batch 339, Epoch 3, Total Tokens: 116\n",
      "Loss: 3.9351110458374023\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 339, Loss: 3.9351110458374023\n",
      "Running Batch 340, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.920454502105713\n",
      "Running Batch 341, Epoch 3, Total Tokens: 163\n",
      "Loss: 3.933272123336792\n",
      "Running Batch 342, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.9080138206481934\n",
      "Running Batch 343, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8830578327178955\n",
      "Running Batch 344, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9387764930725098\n",
      "Running Batch 345, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8795132637023926\n",
      "Running Batch 346, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.913151502609253\n",
      "Running Batch 347, Epoch 3, Total Tokens: 170\n",
      "Loss: 3.8161520957946777\n",
      "Running Batch 348, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8344104290008545\n",
      "Running Batch 349, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.885007858276367\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 349, Loss: 3.885007858276367\n",
      "Running Batch 350, Epoch 3, Total Tokens: 186\n",
      "Loss: 3.9427454471588135\n",
      "Running Batch 351, Epoch 3, Total Tokens: 250\n",
      "Loss: 3.8423221111297607\n",
      "Running Batch 352, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8381967544555664\n",
      "Running Batch 353, Epoch 3, Total Tokens: 112\n",
      "Loss: 3.8727595806121826\n",
      "Running Batch 354, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.8357973098754883\n",
      "Running Batch 355, Epoch 3, Total Tokens: 112\n",
      "Loss: 3.9246957302093506\n",
      "Running Batch 356, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8445348739624023\n",
      "Running Batch 357, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.813420057296753\n",
      "Running Batch 358, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.9241271018981934\n",
      "Running Batch 359, Epoch 3, Total Tokens: 108\n",
      "Loss: 3.8623857498168945\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 359, Loss: 3.8623857498168945\n",
      "Running Batch 360, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8955209255218506\n",
      "Running Batch 361, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.896514892578125\n",
      "Running Batch 362, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.843327283859253\n",
      "Running Batch 363, Epoch 3, Total Tokens: 204\n",
      "Loss: 3.876420259475708\n",
      "Running Batch 364, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.815276861190796\n",
      "Running Batch 365, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.892853260040283\n",
      "Running Batch 366, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.8434183597564697\n",
      "Running Batch 367, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.859057664871216\n",
      "Running Batch 368, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8981082439422607\n",
      "Running Batch 369, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8970894813537598\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 369, Loss: 3.8970894813537598\n",
      "Running Batch 370, Epoch 3, Total Tokens: 224\n",
      "Loss: 3.8348450660705566\n",
      "Running Batch 371, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8186185359954834\n",
      "Running Batch 372, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.9361815452575684\n",
      "Running Batch 373, Epoch 3, Total Tokens: 169\n",
      "Loss: 3.903831958770752\n",
      "Running Batch 374, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.847736120223999\n",
      "Running Batch 375, Epoch 3, Total Tokens: 211\n",
      "Loss: 3.892730474472046\n",
      "Running Batch 376, Epoch 3, Total Tokens: 155\n",
      "Loss: 3.8228912353515625\n",
      "Running Batch 377, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8579466342926025\n",
      "Running Batch 378, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8699355125427246\n",
      "Running Batch 379, Epoch 3, Total Tokens: 165\n",
      "Loss: 3.8086721897125244\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 379, Loss: 3.8086721897125244\n",
      "Running Batch 380, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.843088388442993\n",
      "Running Batch 381, Epoch 3, Total Tokens: 188\n",
      "Loss: 3.814275026321411\n",
      "Running Batch 382, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8439290523529053\n",
      "Running Batch 383, Epoch 3, Total Tokens: 173\n",
      "Loss: 3.856877088546753\n",
      "Running Batch 384, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.7904083728790283\n",
      "Running Batch 385, Epoch 3, Total Tokens: 117\n",
      "Loss: 3.8928334712982178\n",
      "Running Batch 386, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.9099009037017822\n",
      "Running Batch 387, Epoch 3, Total Tokens: 254\n",
      "Loss: 3.953334093093872\n",
      "Running Batch 388, Epoch 3, Total Tokens: 197\n",
      "Loss: 3.912745475769043\n",
      "Running Batch 389, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.855680227279663\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 389, Loss: 3.855680227279663\n",
      "Running Batch 390, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.877171754837036\n",
      "Running Batch 391, Epoch 3, Total Tokens: 109\n",
      "Loss: 3.8685343265533447\n",
      "Running Batch 392, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.811583995819092\n",
      "Running Batch 393, Epoch 3, Total Tokens: 224\n",
      "Loss: 3.86040997505188\n",
      "Running Batch 394, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8539552688598633\n",
      "Running Batch 395, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8292901515960693\n",
      "Running Batch 396, Epoch 3, Total Tokens: 372\n",
      "Loss: 3.778965711593628\n",
      "Running Batch 397, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.9521985054016113\n",
      "Running Batch 398, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8258187770843506\n",
      "Running Batch 399, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.899552345275879\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 399, Loss: 3.899552345275879\n",
      "Running Batch 400, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.9399399757385254\n",
      "Running Batch 401, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8648390769958496\n",
      "Running Batch 402, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8026039600372314\n",
      "Running Batch 403, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.959183692932129\n",
      "Running Batch 404, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.8291454315185547\n",
      "Running Batch 405, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.751969337463379\n",
      "Running Batch 406, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.8382201194763184\n",
      "Running Batch 407, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8521885871887207\n",
      "Running Batch 408, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.872723340988159\n",
      "Running Batch 409, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.7671499252319336\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 409, Loss: 3.7671499252319336\n",
      "Running Batch 410, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.890410900115967\n",
      "Running Batch 411, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.8813955783843994\n",
      "Running Batch 412, Epoch 3, Total Tokens: 452\n",
      "Loss: 3.9580111503601074\n",
      "Running Batch 413, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.881524085998535\n",
      "Running Batch 414, Epoch 3, Total Tokens: 172\n",
      "Loss: 3.82900071144104\n",
      "Running Batch 415, Epoch 3, Total Tokens: 158\n",
      "Loss: 3.8659770488739014\n",
      "Running Batch 416, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8900935649871826\n",
      "Running Batch 417, Epoch 3, Total Tokens: 155\n",
      "Loss: 3.824977397918701\n",
      "Running Batch 418, Epoch 3, Total Tokens: 113\n",
      "Loss: 3.8393850326538086\n",
      "Running Batch 419, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.839399576187134\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 419, Loss: 3.839399576187134\n",
      "Running Batch 420, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8415215015411377\n",
      "Running Batch 421, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.782626152038574\n",
      "Running Batch 422, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.8492658138275146\n",
      "Running Batch 423, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.892570972442627\n",
      "Running Batch 424, Epoch 3, Total Tokens: 172\n",
      "Loss: 3.894611120223999\n",
      "Running Batch 425, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.927588939666748\n",
      "Running Batch 426, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8669991493225098\n",
      "Running Batch 427, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8131275177001953\n",
      "Running Batch 428, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8831517696380615\n",
      "Running Batch 429, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.8816170692443848\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 429, Loss: 3.8816170692443848\n",
      "Running Batch 430, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.88191294670105\n",
      "Running Batch 431, Epoch 3, Total Tokens: 108\n",
      "Loss: 3.9448654651641846\n",
      "Running Batch 432, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8548226356506348\n",
      "Running Batch 433, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.923290491104126\n",
      "Running Batch 434, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.874786853790283\n",
      "Running Batch 435, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.811109781265259\n",
      "Running Batch 436, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.910620927810669\n",
      "Running Batch 437, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.864677667617798\n",
      "Running Batch 438, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8485798835754395\n",
      "Running Batch 439, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.912301778793335\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 439, Loss: 3.912301778793335\n",
      "Running Batch 440, Epoch 3, Total Tokens: 231\n",
      "Loss: 3.9023523330688477\n",
      "Running Batch 441, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8377418518066406\n",
      "Running Batch 442, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8645520210266113\n",
      "Running Batch 443, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.850123167037964\n",
      "Running Batch 444, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.7946701049804688\n",
      "Running Batch 445, Epoch 3, Total Tokens: 217\n",
      "Loss: 3.792158842086792\n",
      "Running Batch 446, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.8812108039855957\n",
      "Running Batch 447, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.878598690032959\n",
      "Running Batch 448, Epoch 3, Total Tokens: 176\n",
      "Loss: 3.778078317642212\n",
      "Running Batch 449, Epoch 3, Total Tokens: 187\n",
      "Loss: 3.929764747619629\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 449, Loss: 3.929764747619629\n",
      "Running Batch 450, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8112587928771973\n",
      "Running Batch 451, Epoch 3, Total Tokens: 122\n",
      "Loss: 3.8919243812561035\n",
      "Running Batch 452, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.870452880859375\n",
      "Running Batch 453, Epoch 3, Total Tokens: 113\n",
      "Loss: 3.872619390487671\n",
      "Running Batch 454, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.8836252689361572\n",
      "Running Batch 455, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8485100269317627\n",
      "Running Batch 456, Epoch 3, Total Tokens: 116\n",
      "Loss: 3.8833439350128174\n",
      "Running Batch 457, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.883880853652954\n",
      "Running Batch 458, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.810283899307251\n",
      "Running Batch 459, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.864820718765259\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 459, Loss: 3.864820718765259\n",
      "Running Batch 460, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.9344427585601807\n",
      "Running Batch 461, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.8732330799102783\n",
      "Running Batch 462, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.932013511657715\n",
      "Running Batch 463, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.895752429962158\n",
      "Running Batch 464, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8726375102996826\n",
      "Running Batch 465, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8226521015167236\n",
      "Running Batch 466, Epoch 3, Total Tokens: 274\n",
      "Loss: 3.7658796310424805\n",
      "Running Batch 467, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.836221933364868\n",
      "Running Batch 468, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.844857692718506\n",
      "Running Batch 469, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8044228553771973\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 469, Loss: 3.8044228553771973\n",
      "Running Batch 470, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.85361647605896\n",
      "Running Batch 471, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.9127700328826904\n",
      "Running Batch 472, Epoch 3, Total Tokens: 117\n",
      "Loss: 3.8936126232147217\n",
      "Running Batch 473, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.830850124359131\n",
      "Running Batch 474, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.880141496658325\n",
      "Running Batch 475, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.9102554321289062\n",
      "Running Batch 476, Epoch 3, Total Tokens: 205\n",
      "Loss: 3.895589590072632\n",
      "Running Batch 477, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8606059551239014\n",
      "Running Batch 478, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.8523173332214355\n",
      "Running Batch 479, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.786923885345459\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 479, Loss: 3.786923885345459\n",
      "Running Batch 480, Epoch 3, Total Tokens: 202\n",
      "Loss: 3.9202051162719727\n",
      "Running Batch 481, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.856715679168701\n",
      "Running Batch 482, Epoch 3, Total Tokens: 155\n",
      "Loss: 3.8816728591918945\n",
      "Running Batch 483, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.8639092445373535\n",
      "Running Batch 484, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8063509464263916\n",
      "Running Batch 485, Epoch 3, Total Tokens: 110\n",
      "Loss: 3.8886430263519287\n",
      "Running Batch 486, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.854581594467163\n",
      "Running Batch 487, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.926588535308838\n",
      "Running Batch 488, Epoch 3, Total Tokens: 225\n",
      "Loss: 3.831514835357666\n",
      "Running Batch 489, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.887873649597168\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 489, Loss: 3.887873649597168\n",
      "Running Batch 490, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.85146164894104\n",
      "Running Batch 491, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.8885624408721924\n",
      "Running Batch 492, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.829078435897827\n",
      "Running Batch 493, Epoch 3, Total Tokens: 111\n",
      "Loss: 3.8157877922058105\n",
      "Running Batch 494, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.929387092590332\n",
      "Running Batch 495, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.806685209274292\n",
      "Running Batch 496, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8075475692749023\n",
      "Running Batch 497, Epoch 3, Total Tokens: 174\n",
      "Loss: 3.8720321655273438\n",
      "Running Batch 498, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8398663997650146\n",
      "Running Batch 499, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.846837282180786\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 499, Loss: 3.846837282180786\n",
      "Running Batch 500, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8368120193481445\n",
      "Running Batch 501, Epoch 3, Total Tokens: 285\n",
      "Loss: 3.835482597351074\n",
      "Running Batch 502, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8636319637298584\n",
      "Running Batch 503, Epoch 3, Total Tokens: 171\n",
      "Loss: 3.8868167400360107\n",
      "Running Batch 504, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.833399534225464\n",
      "Running Batch 505, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.894193172454834\n",
      "Running Batch 506, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.9657211303710938\n",
      "Running Batch 507, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.816746473312378\n",
      "Running Batch 508, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.817570447921753\n",
      "Running Batch 509, Epoch 3, Total Tokens: 118\n",
      "Loss: 3.8162789344787598\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 509, Loss: 3.8162789344787598\n",
      "Running Batch 510, Epoch 3, Total Tokens: 231\n",
      "Loss: 3.7778868675231934\n",
      "Running Batch 511, Epoch 3, Total Tokens: 114\n",
      "Loss: 3.879551649093628\n",
      "Running Batch 512, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.9312734603881836\n",
      "Running Batch 513, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8799421787261963\n",
      "Running Batch 514, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.776777744293213\n",
      "Running Batch 515, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8483052253723145\n",
      "Running Batch 516, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.7945947647094727\n",
      "Running Batch 517, Epoch 3, Total Tokens: 221\n",
      "Loss: 3.828819513320923\n",
      "Running Batch 518, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.844799280166626\n",
      "Running Batch 519, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.9214742183685303\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 519, Loss: 3.9214742183685303\n",
      "Running Batch 520, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8595006465911865\n",
      "Running Batch 521, Epoch 3, Total Tokens: 186\n",
      "Loss: 3.857766628265381\n",
      "Running Batch 522, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8498194217681885\n",
      "Running Batch 523, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.771867513656616\n",
      "Running Batch 524, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.8625171184539795\n",
      "Running Batch 525, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8969709873199463\n",
      "Running Batch 526, Epoch 3, Total Tokens: 97\n",
      "Loss: 3.793609142303467\n",
      "Running Batch 527, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8476836681365967\n",
      "Running Batch 528, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.914759874343872\n",
      "Running Batch 529, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.862053632736206\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 529, Loss: 3.862053632736206\n",
      "Running Batch 530, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8573756217956543\n",
      "Running Batch 531, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8966176509857178\n",
      "Running Batch 532, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8872222900390625\n",
      "Running Batch 533, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.837135076522827\n",
      "Running Batch 534, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.846773386001587\n",
      "Running Batch 535, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.866821527481079\n",
      "Running Batch 536, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8581769466400146\n",
      "Running Batch 537, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.7967944145202637\n",
      "Running Batch 538, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9550087451934814\n",
      "Running Batch 539, Epoch 3, Total Tokens: 384\n",
      "Loss: 3.8421390056610107\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 539, Loss: 3.8421390056610107\n",
      "Running Batch 540, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.8452844619750977\n",
      "Running Batch 541, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8381073474884033\n",
      "Running Batch 542, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8870134353637695\n",
      "Running Batch 543, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.828615427017212\n",
      "Running Batch 544, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.854201316833496\n",
      "Running Batch 545, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8937203884124756\n",
      "Running Batch 546, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.8952505588531494\n",
      "Running Batch 547, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.9382996559143066\n",
      "Running Batch 548, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.903440237045288\n",
      "Running Batch 549, Epoch 3, Total Tokens: 340\n",
      "Loss: 3.9250996112823486\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 549, Loss: 3.9250996112823486\n",
      "Running Batch 550, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.969677448272705\n",
      "Running Batch 551, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.9351844787597656\n",
      "Running Batch 552, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.9294931888580322\n",
      "Running Batch 553, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.9564785957336426\n",
      "Running Batch 554, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.938291549682617\n",
      "Running Batch 555, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8997607231140137\n",
      "Running Batch 556, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8607277870178223\n",
      "Running Batch 557, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.9028496742248535\n",
      "Running Batch 558, Epoch 3, Total Tokens: 169\n",
      "Loss: 3.861166477203369\n",
      "Running Batch 559, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.9108164310455322\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 559, Loss: 3.9108164310455322\n",
      "Running Batch 560, Epoch 3, Total Tokens: 294\n",
      "Loss: 3.8835484981536865\n",
      "Running Batch 561, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8578948974609375\n",
      "Running Batch 562, Epoch 3, Total Tokens: 267\n",
      "Loss: 3.903657913208008\n",
      "Running Batch 563, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9377517700195312\n",
      "Running Batch 564, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.9263596534729004\n",
      "Running Batch 565, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.9148852825164795\n",
      "Running Batch 566, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.932008743286133\n",
      "Running Batch 567, Epoch 3, Total Tokens: 223\n",
      "Loss: 3.8451249599456787\n",
      "Running Batch 568, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8951313495635986\n",
      "Running Batch 569, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.960019588470459\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 569, Loss: 3.960019588470459\n",
      "Running Batch 570, Epoch 3, Total Tokens: 237\n",
      "Loss: 3.9817073345184326\n",
      "Running Batch 571, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.7736382484436035\n",
      "Running Batch 572, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8756825923919678\n",
      "Running Batch 573, Epoch 3, Total Tokens: 160\n",
      "Loss: 3.902689218521118\n",
      "Running Batch 574, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8139421939849854\n",
      "Running Batch 575, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8487844467163086\n",
      "Running Batch 576, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.95963191986084\n",
      "Running Batch 577, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8437459468841553\n",
      "Running Batch 578, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8859469890594482\n",
      "Running Batch 579, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8643646240234375\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 579, Loss: 3.8643646240234375\n",
      "Running Batch 580, Epoch 3, Total Tokens: 174\n",
      "Loss: 3.8595221042633057\n",
      "Running Batch 581, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.787508010864258\n",
      "Running Batch 582, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.846292018890381\n",
      "Running Batch 583, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8752965927124023\n",
      "Running Batch 584, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.855302572250366\n",
      "Running Batch 585, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.855313777923584\n",
      "Running Batch 586, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.892146110534668\n",
      "Running Batch 587, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.8790745735168457\n",
      "Running Batch 588, Epoch 3, Total Tokens: 624\n",
      "Loss: 3.920246124267578\n",
      "Running Batch 589, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.910193681716919\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 589, Loss: 3.910193681716919\n",
      "Running Batch 590, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.8729515075683594\n",
      "Running Batch 591, Epoch 3, Total Tokens: 185\n",
      "Loss: 3.9042534828186035\n",
      "Running Batch 592, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.825186014175415\n",
      "Running Batch 593, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.950312852859497\n",
      "Running Batch 594, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.8852853775024414\n",
      "Running Batch 595, Epoch 3, Total Tokens: 228\n",
      "Loss: 3.8280231952667236\n",
      "Running Batch 596, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.844996690750122\n",
      "Running Batch 597, Epoch 3, Total Tokens: 251\n",
      "Loss: 3.833179235458374\n",
      "Running Batch 598, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.902428388595581\n",
      "Running Batch 599, Epoch 3, Total Tokens: 179\n",
      "Loss: 3.8592689037323\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 599, Loss: 3.8592689037323\n",
      "Running Batch 600, Epoch 3, Total Tokens: 160\n",
      "Loss: 3.8319807052612305\n",
      "Running Batch 601, Epoch 3, Total Tokens: 380\n",
      "Loss: 3.896000623703003\n",
      "Running Batch 602, Epoch 3, Total Tokens: 164\n",
      "Loss: 3.8592467308044434\n",
      "Running Batch 603, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8082056045532227\n",
      "Running Batch 604, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.886382579803467\n",
      "Running Batch 605, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.9273877143859863\n",
      "Running Batch 606, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9139058589935303\n",
      "Running Batch 607, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8837180137634277\n",
      "Running Batch 608, Epoch 3, Total Tokens: 299\n",
      "Loss: 3.856045961380005\n",
      "Running Batch 609, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.883303165435791\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 609, Loss: 3.883303165435791\n",
      "Running Batch 610, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.8729987144470215\n",
      "Running Batch 611, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8818960189819336\n",
      "Running Batch 612, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.855069637298584\n",
      "Running Batch 613, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.851487636566162\n",
      "Running Batch 614, Epoch 3, Total Tokens: 122\n",
      "Loss: 3.929257869720459\n",
      "Running Batch 615, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8151047229766846\n",
      "Running Batch 616, Epoch 3, Total Tokens: 173\n",
      "Loss: 3.918198585510254\n",
      "Running Batch 617, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.947209596633911\n",
      "Running Batch 618, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.9060347080230713\n",
      "Running Batch 619, Epoch 3, Total Tokens: 210\n",
      "Loss: 3.8999111652374268\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 619, Loss: 3.8999111652374268\n",
      "Running Batch 620, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.785142660140991\n",
      "Running Batch 621, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8850553035736084\n",
      "Running Batch 622, Epoch 3, Total Tokens: 220\n",
      "Loss: 3.8174681663513184\n",
      "Running Batch 623, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8546805381774902\n",
      "Running Batch 624, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.831803321838379\n",
      "Running Batch 625, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.829730272293091\n",
      "Running Batch 626, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8909952640533447\n",
      "Running Batch 627, Epoch 3, Total Tokens: 220\n",
      "Loss: 3.7993364334106445\n",
      "Running Batch 628, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.806662082672119\n",
      "Running Batch 629, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8229939937591553\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 629, Loss: 3.8229939937591553\n",
      "Running Batch 630, Epoch 3, Total Tokens: 185\n",
      "Loss: 3.816418409347534\n",
      "Running Batch 631, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.8528499603271484\n",
      "Running Batch 632, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8150794506073\n",
      "Running Batch 633, Epoch 3, Total Tokens: 202\n",
      "Loss: 3.8525917530059814\n",
      "Running Batch 634, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8244173526763916\n",
      "Running Batch 635, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.9411206245422363\n",
      "Running Batch 636, Epoch 3, Total Tokens: 163\n",
      "Loss: 3.934622287750244\n",
      "Running Batch 637, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.806032657623291\n",
      "Running Batch 638, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.850235939025879\n",
      "Running Batch 639, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8228440284729004\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 639, Loss: 3.8228440284729004\n",
      "Running Batch 640, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.81860089302063\n",
      "Running Batch 641, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.85917067527771\n",
      "Running Batch 642, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.862309694290161\n",
      "Running Batch 643, Epoch 3, Total Tokens: 164\n",
      "Loss: 3.8940837383270264\n",
      "Running Batch 644, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8458144664764404\n",
      "Running Batch 645, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.8455007076263428\n",
      "Running Batch 646, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8356149196624756\n",
      "Running Batch 647, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.8303110599517822\n",
      "Running Batch 648, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.781273126602173\n",
      "Running Batch 649, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8407950401306152\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 649, Loss: 3.8407950401306152\n",
      "Running Batch 650, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8335227966308594\n",
      "Running Batch 651, Epoch 3, Total Tokens: 162\n",
      "Loss: 3.8213579654693604\n",
      "Running Batch 652, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8524513244628906\n",
      "Running Batch 653, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8024094104766846\n",
      "Running Batch 654, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.895876884460449\n",
      "Running Batch 655, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8577561378479004\n",
      "Running Batch 656, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.824176788330078\n",
      "Running Batch 657, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.855977773666382\n",
      "Running Batch 658, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.9290106296539307\n",
      "Running Batch 659, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.8912203311920166\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 659, Loss: 3.8912203311920166\n",
      "Running Batch 660, Epoch 3, Total Tokens: 234\n",
      "Loss: 3.8061742782592773\n",
      "Running Batch 661, Epoch 3, Total Tokens: 187\n",
      "Loss: 3.8433549404144287\n",
      "Running Batch 662, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.894075632095337\n",
      "Running Batch 663, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8678181171417236\n",
      "Running Batch 664, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.8662960529327393\n",
      "Running Batch 665, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.7997689247131348\n",
      "Running Batch 666, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.9143216609954834\n",
      "Running Batch 667, Epoch 3, Total Tokens: 116\n",
      "Loss: 3.8387935161590576\n",
      "Running Batch 668, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.872152805328369\n",
      "Running Batch 669, Epoch 3, Total Tokens: 118\n",
      "Loss: 3.861175775527954\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 669, Loss: 3.861175775527954\n",
      "Running Batch 670, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.897702693939209\n",
      "Running Batch 671, Epoch 3, Total Tokens: 112\n",
      "Loss: 3.9313712120056152\n",
      "Running Batch 672, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8262665271759033\n",
      "Running Batch 673, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.866464853286743\n",
      "Running Batch 674, Epoch 3, Total Tokens: 155\n",
      "Loss: 3.8644680976867676\n",
      "Running Batch 675, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8828697204589844\n",
      "Running Batch 676, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.806303024291992\n",
      "Running Batch 677, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.7967021465301514\n",
      "Running Batch 678, Epoch 3, Total Tokens: 106\n",
      "Loss: 3.901467800140381\n",
      "Running Batch 679, Epoch 3, Total Tokens: 334\n",
      "Loss: 3.921370506286621\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 679, Loss: 3.921370506286621\n",
      "Running Batch 680, Epoch 3, Total Tokens: 241\n",
      "Loss: 3.8830807209014893\n",
      "Running Batch 681, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9568889141082764\n",
      "Running Batch 682, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.89837384223938\n",
      "Running Batch 683, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.8651087284088135\n",
      "Running Batch 684, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.84330153465271\n",
      "Running Batch 685, Epoch 3, Total Tokens: 162\n",
      "Loss: 3.8079075813293457\n",
      "Running Batch 686, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.782731294631958\n",
      "Running Batch 687, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.9174773693084717\n",
      "Running Batch 688, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.817805528640747\n",
      "Running Batch 689, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.80307674407959\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 689, Loss: 3.80307674407959\n",
      "Running Batch 690, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.827561855316162\n",
      "Running Batch 691, Epoch 3, Total Tokens: 286\n",
      "Loss: 3.790432929992676\n",
      "Running Batch 692, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8687026500701904\n",
      "Running Batch 693, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8875744342803955\n",
      "Running Batch 694, Epoch 3, Total Tokens: 361\n",
      "Loss: 3.8932945728302\n",
      "Running Batch 695, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.861999750137329\n",
      "Running Batch 696, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8662526607513428\n",
      "Running Batch 697, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.791952610015869\n",
      "Running Batch 698, Epoch 3, Total Tokens: 188\n",
      "Loss: 3.83463454246521\n",
      "Running Batch 699, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8340442180633545\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 699, Loss: 3.8340442180633545\n",
      "Running Batch 700, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.850011110305786\n",
      "Running Batch 701, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8637049198150635\n",
      "Running Batch 702, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.818136215209961\n",
      "Running Batch 703, Epoch 3, Total Tokens: 187\n",
      "Loss: 3.8781039714813232\n",
      "Running Batch 704, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8763482570648193\n",
      "Running Batch 705, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.820124864578247\n",
      "Running Batch 706, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.85617995262146\n",
      "Running Batch 707, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.893157720565796\n",
      "Running Batch 708, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8582122325897217\n",
      "Running Batch 709, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.7911252975463867\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 709, Loss: 3.7911252975463867\n",
      "Running Batch 710, Epoch 3, Total Tokens: 186\n",
      "Loss: 3.8623437881469727\n",
      "Running Batch 711, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.7862939834594727\n",
      "Running Batch 712, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.77339243888855\n",
      "Running Batch 713, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8809401988983154\n",
      "Running Batch 714, Epoch 3, Total Tokens: 182\n",
      "Loss: 3.8401050567626953\n",
      "Running Batch 715, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8683269023895264\n",
      "Running Batch 716, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8604447841644287\n",
      "Running Batch 717, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8456082344055176\n",
      "Running Batch 718, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.885394811630249\n",
      "Running Batch 719, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.9229397773742676\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 719, Loss: 3.9229397773742676\n",
      "Running Batch 720, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.863018035888672\n",
      "Running Batch 721, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.79356050491333\n",
      "Running Batch 722, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8001925945281982\n",
      "Running Batch 723, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.8409481048583984\n",
      "Running Batch 724, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8479063510894775\n",
      "Running Batch 725, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8302664756774902\n",
      "Running Batch 726, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8737521171569824\n",
      "Running Batch 727, Epoch 3, Total Tokens: 162\n",
      "Loss: 3.7862441539764404\n",
      "Running Batch 728, Epoch 3, Total Tokens: 184\n",
      "Loss: 3.8651487827301025\n",
      "Running Batch 729, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.831280469894409\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 729, Loss: 3.831280469894409\n",
      "Running Batch 730, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.8701674938201904\n",
      "Running Batch 731, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.884225606918335\n",
      "Running Batch 732, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8804850578308105\n",
      "Running Batch 733, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8385369777679443\n",
      "Running Batch 734, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.840512275695801\n",
      "Running Batch 735, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8715202808380127\n",
      "Running Batch 736, Epoch 3, Total Tokens: 162\n",
      "Loss: 3.8675670623779297\n",
      "Running Batch 737, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.7992467880249023\n",
      "Running Batch 738, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.863247871398926\n",
      "Running Batch 739, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8517494201660156\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 739, Loss: 3.8517494201660156\n",
      "Running Batch 740, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.8377938270568848\n",
      "Running Batch 741, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.7829344272613525\n",
      "Running Batch 742, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.81210994720459\n",
      "Running Batch 743, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.819819688796997\n",
      "Running Batch 744, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8372905254364014\n",
      "Running Batch 745, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.783151388168335\n",
      "Running Batch 746, Epoch 3, Total Tokens: 168\n",
      "Loss: 3.853339433670044\n",
      "Running Batch 747, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.848520278930664\n",
      "Running Batch 748, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8272323608398438\n",
      "Running Batch 749, Epoch 3, Total Tokens: 527\n",
      "Loss: 3.858379602432251\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 749, Loss: 3.858379602432251\n",
      "Running Batch 750, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8250834941864014\n",
      "Running Batch 751, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.832517147064209\n",
      "Running Batch 752, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.7736074924468994\n",
      "Running Batch 753, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.7698655128479004\n",
      "Running Batch 754, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.850977897644043\n",
      "Running Batch 755, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.8460121154785156\n",
      "Running Batch 756, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8421506881713867\n",
      "Running Batch 757, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8305249214172363\n",
      "Running Batch 758, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.885756492614746\n",
      "Running Batch 759, Epoch 3, Total Tokens: 195\n",
      "Loss: 3.8723037242889404\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 759, Loss: 3.8723037242889404\n",
      "Running Batch 760, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.7782022953033447\n",
      "Running Batch 761, Epoch 3, Total Tokens: 174\n",
      "Loss: 3.811332941055298\n",
      "Running Batch 762, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.839397430419922\n",
      "Running Batch 763, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8045265674591064\n",
      "Running Batch 764, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.956941604614258\n",
      "Running Batch 765, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8431248664855957\n",
      "Running Batch 766, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.8495867252349854\n",
      "Running Batch 767, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.811145305633545\n",
      "Running Batch 768, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8129611015319824\n",
      "Running Batch 769, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.867136240005493\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 769, Loss: 3.867136240005493\n",
      "Running Batch 770, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.7986655235290527\n",
      "Running Batch 771, Epoch 3, Total Tokens: 114\n",
      "Loss: 3.8545844554901123\n",
      "Running Batch 772, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.7845773696899414\n",
      "Running Batch 773, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8983728885650635\n",
      "Running Batch 774, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.7945003509521484\n",
      "Running Batch 775, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.916585683822632\n",
      "Running Batch 776, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.858720302581787\n",
      "Running Batch 777, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8631579875946045\n",
      "Running Batch 778, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8105735778808594\n",
      "Running Batch 779, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.787595748901367\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 779, Loss: 3.787595748901367\n",
      "Running Batch 780, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.8490731716156006\n",
      "Running Batch 781, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.7957763671875\n",
      "Running Batch 782, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.919684410095215\n",
      "Running Batch 783, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.7951414585113525\n",
      "Running Batch 784, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.8301541805267334\n",
      "Running Batch 785, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.813861846923828\n",
      "Running Batch 786, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.906808614730835\n",
      "Running Batch 787, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.7892680168151855\n",
      "Running Batch 788, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8069300651550293\n",
      "Running Batch 789, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8499104976654053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 789, Loss: 3.8499104976654053\n",
      "Running Batch 790, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8052597045898438\n",
      "Running Batch 791, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8646998405456543\n",
      "Running Batch 792, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.864029884338379\n",
      "Running Batch 793, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.843301296234131\n",
      "Running Batch 794, Epoch 3, Total Tokens: 116\n",
      "Loss: 3.8833024501800537\n",
      "Running Batch 795, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8191254138946533\n",
      "Running Batch 796, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.898392677307129\n",
      "Running Batch 797, Epoch 3, Total Tokens: 117\n",
      "Loss: 3.896505832672119\n",
      "Running Batch 798, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.8905253410339355\n",
      "Running Batch 799, Epoch 3, Total Tokens: 158\n",
      "Loss: 3.8553404808044434\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 799, Loss: 3.8553404808044434\n",
      "Running Batch 800, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.7881031036376953\n",
      "Running Batch 801, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8271167278289795\n",
      "Running Batch 802, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8885414600372314\n",
      "Running Batch 803, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8156487941741943\n",
      "Running Batch 804, Epoch 3, Total Tokens: 178\n",
      "Loss: 3.8553097248077393\n",
      "Running Batch 805, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.8622689247131348\n",
      "Running Batch 806, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.872704267501831\n",
      "Running Batch 807, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8405046463012695\n",
      "Running Batch 808, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.825690269470215\n",
      "Running Batch 809, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.849639415740967\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 809, Loss: 3.849639415740967\n",
      "Running Batch 810, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8670153617858887\n",
      "Running Batch 811, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.82893705368042\n",
      "Running Batch 812, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.7887613773345947\n",
      "Running Batch 813, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.810472011566162\n",
      "Running Batch 814, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.9472575187683105\n",
      "Running Batch 815, Epoch 3, Total Tokens: 178\n",
      "Loss: 3.8451035022735596\n",
      "Running Batch 816, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8265609741210938\n",
      "Running Batch 817, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.885638475418091\n",
      "Running Batch 818, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.7648849487304688\n",
      "Running Batch 819, Epoch 3, Total Tokens: 224\n",
      "Loss: 3.8448128700256348\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 819, Loss: 3.8448128700256348\n",
      "Running Batch 820, Epoch 3, Total Tokens: 568\n",
      "Loss: 3.7903919219970703\n",
      "Running Batch 821, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8871257305145264\n",
      "Running Batch 822, Epoch 3, Total Tokens: 357\n",
      "Loss: 3.93461537361145\n",
      "Running Batch 823, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.7342939376831055\n",
      "Running Batch 824, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8708431720733643\n",
      "Running Batch 825, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8095507621765137\n",
      "Running Batch 826, Epoch 3, Total Tokens: 107\n",
      "Loss: 3.8996379375457764\n",
      "Running Batch 827, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.769516944885254\n",
      "Running Batch 828, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.806015968322754\n",
      "Running Batch 829, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.785745143890381\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 829, Loss: 3.785745143890381\n",
      "Running Batch 830, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.7964022159576416\n",
      "Running Batch 831, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.821708917617798\n",
      "Running Batch 832, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.86453914642334\n",
      "Running Batch 833, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.758380651473999\n",
      "Running Batch 834, Epoch 3, Total Tokens: 236\n",
      "Loss: 3.861971616744995\n",
      "Running Batch 835, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.7842142581939697\n",
      "Running Batch 836, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.815063953399658\n",
      "Running Batch 837, Epoch 3, Total Tokens: 281\n",
      "Loss: 3.90675950050354\n",
      "Running Batch 838, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.7770326137542725\n",
      "Running Batch 839, Epoch 3, Total Tokens: 112\n",
      "Loss: 3.8524534702301025\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 839, Loss: 3.8524534702301025\n",
      "Running Batch 840, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.8953521251678467\n",
      "Running Batch 841, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8937392234802246\n",
      "Running Batch 842, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8618693351745605\n",
      "Running Batch 843, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.8347315788269043\n",
      "Running Batch 844, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.803558349609375\n",
      "Running Batch 845, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8746187686920166\n",
      "Running Batch 846, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8599064350128174\n",
      "Running Batch 847, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.859351634979248\n",
      "Running Batch 848, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8430376052856445\n",
      "Running Batch 849, Epoch 3, Total Tokens: 166\n",
      "Loss: 3.8012309074401855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 849, Loss: 3.8012309074401855\n",
      "Running Batch 850, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8223063945770264\n",
      "Running Batch 851, Epoch 3, Total Tokens: 244\n",
      "Loss: 3.864896297454834\n",
      "Running Batch 852, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.7984163761138916\n",
      "Running Batch 853, Epoch 3, Total Tokens: 167\n",
      "Loss: 3.8072316646575928\n",
      "Running Batch 854, Epoch 3, Total Tokens: 296\n",
      "Loss: 3.7534990310668945\n",
      "Running Batch 855, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8372673988342285\n",
      "Running Batch 856, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8163368701934814\n",
      "Running Batch 857, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.756850004196167\n",
      "Running Batch 858, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.8894543647766113\n",
      "Running Batch 859, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.8355257511138916\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 859, Loss: 3.8355257511138916\n",
      "Running Batch 860, Epoch 3, Total Tokens: 118\n",
      "Loss: 3.8638758659362793\n",
      "Running Batch 861, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.814793348312378\n",
      "Running Batch 862, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.7903480529785156\n",
      "Running Batch 863, Epoch 3, Total Tokens: 111\n",
      "Loss: 3.8598880767822266\n",
      "Running Batch 864, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.872095823287964\n",
      "Running Batch 865, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8517396450042725\n",
      "Running Batch 866, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.855238914489746\n",
      "Running Batch 867, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8603017330169678\n",
      "Running Batch 868, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8335957527160645\n",
      "Running Batch 869, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8643484115600586\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 869, Loss: 3.8643484115600586\n",
      "Running Batch 870, Epoch 3, Total Tokens: 220\n",
      "Loss: 3.7758076190948486\n",
      "Running Batch 871, Epoch 3, Total Tokens: 266\n",
      "Loss: 3.8494081497192383\n",
      "Running Batch 872, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.879796266555786\n",
      "Running Batch 873, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.8519656658172607\n",
      "Running Batch 874, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8138115406036377\n",
      "Running Batch 875, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.817223072052002\n",
      "Running Batch 876, Epoch 3, Total Tokens: 126\n",
      "Loss: 3.8690319061279297\n",
      "Running Batch 877, Epoch 3, Total Tokens: 267\n",
      "Loss: 3.8983066082000732\n",
      "Running Batch 878, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.9105069637298584\n",
      "Running Batch 879, Epoch 3, Total Tokens: 116\n",
      "Loss: 3.808481216430664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 879, Loss: 3.808481216430664\n",
      "Running Batch 880, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.962455987930298\n",
      "Running Batch 881, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.752258777618408\n",
      "Running Batch 882, Epoch 3, Total Tokens: 174\n",
      "Loss: 3.8637425899505615\n",
      "Running Batch 883, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8631763458251953\n",
      "Running Batch 884, Epoch 3, Total Tokens: 111\n",
      "Loss: 3.8945000171661377\n",
      "Running Batch 885, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.771132469177246\n",
      "Running Batch 886, Epoch 3, Total Tokens: 188\n",
      "Loss: 3.8870604038238525\n",
      "Running Batch 887, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.885873556137085\n",
      "Running Batch 888, Epoch 3, Total Tokens: 284\n",
      "Loss: 3.7976672649383545\n",
      "Running Batch 889, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.8207151889801025\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 889, Loss: 3.8207151889801025\n",
      "Running Batch 890, Epoch 3, Total Tokens: 237\n",
      "Loss: 3.9057164192199707\n",
      "Running Batch 891, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8834121227264404\n",
      "Running Batch 892, Epoch 3, Total Tokens: 183\n",
      "Loss: 3.7974209785461426\n",
      "Running Batch 893, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8445980548858643\n",
      "Running Batch 894, Epoch 3, Total Tokens: 351\n",
      "Loss: 3.8732545375823975\n",
      "Running Batch 895, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.886852741241455\n",
      "Running Batch 896, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.927443504333496\n",
      "Running Batch 897, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.9549336433410645\n",
      "Running Batch 898, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.849285125732422\n",
      "Running Batch 899, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8569889068603516\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 899, Loss: 3.8569889068603516\n",
      "Running Batch 900, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.9105031490325928\n",
      "Running Batch 901, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8305325508117676\n",
      "Running Batch 902, Epoch 3, Total Tokens: 173\n",
      "Loss: 3.883944034576416\n",
      "Running Batch 903, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.9747371673583984\n",
      "Running Batch 904, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.931041955947876\n",
      "Running Batch 905, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.893857479095459\n",
      "Running Batch 906, Epoch 3, Total Tokens: 135\n",
      "Loss: 4.011345386505127\n",
      "Running Batch 907, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.896462917327881\n",
      "Running Batch 908, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.895015001296997\n",
      "Running Batch 909, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.9226980209350586\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 909, Loss: 3.9226980209350586\n",
      "Running Batch 910, Epoch 3, Total Tokens: 418\n",
      "Loss: 3.908616065979004\n",
      "Running Batch 911, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.883923053741455\n",
      "Running Batch 912, Epoch 3, Total Tokens: 282\n",
      "Loss: 3.9038169384002686\n",
      "Running Batch 913, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.928853750228882\n",
      "Running Batch 914, Epoch 3, Total Tokens: 99\n",
      "Loss: 3.9822347164154053\n",
      "Running Batch 915, Epoch 3, Total Tokens: 112\n",
      "Loss: 3.896167516708374\n",
      "Running Batch 916, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.9179298877716064\n",
      "Running Batch 917, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.9375598430633545\n",
      "Running Batch 918, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.790687084197998\n",
      "Running Batch 919, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.8996288776397705\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 919, Loss: 3.8996288776397705\n",
      "Running Batch 920, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.9402997493743896\n",
      "Running Batch 921, Epoch 3, Total Tokens: 199\n",
      "Loss: 3.8617379665374756\n",
      "Running Batch 922, Epoch 3, Total Tokens: 157\n",
      "Loss: 3.9058821201324463\n",
      "Running Batch 923, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.862260580062866\n",
      "Running Batch 924, Epoch 3, Total Tokens: 169\n",
      "Loss: 3.8902015686035156\n",
      "Running Batch 925, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8774163722991943\n",
      "Running Batch 926, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8309578895568848\n",
      "Running Batch 927, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.880340814590454\n",
      "Running Batch 928, Epoch 3, Total Tokens: 113\n",
      "Loss: 3.9985711574554443\n",
      "Running Batch 929, Epoch 3, Total Tokens: 295\n",
      "Loss: 3.846041679382324\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 929, Loss: 3.846041679382324\n",
      "Running Batch 930, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.9380173683166504\n",
      "Running Batch 931, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8833014965057373\n",
      "Running Batch 932, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8316774368286133\n",
      "Running Batch 933, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.9067676067352295\n",
      "Running Batch 934, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.9283926486968994\n",
      "Running Batch 935, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.9239680767059326\n",
      "Running Batch 936, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.9558143615722656\n",
      "Running Batch 937, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.898947238922119\n",
      "Running Batch 938, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.886198043823242\n",
      "Running Batch 939, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8996706008911133\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 939, Loss: 3.8996706008911133\n",
      "Running Batch 940, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.871403694152832\n",
      "Running Batch 941, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.925041913986206\n",
      "Running Batch 942, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.828169107437134\n",
      "Running Batch 943, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.819967746734619\n",
      "Running Batch 944, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.9292690753936768\n",
      "Running Batch 945, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8250539302825928\n",
      "Running Batch 946, Epoch 3, Total Tokens: 187\n",
      "Loss: 3.9434163570404053\n",
      "Running Batch 947, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.8918111324310303\n",
      "Running Batch 948, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8674492835998535\n",
      "Running Batch 949, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.8038763999938965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 949, Loss: 3.8038763999938965\n",
      "Running Batch 950, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.894643545150757\n",
      "Running Batch 951, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.935472249984741\n",
      "Running Batch 952, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.835798978805542\n",
      "Running Batch 953, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.807499647140503\n",
      "Running Batch 954, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.802035331726074\n",
      "Running Batch 955, Epoch 3, Total Tokens: 181\n",
      "Loss: 3.96593976020813\n",
      "Running Batch 956, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.9419939517974854\n",
      "Running Batch 957, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.9216322898864746\n",
      "Running Batch 958, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.851611852645874\n",
      "Running Batch 959, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.900425910949707\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 959, Loss: 3.900425910949707\n",
      "Running Batch 960, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.8783621788024902\n",
      "Running Batch 961, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8531973361968994\n",
      "Running Batch 962, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8351259231567383\n",
      "Running Batch 963, Epoch 3, Total Tokens: 125\n",
      "Loss: 3.7949469089508057\n",
      "Running Batch 964, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.752939224243164\n",
      "Running Batch 965, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.861912965774536\n",
      "Running Batch 966, Epoch 3, Total Tokens: 155\n",
      "Loss: 3.8124806880950928\n",
      "Running Batch 967, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.923337697982788\n",
      "Running Batch 968, Epoch 3, Total Tokens: 190\n",
      "Loss: 3.8966550827026367\n",
      "Running Batch 969, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.929725170135498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 969, Loss: 3.929725170135498\n",
      "Running Batch 970, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.890126943588257\n",
      "Running Batch 971, Epoch 3, Total Tokens: 109\n",
      "Loss: 3.8771586418151855\n",
      "Running Batch 972, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.9184048175811768\n",
      "Running Batch 973, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.8362228870391846\n",
      "Running Batch 974, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.853421688079834\n",
      "Running Batch 975, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.803629159927368\n",
      "Running Batch 976, Epoch 3, Total Tokens: 175\n",
      "Loss: 3.9289541244506836\n",
      "Running Batch 977, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.84962797164917\n",
      "Running Batch 978, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.83073091506958\n",
      "Running Batch 979, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.868739366531372\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 979, Loss: 3.868739366531372\n",
      "Running Batch 980, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.8631622791290283\n",
      "Running Batch 981, Epoch 3, Total Tokens: 184\n",
      "Loss: 3.8619463443756104\n",
      "Running Batch 982, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8348639011383057\n",
      "Running Batch 983, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8745875358581543\n",
      "Running Batch 984, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.94026517868042\n",
      "Running Batch 985, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.8461437225341797\n",
      "Running Batch 986, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8527307510375977\n",
      "Running Batch 987, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.853440284729004\n",
      "Running Batch 988, Epoch 3, Total Tokens: 161\n",
      "Loss: 3.8710110187530518\n",
      "Running Batch 989, Epoch 3, Total Tokens: 367\n",
      "Loss: 3.9340016841888428\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 989, Loss: 3.9340016841888428\n",
      "Running Batch 990, Epoch 3, Total Tokens: 178\n",
      "Loss: 3.88504695892334\n",
      "Running Batch 991, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8881771564483643\n",
      "Running Batch 992, Epoch 3, Total Tokens: 139\n",
      "Loss: 3.8761589527130127\n",
      "Running Batch 993, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.811876058578491\n",
      "Running Batch 994, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8306643962860107\n",
      "Running Batch 995, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8168554306030273\n",
      "Running Batch 996, Epoch 3, Total Tokens: 118\n",
      "Loss: 3.8349175453186035\n",
      "Running Batch 997, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.9100687503814697\n",
      "Running Batch 998, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.911085844039917\n",
      "Running Batch 999, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.8192481994628906\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 999, Loss: 3.8192481994628906\n",
      "Running Batch 1000, Epoch 3, Total Tokens: 179\n",
      "Loss: 3.8873960971832275\n",
      "Running Batch 1001, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8530385494232178\n",
      "Running Batch 1002, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8372089862823486\n",
      "Running Batch 1003, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8808274269104004\n",
      "Running Batch 1004, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8715860843658447\n",
      "Running Batch 1005, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.796475410461426\n",
      "Running Batch 1006, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8197274208068848\n",
      "Running Batch 1007, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8119099140167236\n",
      "Running Batch 1008, Epoch 3, Total Tokens: 170\n",
      "Loss: 3.875758647918701\n",
      "Running Batch 1009, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.901395082473755\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1009, Loss: 3.901395082473755\n",
      "Running Batch 1010, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.84157133102417\n",
      "Running Batch 1011, Epoch 3, Total Tokens: 629\n",
      "Loss: 3.817099094390869\n",
      "Running Batch 1012, Epoch 3, Total Tokens: 173\n",
      "Loss: 3.8075525760650635\n",
      "Running Batch 1013, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.9063804149627686\n",
      "Running Batch 1014, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.9685847759246826\n",
      "Running Batch 1015, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8917160034179688\n",
      "Running Batch 1016, Epoch 3, Total Tokens: 199\n",
      "Loss: 3.8613171577453613\n",
      "Running Batch 1017, Epoch 3, Total Tokens: 130\n",
      "Loss: 3.8057355880737305\n",
      "Running Batch 1018, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.931209087371826\n",
      "Running Batch 1019, Epoch 3, Total Tokens: 171\n",
      "Loss: 3.7667768001556396\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1019, Loss: 3.7667768001556396\n",
      "Running Batch 1020, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8300983905792236\n",
      "Running Batch 1021, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8967230319976807\n",
      "Running Batch 1022, Epoch 3, Total Tokens: 171\n",
      "Loss: 3.802125930786133\n",
      "Running Batch 1023, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.9075815677642822\n",
      "Running Batch 1024, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.8643300533294678\n",
      "Running Batch 1025, Epoch 3, Total Tokens: 193\n",
      "Loss: 3.830613851547241\n",
      "Running Batch 1026, Epoch 3, Total Tokens: 185\n",
      "Loss: 3.8110852241516113\n",
      "Running Batch 1027, Epoch 3, Total Tokens: 131\n",
      "Loss: 3.885246515274048\n",
      "Running Batch 1028, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.7938473224639893\n",
      "Running Batch 1029, Epoch 3, Total Tokens: 113\n",
      "Loss: 3.81958270072937\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1029, Loss: 3.81958270072937\n",
      "Running Batch 1030, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.834146499633789\n",
      "Running Batch 1031, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.8239667415618896\n",
      "Running Batch 1032, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.822136878967285\n",
      "Running Batch 1033, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.8686468601226807\n",
      "Running Batch 1034, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8421976566314697\n",
      "Running Batch 1035, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.8613123893737793\n",
      "Running Batch 1036, Epoch 3, Total Tokens: 122\n",
      "Loss: 3.8548078536987305\n",
      "Running Batch 1037, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8332667350769043\n",
      "Running Batch 1038, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.842151641845703\n",
      "Running Batch 1039, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8552873134613037\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1039, Loss: 3.8552873134613037\n",
      "Running Batch 1040, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8585386276245117\n",
      "Running Batch 1041, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.873218297958374\n",
      "Running Batch 1042, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8247036933898926\n",
      "Running Batch 1043, Epoch 3, Total Tokens: 195\n",
      "Loss: 3.9123525619506836\n",
      "Running Batch 1044, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.799119234085083\n",
      "Running Batch 1045, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8171544075012207\n",
      "Running Batch 1046, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.834780216217041\n",
      "Running Batch 1047, Epoch 3, Total Tokens: 214\n",
      "Loss: 3.8089230060577393\n",
      "Running Batch 1048, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8697166442871094\n",
      "Running Batch 1049, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.868725061416626\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1049, Loss: 3.868725061416626\n",
      "Running Batch 1050, Epoch 3, Total Tokens: 337\n",
      "Loss: 3.8152928352355957\n",
      "Running Batch 1051, Epoch 3, Total Tokens: 119\n",
      "Loss: 3.8698220252990723\n",
      "Running Batch 1052, Epoch 3, Total Tokens: 121\n",
      "Loss: 3.8561346530914307\n",
      "Running Batch 1053, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.802381992340088\n",
      "Running Batch 1054, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.842209577560425\n",
      "Running Batch 1055, Epoch 3, Total Tokens: 127\n",
      "Loss: 3.8313143253326416\n",
      "Running Batch 1056, Epoch 3, Total Tokens: 191\n",
      "Loss: 3.853060245513916\n",
      "Running Batch 1057, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.9541122913360596\n",
      "Running Batch 1058, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8202805519104004\n",
      "Running Batch 1059, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.8454904556274414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1059, Loss: 3.8454904556274414\n",
      "Running Batch 1060, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.7544913291931152\n",
      "Running Batch 1061, Epoch 3, Total Tokens: 206\n",
      "Loss: 3.9189326763153076\n",
      "Running Batch 1062, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.748324155807495\n",
      "Running Batch 1063, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8212130069732666\n",
      "Running Batch 1064, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.855008840560913\n",
      "Running Batch 1065, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.839853048324585\n",
      "Running Batch 1066, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.8266587257385254\n",
      "Running Batch 1067, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.813619613647461\n",
      "Running Batch 1068, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.848572254180908\n",
      "Running Batch 1069, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.809303045272827\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1069, Loss: 3.809303045272827\n",
      "Running Batch 1070, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.8151063919067383\n",
      "Running Batch 1071, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8309879302978516\n",
      "Running Batch 1072, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.8103060722351074\n",
      "Running Batch 1073, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.816941976547241\n",
      "Running Batch 1074, Epoch 3, Total Tokens: 147\n",
      "Loss: 3.8979156017303467\n",
      "Running Batch 1075, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.888585090637207\n",
      "Running Batch 1076, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8374452590942383\n",
      "Running Batch 1077, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.906057834625244\n",
      "Running Batch 1078, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.7938506603240967\n",
      "Running Batch 1079, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.9216532707214355\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1079, Loss: 3.9216532707214355\n",
      "Running Batch 1080, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.8844149112701416\n",
      "Running Batch 1081, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.8458855152130127\n",
      "Running Batch 1082, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8429574966430664\n",
      "Running Batch 1083, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.843291759490967\n",
      "Running Batch 1084, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.822693109512329\n",
      "Running Batch 1085, Epoch 3, Total Tokens: 242\n",
      "Loss: 3.8879587650299072\n",
      "Running Batch 1086, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.8957486152648926\n",
      "Running Batch 1087, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.9064886569976807\n",
      "Running Batch 1088, Epoch 3, Total Tokens: 123\n",
      "Loss: 3.870931386947632\n",
      "Running Batch 1089, Epoch 3, Total Tokens: 118\n",
      "Loss: 3.8164281845092773\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1089, Loss: 3.8164281845092773\n",
      "Running Batch 1090, Epoch 3, Total Tokens: 196\n",
      "Loss: 3.854452610015869\n",
      "Running Batch 1091, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.875425100326538\n",
      "Running Batch 1092, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.877295970916748\n",
      "Running Batch 1093, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.819709300994873\n",
      "Running Batch 1094, Epoch 3, Total Tokens: 177\n",
      "Loss: 3.8451757431030273\n",
      "Running Batch 1095, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.786512851715088\n",
      "Running Batch 1096, Epoch 3, Total Tokens: 122\n",
      "Loss: 3.9136571884155273\n",
      "Running Batch 1097, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.8111162185668945\n",
      "Running Batch 1098, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8563482761383057\n",
      "Running Batch 1099, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.8060569763183594\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1099, Loss: 3.8060569763183594\n",
      "Running Batch 1100, Epoch 3, Total Tokens: 249\n",
      "Loss: 3.793696165084839\n",
      "Running Batch 1101, Epoch 3, Total Tokens: 196\n",
      "Loss: 3.894289493560791\n",
      "Running Batch 1102, Epoch 3, Total Tokens: 172\n",
      "Loss: 3.9283370971679688\n",
      "Running Batch 1103, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.781360149383545\n",
      "Running Batch 1104, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.845663547515869\n",
      "Running Batch 1105, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8171398639678955\n",
      "Running Batch 1106, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8551175594329834\n",
      "Running Batch 1107, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.828038454055786\n",
      "Running Batch 1108, Epoch 3, Total Tokens: 133\n",
      "Loss: 4.064203262329102\n",
      "Running Batch 1109, Epoch 3, Total Tokens: 142\n",
      "Loss: 3.9606106281280518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1109, Loss: 3.9606106281280518\n",
      "Running Batch 1110, Epoch 3, Total Tokens: 141\n",
      "Loss: 3.952378273010254\n",
      "Running Batch 1111, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.9559078216552734\n",
      "Running Batch 1112, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.962069272994995\n",
      "Running Batch 1113, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.9719772338867188\n",
      "Running Batch 1114, Epoch 3, Total Tokens: 187\n",
      "Loss: 3.927180051803589\n",
      "Running Batch 1115, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.927621364593506\n",
      "Running Batch 1116, Epoch 3, Total Tokens: 170\n",
      "Loss: 3.858569383621216\n",
      "Running Batch 1117, Epoch 3, Total Tokens: 165\n",
      "Loss: 3.8773255348205566\n",
      "Running Batch 1118, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.8898353576660156\n",
      "Running Batch 1119, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.9118967056274414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1119, Loss: 3.9118967056274414\n",
      "Running Batch 1120, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.8103816509246826\n",
      "Running Batch 1121, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8130722045898438\n",
      "Running Batch 1122, Epoch 3, Total Tokens: 219\n",
      "Loss: 3.9018189907073975\n",
      "Running Batch 1123, Epoch 3, Total Tokens: 258\n",
      "Loss: 3.872741222381592\n",
      "Running Batch 1124, Epoch 3, Total Tokens: 138\n",
      "Loss: 3.862452507019043\n",
      "Running Batch 1125, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.9160754680633545\n",
      "Running Batch 1126, Epoch 3, Total Tokens: 288\n",
      "Loss: 3.8412816524505615\n",
      "Running Batch 1127, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.9071407318115234\n",
      "Running Batch 1128, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.8222579956054688\n",
      "Running Batch 1129, Epoch 3, Total Tokens: 356\n",
      "Loss: 3.8331356048583984\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1129, Loss: 3.8331356048583984\n",
      "Running Batch 1130, Epoch 3, Total Tokens: 170\n",
      "Loss: 3.881334066390991\n",
      "Running Batch 1131, Epoch 3, Total Tokens: 122\n",
      "Loss: 3.839372396469116\n",
      "Running Batch 1132, Epoch 3, Total Tokens: 149\n",
      "Loss: 3.8295485973358154\n",
      "Running Batch 1133, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8171989917755127\n",
      "Running Batch 1134, Epoch 3, Total Tokens: 209\n",
      "Loss: 3.9240331649780273\n",
      "Running Batch 1135, Epoch 3, Total Tokens: 183\n",
      "Loss: 3.814981460571289\n",
      "Running Batch 1136, Epoch 3, Total Tokens: 156\n",
      "Loss: 3.806304931640625\n",
      "Running Batch 1137, Epoch 3, Total Tokens: 143\n",
      "Loss: 3.8554999828338623\n",
      "Running Batch 1138, Epoch 3, Total Tokens: 150\n",
      "Loss: 3.8722174167633057\n",
      "Running Batch 1139, Epoch 3, Total Tokens: 151\n",
      "Loss: 3.81656551361084\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1139, Loss: 3.81656551361084\n",
      "Running Batch 1140, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.876685619354248\n",
      "Running Batch 1141, Epoch 3, Total Tokens: 170\n",
      "Loss: 3.8413093090057373\n",
      "Running Batch 1142, Epoch 3, Total Tokens: 133\n",
      "Loss: 3.857076644897461\n",
      "Running Batch 1143, Epoch 3, Total Tokens: 152\n",
      "Loss: 3.8328640460968018\n",
      "Running Batch 1144, Epoch 3, Total Tokens: 244\n",
      "Loss: 3.8808071613311768\n",
      "Running Batch 1145, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.9286389350891113\n",
      "Running Batch 1146, Epoch 3, Total Tokens: 181\n",
      "Loss: 3.8359885215759277\n",
      "Running Batch 1147, Epoch 3, Total Tokens: 135\n",
      "Loss: 3.863405466079712\n",
      "Running Batch 1148, Epoch 3, Total Tokens: 167\n",
      "Loss: 3.812471628189087\n",
      "Running Batch 1149, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.86177396774292\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1149, Loss: 3.86177396774292\n",
      "Running Batch 1150, Epoch 3, Total Tokens: 140\n",
      "Loss: 3.8355801105499268\n",
      "Running Batch 1151, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.8564541339874268\n",
      "Running Batch 1152, Epoch 3, Total Tokens: 153\n",
      "Loss: 3.847022533416748\n",
      "Running Batch 1153, Epoch 3, Total Tokens: 137\n",
      "Loss: 3.804821491241455\n",
      "Running Batch 1154, Epoch 3, Total Tokens: 230\n",
      "Loss: 3.8111236095428467\n",
      "Running Batch 1155, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.822336196899414\n",
      "Running Batch 1156, Epoch 3, Total Tokens: 115\n",
      "Loss: 3.902634620666504\n",
      "Running Batch 1157, Epoch 3, Total Tokens: 154\n",
      "Loss: 3.894467830657959\n",
      "Running Batch 1158, Epoch 3, Total Tokens: 120\n",
      "Loss: 3.787799596786499\n",
      "Running Batch 1159, Epoch 3, Total Tokens: 176\n",
      "Loss: 3.7738261222839355\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1159, Loss: 3.7738261222839355\n",
      "Running Batch 1160, Epoch 3, Total Tokens: 285\n",
      "Loss: 3.8664424419403076\n",
      "Running Batch 1161, Epoch 3, Total Tokens: 128\n",
      "Loss: 3.7876529693603516\n",
      "Running Batch 1162, Epoch 3, Total Tokens: 146\n",
      "Loss: 3.7803118228912354\n",
      "Running Batch 1163, Epoch 3, Total Tokens: 159\n",
      "Loss: 3.872464418411255\n",
      "Running Batch 1164, Epoch 3, Total Tokens: 136\n",
      "Loss: 3.8098866939544678\n",
      "Running Batch 1165, Epoch 3, Total Tokens: 132\n",
      "Loss: 3.803246021270752\n",
      "Running Batch 1166, Epoch 3, Total Tokens: 148\n",
      "Loss: 3.809828758239746\n",
      "Running Batch 1167, Epoch 3, Total Tokens: 145\n",
      "Loss: 3.791923761367798\n",
      "Running Batch 1168, Epoch 3, Total Tokens: 144\n",
      "Loss: 3.831035614013672\n",
      "Running Batch 1169, Epoch 3, Total Tokens: 129\n",
      "Loss: 3.8531734943389893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1169, Loss: 3.8531734943389893\n",
      "Running Batch 1170, Epoch 3, Total Tokens: 124\n",
      "Loss: 3.9357731342315674\n",
      "Running Batch 1171, Epoch 3, Total Tokens: 134\n",
      "Loss: 3.800748825073242\n",
      "AVG LOSS: 3.3030085968483025, Epoch: 4\n",
      "Running Batch 0, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8239691257476807\n",
      "Running Batch 1, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.799060344696045\n",
      "Running Batch 2, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.8668861389160156\n",
      "Running Batch 3, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8565518856048584\n",
      "Running Batch 4, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8055105209350586\n",
      "Running Batch 5, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.9096884727478027\n",
      "Running Batch 6, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.815502166748047\n",
      "Running Batch 7, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8696794509887695\n",
      "Running Batch 8, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.7918500900268555\n",
      "Running Batch 9, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.8453543186187744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 9, Loss: 3.8453543186187744\n",
      "Running Batch 10, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.800525426864624\n",
      "Running Batch 11, Epoch 4, Total Tokens: 288\n",
      "Loss: 3.837351083755493\n",
      "Running Batch 12, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8131723403930664\n",
      "Running Batch 13, Epoch 4, Total Tokens: 224\n",
      "Loss: 3.8264687061309814\n",
      "Running Batch 14, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.8350276947021484\n",
      "Running Batch 15, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8450467586517334\n",
      "Running Batch 16, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.788668155670166\n",
      "Running Batch 17, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.821537971496582\n",
      "Running Batch 18, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8515913486480713\n",
      "Running Batch 19, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.8796026706695557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 19, Loss: 3.8796026706695557\n",
      "Running Batch 20, Epoch 4, Total Tokens: 244\n",
      "Loss: 3.8108818531036377\n",
      "Running Batch 21, Epoch 4, Total Tokens: 295\n",
      "Loss: 3.8524672985076904\n",
      "Running Batch 22, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.8103787899017334\n",
      "Running Batch 23, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.7873220443725586\n",
      "Running Batch 24, Epoch 4, Total Tokens: 214\n",
      "Loss: 3.74126935005188\n",
      "Running Batch 25, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.7983741760253906\n",
      "Running Batch 26, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8900554180145264\n",
      "Running Batch 27, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.8349270820617676\n",
      "Running Batch 28, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.920079231262207\n",
      "Running Batch 29, Epoch 4, Total Tokens: 110\n",
      "Loss: 3.8069264888763428\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 29, Loss: 3.8069264888763428\n",
      "Running Batch 30, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.9006612300872803\n",
      "Running Batch 31, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.805004358291626\n",
      "Running Batch 32, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.89267635345459\n",
      "Running Batch 33, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.807124614715576\n",
      "Running Batch 34, Epoch 4, Total Tokens: 181\n",
      "Loss: 3.9060840606689453\n",
      "Running Batch 35, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.854767084121704\n",
      "Running Batch 36, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8290867805480957\n",
      "Running Batch 37, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.860930919647217\n",
      "Running Batch 38, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.778820753097534\n",
      "Running Batch 39, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8113319873809814\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 39, Loss: 3.8113319873809814\n",
      "Running Batch 40, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8482730388641357\n",
      "Running Batch 41, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.836038827896118\n",
      "Running Batch 42, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.801966428756714\n",
      "Running Batch 43, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.9168341159820557\n",
      "Running Batch 44, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8240556716918945\n",
      "Running Batch 45, Epoch 4, Total Tokens: 162\n",
      "Loss: 3.789630174636841\n",
      "Running Batch 46, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.915182590484619\n",
      "Running Batch 47, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8753883838653564\n",
      "Running Batch 48, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8220674991607666\n",
      "Running Batch 49, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.7941036224365234\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 49, Loss: 3.7941036224365234\n",
      "Running Batch 50, Epoch 4, Total Tokens: 113\n",
      "Loss: 3.8559772968292236\n",
      "Running Batch 51, Epoch 4, Total Tokens: 113\n",
      "Loss: 3.8339309692382812\n",
      "Running Batch 52, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.83296537399292\n",
      "Running Batch 53, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.8634018898010254\n",
      "Running Batch 54, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.79803204536438\n",
      "Running Batch 55, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8036386966705322\n",
      "Running Batch 56, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.810009479522705\n",
      "Running Batch 57, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.7820372581481934\n",
      "Running Batch 58, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8420016765594482\n",
      "Running Batch 59, Epoch 4, Total Tokens: 178\n",
      "Loss: 3.8348405361175537\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 59, Loss: 3.8348405361175537\n",
      "Running Batch 60, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.76104736328125\n",
      "Running Batch 61, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.842851161956787\n",
      "Running Batch 62, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.7838799953460693\n",
      "Running Batch 63, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.79671573638916\n",
      "Running Batch 64, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8761258125305176\n",
      "Running Batch 65, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.8627872467041016\n",
      "Running Batch 66, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8127667903900146\n",
      "Running Batch 67, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8151211738586426\n",
      "Running Batch 68, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.866736650466919\n",
      "Running Batch 69, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.860189199447632\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 69, Loss: 3.860189199447632\n",
      "Running Batch 70, Epoch 4, Total Tokens: 183\n",
      "Loss: 3.8155698776245117\n",
      "Running Batch 71, Epoch 4, Total Tokens: 234\n",
      "Loss: 3.8314197063446045\n",
      "Running Batch 72, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8662219047546387\n",
      "Running Batch 73, Epoch 4, Total Tokens: 164\n",
      "Loss: 3.826953411102295\n",
      "Running Batch 74, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.818816900253296\n",
      "Running Batch 75, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.827700614929199\n",
      "Running Batch 76, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.8306472301483154\n",
      "Running Batch 77, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.802140235900879\n",
      "Running Batch 78, Epoch 4, Total Tokens: 182\n",
      "Loss: 3.8794641494750977\n",
      "Running Batch 79, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8016395568847656\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 79, Loss: 3.8016395568847656\n",
      "Running Batch 80, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.846815347671509\n",
      "Running Batch 81, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.754737377166748\n",
      "Running Batch 82, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.810697555541992\n",
      "Running Batch 83, Epoch 4, Total Tokens: 111\n",
      "Loss: 3.7917637825012207\n",
      "Running Batch 84, Epoch 4, Total Tokens: 199\n",
      "Loss: 3.8041675090789795\n",
      "Running Batch 85, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8114120960235596\n",
      "Running Batch 86, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8827497959136963\n",
      "Running Batch 87, Epoch 4, Total Tokens: 261\n",
      "Loss: 3.860200881958008\n",
      "Running Batch 88, Epoch 4, Total Tokens: 267\n",
      "Loss: 3.826256513595581\n",
      "Running Batch 89, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8852553367614746\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 89, Loss: 3.8852553367614746\n",
      "Running Batch 90, Epoch 4, Total Tokens: 181\n",
      "Loss: 3.9779791831970215\n",
      "Running Batch 91, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.8517069816589355\n",
      "Running Batch 92, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.818485736846924\n",
      "Running Batch 93, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.8231632709503174\n",
      "Running Batch 94, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.827979803085327\n",
      "Running Batch 95, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.8797802925109863\n",
      "Running Batch 96, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8079330921173096\n",
      "Running Batch 97, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.793888568878174\n",
      "Running Batch 98, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.784130096435547\n",
      "Running Batch 99, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.819751739501953\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 99, Loss: 3.819751739501953\n",
      "Running Batch 100, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.781891107559204\n",
      "Running Batch 101, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.821303606033325\n",
      "Running Batch 102, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.840283155441284\n",
      "Running Batch 103, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.829833745956421\n",
      "Running Batch 104, Epoch 4, Total Tokens: 244\n",
      "Loss: 3.843764305114746\n",
      "Running Batch 105, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.837648868560791\n",
      "Running Batch 106, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8624401092529297\n",
      "Running Batch 107, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8407905101776123\n",
      "Running Batch 108, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8889009952545166\n",
      "Running Batch 109, Epoch 4, Total Tokens: 282\n",
      "Loss: 3.7716362476348877\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 109, Loss: 3.7716362476348877\n",
      "Running Batch 110, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.788038730621338\n",
      "Running Batch 111, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8752448558807373\n",
      "Running Batch 112, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.7988436222076416\n",
      "Running Batch 113, Epoch 4, Total Tokens: 166\n",
      "Loss: 3.8306353092193604\n",
      "Running Batch 114, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8699753284454346\n",
      "Running Batch 115, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.7931251525878906\n",
      "Running Batch 116, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.82014799118042\n",
      "Running Batch 117, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8167831897735596\n",
      "Running Batch 118, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7912609577178955\n",
      "Running Batch 119, Epoch 4, Total Tokens: 337\n",
      "Loss: 3.7666404247283936\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 119, Loss: 3.7666404247283936\n",
      "Running Batch 120, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8278350830078125\n",
      "Running Batch 121, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.838538885116577\n",
      "Running Batch 122, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8088951110839844\n",
      "Running Batch 123, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8253579139709473\n",
      "Running Batch 124, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8406009674072266\n",
      "Running Batch 125, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8261308670043945\n",
      "Running Batch 126, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8700549602508545\n",
      "Running Batch 127, Epoch 4, Total Tokens: 322\n",
      "Loss: 3.8199830055236816\n",
      "Running Batch 128, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.790261745452881\n",
      "Running Batch 129, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.7940852642059326\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 129, Loss: 3.7940852642059326\n",
      "Running Batch 130, Epoch 4, Total Tokens: 190\n",
      "Loss: 3.8947246074676514\n",
      "Running Batch 131, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.767914056777954\n",
      "Running Batch 132, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.787623405456543\n",
      "Running Batch 133, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8423445224761963\n",
      "Running Batch 134, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8296444416046143\n",
      "Running Batch 135, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.857267141342163\n",
      "Running Batch 136, Epoch 4, Total Tokens: 205\n",
      "Loss: 3.77370285987854\n",
      "Running Batch 137, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8943288326263428\n",
      "Running Batch 138, Epoch 4, Total Tokens: 210\n",
      "Loss: 3.840881586074829\n",
      "Running Batch 139, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.8189101219177246\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 139, Loss: 3.8189101219177246\n",
      "Running Batch 140, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.82576847076416\n",
      "Running Batch 141, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8738558292388916\n",
      "Running Batch 142, Epoch 4, Total Tokens: 166\n",
      "Loss: 3.725400686264038\n",
      "Running Batch 143, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.7739431858062744\n",
      "Running Batch 144, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.85506010055542\n",
      "Running Batch 145, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.808326244354248\n",
      "Running Batch 146, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8298180103302\n",
      "Running Batch 147, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.805919885635376\n",
      "Running Batch 148, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.858140230178833\n",
      "Running Batch 149, Epoch 4, Total Tokens: 266\n",
      "Loss: 3.821772575378418\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 149, Loss: 3.821772575378418\n",
      "Running Batch 150, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7978768348693848\n",
      "Running Batch 151, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.8355486392974854\n",
      "Running Batch 152, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.76772141456604\n",
      "Running Batch 153, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.9238247871398926\n",
      "Running Batch 154, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.818004846572876\n",
      "Running Batch 155, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.796322822570801\n",
      "Running Batch 156, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.763186454772949\n",
      "Running Batch 157, Epoch 4, Total Tokens: 299\n",
      "Loss: 3.7963826656341553\n",
      "Running Batch 158, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.879060983657837\n",
      "Running Batch 159, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.815351724624634\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 159, Loss: 3.815351724624634\n",
      "Running Batch 160, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.8925065994262695\n",
      "Running Batch 161, Epoch 4, Total Tokens: 286\n",
      "Loss: 3.7679855823516846\n",
      "Running Batch 162, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.841665744781494\n",
      "Running Batch 163, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.8271119594573975\n",
      "Running Batch 164, Epoch 4, Total Tokens: 158\n",
      "Loss: 3.7704615592956543\n",
      "Running Batch 165, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.8128011226654053\n",
      "Running Batch 166, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.7656595706939697\n",
      "Running Batch 167, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.810936212539673\n",
      "Running Batch 168, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.823685884475708\n",
      "Running Batch 169, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.780846118927002\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 169, Loss: 3.780846118927002\n",
      "Running Batch 170, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.852107286453247\n",
      "Running Batch 171, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7744600772857666\n",
      "Running Batch 172, Epoch 4, Total Tokens: 111\n",
      "Loss: 3.789795160293579\n",
      "Running Batch 173, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.7759711742401123\n",
      "Running Batch 174, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8920528888702393\n",
      "Running Batch 175, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.919800043106079\n",
      "Running Batch 176, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.78859806060791\n",
      "Running Batch 177, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.799948215484619\n",
      "Running Batch 178, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.8186416625976562\n",
      "Running Batch 179, Epoch 4, Total Tokens: 176\n",
      "Loss: 3.8320815563201904\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 179, Loss: 3.8320815563201904\n",
      "Running Batch 180, Epoch 4, Total Tokens: 156\n",
      "Loss: 3.9302847385406494\n",
      "Running Batch 181, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8714940547943115\n",
      "Running Batch 182, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.9080092906951904\n",
      "Running Batch 183, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8281631469726562\n",
      "Running Batch 184, Epoch 4, Total Tokens: 205\n",
      "Loss: 3.7907328605651855\n",
      "Running Batch 185, Epoch 4, Total Tokens: 176\n",
      "Loss: 3.841648578643799\n",
      "Running Batch 186, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8016715049743652\n",
      "Running Batch 187, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.869968891143799\n",
      "Running Batch 188, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.8293089866638184\n",
      "Running Batch 189, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.790595769882202\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 189, Loss: 3.790595769882202\n",
      "Running Batch 190, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8164713382720947\n",
      "Running Batch 191, Epoch 4, Total Tokens: 168\n",
      "Loss: 3.8141205310821533\n",
      "Running Batch 192, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8848774433135986\n",
      "Running Batch 193, Epoch 4, Total Tokens: 262\n",
      "Loss: 3.7613472938537598\n",
      "Running Batch 194, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8010683059692383\n",
      "Running Batch 195, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8298983573913574\n",
      "Running Batch 196, Epoch 4, Total Tokens: 242\n",
      "Loss: 3.800837993621826\n",
      "Running Batch 197, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8725783824920654\n",
      "Running Batch 198, Epoch 4, Total Tokens: 214\n",
      "Loss: 3.8055129051208496\n",
      "Running Batch 199, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.7863988876342773\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 199, Loss: 3.7863988876342773\n",
      "Running Batch 200, Epoch 4, Total Tokens: 164\n",
      "Loss: 3.8048524856567383\n",
      "Running Batch 201, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.931408405303955\n",
      "Running Batch 202, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8155033588409424\n",
      "Running Batch 203, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.830437183380127\n",
      "Running Batch 204, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.810153007507324\n",
      "Running Batch 205, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.9062445163726807\n",
      "Running Batch 206, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.850564956665039\n",
      "Running Batch 207, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8075170516967773\n",
      "Running Batch 208, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8118550777435303\n",
      "Running Batch 209, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.818784713745117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 209, Loss: 3.818784713745117\n",
      "Running Batch 210, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.9072654247283936\n",
      "Running Batch 211, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.7301218509674072\n",
      "Running Batch 212, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8172247409820557\n",
      "Running Batch 213, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.766850471496582\n",
      "Running Batch 214, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8399455547332764\n",
      "Running Batch 215, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8722376823425293\n",
      "Running Batch 216, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.7965447902679443\n",
      "Running Batch 217, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.760401725769043\n",
      "Running Batch 218, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.792226791381836\n",
      "Running Batch 219, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.803873300552368\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 219, Loss: 3.803873300552368\n",
      "Running Batch 220, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.798387050628662\n",
      "Running Batch 221, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.7723886966705322\n",
      "Running Batch 222, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8542699813842773\n",
      "Running Batch 223, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8440213203430176\n",
      "Running Batch 224, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.822910785675049\n",
      "Running Batch 225, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.8368585109710693\n",
      "Running Batch 226, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.8979129791259766\n",
      "Running Batch 227, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.7578582763671875\n",
      "Running Batch 228, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.859757661819458\n",
      "Running Batch 229, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.7614235877990723\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 229, Loss: 3.7614235877990723\n",
      "Running Batch 230, Epoch 4, Total Tokens: 117\n",
      "Loss: 3.8865931034088135\n",
      "Running Batch 231, Epoch 4, Total Tokens: 187\n",
      "Loss: 3.906730890274048\n",
      "Running Batch 232, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8759500980377197\n",
      "Running Batch 233, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.7265546321868896\n",
      "Running Batch 234, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.815343141555786\n",
      "Running Batch 235, Epoch 4, Total Tokens: 624\n",
      "Loss: 3.855733633041382\n",
      "Running Batch 236, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.81154465675354\n",
      "Running Batch 237, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8526856899261475\n",
      "Running Batch 238, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.7771518230438232\n",
      "Running Batch 239, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.8402538299560547\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 239, Loss: 3.8402538299560547\n",
      "Running Batch 240, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.824150800704956\n",
      "Running Batch 241, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8925468921661377\n",
      "Running Batch 242, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.7569503784179688\n",
      "Running Batch 243, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.797367811203003\n",
      "Running Batch 244, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.734147787094116\n",
      "Running Batch 245, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.85188889503479\n",
      "Running Batch 246, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8068864345550537\n",
      "Running Batch 247, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8716702461242676\n",
      "Running Batch 248, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.71252703666687\n",
      "Running Batch 249, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8231313228607178\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 249, Loss: 3.8231313228607178\n",
      "Running Batch 250, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8750252723693848\n",
      "Running Batch 251, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8506078720092773\n",
      "Running Batch 252, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.756956100463867\n",
      "Running Batch 253, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8740365505218506\n",
      "Running Batch 254, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.846944570541382\n",
      "Running Batch 255, Epoch 4, Total Tokens: 195\n",
      "Loss: 3.8405213356018066\n",
      "Running Batch 256, Epoch 4, Total Tokens: 237\n",
      "Loss: 3.774231195449829\n",
      "Running Batch 257, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.7427051067352295\n",
      "Running Batch 258, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.7981314659118652\n",
      "Running Batch 259, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.7496447563171387\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 259, Loss: 3.7496447563171387\n",
      "Running Batch 260, Epoch 4, Total Tokens: 160\n",
      "Loss: 3.7614893913269043\n",
      "Running Batch 261, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.897038698196411\n",
      "Running Batch 262, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.892122983932495\n",
      "Running Batch 263, Epoch 4, Total Tokens: 174\n",
      "Loss: 3.9072914123535156\n",
      "Running Batch 264, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.9098563194274902\n",
      "Running Batch 265, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.9061832427978516\n",
      "Running Batch 266, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.901754856109619\n",
      "Running Batch 267, Epoch 4, Total Tokens: 163\n",
      "Loss: 3.910905122756958\n",
      "Running Batch 268, Epoch 4, Total Tokens: 351\n",
      "Loss: 3.9824459552764893\n",
      "Running Batch 269, Epoch 4, Total Tokens: 155\n",
      "Loss: 4.066253185272217\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 269, Loss: 4.066253185272217\n",
      "Running Batch 270, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.903107166290283\n",
      "Running Batch 271, Epoch 4, Total Tokens: 168\n",
      "Loss: 3.90214204788208\n",
      "Running Batch 272, Epoch 4, Total Tokens: 171\n",
      "Loss: 3.821960210800171\n",
      "Running Batch 273, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8942418098449707\n",
      "Running Batch 274, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.9112823009490967\n",
      "Running Batch 275, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8934829235076904\n",
      "Running Batch 276, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8753817081451416\n",
      "Running Batch 277, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.952662944793701\n",
      "Running Batch 278, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8698039054870605\n",
      "Running Batch 279, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8760459423065186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 279, Loss: 3.8760459423065186\n",
      "Running Batch 280, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.959256410598755\n",
      "Running Batch 281, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.94620418548584\n",
      "Running Batch 282, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.9313673973083496\n",
      "Running Batch 283, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.9780423641204834\n",
      "Running Batch 284, Epoch 4, Total Tokens: 112\n",
      "Loss: 3.988694667816162\n",
      "Running Batch 285, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.9069535732269287\n",
      "Running Batch 286, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.977032423019409\n",
      "Running Batch 287, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.809345245361328\n",
      "Running Batch 288, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.9483001232147217\n",
      "Running Batch 289, Epoch 4, Total Tokens: 177\n",
      "Loss: 3.965001344680786\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 289, Loss: 3.965001344680786\n",
      "Running Batch 290, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8618156909942627\n",
      "Running Batch 291, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.838327407836914\n",
      "Running Batch 292, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8715884685516357\n",
      "Running Batch 293, Epoch 4, Total Tokens: 219\n",
      "Loss: 3.858839511871338\n",
      "Running Batch 294, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.894960880279541\n",
      "Running Batch 295, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.836254119873047\n",
      "Running Batch 296, Epoch 4, Total Tokens: 158\n",
      "Loss: 3.8960344791412354\n",
      "Running Batch 297, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8648035526275635\n",
      "Running Batch 298, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.855313777923584\n",
      "Running Batch 299, Epoch 4, Total Tokens: 169\n",
      "Loss: 3.9611878395080566\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 299, Loss: 3.9611878395080566\n",
      "Running Batch 300, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.912156105041504\n",
      "Running Batch 301, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.963890552520752\n",
      "Running Batch 302, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8113017082214355\n",
      "Running Batch 303, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.789868116378784\n",
      "Running Batch 304, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.829777956008911\n",
      "Running Batch 305, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.8310203552246094\n",
      "Running Batch 306, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.815748453140259\n",
      "Running Batch 307, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.878469228744507\n",
      "Running Batch 308, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.7734246253967285\n",
      "Running Batch 309, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.921321153640747\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 309, Loss: 3.921321153640747\n",
      "Running Batch 310, Epoch 4, Total Tokens: 211\n",
      "Loss: 3.8440093994140625\n",
      "Running Batch 311, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.900674343109131\n",
      "Running Batch 312, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.920023202896118\n",
      "Running Batch 313, Epoch 4, Total Tokens: 249\n",
      "Loss: 3.9185094833374023\n",
      "Running Batch 314, Epoch 4, Total Tokens: 284\n",
      "Loss: 3.791137456893921\n",
      "Running Batch 315, Epoch 4, Total Tokens: 629\n",
      "Loss: 3.8059310913085938\n",
      "Running Batch 316, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.858692169189453\n",
      "Running Batch 317, Epoch 4, Total Tokens: 110\n",
      "Loss: 3.8726868629455566\n",
      "Running Batch 318, Epoch 4, Total Tokens: 115\n",
      "Loss: 3.9862060546875\n",
      "Running Batch 319, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8085856437683105\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 319, Loss: 3.8085856437683105\n",
      "Running Batch 320, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.9592196941375732\n",
      "Running Batch 321, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8786492347717285\n",
      "Running Batch 322, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8248403072357178\n",
      "Running Batch 323, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8702728748321533\n",
      "Running Batch 324, Epoch 4, Total Tokens: 113\n",
      "Loss: 3.877678632736206\n",
      "Running Batch 325, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8862247467041016\n",
      "Running Batch 326, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8419029712677\n",
      "Running Batch 327, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.867635726928711\n",
      "Running Batch 328, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8891210556030273\n",
      "Running Batch 329, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8921992778778076\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 329, Loss: 3.8921992778778076\n",
      "Running Batch 330, Epoch 4, Total Tokens: 229\n",
      "Loss: 3.882629632949829\n",
      "Running Batch 331, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8459255695343018\n",
      "Running Batch 332, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8088715076446533\n",
      "Running Batch 333, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.8286468982696533\n",
      "Running Batch 334, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7865467071533203\n",
      "Running Batch 335, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.857795000076294\n",
      "Running Batch 336, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.8552207946777344\n",
      "Running Batch 337, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8450281620025635\n",
      "Running Batch 338, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.773733139038086\n",
      "Running Batch 339, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.730344772338867\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 339, Loss: 3.730344772338867\n",
      "Running Batch 340, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.864758014678955\n",
      "Running Batch 341, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8281259536743164\n",
      "Running Batch 342, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.893019199371338\n",
      "Running Batch 343, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.864384651184082\n",
      "Running Batch 344, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.841411828994751\n",
      "Running Batch 345, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.859274387359619\n",
      "Running Batch 346, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8539774417877197\n",
      "Running Batch 347, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.820103645324707\n",
      "Running Batch 348, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8917620182037354\n",
      "Running Batch 349, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.766796350479126\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 349, Loss: 3.766796350479126\n",
      "Running Batch 350, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8364975452423096\n",
      "Running Batch 351, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.812819480895996\n",
      "Running Batch 352, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8798766136169434\n",
      "Running Batch 353, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8286256790161133\n",
      "Running Batch 354, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.940807342529297\n",
      "Running Batch 355, Epoch 4, Total Tokens: 167\n",
      "Loss: 3.9897043704986572\n",
      "Running Batch 356, Epoch 4, Total Tokens: 137\n",
      "Loss: 4.189386367797852\n",
      "Running Batch 357, Epoch 4, Total Tokens: 130\n",
      "Loss: 4.15974235534668\n",
      "Running Batch 358, Epoch 4, Total Tokens: 144\n",
      "Loss: 4.219797134399414\n",
      "Running Batch 359, Epoch 4, Total Tokens: 150\n",
      "Loss: 4.098395824432373\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 359, Loss: 4.098395824432373\n",
      "Running Batch 360, Epoch 4, Total Tokens: 151\n",
      "Loss: 4.022985935211182\n",
      "Running Batch 361, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.951677083969116\n",
      "Running Batch 362, Epoch 4, Total Tokens: 144\n",
      "Loss: 4.039123058319092\n",
      "Running Batch 363, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.971982717514038\n",
      "Running Batch 364, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.922412633895874\n",
      "Running Batch 365, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.963754415512085\n",
      "Running Batch 366, Epoch 4, Total Tokens: 145\n",
      "Loss: 4.1311726570129395\n",
      "Running Batch 367, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.9888439178466797\n",
      "Running Batch 368, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.9519150257110596\n",
      "Running Batch 369, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.988353967666626\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 369, Loss: 3.988353967666626\n",
      "Running Batch 370, Epoch 4, Total Tokens: 228\n",
      "Loss: 3.9425199031829834\n",
      "Running Batch 371, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.893160581588745\n",
      "Running Batch 372, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.910202741622925\n",
      "Running Batch 373, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.915701389312744\n",
      "Running Batch 374, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.9382264614105225\n",
      "Running Batch 375, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.9056057929992676\n",
      "Running Batch 376, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.9404518604278564\n",
      "Running Batch 377, Epoch 4, Total Tokens: 138\n",
      "Loss: 4.047755718231201\n",
      "Running Batch 378, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.927640676498413\n",
      "Running Batch 379, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.9127438068389893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 379, Loss: 3.9127438068389893\n",
      "Running Batch 380, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.8714427947998047\n",
      "Running Batch 381, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.889705181121826\n",
      "Running Batch 382, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.9136745929718018\n",
      "Running Batch 383, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.9703354835510254\n",
      "Running Batch 384, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.87656831741333\n",
      "Running Batch 385, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.9479238986968994\n",
      "Running Batch 386, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.9570369720458984\n",
      "Running Batch 387, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.9296820163726807\n",
      "Running Batch 388, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.867511749267578\n",
      "Running Batch 389, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.9409046173095703\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 389, Loss: 3.9409046173095703\n",
      "Running Batch 390, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.908824920654297\n",
      "Running Batch 391, Epoch 4, Total Tokens: 131\n",
      "Loss: 4.00244665145874\n",
      "Running Batch 392, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.978355646133423\n",
      "Running Batch 393, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.9592161178588867\n",
      "Running Batch 394, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.954347610473633\n",
      "Running Batch 395, Epoch 4, Total Tokens: 527\n",
      "Loss: 4.048945426940918\n",
      "Running Batch 396, Epoch 4, Total Tokens: 138\n",
      "Loss: 4.197419166564941\n",
      "Running Batch 397, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.9482014179229736\n",
      "Running Batch 398, Epoch 4, Total Tokens: 133\n",
      "Loss: 4.036747455596924\n",
      "Running Batch 399, Epoch 4, Total Tokens: 117\n",
      "Loss: 4.179059028625488\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 399, Loss: 4.179059028625488\n",
      "Running Batch 400, Epoch 4, Total Tokens: 153\n",
      "Loss: 4.001760005950928\n",
      "Running Batch 401, Epoch 4, Total Tokens: 125\n",
      "Loss: 4.0883564949035645\n",
      "Running Batch 402, Epoch 4, Total Tokens: 140\n",
      "Loss: 4.18806791305542\n",
      "Running Batch 403, Epoch 4, Total Tokens: 139\n",
      "Loss: 4.177560806274414\n",
      "Running Batch 404, Epoch 4, Total Tokens: 134\n",
      "Loss: 4.094181537628174\n",
      "Running Batch 405, Epoch 4, Total Tokens: 128\n",
      "Loss: 4.116706371307373\n",
      "Running Batch 406, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.995330572128296\n",
      "Running Batch 407, Epoch 4, Total Tokens: 148\n",
      "Loss: 4.066993713378906\n",
      "Running Batch 408, Epoch 4, Total Tokens: 158\n",
      "Loss: 4.0222249031066895\n",
      "Running Batch 409, Epoch 4, Total Tokens: 285\n",
      "Loss: 4.036745548248291\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 409, Loss: 4.036745548248291\n",
      "Running Batch 410, Epoch 4, Total Tokens: 156\n",
      "Loss: 4.108395576477051\n",
      "Running Batch 411, Epoch 4, Total Tokens: 128\n",
      "Loss: 4.126646041870117\n",
      "Running Batch 412, Epoch 4, Total Tokens: 141\n",
      "Loss: 4.066117286682129\n",
      "Running Batch 413, Epoch 4, Total Tokens: 124\n",
      "Loss: 4.0769758224487305\n",
      "Running Batch 414, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8933517932891846\n",
      "Running Batch 415, Epoch 4, Total Tokens: 324\n",
      "Loss: 4.050252914428711\n",
      "Running Batch 416, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.9506099224090576\n",
      "Running Batch 417, Epoch 4, Total Tokens: 150\n",
      "Loss: 4.067607879638672\n",
      "Running Batch 418, Epoch 4, Total Tokens: 146\n",
      "Loss: 4.1258368492126465\n",
      "Running Batch 419, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.927396774291992\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 419, Loss: 3.927396774291992\n",
      "Running Batch 420, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.8988561630249023\n",
      "Running Batch 421, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.985638380050659\n",
      "Running Batch 422, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.934109687805176\n",
      "Running Batch 423, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.926407814025879\n",
      "Running Batch 424, Epoch 4, Total Tokens: 228\n",
      "Loss: 3.9267563819885254\n",
      "Running Batch 425, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.873779058456421\n",
      "Running Batch 426, Epoch 4, Total Tokens: 185\n",
      "Loss: 3.9516453742980957\n",
      "Running Batch 427, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.932053565979004\n",
      "Running Batch 428, Epoch 4, Total Tokens: 97\n",
      "Loss: 3.9826173782348633\n",
      "Running Batch 429, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8972737789154053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 429, Loss: 3.8972737789154053\n",
      "Running Batch 430, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.897430419921875\n",
      "Running Batch 431, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.8407185077667236\n",
      "Running Batch 432, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.9730148315429688\n",
      "Running Batch 433, Epoch 4, Total Tokens: 153\n",
      "Loss: 4.01943826675415\n",
      "Running Batch 434, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.9707000255584717\n",
      "Running Batch 435, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.871591806411743\n",
      "Running Batch 436, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.823498010635376\n",
      "Running Batch 437, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.920710325241089\n",
      "Running Batch 438, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.95063853263855\n",
      "Running Batch 439, Epoch 4, Total Tokens: 156\n",
      "Loss: 3.857383966445923\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 439, Loss: 3.857383966445923\n",
      "Running Batch 440, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8625683784484863\n",
      "Running Batch 441, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.877678155899048\n",
      "Running Batch 442, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.9689691066741943\n",
      "Running Batch 443, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.897071361541748\n",
      "Running Batch 444, Epoch 4, Total Tokens: 220\n",
      "Loss: 3.942852020263672\n",
      "Running Batch 445, Epoch 4, Total Tokens: 206\n",
      "Loss: 3.9122514724731445\n",
      "Running Batch 446, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.9254448413848877\n",
      "Running Batch 447, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8400652408599854\n",
      "Running Batch 448, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8778746128082275\n",
      "Running Batch 449, Epoch 4, Total Tokens: 187\n",
      "Loss: 3.8812978267669678\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 449, Loss: 3.8812978267669678\n",
      "Running Batch 450, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.801306962966919\n",
      "Running Batch 451, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8305935859680176\n",
      "Running Batch 452, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.858247756958008\n",
      "Running Batch 453, Epoch 4, Total Tokens: 184\n",
      "Loss: 3.9239141941070557\n",
      "Running Batch 454, Epoch 4, Total Tokens: 568\n",
      "Loss: 3.84860897064209\n",
      "Running Batch 455, Epoch 4, Total Tokens: 110\n",
      "Loss: 3.94653582572937\n",
      "Running Batch 456, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.9011378288269043\n",
      "Running Batch 457, Epoch 4, Total Tokens: 361\n",
      "Loss: 3.9611306190490723\n",
      "Running Batch 458, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8445534706115723\n",
      "Running Batch 459, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.9350647926330566\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 459, Loss: 3.9350647926330566\n",
      "Running Batch 460, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8603549003601074\n",
      "Running Batch 461, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8344457149505615\n",
      "Running Batch 462, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.8101634979248047\n",
      "Running Batch 463, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.910003185272217\n",
      "Running Batch 464, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.8897790908813477\n",
      "Running Batch 465, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.875706195831299\n",
      "Running Batch 466, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.909167766571045\n",
      "Running Batch 467, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.843817710876465\n",
      "Running Batch 468, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.9408979415893555\n",
      "Running Batch 469, Epoch 4, Total Tokens: 170\n",
      "Loss: 3.858170747756958\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 469, Loss: 3.858170747756958\n",
      "Running Batch 470, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.9767613410949707\n",
      "Running Batch 471, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.9165918827056885\n",
      "Running Batch 472, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.9313340187072754\n",
      "Running Batch 473, Epoch 4, Total Tokens: 111\n",
      "Loss: 3.9377598762512207\n",
      "Running Batch 474, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8709824085235596\n",
      "Running Batch 475, Epoch 4, Total Tokens: 209\n",
      "Loss: 3.9626522064208984\n",
      "Running Batch 476, Epoch 4, Total Tokens: 181\n",
      "Loss: 3.9467949867248535\n",
      "Running Batch 477, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8543479442596436\n",
      "Running Batch 478, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.7733216285705566\n",
      "Running Batch 479, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.867133855819702\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 479, Loss: 3.867133855819702\n",
      "Running Batch 480, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.875563621520996\n",
      "Running Batch 481, Epoch 4, Total Tokens: 236\n",
      "Loss: 3.9104676246643066\n",
      "Running Batch 482, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.746692419052124\n",
      "Running Batch 483, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8776941299438477\n",
      "Running Batch 484, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8605074882507324\n",
      "Running Batch 485, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.9232659339904785\n",
      "Running Batch 486, Epoch 4, Total Tokens: 182\n",
      "Loss: 3.8899612426757812\n",
      "Running Batch 487, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8171472549438477\n",
      "Running Batch 488, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.989891767501831\n",
      "Running Batch 489, Epoch 4, Total Tokens: 176\n",
      "Loss: 3.819509983062744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 489, Loss: 3.819509983062744\n",
      "Running Batch 490, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.9135828018188477\n",
      "Running Batch 491, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.807178258895874\n",
      "Running Batch 492, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.865291118621826\n",
      "Running Batch 493, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.914823055267334\n",
      "Running Batch 494, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.9155826568603516\n",
      "Running Batch 495, Epoch 4, Total Tokens: 572\n",
      "Loss: 3.8645522594451904\n",
      "Running Batch 496, Epoch 4, Total Tokens: 158\n",
      "Loss: 3.841604709625244\n",
      "Running Batch 497, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.854696750640869\n",
      "Running Batch 498, Epoch 4, Total Tokens: 190\n",
      "Loss: 3.825864553451538\n",
      "Running Batch 499, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.893465042114258\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 499, Loss: 3.893465042114258\n",
      "Running Batch 500, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.855156421661377\n",
      "Running Batch 501, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.897052526473999\n",
      "Running Batch 502, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8785319328308105\n",
      "Running Batch 503, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.862663745880127\n",
      "Running Batch 504, Epoch 4, Total Tokens: 230\n",
      "Loss: 3.8056726455688477\n",
      "Running Batch 505, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.9851601123809814\n",
      "Running Batch 506, Epoch 4, Total Tokens: 129\n",
      "Loss: 4.059581279754639\n",
      "Running Batch 507, Epoch 4, Total Tokens: 140\n",
      "Loss: 4.202756881713867\n",
      "Running Batch 508, Epoch 4, Total Tokens: 172\n",
      "Loss: 4.079953670501709\n",
      "Running Batch 509, Epoch 4, Total Tokens: 152\n",
      "Loss: 4.073333263397217\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 509, Loss: 4.073333263397217\n",
      "Running Batch 510, Epoch 4, Total Tokens: 294\n",
      "Loss: 4.036197662353516\n",
      "Running Batch 511, Epoch 4, Total Tokens: 151\n",
      "Loss: 4.009374618530273\n",
      "Running Batch 512, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.978513717651367\n",
      "Running Batch 513, Epoch 4, Total Tokens: 176\n",
      "Loss: 3.9657938480377197\n",
      "Running Batch 514, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.889535665512085\n",
      "Running Batch 515, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.868272066116333\n",
      "Running Batch 516, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.9078369140625\n",
      "Running Batch 517, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.9926187992095947\n",
      "Running Batch 518, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.9186460971832275\n",
      "Running Batch 519, Epoch 4, Total Tokens: 156\n",
      "Loss: 3.9791483879089355\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 519, Loss: 3.9791483879089355\n",
      "Running Batch 520, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8962323665618896\n",
      "Running Batch 521, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.9124553203582764\n",
      "Running Batch 522, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.9776957035064697\n",
      "Running Batch 523, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.8697311878204346\n",
      "Running Batch 524, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.949631929397583\n",
      "Running Batch 525, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8565540313720703\n",
      "Running Batch 526, Epoch 4, Total Tokens: 106\n",
      "Loss: 3.918344736099243\n",
      "Running Batch 527, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.9278883934020996\n",
      "Running Batch 528, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.8935189247131348\n",
      "Running Batch 529, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.957167387008667\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 529, Loss: 3.957167387008667\n",
      "Running Batch 530, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8862082958221436\n",
      "Running Batch 531, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.9241862297058105\n",
      "Running Batch 532, Epoch 4, Total Tokens: 152\n",
      "Loss: 4.000402450561523\n",
      "Running Batch 533, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8535594940185547\n",
      "Running Batch 534, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.866978168487549\n",
      "Running Batch 535, Epoch 4, Total Tokens: 199\n",
      "Loss: 3.9566025733947754\n",
      "Running Batch 536, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.860123872756958\n",
      "Running Batch 537, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.816237449645996\n",
      "Running Batch 538, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.870124578475952\n",
      "Running Batch 539, Epoch 4, Total Tokens: 224\n",
      "Loss: 3.91135311126709\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 539, Loss: 3.91135311126709\n",
      "Running Batch 540, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8688132762908936\n",
      "Running Batch 541, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7785749435424805\n",
      "Running Batch 542, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.98734188079834\n",
      "Running Batch 543, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.868936777114868\n",
      "Running Batch 544, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.871309280395508\n",
      "Running Batch 545, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8727545738220215\n",
      "Running Batch 546, Epoch 4, Total Tokens: 166\n",
      "Loss: 3.927509307861328\n",
      "Running Batch 547, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8527255058288574\n",
      "Running Batch 548, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.923844337463379\n",
      "Running Batch 549, Epoch 4, Total Tokens: 254\n",
      "Loss: 3.847952127456665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 549, Loss: 3.847952127456665\n",
      "Running Batch 550, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.950902223587036\n",
      "Running Batch 551, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.847918748855591\n",
      "Running Batch 552, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.831777811050415\n",
      "Running Batch 553, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8113954067230225\n",
      "Running Batch 554, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.863363742828369\n",
      "Running Batch 555, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.8583121299743652\n",
      "Running Batch 556, Epoch 4, Total Tokens: 179\n",
      "Loss: 3.9150450229644775\n",
      "Running Batch 557, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8813085556030273\n",
      "Running Batch 558, Epoch 4, Total Tokens: 170\n",
      "Loss: 3.989236831665039\n",
      "Running Batch 559, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8204667568206787\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 559, Loss: 3.8204667568206787\n",
      "Running Batch 560, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.8329379558563232\n",
      "Running Batch 561, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.802269458770752\n",
      "Running Batch 562, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8593292236328125\n",
      "Running Batch 563, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.979227066040039\n",
      "Running Batch 564, Epoch 4, Total Tokens: 117\n",
      "Loss: 3.8663344383239746\n",
      "Running Batch 565, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.783472776412964\n",
      "Running Batch 566, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.902172088623047\n",
      "Running Batch 567, Epoch 4, Total Tokens: 172\n",
      "Loss: 3.8413431644439697\n",
      "Running Batch 568, Epoch 4, Total Tokens: 106\n",
      "Loss: 3.929810047149658\n",
      "Running Batch 569, Epoch 4, Total Tokens: 220\n",
      "Loss: 3.9564967155456543\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 569, Loss: 3.9564967155456543\n",
      "Running Batch 570, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.866724967956543\n",
      "Running Batch 571, Epoch 4, Total Tokens: 170\n",
      "Loss: 3.87760591506958\n",
      "Running Batch 572, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.8596646785736084\n",
      "Running Batch 573, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.871629476547241\n",
      "Running Batch 574, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8168396949768066\n",
      "Running Batch 575, Epoch 4, Total Tokens: 285\n",
      "Loss: 3.8451597690582275\n",
      "Running Batch 576, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.9413554668426514\n",
      "Running Batch 577, Epoch 4, Total Tokens: 257\n",
      "Loss: 3.7685296535491943\n",
      "Running Batch 578, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.906792640686035\n",
      "Running Batch 579, Epoch 4, Total Tokens: 202\n",
      "Loss: 3.910853862762451\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 579, Loss: 3.910853862762451\n",
      "Running Batch 580, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8894293308258057\n",
      "Running Batch 581, Epoch 4, Total Tokens: 112\n",
      "Loss: 3.9066436290740967\n",
      "Running Batch 582, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.921510696411133\n",
      "Running Batch 583, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.87756085395813\n",
      "Running Batch 584, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.8687634468078613\n",
      "Running Batch 585, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.887676477432251\n",
      "Running Batch 586, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.789999008178711\n",
      "Running Batch 587, Epoch 4, Total Tokens: 237\n",
      "Loss: 3.933351516723633\n",
      "Running Batch 588, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8608057498931885\n",
      "Running Batch 589, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.844256639480591\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 589, Loss: 3.844256639480591\n",
      "Running Batch 590, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.7810845375061035\n",
      "Running Batch 591, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.842411756515503\n",
      "Running Batch 592, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.84659743309021\n",
      "Running Batch 593, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.891494035720825\n",
      "Running Batch 594, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8019216060638428\n",
      "Running Batch 595, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8891916275024414\n",
      "Running Batch 596, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8466901779174805\n",
      "Running Batch 597, Epoch 4, Total Tokens: 267\n",
      "Loss: 3.8117969036102295\n",
      "Running Batch 598, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.840181589126587\n",
      "Running Batch 599, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.778596878051758\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 599, Loss: 3.778596878051758\n",
      "Running Batch 600, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8286287784576416\n",
      "Running Batch 601, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.830557107925415\n",
      "Running Batch 602, Epoch 4, Total Tokens: 187\n",
      "Loss: 3.876399517059326\n",
      "Running Batch 603, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.811333417892456\n",
      "Running Batch 604, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8449621200561523\n",
      "Running Batch 605, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8479557037353516\n",
      "Running Batch 606, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.846513271331787\n",
      "Running Batch 607, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.890756845474243\n",
      "Running Batch 608, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8450539112091064\n",
      "Running Batch 609, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.846250295639038\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 609, Loss: 3.846250295639038\n",
      "Running Batch 610, Epoch 4, Total Tokens: 180\n",
      "Loss: 3.8076319694519043\n",
      "Running Batch 611, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.811581611633301\n",
      "Running Batch 612, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.8857576847076416\n",
      "Running Batch 613, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.7987208366394043\n",
      "Running Batch 614, Epoch 4, Total Tokens: 380\n",
      "Loss: 3.8221499919891357\n",
      "Running Batch 615, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8599586486816406\n",
      "Running Batch 616, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.860795021057129\n",
      "Running Batch 617, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.9371373653411865\n",
      "Running Batch 618, Epoch 4, Total Tokens: 195\n",
      "Loss: 3.8180415630340576\n",
      "Running Batch 619, Epoch 4, Total Tokens: 171\n",
      "Loss: 3.8789000511169434\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 619, Loss: 3.8789000511169434\n",
      "Running Batch 620, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.9095101356506348\n",
      "Running Batch 621, Epoch 4, Total Tokens: 186\n",
      "Loss: 3.817444324493408\n",
      "Running Batch 622, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8825974464416504\n",
      "Running Batch 623, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.9205989837646484\n",
      "Running Batch 624, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7948367595672607\n",
      "Running Batch 625, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8538382053375244\n",
      "Running Batch 626, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.9848577976226807\n",
      "Running Batch 627, Epoch 4, Total Tokens: 231\n",
      "Loss: 3.8088736534118652\n",
      "Running Batch 628, Epoch 4, Total Tokens: 190\n",
      "Loss: 3.8751518726348877\n",
      "Running Batch 629, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.9268767833709717\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 629, Loss: 3.9268767833709717\n",
      "Running Batch 630, Epoch 4, Total Tokens: 296\n",
      "Loss: 3.8620543479919434\n",
      "Running Batch 631, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.853825330734253\n",
      "Running Batch 632, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.818910598754883\n",
      "Running Batch 633, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.8123326301574707\n",
      "Running Batch 634, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.855790853500366\n",
      "Running Batch 635, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8097212314605713\n",
      "Running Batch 636, Epoch 4, Total Tokens: 183\n",
      "Loss: 3.8943264484405518\n",
      "Running Batch 637, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.795896530151367\n",
      "Running Batch 638, Epoch 4, Total Tokens: 111\n",
      "Loss: 3.801837921142578\n",
      "Running Batch 639, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8770861625671387\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 639, Loss: 3.8770861625671387\n",
      "Running Batch 640, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.921865224838257\n",
      "Running Batch 641, Epoch 4, Total Tokens: 162\n",
      "Loss: 3.892887592315674\n",
      "Running Batch 642, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8152706623077393\n",
      "Running Batch 643, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.8579983711242676\n",
      "Running Batch 644, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8007748126983643\n",
      "Running Batch 645, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.821796417236328\n",
      "Running Batch 646, Epoch 4, Total Tokens: 184\n",
      "Loss: 3.858947515487671\n",
      "Running Batch 647, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.842181921005249\n",
      "Running Batch 648, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.8184561729431152\n",
      "Running Batch 649, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8510162830352783\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 649, Loss: 3.8510162830352783\n",
      "Running Batch 650, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8746588230133057\n",
      "Running Batch 651, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.93975567817688\n",
      "Running Batch 652, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.98858380317688\n",
      "Running Batch 653, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.938174247741699\n",
      "Running Batch 654, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.960949420928955\n",
      "Running Batch 655, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.911074161529541\n",
      "Running Batch 656, Epoch 4, Total Tokens: 452\n",
      "Loss: 4.031297206878662\n",
      "Running Batch 657, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.990405321121216\n",
      "Running Batch 658, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.9359002113342285\n",
      "Running Batch 659, Epoch 4, Total Tokens: 169\n",
      "Loss: 3.8898062705993652\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 659, Loss: 3.8898062705993652\n",
      "Running Batch 660, Epoch 4, Total Tokens: 115\n",
      "Loss: 3.920335054397583\n",
      "Running Batch 661, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.9615540504455566\n",
      "Running Batch 662, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.891761302947998\n",
      "Running Batch 663, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.93114972114563\n",
      "Running Batch 664, Epoch 4, Total Tokens: 119\n",
      "Loss: 3.903827428817749\n",
      "Running Batch 665, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8934481143951416\n",
      "Running Batch 666, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.861441135406494\n",
      "Running Batch 667, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.870311975479126\n",
      "Running Batch 668, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8721485137939453\n",
      "Running Batch 669, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.945016384124756\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 669, Loss: 3.945016384124756\n",
      "Running Batch 670, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.9000325202941895\n",
      "Running Batch 671, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.896820545196533\n",
      "Running Batch 672, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8544507026672363\n",
      "Running Batch 673, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.8793671131134033\n",
      "Running Batch 674, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.789487838745117\n",
      "Running Batch 675, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8002734184265137\n",
      "Running Batch 676, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8572754859924316\n",
      "Running Batch 677, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8572776317596436\n",
      "Running Batch 678, Epoch 4, Total Tokens: 174\n",
      "Loss: 3.7955334186553955\n",
      "Running Batch 679, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8274450302124023\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 679, Loss: 3.8274450302124023\n",
      "Running Batch 680, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.848212718963623\n",
      "Running Batch 681, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8305141925811768\n",
      "Running Batch 682, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.753178358078003\n",
      "Running Batch 683, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8639214038848877\n",
      "Running Batch 684, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8479413986206055\n",
      "Running Batch 685, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.856808662414551\n",
      "Running Batch 686, Epoch 4, Total Tokens: 188\n",
      "Loss: 3.848210334777832\n",
      "Running Batch 687, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.896131992340088\n",
      "Running Batch 688, Epoch 4, Total Tokens: 274\n",
      "Loss: 3.7955851554870605\n",
      "Running Batch 689, Epoch 4, Total Tokens: 181\n",
      "Loss: 3.8423078060150146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 689, Loss: 3.8423078060150146\n",
      "Running Batch 690, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.820773124694824\n",
      "Running Batch 691, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.81255841255188\n",
      "Running Batch 692, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8770389556884766\n",
      "Running Batch 693, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8126087188720703\n",
      "Running Batch 694, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.8531694412231445\n",
      "Running Batch 695, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.9090373516082764\n",
      "Running Batch 696, Epoch 4, Total Tokens: 202\n",
      "Loss: 3.868196487426758\n",
      "Running Batch 697, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8552732467651367\n",
      "Running Batch 698, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.9047553539276123\n",
      "Running Batch 699, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8348805904388428\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 699, Loss: 3.8348805904388428\n",
      "Running Batch 700, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.898075819015503\n",
      "Running Batch 701, Epoch 4, Total Tokens: 104\n",
      "Loss: 3.919245719909668\n",
      "Running Batch 702, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.918217182159424\n",
      "Running Batch 703, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8882551193237305\n",
      "Running Batch 704, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8104615211486816\n",
      "Running Batch 705, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8363723754882812\n",
      "Running Batch 706, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.909715175628662\n",
      "Running Batch 707, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8659987449645996\n",
      "Running Batch 708, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8331239223480225\n",
      "Running Batch 709, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.9108309745788574\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 709, Loss: 3.9108309745788574\n",
      "Running Batch 710, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.884978771209717\n",
      "Running Batch 711, Epoch 4, Total Tokens: 196\n",
      "Loss: 3.845735788345337\n",
      "Running Batch 712, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.822089195251465\n",
      "Running Batch 713, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.852450132369995\n",
      "Running Batch 714, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8910164833068848\n",
      "Running Batch 715, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7729530334472656\n",
      "Running Batch 716, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.91595721244812\n",
      "Running Batch 717, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.785947561264038\n",
      "Running Batch 718, Epoch 4, Total Tokens: 299\n",
      "Loss: 3.772434949874878\n",
      "Running Batch 719, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.8785524368286133\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 719, Loss: 3.8785524368286133\n",
      "Running Batch 720, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8596091270446777\n",
      "Running Batch 721, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.880345106124878\n",
      "Running Batch 722, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8546125888824463\n",
      "Running Batch 723, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8680777549743652\n",
      "Running Batch 724, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.870034694671631\n",
      "Running Batch 725, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.788933753967285\n",
      "Running Batch 726, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.901677131652832\n",
      "Running Batch 727, Epoch 4, Total Tokens: 220\n",
      "Loss: 3.8003993034362793\n",
      "Running Batch 728, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.849989414215088\n",
      "Running Batch 729, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.7995121479034424\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 729, Loss: 3.7995121479034424\n",
      "Running Batch 730, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.9802188873291016\n",
      "Running Batch 731, Epoch 4, Total Tokens: 357\n",
      "Loss: 3.8536922931671143\n",
      "Running Batch 732, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7813024520874023\n",
      "Running Batch 733, Epoch 4, Total Tokens: 494\n",
      "Loss: 3.8452353477478027\n",
      "Running Batch 734, Epoch 4, Total Tokens: 219\n",
      "Loss: 3.81122088432312\n",
      "Running Batch 735, Epoch 4, Total Tokens: 281\n",
      "Loss: 3.8044793605804443\n",
      "Running Batch 736, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8086774349212646\n",
      "Running Batch 737, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.92791485786438\n",
      "Running Batch 738, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.810922622680664\n",
      "Running Batch 739, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8426334857940674\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 739, Loss: 3.8426334857940674\n",
      "Running Batch 740, Epoch 4, Total Tokens: 188\n",
      "Loss: 3.837583065032959\n",
      "Running Batch 741, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8091509342193604\n",
      "Running Batch 742, Epoch 4, Total Tokens: 234\n",
      "Loss: 3.816744327545166\n",
      "Running Batch 743, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.823124408721924\n",
      "Running Batch 744, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8518106937408447\n",
      "Running Batch 745, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.7991793155670166\n",
      "Running Batch 746, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.7490782737731934\n",
      "Running Batch 747, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.798321008682251\n",
      "Running Batch 748, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8568310737609863\n",
      "Running Batch 749, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.8204739093780518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 749, Loss: 3.8204739093780518\n",
      "Running Batch 750, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.7513182163238525\n",
      "Running Batch 751, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8440277576446533\n",
      "Running Batch 752, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.861717462539673\n",
      "Running Batch 753, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.902275562286377\n",
      "Running Batch 754, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.856180429458618\n",
      "Running Batch 755, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.812361240386963\n",
      "Running Batch 756, Epoch 4, Total Tokens: 178\n",
      "Loss: 3.882366180419922\n",
      "Running Batch 757, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8442037105560303\n",
      "Running Batch 758, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.8841094970703125\n",
      "Running Batch 759, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.862826108932495\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 759, Loss: 3.862826108932495\n",
      "Running Batch 760, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.808905601501465\n",
      "Running Batch 761, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8352532386779785\n",
      "Running Batch 762, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8171913623809814\n",
      "Running Batch 763, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.837374687194824\n",
      "Running Batch 764, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8521902561187744\n",
      "Running Batch 765, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.7907376289367676\n",
      "Running Batch 766, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.790052890777588\n",
      "Running Batch 767, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.78965163230896\n",
      "Running Batch 768, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8140110969543457\n",
      "Running Batch 769, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8366658687591553\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 769, Loss: 3.8366658687591553\n",
      "Running Batch 770, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.7912631034851074\n",
      "Running Batch 771, Epoch 4, Total Tokens: 217\n",
      "Loss: 3.8456413745880127\n",
      "Running Batch 772, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.7979581356048584\n",
      "Running Batch 773, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.8111138343811035\n",
      "Running Batch 774, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.823517084121704\n",
      "Running Batch 775, Epoch 4, Total Tokens: 203\n",
      "Loss: 3.902172565460205\n",
      "Running Batch 776, Epoch 4, Total Tokens: 188\n",
      "Loss: 3.8395907878875732\n",
      "Running Batch 777, Epoch 4, Total Tokens: 211\n",
      "Loss: 3.817833662033081\n",
      "Running Batch 778, Epoch 4, Total Tokens: 258\n",
      "Loss: 3.831468343734741\n",
      "Running Batch 779, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.802663803100586\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 779, Loss: 3.802663803100586\n",
      "Running Batch 780, Epoch 4, Total Tokens: 287\n",
      "Loss: 3.83270263671875\n",
      "Running Batch 781, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.798675060272217\n",
      "Running Batch 782, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8290786743164062\n",
      "Running Batch 783, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.7985734939575195\n",
      "Running Batch 784, Epoch 4, Total Tokens: 199\n",
      "Loss: 3.7529520988464355\n",
      "Running Batch 785, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.864516258239746\n",
      "Running Batch 786, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.7669591903686523\n",
      "Running Batch 787, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.847515821456909\n",
      "Running Batch 788, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8135547637939453\n",
      "Running Batch 789, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.7939367294311523\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 789, Loss: 3.7939367294311523\n",
      "Running Batch 790, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8034422397613525\n",
      "Running Batch 791, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.7956626415252686\n",
      "Running Batch 792, Epoch 4, Total Tokens: 225\n",
      "Loss: 3.7564966678619385\n",
      "Running Batch 793, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.9024698734283447\n",
      "Running Batch 794, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8426342010498047\n",
      "Running Batch 795, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8585104942321777\n",
      "Running Batch 796, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.822359800338745\n",
      "Running Batch 797, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.7481205463409424\n",
      "Running Batch 798, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.7763853073120117\n",
      "Running Batch 799, Epoch 4, Total Tokens: 162\n",
      "Loss: 3.8910977840423584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 799, Loss: 3.8910977840423584\n",
      "Running Batch 800, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8266963958740234\n",
      "Running Batch 801, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.803145170211792\n",
      "Running Batch 802, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.7777624130249023\n",
      "Running Batch 803, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8392271995544434\n",
      "Running Batch 804, Epoch 4, Total Tokens: 167\n",
      "Loss: 3.819098949432373\n",
      "Running Batch 805, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8300514221191406\n",
      "Running Batch 806, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.754725694656372\n",
      "Running Batch 807, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.82254695892334\n",
      "Running Batch 808, Epoch 4, Total Tokens: 119\n",
      "Loss: 3.839268684387207\n",
      "Running Batch 809, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8593099117279053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 809, Loss: 3.8593099117279053\n",
      "Running Batch 810, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.862597942352295\n",
      "Running Batch 811, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8021790981292725\n",
      "Running Batch 812, Epoch 4, Total Tokens: 202\n",
      "Loss: 3.83154034614563\n",
      "Running Batch 813, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.9593935012817383\n",
      "Running Batch 814, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.7410943508148193\n",
      "Running Batch 815, Epoch 4, Total Tokens: 172\n",
      "Loss: 3.8321280479431152\n",
      "Running Batch 816, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.8112268447875977\n",
      "Running Batch 817, Epoch 4, Total Tokens: 188\n",
      "Loss: 3.786226272583008\n",
      "Running Batch 818, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.858962059020996\n",
      "Running Batch 819, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.857163667678833\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 819, Loss: 3.857163667678833\n",
      "Running Batch 820, Epoch 4, Total Tokens: 112\n",
      "Loss: 3.874464750289917\n",
      "Running Batch 821, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8512232303619385\n",
      "Running Batch 822, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.780916452407837\n",
      "Running Batch 823, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.7948997020721436\n",
      "Running Batch 824, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.8208019733428955\n",
      "Running Batch 825, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.863675355911255\n",
      "Running Batch 826, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.8719804286956787\n",
      "Running Batch 827, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8621456623077393\n",
      "Running Batch 828, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8847265243530273\n",
      "Running Batch 829, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7962162494659424\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 829, Loss: 3.7962162494659424\n",
      "Running Batch 830, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8343634605407715\n",
      "Running Batch 831, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.90246319770813\n",
      "Running Batch 832, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.838192939758301\n",
      "Running Batch 833, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8281667232513428\n",
      "Running Batch 834, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.850707530975342\n",
      "Running Batch 835, Epoch 4, Total Tokens: 107\n",
      "Loss: 3.8262271881103516\n",
      "Running Batch 836, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.8561809062957764\n",
      "Running Batch 837, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.854295253753662\n",
      "Running Batch 838, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8314852714538574\n",
      "Running Batch 839, Epoch 4, Total Tokens: 181\n",
      "Loss: 3.824122905731201\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 839, Loss: 3.824122905731201\n",
      "Running Batch 840, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.8798604011535645\n",
      "Running Batch 841, Epoch 4, Total Tokens: 340\n",
      "Loss: 3.818342685699463\n",
      "Running Batch 842, Epoch 4, Total Tokens: 241\n",
      "Loss: 3.828554153442383\n",
      "Running Batch 843, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.907573938369751\n",
      "Running Batch 844, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.79606556892395\n",
      "Running Batch 845, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8289127349853516\n",
      "Running Batch 846, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8256564140319824\n",
      "Running Batch 847, Epoch 4, Total Tokens: 160\n",
      "Loss: 3.7982583045959473\n",
      "Running Batch 848, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.90498423576355\n",
      "Running Batch 849, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.965982437133789\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 849, Loss: 3.965982437133789\n",
      "Running Batch 850, Epoch 4, Total Tokens: 186\n",
      "Loss: 3.876703977584839\n",
      "Running Batch 851, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8051793575286865\n",
      "Running Batch 852, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8363211154937744\n",
      "Running Batch 853, Epoch 4, Total Tokens: 110\n",
      "Loss: 3.78143310546875\n",
      "Running Batch 854, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.810063600540161\n",
      "Running Batch 855, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8481857776641846\n",
      "Running Batch 856, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.831571102142334\n",
      "Running Batch 857, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8781070709228516\n",
      "Running Batch 858, Epoch 4, Total Tokens: 115\n",
      "Loss: 3.9077935218811035\n",
      "Running Batch 859, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.8392934799194336\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 859, Loss: 3.8392934799194336\n",
      "Running Batch 860, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8231663703918457\n",
      "Running Batch 861, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.9293644428253174\n",
      "Running Batch 862, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.867053747177124\n",
      "Running Batch 863, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8575704097747803\n",
      "Running Batch 864, Epoch 4, Total Tokens: 170\n",
      "Loss: 3.8005762100219727\n",
      "Running Batch 865, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8402044773101807\n",
      "Running Batch 866, Epoch 4, Total Tokens: 127\n",
      "Loss: 3.795957088470459\n",
      "Running Batch 867, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8132312297821045\n",
      "Running Batch 868, Epoch 4, Total Tokens: 196\n",
      "Loss: 3.851245164871216\n",
      "Running Batch 869, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8538401126861572\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 869, Loss: 3.8538401126861572\n",
      "Running Batch 870, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.859046459197998\n",
      "Running Batch 871, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.705637216567993\n",
      "Running Batch 872, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8892037868499756\n",
      "Running Batch 873, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.848771810531616\n",
      "Running Batch 874, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8131558895111084\n",
      "Running Batch 875, Epoch 4, Total Tokens: 199\n",
      "Loss: 3.8466975688934326\n",
      "Running Batch 876, Epoch 4, Total Tokens: 117\n",
      "Loss: 3.8695695400238037\n",
      "Running Batch 877, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.863943099975586\n",
      "Running Batch 878, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.825439453125\n",
      "Running Batch 879, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.8887648582458496\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 879, Loss: 3.8887648582458496\n",
      "Running Batch 880, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.802152395248413\n",
      "Running Batch 881, Epoch 4, Total Tokens: 170\n",
      "Loss: 3.840876817703247\n",
      "Running Batch 882, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8658926486968994\n",
      "Running Batch 883, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.7393300533294678\n",
      "Running Batch 884, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.784789562225342\n",
      "Running Batch 885, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.870159864425659\n",
      "Running Batch 886, Epoch 4, Total Tokens: 163\n",
      "Loss: 3.812143325805664\n",
      "Running Batch 887, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8351430892944336\n",
      "Running Batch 888, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8350491523742676\n",
      "Running Batch 889, Epoch 4, Total Tokens: 250\n",
      "Loss: 3.8657286167144775\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 889, Loss: 3.8657286167144775\n",
      "Running Batch 890, Epoch 4, Total Tokens: 111\n",
      "Loss: 3.8851311206817627\n",
      "Running Batch 891, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.8008322715759277\n",
      "Running Batch 892, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.7834715843200684\n",
      "Running Batch 893, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8166744709014893\n",
      "Running Batch 894, Epoch 4, Total Tokens: 178\n",
      "Loss: 3.810497760772705\n",
      "Running Batch 895, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8677124977111816\n",
      "Running Batch 896, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.8291749954223633\n",
      "Running Batch 897, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8156955242156982\n",
      "Running Batch 898, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.784640312194824\n",
      "Running Batch 899, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.8564624786376953\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 899, Loss: 3.8564624786376953\n",
      "Running Batch 900, Epoch 4, Total Tokens: 169\n",
      "Loss: 3.879934072494507\n",
      "Running Batch 901, Epoch 4, Total Tokens: 326\n",
      "Loss: 3.8747317790985107\n",
      "Running Batch 902, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.911120653152466\n",
      "Running Batch 903, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8138537406921387\n",
      "Running Batch 904, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8448667526245117\n",
      "Running Batch 905, Epoch 4, Total Tokens: 108\n",
      "Loss: 3.907958507537842\n",
      "Running Batch 906, Epoch 4, Total Tokens: 118\n",
      "Loss: 3.857611656188965\n",
      "Running Batch 907, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.8268394470214844\n",
      "Running Batch 908, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.858452796936035\n",
      "Running Batch 909, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8163959980010986\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 909, Loss: 3.8163959980010986\n",
      "Running Batch 910, Epoch 4, Total Tokens: 197\n",
      "Loss: 3.7778546810150146\n",
      "Running Batch 911, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8403124809265137\n",
      "Running Batch 912, Epoch 4, Total Tokens: 117\n",
      "Loss: 3.7936341762542725\n",
      "Running Batch 913, Epoch 4, Total Tokens: 171\n",
      "Loss: 3.8047263622283936\n",
      "Running Batch 914, Epoch 4, Total Tokens: 179\n",
      "Loss: 3.8013498783111572\n",
      "Running Batch 915, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.848093271255493\n",
      "Running Batch 916, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7992970943450928\n",
      "Running Batch 917, Epoch 4, Total Tokens: 155\n",
      "Loss: 3.7545111179351807\n",
      "Running Batch 918, Epoch 4, Total Tokens: 171\n",
      "Loss: 3.841233491897583\n",
      "Running Batch 919, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.795936107635498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 919, Loss: 3.795936107635498\n",
      "Running Batch 920, Epoch 4, Total Tokens: 162\n",
      "Loss: 3.964261293411255\n",
      "Running Batch 921, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.857325315475464\n",
      "Running Batch 922, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8706278800964355\n",
      "Running Batch 923, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8262059688568115\n",
      "Running Batch 924, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.8259501457214355\n",
      "Running Batch 925, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.827781915664673\n",
      "Running Batch 926, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.750136375427246\n",
      "Running Batch 927, Epoch 4, Total Tokens: 192\n",
      "Loss: 3.8351166248321533\n",
      "Running Batch 928, Epoch 4, Total Tokens: 367\n",
      "Loss: 3.8020269870758057\n",
      "Running Batch 929, Epoch 4, Total Tokens: 125\n",
      "Loss: 3.7696168422698975\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 929, Loss: 3.7696168422698975\n",
      "Running Batch 930, Epoch 4, Total Tokens: 221\n",
      "Loss: 3.837515354156494\n",
      "Running Batch 931, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.750032424926758\n",
      "Running Batch 932, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.826244592666626\n",
      "Running Batch 933, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.9063966274261475\n",
      "Running Batch 934, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.891899824142456\n",
      "Running Batch 935, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.844275951385498\n",
      "Running Batch 936, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.8086211681365967\n",
      "Running Batch 937, Epoch 4, Total Tokens: 224\n",
      "Loss: 3.7762584686279297\n",
      "Running Batch 938, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8219118118286133\n",
      "Running Batch 939, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.7993319034576416\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 939, Loss: 3.7993319034576416\n",
      "Running Batch 940, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.835756301879883\n",
      "Running Batch 941, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.832204580307007\n",
      "Running Batch 942, Epoch 4, Total Tokens: 293\n",
      "Loss: 3.7316348552703857\n",
      "Running Batch 943, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.9196574687957764\n",
      "Running Batch 944, Epoch 4, Total Tokens: 107\n",
      "Loss: 3.8384947776794434\n",
      "Running Batch 945, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8441789150238037\n",
      "Running Batch 946, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.785431385040283\n",
      "Running Batch 947, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.848710060119629\n",
      "Running Batch 948, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8164069652557373\n",
      "Running Batch 949, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.877149820327759\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 949, Loss: 3.877149820327759\n",
      "Running Batch 950, Epoch 4, Total Tokens: 122\n",
      "Loss: 3.8644003868103027\n",
      "Running Batch 951, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7905988693237305\n",
      "Running Batch 952, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8750338554382324\n",
      "Running Batch 953, Epoch 4, Total Tokens: 254\n",
      "Loss: 3.819241762161255\n",
      "Running Batch 954, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.866093158721924\n",
      "Running Batch 955, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.7960970401763916\n",
      "Running Batch 956, Epoch 4, Total Tokens: 164\n",
      "Loss: 3.856513261795044\n",
      "Running Batch 957, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.889972686767578\n",
      "Running Batch 958, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.873816728591919\n",
      "Running Batch 959, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.909842014312744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 959, Loss: 3.909842014312744\n",
      "Running Batch 960, Epoch 4, Total Tokens: 167\n",
      "Loss: 3.7938530445098877\n",
      "Running Batch 961, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8344781398773193\n",
      "Running Batch 962, Epoch 4, Total Tokens: 203\n",
      "Loss: 3.8402371406555176\n",
      "Running Batch 963, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.830735921859741\n",
      "Running Batch 964, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.837594509124756\n",
      "Running Batch 965, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8064591884613037\n",
      "Running Batch 966, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.791649341583252\n",
      "Running Batch 967, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8062005043029785\n",
      "Running Batch 968, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.9428043365478516\n",
      "Running Batch 969, Epoch 4, Total Tokens: 281\n",
      "Loss: 3.8180458545684814\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 969, Loss: 3.8180458545684814\n",
      "Running Batch 970, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8797621726989746\n",
      "Running Batch 971, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.9153592586517334\n",
      "Running Batch 972, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.79880690574646\n",
      "Running Batch 973, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.7685720920562744\n",
      "Running Batch 974, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.7696948051452637\n",
      "Running Batch 975, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.812917709350586\n",
      "Running Batch 976, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8316867351531982\n",
      "Running Batch 977, Epoch 4, Total Tokens: 162\n",
      "Loss: 3.7970802783966064\n",
      "Running Batch 978, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.897170305252075\n",
      "Running Batch 979, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.8522989749908447\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 979, Loss: 3.8522989749908447\n",
      "Running Batch 980, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.8388521671295166\n",
      "Running Batch 981, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.794558525085449\n",
      "Running Batch 982, Epoch 4, Total Tokens: 185\n",
      "Loss: 3.8154613971710205\n",
      "Running Batch 983, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.796936273574829\n",
      "Running Batch 984, Epoch 4, Total Tokens: 119\n",
      "Loss: 3.8694732189178467\n",
      "Running Batch 985, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.7871668338775635\n",
      "Running Batch 986, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.7780909538269043\n",
      "Running Batch 987, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.723334312438965\n",
      "Running Batch 988, Epoch 4, Total Tokens: 360\n",
      "Loss: 3.824772834777832\n",
      "Running Batch 989, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.894084930419922\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 989, Loss: 3.894084930419922\n",
      "Running Batch 990, Epoch 4, Total Tokens: 156\n",
      "Loss: 3.873885154724121\n",
      "Running Batch 991, Epoch 4, Total Tokens: 193\n",
      "Loss: 3.731011152267456\n",
      "Running Batch 992, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.8613641262054443\n",
      "Running Batch 993, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8584136962890625\n",
      "Running Batch 994, Epoch 4, Total Tokens: 142\n",
      "Loss: 3.8216686248779297\n",
      "Running Batch 995, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.800589084625244\n",
      "Running Batch 996, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.747288227081299\n",
      "Running Batch 997, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.7690751552581787\n",
      "Running Batch 998, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.776064157485962\n",
      "Running Batch 999, Epoch 4, Total Tokens: 334\n",
      "Loss: 3.7890026569366455\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 999, Loss: 3.7890026569366455\n",
      "Running Batch 1000, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.844317674636841\n",
      "Running Batch 1001, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.7629528045654297\n",
      "Running Batch 1002, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.776691198348999\n",
      "Running Batch 1003, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.849444627761841\n",
      "Running Batch 1004, Epoch 4, Total Tokens: 190\n",
      "Loss: 3.833425998687744\n",
      "Running Batch 1005, Epoch 4, Total Tokens: 174\n",
      "Loss: 3.7977280616760254\n",
      "Running Batch 1006, Epoch 4, Total Tokens: 201\n",
      "Loss: 3.800455331802368\n",
      "Running Batch 1007, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8391902446746826\n",
      "Running Batch 1008, Epoch 4, Total Tokens: 203\n",
      "Loss: 3.8432297706604004\n",
      "Running Batch 1009, Epoch 4, Total Tokens: 266\n",
      "Loss: 3.854706048965454\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1009, Loss: 3.854706048965454\n",
      "Running Batch 1010, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.7371199131011963\n",
      "Running Batch 1011, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8205785751342773\n",
      "Running Batch 1012, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.7960362434387207\n",
      "Running Batch 1013, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.796560049057007\n",
      "Running Batch 1014, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.7929511070251465\n",
      "Running Batch 1015, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.7915027141571045\n",
      "Running Batch 1016, Epoch 4, Total Tokens: 251\n",
      "Loss: 3.7865166664123535\n",
      "Running Batch 1017, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.787595510482788\n",
      "Running Batch 1018, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.806999921798706\n",
      "Running Batch 1019, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8393008708953857\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1019, Loss: 3.8393008708953857\n",
      "Running Batch 1020, Epoch 4, Total Tokens: 139\n",
      "Loss: 3.8029613494873047\n",
      "Running Batch 1021, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.7763023376464844\n",
      "Running Batch 1022, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.816042900085449\n",
      "Running Batch 1023, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.7715566158294678\n",
      "Running Batch 1024, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.746870279312134\n",
      "Running Batch 1025, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.816509962081909\n",
      "Running Batch 1026, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.7878475189208984\n",
      "Running Batch 1027, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.8635194301605225\n",
      "Running Batch 1028, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.777195692062378\n",
      "Running Batch 1029, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.7964859008789062\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1029, Loss: 3.7964859008789062\n",
      "Running Batch 1030, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.723607301712036\n",
      "Running Batch 1031, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.8065195083618164\n",
      "Running Batch 1032, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.826529026031494\n",
      "Running Batch 1033, Epoch 4, Total Tokens: 231\n",
      "Loss: 3.7306950092315674\n",
      "Running Batch 1034, Epoch 4, Total Tokens: 195\n",
      "Loss: 3.781074285507202\n",
      "Running Batch 1035, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.875788450241089\n",
      "Running Batch 1036, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.809511184692383\n",
      "Running Batch 1037, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8681440353393555\n",
      "Running Batch 1038, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.8438284397125244\n",
      "Running Batch 1039, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8836963176727295\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1039, Loss: 3.8836963176727295\n",
      "Running Batch 1040, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.8776657581329346\n",
      "Running Batch 1041, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.7996022701263428\n",
      "Running Batch 1042, Epoch 4, Total Tokens: 206\n",
      "Loss: 3.7763545513153076\n",
      "Running Batch 1043, Epoch 4, Total Tokens: 169\n",
      "Loss: 3.882338047027588\n",
      "Running Batch 1044, Epoch 4, Total Tokens: 236\n",
      "Loss: 3.809574604034424\n",
      "Running Batch 1045, Epoch 4, Total Tokens: 157\n",
      "Loss: 3.782898426055908\n",
      "Running Batch 1046, Epoch 4, Total Tokens: 129\n",
      "Loss: 3.8347795009613037\n",
      "Running Batch 1047, Epoch 4, Total Tokens: 117\n",
      "Loss: 3.9073398113250732\n",
      "Running Batch 1048, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8519318103790283\n",
      "Running Batch 1049, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8560264110565186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1049, Loss: 3.8560264110565186\n",
      "Running Batch 1050, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.816821336746216\n",
      "Running Batch 1051, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.78237247467041\n",
      "Running Batch 1052, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.820418119430542\n",
      "Running Batch 1053, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.7987825870513916\n",
      "Running Batch 1054, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8142647743225098\n",
      "Running Batch 1055, Epoch 4, Total Tokens: 107\n",
      "Loss: 3.820129632949829\n",
      "Running Batch 1056, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.803123950958252\n",
      "Running Batch 1057, Epoch 4, Total Tokens: 191\n",
      "Loss: 3.861539125442505\n",
      "Running Batch 1058, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.8419253826141357\n",
      "Running Batch 1059, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.7946231365203857\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1059, Loss: 3.7946231365203857\n",
      "Running Batch 1060, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.860602855682373\n",
      "Running Batch 1061, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.740311861038208\n",
      "Running Batch 1062, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8165011405944824\n",
      "Running Batch 1063, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.7836434841156006\n",
      "Running Batch 1064, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.7569475173950195\n",
      "Running Batch 1065, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.821310520172119\n",
      "Running Batch 1066, Epoch 4, Total Tokens: 372\n",
      "Loss: 3.764845609664917\n",
      "Running Batch 1067, Epoch 4, Total Tokens: 173\n",
      "Loss: 3.883289098739624\n",
      "Running Batch 1068, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.877734899520874\n",
      "Running Batch 1069, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.8231003284454346\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1069, Loss: 3.8231003284454346\n",
      "Running Batch 1070, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.788120985031128\n",
      "Running Batch 1071, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.8073434829711914\n",
      "Running Batch 1072, Epoch 4, Total Tokens: 124\n",
      "Loss: 3.788987874984741\n",
      "Running Batch 1073, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.884051561355591\n",
      "Running Batch 1074, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.834615707397461\n",
      "Running Batch 1075, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7920684814453125\n",
      "Running Batch 1076, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.7917182445526123\n",
      "Running Batch 1077, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8957974910736084\n",
      "Running Batch 1078, Epoch 4, Total Tokens: 206\n",
      "Loss: 3.811988115310669\n",
      "Running Batch 1079, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.8301334381103516\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1079, Loss: 3.8301334381103516\n",
      "Running Batch 1080, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7884891033172607\n",
      "Running Batch 1081, Epoch 4, Total Tokens: 159\n",
      "Loss: 3.7944416999816895\n",
      "Running Batch 1082, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.824840784072876\n",
      "Running Batch 1083, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.7217512130737305\n",
      "Running Batch 1084, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.762338399887085\n",
      "Running Batch 1085, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.847778797149658\n",
      "Running Batch 1086, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8380072116851807\n",
      "Running Batch 1087, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.740504741668701\n",
      "Running Batch 1088, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.7726573944091797\n",
      "Running Batch 1089, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.788177490234375\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1089, Loss: 3.788177490234375\n",
      "Running Batch 1090, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.7957026958465576\n",
      "Running Batch 1091, Epoch 4, Total Tokens: 141\n",
      "Loss: 3.8145737648010254\n",
      "Running Batch 1092, Epoch 4, Total Tokens: 185\n",
      "Loss: 3.84745454788208\n",
      "Running Batch 1093, Epoch 4, Total Tokens: 99\n",
      "Loss: 3.8098206520080566\n",
      "Running Batch 1094, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.793592691421509\n",
      "Running Batch 1095, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.7429986000061035\n",
      "Running Batch 1096, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.772573709487915\n",
      "Running Batch 1097, Epoch 4, Total Tokens: 160\n",
      "Loss: 3.85304856300354\n",
      "Running Batch 1098, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.759492874145508\n",
      "Running Batch 1099, Epoch 4, Total Tokens: 131\n",
      "Loss: 3.8159663677215576\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1099, Loss: 3.8159663677215576\n",
      "Running Batch 1100, Epoch 4, Total Tokens: 169\n",
      "Loss: 3.8213424682617188\n",
      "Running Batch 1101, Epoch 4, Total Tokens: 116\n",
      "Loss: 3.7780826091766357\n",
      "Running Batch 1102, Epoch 4, Total Tokens: 136\n",
      "Loss: 3.767080545425415\n",
      "Running Batch 1103, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.7897443771362305\n",
      "Running Batch 1104, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.850747585296631\n",
      "Running Batch 1105, Epoch 4, Total Tokens: 137\n",
      "Loss: 3.8488643169403076\n",
      "Running Batch 1106, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.706216812133789\n",
      "Running Batch 1107, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.75429105758667\n",
      "Running Batch 1108, Epoch 4, Total Tokens: 114\n",
      "Loss: 3.7790331840515137\n",
      "Running Batch 1109, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8398687839508057\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1109, Loss: 3.8398687839508057\n",
      "Running Batch 1110, Epoch 4, Total Tokens: 143\n",
      "Loss: 3.8282692432403564\n",
      "Running Batch 1111, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.7731425762176514\n",
      "Running Batch 1112, Epoch 4, Total Tokens: 120\n",
      "Loss: 3.8617470264434814\n",
      "Running Batch 1113, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.763934373855591\n",
      "Running Batch 1114, Epoch 4, Total Tokens: 156\n",
      "Loss: 3.7588772773742676\n",
      "Running Batch 1115, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.782477855682373\n",
      "Running Batch 1116, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.8556156158447266\n",
      "Running Batch 1117, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.7849974632263184\n",
      "Running Batch 1118, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.819166660308838\n",
      "Running Batch 1119, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.745441198348999\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1119, Loss: 3.745441198348999\n",
      "Running Batch 1120, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.8216872215270996\n",
      "Running Batch 1121, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.831835985183716\n",
      "Running Batch 1122, Epoch 4, Total Tokens: 153\n",
      "Loss: 3.8139238357543945\n",
      "Running Batch 1123, Epoch 4, Total Tokens: 172\n",
      "Loss: 3.8078207969665527\n",
      "Running Batch 1124, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.938807249069214\n",
      "Running Batch 1125, Epoch 4, Total Tokens: 356\n",
      "Loss: 3.7874364852905273\n",
      "Running Batch 1126, Epoch 4, Total Tokens: 151\n",
      "Loss: 3.8222239017486572\n",
      "Running Batch 1127, Epoch 4, Total Tokens: 135\n",
      "Loss: 3.8208234310150146\n",
      "Running Batch 1128, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.8097031116485596\n",
      "Running Batch 1129, Epoch 4, Total Tokens: 149\n",
      "Loss: 3.8041627407073975\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1129, Loss: 3.8041627407073975\n",
      "Running Batch 1130, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.829998731613159\n",
      "Running Batch 1131, Epoch 4, Total Tokens: 428\n",
      "Loss: 3.838387966156006\n",
      "Running Batch 1132, Epoch 4, Total Tokens: 166\n",
      "Loss: 3.7787811756134033\n",
      "Running Batch 1133, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.799100399017334\n",
      "Running Batch 1134, Epoch 4, Total Tokens: 130\n",
      "Loss: 3.802281141281128\n",
      "Running Batch 1135, Epoch 4, Total Tokens: 154\n",
      "Loss: 3.8908417224884033\n",
      "Running Batch 1136, Epoch 4, Total Tokens: 187\n",
      "Loss: 3.8199069499969482\n",
      "Running Batch 1137, Epoch 4, Total Tokens: 145\n",
      "Loss: 3.7886853218078613\n",
      "Running Batch 1138, Epoch 4, Total Tokens: 163\n",
      "Loss: 3.864201307296753\n",
      "Running Batch 1139, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.76981258392334\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1139, Loss: 3.76981258392334\n",
      "Running Batch 1140, Epoch 4, Total Tokens: 123\n",
      "Loss: 3.8657281398773193\n",
      "Running Batch 1141, Epoch 4, Total Tokens: 126\n",
      "Loss: 3.814572334289551\n",
      "Running Batch 1142, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.911527633666992\n",
      "Running Batch 1143, Epoch 4, Total Tokens: 384\n",
      "Loss: 3.9068856239318848\n",
      "Running Batch 1144, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.794741630554199\n",
      "Running Batch 1145, Epoch 4, Total Tokens: 133\n",
      "Loss: 3.8738601207733154\n",
      "Running Batch 1146, Epoch 4, Total Tokens: 148\n",
      "Loss: 3.767141580581665\n",
      "Running Batch 1147, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.7960867881774902\n",
      "Running Batch 1148, Epoch 4, Total Tokens: 165\n",
      "Loss: 3.832362174987793\n",
      "Running Batch 1149, Epoch 4, Total Tokens: 138\n",
      "Loss: 3.8590211868286133\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1149, Loss: 3.8590211868286133\n",
      "Running Batch 1150, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.7516977787017822\n",
      "Running Batch 1151, Epoch 4, Total Tokens: 132\n",
      "Loss: 3.798607110977173\n",
      "Running Batch 1152, Epoch 4, Total Tokens: 119\n",
      "Loss: 3.792022705078125\n",
      "Running Batch 1153, Epoch 4, Total Tokens: 179\n",
      "Loss: 3.8124678134918213\n",
      "Running Batch 1154, Epoch 4, Total Tokens: 418\n",
      "Loss: 3.815370559692383\n",
      "Running Batch 1155, Epoch 4, Total Tokens: 147\n",
      "Loss: 3.795484781265259\n",
      "Running Batch 1156, Epoch 4, Total Tokens: 178\n",
      "Loss: 3.835798501968384\n",
      "Running Batch 1157, Epoch 4, Total Tokens: 223\n",
      "Loss: 3.841778516769409\n",
      "Running Batch 1158, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.830843925476074\n",
      "Running Batch 1159, Epoch 4, Total Tokens: 115\n",
      "Loss: 3.777087688446045\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1159, Loss: 3.777087688446045\n",
      "Running Batch 1160, Epoch 4, Total Tokens: 152\n",
      "Loss: 3.815338373184204\n",
      "Running Batch 1161, Epoch 4, Total Tokens: 161\n",
      "Loss: 3.817111015319824\n",
      "Running Batch 1162, Epoch 4, Total Tokens: 144\n",
      "Loss: 3.840707540512085\n",
      "Running Batch 1163, Epoch 4, Total Tokens: 134\n",
      "Loss: 3.7597262859344482\n",
      "Running Batch 1164, Epoch 4, Total Tokens: 140\n",
      "Loss: 3.763864755630493\n",
      "Running Batch 1165, Epoch 4, Total Tokens: 183\n",
      "Loss: 3.780163526535034\n",
      "Running Batch 1166, Epoch 4, Total Tokens: 128\n",
      "Loss: 3.8807671070098877\n",
      "Running Batch 1167, Epoch 4, Total Tokens: 150\n",
      "Loss: 3.7688591480255127\n",
      "Running Batch 1168, Epoch 4, Total Tokens: 146\n",
      "Loss: 3.851191282272339\n",
      "Running Batch 1169, Epoch 4, Total Tokens: 121\n",
      "Loss: 3.7789225578308105\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 1169, Loss: 3.7789225578308105\n",
      "Running Batch 1170, Epoch 4, Total Tokens: 254\n",
      "Loss: 3.8385603427886963\n",
      "Running Batch 1171, Epoch 4, Total Tokens: 258\n",
      "Loss: 3.8787431716918945\n",
      "AVG LOSS: 3.8538209869186217, Epoch: 5\n",
      "Running Batch 0, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.817129135131836\n",
      "Running Batch 1, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.807586431503296\n",
      "Running Batch 2, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7744314670562744\n",
      "Running Batch 3, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7893199920654297\n",
      "Running Batch 4, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8224904537200928\n",
      "Running Batch 5, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.787889242172241\n",
      "Running Batch 6, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8265957832336426\n",
      "Running Batch 7, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8709933757781982\n",
      "Running Batch 8, Epoch 5, Total Tokens: 230\n",
      "Loss: 3.8236451148986816\n",
      "Running Batch 9, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.7503156661987305\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 9, Loss: 3.7503156661987305\n",
      "Running Batch 10, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7578659057617188\n",
      "Running Batch 11, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8351497650146484\n",
      "Running Batch 12, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8098831176757812\n",
      "Running Batch 13, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.762159585952759\n",
      "Running Batch 14, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.911111831665039\n",
      "Running Batch 15, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7671430110931396\n",
      "Running Batch 16, Epoch 5, Total Tokens: 172\n",
      "Loss: 3.7949142456054688\n",
      "Running Batch 17, Epoch 5, Total Tokens: 324\n",
      "Loss: 3.80802321434021\n",
      "Running Batch 18, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.7399423122406006\n",
      "Running Batch 19, Epoch 5, Total Tokens: 105\n",
      "Loss: 3.7336769104003906\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 19, Loss: 3.7336769104003906\n",
      "Running Batch 20, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7834086418151855\n",
      "Running Batch 21, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8267617225646973\n",
      "Running Batch 22, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.824686050415039\n",
      "Running Batch 23, Epoch 5, Total Tokens: 182\n",
      "Loss: 3.8160018920898438\n",
      "Running Batch 24, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.7349326610565186\n",
      "Running Batch 25, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7918760776519775\n",
      "Running Batch 26, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8331820964813232\n",
      "Running Batch 27, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.889667272567749\n",
      "Running Batch 28, Epoch 5, Total Tokens: 214\n",
      "Loss: 3.876446008682251\n",
      "Running Batch 29, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.86820387840271\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 29, Loss: 3.86820387840271\n",
      "Running Batch 30, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.908226728439331\n",
      "Running Batch 31, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7212047576904297\n",
      "Running Batch 32, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7993428707122803\n",
      "Running Batch 33, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8489387035369873\n",
      "Running Batch 34, Epoch 5, Total Tokens: 179\n",
      "Loss: 3.7448229789733887\n",
      "Running Batch 35, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7335121631622314\n",
      "Running Batch 36, Epoch 5, Total Tokens: 177\n",
      "Loss: 3.819373369216919\n",
      "Running Batch 37, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.891662120819092\n",
      "Running Batch 38, Epoch 5, Total Tokens: 185\n",
      "Loss: 3.8404510021209717\n",
      "Running Batch 39, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.7656240463256836\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 39, Loss: 3.7656240463256836\n",
      "Running Batch 40, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7494075298309326\n",
      "Running Batch 41, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8878135681152344\n",
      "Running Batch 42, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.750974178314209\n",
      "Running Batch 43, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7678284645080566\n",
      "Running Batch 44, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.770378828048706\n",
      "Running Batch 45, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.906529188156128\n",
      "Running Batch 46, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8032023906707764\n",
      "Running Batch 47, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.763833999633789\n",
      "Running Batch 48, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.7487001419067383\n",
      "Running Batch 49, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7948906421661377\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 49, Loss: 3.7948906421661377\n",
      "Running Batch 50, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.8361456394195557\n",
      "Running Batch 51, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.7554306983947754\n",
      "Running Batch 52, Epoch 5, Total Tokens: 171\n",
      "Loss: 3.7781741619110107\n",
      "Running Batch 53, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.845743417739868\n",
      "Running Batch 54, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8313238620758057\n",
      "Running Batch 55, Epoch 5, Total Tokens: 351\n",
      "Loss: 3.7800843715667725\n",
      "Running Batch 56, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8551387786865234\n",
      "Running Batch 57, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7986505031585693\n",
      "Running Batch 58, Epoch 5, Total Tokens: 294\n",
      "Loss: 3.792323112487793\n",
      "Running Batch 59, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.870076894760132\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 59, Loss: 3.870076894760132\n",
      "Running Batch 60, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.921910524368286\n",
      "Running Batch 61, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7678346633911133\n",
      "Running Batch 62, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.850881576538086\n",
      "Running Batch 63, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.750432252883911\n",
      "Running Batch 64, Epoch 5, Total Tokens: 199\n",
      "Loss: 3.8151440620422363\n",
      "Running Batch 65, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.804288148880005\n",
      "Running Batch 66, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.793050527572632\n",
      "Running Batch 67, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.8552544116973877\n",
      "Running Batch 68, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7954769134521484\n",
      "Running Batch 69, Epoch 5, Total Tokens: 428\n",
      "Loss: 3.7822630405426025\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 69, Loss: 3.7822630405426025\n",
      "Running Batch 70, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.794735908508301\n",
      "Running Batch 71, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.7444872856140137\n",
      "Running Batch 72, Epoch 5, Total Tokens: 187\n",
      "Loss: 3.896165132522583\n",
      "Running Batch 73, Epoch 5, Total Tokens: 158\n",
      "Loss: 3.784362554550171\n",
      "Running Batch 74, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.8789947032928467\n",
      "Running Batch 75, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.7827670574188232\n",
      "Running Batch 76, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8227083683013916\n",
      "Running Batch 77, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8134586811065674\n",
      "Running Batch 78, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8036348819732666\n",
      "Running Batch 79, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.886554002761841\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 79, Loss: 3.886554002761841\n",
      "Running Batch 80, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.869152545928955\n",
      "Running Batch 81, Epoch 5, Total Tokens: 112\n",
      "Loss: 3.8244216442108154\n",
      "Running Batch 82, Epoch 5, Total Tokens: 262\n",
      "Loss: 3.760016918182373\n",
      "Running Batch 83, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.819495916366577\n",
      "Running Batch 84, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7746994495391846\n",
      "Running Batch 85, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8072855472564697\n",
      "Running Batch 86, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.808844804763794\n",
      "Running Batch 87, Epoch 5, Total Tokens: 179\n",
      "Loss: 3.936434268951416\n",
      "Running Batch 88, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.8372113704681396\n",
      "Running Batch 89, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.8365588188171387\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 89, Loss: 3.8365588188171387\n",
      "Running Batch 90, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.870816469192505\n",
      "Running Batch 91, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.7886791229248047\n",
      "Running Batch 92, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.781982183456421\n",
      "Running Batch 93, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.836196184158325\n",
      "Running Batch 94, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7389402389526367\n",
      "Running Batch 95, Epoch 5, Total Tokens: 190\n",
      "Loss: 3.8149490356445312\n",
      "Running Batch 96, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.769655704498291\n",
      "Running Batch 97, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8311705589294434\n",
      "Running Batch 98, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.848459005355835\n",
      "Running Batch 99, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8244059085845947\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 99, Loss: 3.8244059085845947\n",
      "Running Batch 100, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.762187957763672\n",
      "Running Batch 101, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7099952697753906\n",
      "Running Batch 102, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.816340446472168\n",
      "Running Batch 103, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.815082311630249\n",
      "Running Batch 104, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.806155204772949\n",
      "Running Batch 105, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8632540702819824\n",
      "Running Batch 106, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8090760707855225\n",
      "Running Batch 107, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.795896053314209\n",
      "Running Batch 108, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.7828495502471924\n",
      "Running Batch 109, Epoch 5, Total Tokens: 184\n",
      "Loss: 3.8083980083465576\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 109, Loss: 3.8083980083465576\n",
      "Running Batch 110, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.794811725616455\n",
      "Running Batch 111, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.805086135864258\n",
      "Running Batch 112, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.7321481704711914\n",
      "Running Batch 113, Epoch 5, Total Tokens: 261\n",
      "Loss: 3.863924741744995\n",
      "Running Batch 114, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.817394256591797\n",
      "Running Batch 115, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.788015842437744\n",
      "Running Batch 116, Epoch 5, Total Tokens: 182\n",
      "Loss: 3.835240125656128\n",
      "Running Batch 117, Epoch 5, Total Tokens: 187\n",
      "Loss: 3.899146795272827\n",
      "Running Batch 118, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7911171913146973\n",
      "Running Batch 119, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.8070926666259766\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 119, Loss: 3.8070926666259766\n",
      "Running Batch 120, Epoch 5, Total Tokens: 111\n",
      "Loss: 3.840017795562744\n",
      "Running Batch 121, Epoch 5, Total Tokens: 254\n",
      "Loss: 3.8073537349700928\n",
      "Running Batch 122, Epoch 5, Total Tokens: 113\n",
      "Loss: 3.7863287925720215\n",
      "Running Batch 123, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.843095541000366\n",
      "Running Batch 124, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8173041343688965\n",
      "Running Batch 125, Epoch 5, Total Tokens: 105\n",
      "Loss: 3.744396448135376\n",
      "Running Batch 126, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.806776285171509\n",
      "Running Batch 127, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.792489528656006\n",
      "Running Batch 128, Epoch 5, Total Tokens: 205\n",
      "Loss: 3.7452871799468994\n",
      "Running Batch 129, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.843303918838501\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 129, Loss: 3.843303918838501\n",
      "Running Batch 130, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.855558156967163\n",
      "Running Batch 131, Epoch 5, Total Tokens: 113\n",
      "Loss: 3.8417270183563232\n",
      "Running Batch 132, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.92004656791687\n",
      "Running Batch 133, Epoch 5, Total Tokens: 192\n",
      "Loss: 3.812657356262207\n",
      "Running Batch 134, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.78985333442688\n",
      "Running Batch 135, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.871692657470703\n",
      "Running Batch 136, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.798006534576416\n",
      "Running Batch 137, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.854050874710083\n",
      "Running Batch 138, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7609806060791016\n",
      "Running Batch 139, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8236677646636963\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 139, Loss: 3.8236677646636963\n",
      "Running Batch 140, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8675947189331055\n",
      "Running Batch 141, Epoch 5, Total Tokens: 183\n",
      "Loss: 3.7947497367858887\n",
      "Running Batch 142, Epoch 5, Total Tokens: 250\n",
      "Loss: 3.8456852436065674\n",
      "Running Batch 143, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.866762161254883\n",
      "Running Batch 144, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8035247325897217\n",
      "Running Batch 145, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7440547943115234\n",
      "Running Batch 146, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.792483329772949\n",
      "Running Batch 147, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.7622008323669434\n",
      "Running Batch 148, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.843888759613037\n",
      "Running Batch 149, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.787919521331787\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 149, Loss: 3.787919521331787\n",
      "Running Batch 150, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.8707664012908936\n",
      "Running Batch 151, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8337631225585938\n",
      "Running Batch 152, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8121533393859863\n",
      "Running Batch 153, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.7771553993225098\n",
      "Running Batch 154, Epoch 5, Total Tokens: 190\n",
      "Loss: 3.7021324634552\n",
      "Running Batch 155, Epoch 5, Total Tokens: 101\n",
      "Loss: 3.802664279937744\n",
      "Running Batch 156, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.785985231399536\n",
      "Running Batch 157, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.754114866256714\n",
      "Running Batch 158, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8501851558685303\n",
      "Running Batch 159, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7488622665405273\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 159, Loss: 3.7488622665405273\n",
      "Running Batch 160, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8548848628997803\n",
      "Running Batch 161, Epoch 5, Total Tokens: 219\n",
      "Loss: 3.869199752807617\n",
      "Running Batch 162, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.8645102977752686\n",
      "Running Batch 163, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8159286975860596\n",
      "Running Batch 164, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.7796621322631836\n",
      "Running Batch 165, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.7908599376678467\n",
      "Running Batch 166, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7724809646606445\n",
      "Running Batch 167, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8208696842193604\n",
      "Running Batch 168, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.853060722351074\n",
      "Running Batch 169, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.836951732635498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 169, Loss: 3.836951732635498\n",
      "Running Batch 170, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.762789726257324\n",
      "Running Batch 171, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.8465161323547363\n",
      "Running Batch 172, Epoch 5, Total Tokens: 164\n",
      "Loss: 3.798583507537842\n",
      "Running Batch 173, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.7628581523895264\n",
      "Running Batch 174, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.758894681930542\n",
      "Running Batch 175, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8281409740448\n",
      "Running Batch 176, Epoch 5, Total Tokens: 112\n",
      "Loss: 3.791348695755005\n",
      "Running Batch 177, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8332271575927734\n",
      "Running Batch 178, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7902238368988037\n",
      "Running Batch 179, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8098227977752686\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 179, Loss: 3.8098227977752686\n",
      "Running Batch 180, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7628443241119385\n",
      "Running Batch 181, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7990548610687256\n",
      "Running Batch 182, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.7905709743499756\n",
      "Running Batch 183, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.806752920150757\n",
      "Running Batch 184, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.869657039642334\n",
      "Running Batch 185, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8252227306365967\n",
      "Running Batch 186, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8453052043914795\n",
      "Running Batch 187, Epoch 5, Total Tokens: 188\n",
      "Loss: 3.828284978866577\n",
      "Running Batch 188, Epoch 5, Total Tokens: 167\n",
      "Loss: 3.751924991607666\n",
      "Running Batch 189, Epoch 5, Total Tokens: 190\n",
      "Loss: 3.820917844772339\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 189, Loss: 3.820917844772339\n",
      "Running Batch 190, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8487589359283447\n",
      "Running Batch 191, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.860025405883789\n",
      "Running Batch 192, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7986409664154053\n",
      "Running Batch 193, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.7901065349578857\n",
      "Running Batch 194, Epoch 5, Total Tokens: 234\n",
      "Loss: 3.8564908504486084\n",
      "Running Batch 195, Epoch 5, Total Tokens: 118\n",
      "Loss: 3.9485931396484375\n",
      "Running Batch 196, Epoch 5, Total Tokens: 452\n",
      "Loss: 3.964508295059204\n",
      "Running Batch 197, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8363187313079834\n",
      "Running Batch 198, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.8202953338623047\n",
      "Running Batch 199, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.8680076599121094\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 199, Loss: 3.8680076599121094\n",
      "Running Batch 200, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.751640558242798\n",
      "Running Batch 201, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.781435966491699\n",
      "Running Batch 202, Epoch 5, Total Tokens: 210\n",
      "Loss: 3.8798937797546387\n",
      "Running Batch 203, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8686206340789795\n",
      "Running Batch 204, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.8864877223968506\n",
      "Running Batch 205, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.753767251968384\n",
      "Running Batch 206, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7862887382507324\n",
      "Running Batch 207, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.797199249267578\n",
      "Running Batch 208, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8286869525909424\n",
      "Running Batch 209, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.815905809402466\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 209, Loss: 3.815905809402466\n",
      "Running Batch 210, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8415277004241943\n",
      "Running Batch 211, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.841550827026367\n",
      "Running Batch 212, Epoch 5, Total Tokens: 201\n",
      "Loss: 3.7645761966705322\n",
      "Running Batch 213, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.843872308731079\n",
      "Running Batch 214, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7880711555480957\n",
      "Running Batch 215, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.819150686264038\n",
      "Running Batch 216, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8544836044311523\n",
      "Running Batch 217, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.70798659324646\n",
      "Running Batch 218, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.8088085651397705\n",
      "Running Batch 219, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.832628011703491\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 219, Loss: 3.832628011703491\n",
      "Running Batch 220, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.835610866546631\n",
      "Running Batch 221, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.812023639678955\n",
      "Running Batch 222, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.858170986175537\n",
      "Running Batch 223, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8398125171661377\n",
      "Running Batch 224, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8489785194396973\n",
      "Running Batch 225, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8612735271453857\n",
      "Running Batch 226, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.785388469696045\n",
      "Running Batch 227, Epoch 5, Total Tokens: 101\n",
      "Loss: 3.779054880142212\n",
      "Running Batch 228, Epoch 5, Total Tokens: 176\n",
      "Loss: 3.7783987522125244\n",
      "Running Batch 229, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.815288543701172\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 229, Loss: 3.815288543701172\n",
      "Running Batch 230, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7885522842407227\n",
      "Running Batch 231, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7874550819396973\n",
      "Running Batch 232, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8007519245147705\n",
      "Running Batch 233, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.8015666007995605\n",
      "Running Batch 234, Epoch 5, Total Tokens: 527\n",
      "Loss: 3.908810615539551\n",
      "Running Batch 235, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.739300489425659\n",
      "Running Batch 236, Epoch 5, Total Tokens: 367\n",
      "Loss: 3.8039755821228027\n",
      "Running Batch 237, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.791659116744995\n",
      "Running Batch 238, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.846292734146118\n",
      "Running Batch 239, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.748162031173706\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 239, Loss: 3.748162031173706\n",
      "Running Batch 240, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.8344621658325195\n",
      "Running Batch 241, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.8291378021240234\n",
      "Running Batch 242, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8049471378326416\n",
      "Running Batch 243, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8099522590637207\n",
      "Running Batch 244, Epoch 5, Total Tokens: 196\n",
      "Loss: 3.7223618030548096\n",
      "Running Batch 245, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.7430832386016846\n",
      "Running Batch 246, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.862233877182007\n",
      "Running Batch 247, Epoch 5, Total Tokens: 176\n",
      "Loss: 3.779115676879883\n",
      "Running Batch 248, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8466155529022217\n",
      "Running Batch 249, Epoch 5, Total Tokens: 228\n",
      "Loss: 3.7709217071533203\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 249, Loss: 3.7709217071533203\n",
      "Running Batch 250, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7874207496643066\n",
      "Running Batch 251, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.860431671142578\n",
      "Running Batch 252, Epoch 5, Total Tokens: 199\n",
      "Loss: 3.837928056716919\n",
      "Running Batch 253, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.807981014251709\n",
      "Running Batch 254, Epoch 5, Total Tokens: 166\n",
      "Loss: 3.824979543685913\n",
      "Running Batch 255, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.817147970199585\n",
      "Running Batch 256, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7988555431365967\n",
      "Running Batch 257, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.764378309249878\n",
      "Running Batch 258, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7987747192382812\n",
      "Running Batch 259, Epoch 5, Total Tokens: 281\n",
      "Loss: 3.812340021133423\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 259, Loss: 3.812340021133423\n",
      "Running Batch 260, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.804455041885376\n",
      "Running Batch 261, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7861032485961914\n",
      "Running Batch 262, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.795865058898926\n",
      "Running Batch 263, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.810839891433716\n",
      "Running Batch 264, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.85168719291687\n",
      "Running Batch 265, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.806142807006836\n",
      "Running Batch 266, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7294774055480957\n",
      "Running Batch 267, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.845079183578491\n",
      "Running Batch 268, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.774322748184204\n",
      "Running Batch 269, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7582716941833496\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 269, Loss: 3.7582716941833496\n",
      "Running Batch 270, Epoch 5, Total Tokens: 629\n",
      "Loss: 3.745556592941284\n",
      "Running Batch 271, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8324413299560547\n",
      "Running Batch 272, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.851987838745117\n",
      "Running Batch 273, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7718348503112793\n",
      "Running Batch 274, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.824542760848999\n",
      "Running Batch 275, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7998740673065186\n",
      "Running Batch 276, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.767940044403076\n",
      "Running Batch 277, Epoch 5, Total Tokens: 114\n",
      "Loss: 3.8631789684295654\n",
      "Running Batch 278, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.915748119354248\n",
      "Running Batch 279, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8513095378875732\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 279, Loss: 3.8513095378875732\n",
      "Running Batch 280, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.778038263320923\n",
      "Running Batch 281, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8804428577423096\n",
      "Running Batch 282, Epoch 5, Total Tokens: 380\n",
      "Loss: 3.8086161613464355\n",
      "Running Batch 283, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7921993732452393\n",
      "Running Batch 284, Epoch 5, Total Tokens: 195\n",
      "Loss: 3.7450125217437744\n",
      "Running Batch 285, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.7906761169433594\n",
      "Running Batch 286, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.793660879135132\n",
      "Running Batch 287, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7945055961608887\n",
      "Running Batch 288, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8570854663848877\n",
      "Running Batch 289, Epoch 5, Total Tokens: 109\n",
      "Loss: 3.8501508235931396\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 289, Loss: 3.8501508235931396\n",
      "Running Batch 290, Epoch 5, Total Tokens: 99\n",
      "Loss: 3.8487966060638428\n",
      "Running Batch 291, Epoch 5, Total Tokens: 118\n",
      "Loss: 3.876986265182495\n",
      "Running Batch 292, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7489359378814697\n",
      "Running Batch 293, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8522398471832275\n",
      "Running Batch 294, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.811718463897705\n",
      "Running Batch 295, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.7330591678619385\n",
      "Running Batch 296, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8243064880371094\n",
      "Running Batch 297, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.9023799896240234\n",
      "Running Batch 298, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8286502361297607\n",
      "Running Batch 299, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.816067934036255\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 299, Loss: 3.816067934036255\n",
      "Running Batch 300, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.8309974670410156\n",
      "Running Batch 301, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.845043420791626\n",
      "Running Batch 302, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8072924613952637\n",
      "Running Batch 303, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.7374658584594727\n",
      "Running Batch 304, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7518410682678223\n",
      "Running Batch 305, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8123364448547363\n",
      "Running Batch 306, Epoch 5, Total Tokens: 340\n",
      "Loss: 3.7810556888580322\n",
      "Running Batch 307, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8636558055877686\n",
      "Running Batch 308, Epoch 5, Total Tokens: 160\n",
      "Loss: 3.793987512588501\n",
      "Running Batch 309, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.762120246887207\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 309, Loss: 3.762120246887207\n",
      "Running Batch 310, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.7889325618743896\n",
      "Running Batch 311, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.7388038635253906\n",
      "Running Batch 312, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.8435232639312744\n",
      "Running Batch 313, Epoch 5, Total Tokens: 572\n",
      "Loss: 3.8122262954711914\n",
      "Running Batch 314, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.765291929244995\n",
      "Running Batch 315, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.8191351890563965\n",
      "Running Batch 316, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8112823963165283\n",
      "Running Batch 317, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.7819530963897705\n",
      "Running Batch 318, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7379703521728516\n",
      "Running Batch 319, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.786223888397217\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 319, Loss: 3.786223888397217\n",
      "Running Batch 320, Epoch 5, Total Tokens: 115\n",
      "Loss: 3.9142041206359863\n",
      "Running Batch 321, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.7463691234588623\n",
      "Running Batch 322, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.864393949508667\n",
      "Running Batch 323, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7890591621398926\n",
      "Running Batch 324, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8809030055999756\n",
      "Running Batch 325, Epoch 5, Total Tokens: 191\n",
      "Loss: 3.870389699935913\n",
      "Running Batch 326, Epoch 5, Total Tokens: 170\n",
      "Loss: 3.8289923667907715\n",
      "Running Batch 327, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.788595199584961\n",
      "Running Batch 328, Epoch 5, Total Tokens: 174\n",
      "Loss: 3.762864828109741\n",
      "Running Batch 329, Epoch 5, Total Tokens: 204\n",
      "Loss: 3.7454171180725098\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 329, Loss: 3.7454171180725098\n",
      "Running Batch 330, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.8413267135620117\n",
      "Running Batch 331, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.9025039672851562\n",
      "Running Batch 332, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.796517848968506\n",
      "Running Batch 333, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.826172351837158\n",
      "Running Batch 334, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7692618370056152\n",
      "Running Batch 335, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.759850025177002\n",
      "Running Batch 336, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7842319011688232\n",
      "Running Batch 337, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.799597978591919\n",
      "Running Batch 338, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.903787851333618\n",
      "Running Batch 339, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8245084285736084\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 339, Loss: 3.8245084285736084\n",
      "Running Batch 340, Epoch 5, Total Tokens: 211\n",
      "Loss: 3.7705700397491455\n",
      "Running Batch 341, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.779049873352051\n",
      "Running Batch 342, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.851020336151123\n",
      "Running Batch 343, Epoch 5, Total Tokens: 103\n",
      "Loss: 3.90859317779541\n",
      "Running Batch 344, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8412845134735107\n",
      "Running Batch 345, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.7699451446533203\n",
      "Running Batch 346, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.733809232711792\n",
      "Running Batch 347, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.80865740776062\n",
      "Running Batch 348, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.828291416168213\n",
      "Running Batch 349, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.7984676361083984\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 349, Loss: 3.7984676361083984\n",
      "Running Batch 350, Epoch 5, Total Tokens: 191\n",
      "Loss: 3.710052013397217\n",
      "Running Batch 351, Epoch 5, Total Tokens: 195\n",
      "Loss: 3.8280253410339355\n",
      "Running Batch 352, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.871349811553955\n",
      "Running Batch 353, Epoch 5, Total Tokens: 224\n",
      "Loss: 3.78383731842041\n",
      "Running Batch 354, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.9025278091430664\n",
      "Running Batch 355, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.819589138031006\n",
      "Running Batch 356, Epoch 5, Total Tokens: 167\n",
      "Loss: 3.78411865234375\n",
      "Running Batch 357, Epoch 5, Total Tokens: 210\n",
      "Loss: 3.8204054832458496\n",
      "Running Batch 358, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.833592176437378\n",
      "Running Batch 359, Epoch 5, Total Tokens: 163\n",
      "Loss: 3.7608840465545654\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 359, Loss: 3.7608840465545654\n",
      "Running Batch 360, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8568549156188965\n",
      "Running Batch 361, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.798506021499634\n",
      "Running Batch 362, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.768749713897705\n",
      "Running Batch 363, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.8381330966949463\n",
      "Running Batch 364, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.806084156036377\n",
      "Running Batch 365, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.8514955043792725\n",
      "Running Batch 366, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.895664930343628\n",
      "Running Batch 367, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.811553478240967\n",
      "Running Batch 368, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.8044543266296387\n",
      "Running Batch 369, Epoch 5, Total Tokens: 199\n",
      "Loss: 3.7728960514068604\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 369, Loss: 3.7728960514068604\n",
      "Running Batch 370, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.782689332962036\n",
      "Running Batch 371, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.774327278137207\n",
      "Running Batch 372, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7732410430908203\n",
      "Running Batch 373, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8535773754119873\n",
      "Running Batch 374, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.777468204498291\n",
      "Running Batch 375, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.8887526988983154\n",
      "Running Batch 376, Epoch 5, Total Tokens: 116\n",
      "Loss: 3.717310667037964\n",
      "Running Batch 377, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8648428916931152\n",
      "Running Batch 378, Epoch 5, Total Tokens: 267\n",
      "Loss: 3.8009610176086426\n",
      "Running Batch 379, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8629682064056396\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 379, Loss: 3.8629682064056396\n",
      "Running Batch 380, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.796563148498535\n",
      "Running Batch 381, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.847623825073242\n",
      "Running Batch 382, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8173253536224365\n",
      "Running Batch 383, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.846750259399414\n",
      "Running Batch 384, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8854527473449707\n",
      "Running Batch 385, Epoch 5, Total Tokens: 206\n",
      "Loss: 3.7538421154022217\n",
      "Running Batch 386, Epoch 5, Total Tokens: 163\n",
      "Loss: 3.7436766624450684\n",
      "Running Batch 387, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.771003246307373\n",
      "Running Batch 388, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7695302963256836\n",
      "Running Batch 389, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.762869358062744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 389, Loss: 3.762869358062744\n",
      "Running Batch 390, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.815314769744873\n",
      "Running Batch 391, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.846514940261841\n",
      "Running Batch 392, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.7176077365875244\n",
      "Running Batch 393, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.786271810531616\n",
      "Running Batch 394, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.7498998641967773\n",
      "Running Batch 395, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7895348072052\n",
      "Running Batch 396, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.7937140464782715\n",
      "Running Batch 397, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.9298582077026367\n",
      "Running Batch 398, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.807502508163452\n",
      "Running Batch 399, Epoch 5, Total Tokens: 164\n",
      "Loss: 3.8437323570251465\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 399, Loss: 3.8437323570251465\n",
      "Running Batch 400, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7479910850524902\n",
      "Running Batch 401, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.8352749347686768\n",
      "Running Batch 402, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.7688729763031006\n",
      "Running Batch 403, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.796509027481079\n",
      "Running Batch 404, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8195695877075195\n",
      "Running Batch 405, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7685651779174805\n",
      "Running Batch 406, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.8371944427490234\n",
      "Running Batch 407, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7981984615325928\n",
      "Running Batch 408, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.796750068664551\n",
      "Running Batch 409, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8160898685455322\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 409, Loss: 3.8160898685455322\n",
      "Running Batch 410, Epoch 5, Total Tokens: 110\n",
      "Loss: 3.791320323944092\n",
      "Running Batch 411, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8186728954315186\n",
      "Running Batch 412, Epoch 5, Total Tokens: 203\n",
      "Loss: 3.8238329887390137\n",
      "Running Batch 413, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.850313901901245\n",
      "Running Batch 414, Epoch 5, Total Tokens: 185\n",
      "Loss: 3.848423480987549\n",
      "Running Batch 415, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.808227300643921\n",
      "Running Batch 416, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7346503734588623\n",
      "Running Batch 417, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7679855823516846\n",
      "Running Batch 418, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.816896677017212\n",
      "Running Batch 419, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.7759323120117188\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 419, Loss: 3.7759323120117188\n",
      "Running Batch 420, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.771644353866577\n",
      "Running Batch 421, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.807509422302246\n",
      "Running Batch 422, Epoch 5, Total Tokens: 244\n",
      "Loss: 3.8099026679992676\n",
      "Running Batch 423, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.837571144104004\n",
      "Running Batch 424, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.723846673965454\n",
      "Running Batch 425, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8392844200134277\n",
      "Running Batch 426, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.767000198364258\n",
      "Running Batch 427, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.769683837890625\n",
      "Running Batch 428, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.796396255493164\n",
      "Running Batch 429, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7645390033721924\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 429, Loss: 3.7645390033721924\n",
      "Running Batch 430, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.850661039352417\n",
      "Running Batch 431, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8547654151916504\n",
      "Running Batch 432, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.746983289718628\n",
      "Running Batch 433, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.826881170272827\n",
      "Running Batch 434, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.820491075515747\n",
      "Running Batch 435, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.7588768005371094\n",
      "Running Batch 436, Epoch 5, Total Tokens: 188\n",
      "Loss: 3.785290241241455\n",
      "Running Batch 437, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.855815887451172\n",
      "Running Batch 438, Epoch 5, Total Tokens: 158\n",
      "Loss: 3.806119918823242\n",
      "Running Batch 439, Epoch 5, Total Tokens: 624\n",
      "Loss: 3.8595874309539795\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 439, Loss: 3.8595874309539795\n",
      "Running Batch 440, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8422765731811523\n",
      "Running Batch 441, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.768714189529419\n",
      "Running Batch 442, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.803765058517456\n",
      "Running Batch 443, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.830857992172241\n",
      "Running Batch 444, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.827329158782959\n",
      "Running Batch 445, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.7232208251953125\n",
      "Running Batch 446, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.79655122756958\n",
      "Running Batch 447, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7924671173095703\n",
      "Running Batch 448, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.91491961479187\n",
      "Running Batch 449, Epoch 5, Total Tokens: 249\n",
      "Loss: 3.752854347229004\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 449, Loss: 3.752854347229004\n",
      "Running Batch 450, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7746620178222656\n",
      "Running Batch 451, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.763758897781372\n",
      "Running Batch 452, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.852879047393799\n",
      "Running Batch 453, Epoch 5, Total Tokens: 206\n",
      "Loss: 3.740462064743042\n",
      "Running Batch 454, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.855689525604248\n",
      "Running Batch 455, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8227579593658447\n",
      "Running Batch 456, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.814490556716919\n",
      "Running Batch 457, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.8444161415100098\n",
      "Running Batch 458, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.7643911838531494\n",
      "Running Batch 459, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.8151445388793945\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 459, Loss: 3.8151445388793945\n",
      "Running Batch 460, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7952215671539307\n",
      "Running Batch 461, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8429677486419678\n",
      "Running Batch 462, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.7448673248291016\n",
      "Running Batch 463, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7606358528137207\n",
      "Running Batch 464, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.8073670864105225\n",
      "Running Batch 465, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.825068235397339\n",
      "Running Batch 466, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.795806646347046\n",
      "Running Batch 467, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8479115962982178\n",
      "Running Batch 468, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8224518299102783\n",
      "Running Batch 469, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.823216438293457\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 469, Loss: 3.823216438293457\n",
      "Running Batch 470, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.825547218322754\n",
      "Running Batch 471, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8530867099761963\n",
      "Running Batch 472, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.788773775100708\n",
      "Running Batch 473, Epoch 5, Total Tokens: 267\n",
      "Loss: 3.8288209438323975\n",
      "Running Batch 474, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8180418014526367\n",
      "Running Batch 475, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.767673969268799\n",
      "Running Batch 476, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8745856285095215\n",
      "Running Batch 477, Epoch 5, Total Tokens: 196\n",
      "Loss: 3.797435998916626\n",
      "Running Batch 478, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.89983868598938\n",
      "Running Batch 479, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.796891927719116\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 479, Loss: 3.796891927719116\n",
      "Running Batch 480, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8785972595214844\n",
      "Running Batch 481, Epoch 5, Total Tokens: 168\n",
      "Loss: 3.864854097366333\n",
      "Running Batch 482, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.7689743041992188\n",
      "Running Batch 483, Epoch 5, Total Tokens: 360\n",
      "Loss: 3.8569552898406982\n",
      "Running Batch 484, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.79044246673584\n",
      "Running Batch 485, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.7914817333221436\n",
      "Running Batch 486, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.8292012214660645\n",
      "Running Batch 487, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.821059226989746\n",
      "Running Batch 488, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7983720302581787\n",
      "Running Batch 489, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.780621290206909\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 489, Loss: 3.780621290206909\n",
      "Running Batch 490, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.860450029373169\n",
      "Running Batch 491, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7503104209899902\n",
      "Running Batch 492, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7284135818481445\n",
      "Running Batch 493, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8186676502227783\n",
      "Running Batch 494, Epoch 5, Total Tokens: 176\n",
      "Loss: 3.8373727798461914\n",
      "Running Batch 495, Epoch 5, Total Tokens: 293\n",
      "Loss: 3.739184856414795\n",
      "Running Batch 496, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8056259155273438\n",
      "Running Batch 497, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8066203594207764\n",
      "Running Batch 498, Epoch 5, Total Tokens: 225\n",
      "Loss: 3.7724575996398926\n",
      "Running Batch 499, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.839691162109375\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 499, Loss: 3.839691162109375\n",
      "Running Batch 500, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.8605451583862305\n",
      "Running Batch 501, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7443411350250244\n",
      "Running Batch 502, Epoch 5, Total Tokens: 372\n",
      "Loss: 3.6936538219451904\n",
      "Running Batch 503, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.802150011062622\n",
      "Running Batch 504, Epoch 5, Total Tokens: 220\n",
      "Loss: 3.8267576694488525\n",
      "Running Batch 505, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8137154579162598\n",
      "Running Batch 506, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.7699191570281982\n",
      "Running Batch 507, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.751983404159546\n",
      "Running Batch 508, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7375264167785645\n",
      "Running Batch 509, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7872872352600098\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 509, Loss: 3.7872872352600098\n",
      "Running Batch 510, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.857508420944214\n",
      "Running Batch 511, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.7642786502838135\n",
      "Running Batch 512, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.7939555644989014\n",
      "Running Batch 513, Epoch 5, Total Tokens: 180\n",
      "Loss: 3.8273746967315674\n",
      "Running Batch 514, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.695787191390991\n",
      "Running Batch 515, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7620747089385986\n",
      "Running Batch 516, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8966169357299805\n",
      "Running Batch 517, Epoch 5, Total Tokens: 229\n",
      "Loss: 3.7944061756134033\n",
      "Running Batch 518, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.784940242767334\n",
      "Running Batch 519, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.8394999504089355\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 519, Loss: 3.8394999504089355\n",
      "Running Batch 520, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.829047203063965\n",
      "Running Batch 521, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8389973640441895\n",
      "Running Batch 522, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7707598209381104\n",
      "Running Batch 523, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7370455265045166\n",
      "Running Batch 524, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.779735803604126\n",
      "Running Batch 525, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.822730779647827\n",
      "Running Batch 526, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.796276092529297\n",
      "Running Batch 527, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.82230544090271\n",
      "Running Batch 528, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.8285582065582275\n",
      "Running Batch 529, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.905316114425659\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 529, Loss: 3.905316114425659\n",
      "Running Batch 530, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7930960655212402\n",
      "Running Batch 531, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8596997261047363\n",
      "Running Batch 532, Epoch 5, Total Tokens: 217\n",
      "Loss: 3.7586581707000732\n",
      "Running Batch 533, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.8230667114257812\n",
      "Running Batch 534, Epoch 5, Total Tokens: 203\n",
      "Loss: 3.857975959777832\n",
      "Running Batch 535, Epoch 5, Total Tokens: 202\n",
      "Loss: 3.7817869186401367\n",
      "Running Batch 536, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.759748935699463\n",
      "Running Batch 537, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.776826858520508\n",
      "Running Batch 538, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7294564247131348\n",
      "Running Batch 539, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.801811933517456\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 539, Loss: 3.801811933517456\n",
      "Running Batch 540, Epoch 5, Total Tokens: 113\n",
      "Loss: 3.79451584815979\n",
      "Running Batch 541, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.805906057357788\n",
      "Running Batch 542, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.8101978302001953\n",
      "Running Batch 543, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.804211139678955\n",
      "Running Batch 544, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7274839878082275\n",
      "Running Batch 545, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8063511848449707\n",
      "Running Batch 546, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8235270977020264\n",
      "Running Batch 547, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8109490871429443\n",
      "Running Batch 548, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.749979019165039\n",
      "Running Batch 549, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8007965087890625\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 549, Loss: 3.8007965087890625\n",
      "Running Batch 550, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.740631341934204\n",
      "Running Batch 551, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.772426128387451\n",
      "Running Batch 552, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8155839443206787\n",
      "Running Batch 553, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.7842798233032227\n",
      "Running Batch 554, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7441625595092773\n",
      "Running Batch 555, Epoch 5, Total Tokens: 384\n",
      "Loss: 3.7872021198272705\n",
      "Running Batch 556, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.7670297622680664\n",
      "Running Batch 557, Epoch 5, Total Tokens: 170\n",
      "Loss: 3.868807315826416\n",
      "Running Batch 558, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8428523540496826\n",
      "Running Batch 559, Epoch 5, Total Tokens: 158\n",
      "Loss: 3.7892649173736572\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 559, Loss: 3.7892649173736572\n",
      "Running Batch 560, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.7437245845794678\n",
      "Running Batch 561, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8073244094848633\n",
      "Running Batch 562, Epoch 5, Total Tokens: 166\n",
      "Loss: 3.7419869899749756\n",
      "Running Batch 563, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.777440309524536\n",
      "Running Batch 564, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.8198814392089844\n",
      "Running Batch 565, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.831120491027832\n",
      "Running Batch 566, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8652713298797607\n",
      "Running Batch 567, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.7911596298217773\n",
      "Running Batch 568, Epoch 5, Total Tokens: 356\n",
      "Loss: 3.767692804336548\n",
      "Running Batch 569, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.7846672534942627\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 569, Loss: 3.7846672534942627\n",
      "Running Batch 570, Epoch 5, Total Tokens: 116\n",
      "Loss: 3.857100486755371\n",
      "Running Batch 571, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8209733963012695\n",
      "Running Batch 572, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.747184991836548\n",
      "Running Batch 573, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.797362804412842\n",
      "Running Batch 574, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.7920167446136475\n",
      "Running Batch 575, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7158725261688232\n",
      "Running Batch 576, Epoch 5, Total Tokens: 236\n",
      "Loss: 3.7814576625823975\n",
      "Running Batch 577, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8193745613098145\n",
      "Running Batch 578, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7913177013397217\n",
      "Running Batch 579, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8317058086395264\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 579, Loss: 3.8317058086395264\n",
      "Running Batch 580, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.779845952987671\n",
      "Running Batch 581, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7070884704589844\n",
      "Running Batch 582, Epoch 5, Total Tokens: 179\n",
      "Loss: 3.6862893104553223\n",
      "Running Batch 583, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.764286518096924\n",
      "Running Batch 584, Epoch 5, Total Tokens: 172\n",
      "Loss: 3.8417906761169434\n",
      "Running Batch 585, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.857656717300415\n",
      "Running Batch 586, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.762779951095581\n",
      "Running Batch 587, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.850525140762329\n",
      "Running Batch 588, Epoch 5, Total Tokens: 299\n",
      "Loss: 3.8726885318756104\n",
      "Running Batch 589, Epoch 5, Total Tokens: 258\n",
      "Loss: 3.812407970428467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 589, Loss: 3.812407970428467\n",
      "Running Batch 590, Epoch 5, Total Tokens: 164\n",
      "Loss: 3.8202967643737793\n",
      "Running Batch 591, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7987794876098633\n",
      "Running Batch 592, Epoch 5, Total Tokens: 171\n",
      "Loss: 3.868689775466919\n",
      "Running Batch 593, Epoch 5, Total Tokens: 357\n",
      "Loss: 3.8264966011047363\n",
      "Running Batch 594, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8628733158111572\n",
      "Running Batch 595, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.805999755859375\n",
      "Running Batch 596, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8196628093719482\n",
      "Running Batch 597, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.783926248550415\n",
      "Running Batch 598, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.9246060848236084\n",
      "Running Batch 599, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8034744262695312\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 599, Loss: 3.8034744262695312\n",
      "Running Batch 600, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7721855640411377\n",
      "Running Batch 601, Epoch 5, Total Tokens: 228\n",
      "Loss: 3.8294732570648193\n",
      "Running Batch 602, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7439985275268555\n",
      "Running Batch 603, Epoch 5, Total Tokens: 266\n",
      "Loss: 3.7926101684570312\n",
      "Running Batch 604, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8000736236572266\n",
      "Running Batch 605, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7869181632995605\n",
      "Running Batch 606, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.878840208053589\n",
      "Running Batch 607, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.785428285598755\n",
      "Running Batch 608, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8044819831848145\n",
      "Running Batch 609, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8273956775665283\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 609, Loss: 3.8273956775665283\n",
      "Running Batch 610, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.7525463104248047\n",
      "Running Batch 611, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8250951766967773\n",
      "Running Batch 612, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.782947301864624\n",
      "Running Batch 613, Epoch 5, Total Tokens: 170\n",
      "Loss: 3.7707200050354004\n",
      "Running Batch 614, Epoch 5, Total Tokens: 107\n",
      "Loss: 3.837008476257324\n",
      "Running Batch 615, Epoch 5, Total Tokens: 237\n",
      "Loss: 3.751981258392334\n",
      "Running Batch 616, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8178305625915527\n",
      "Running Batch 617, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.774785280227661\n",
      "Running Batch 618, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.7506401538848877\n",
      "Running Batch 619, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8453915119171143\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 619, Loss: 3.8453915119171143\n",
      "Running Batch 620, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7910709381103516\n",
      "Running Batch 621, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8400847911834717\n",
      "Running Batch 622, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.814014196395874\n",
      "Running Batch 623, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.818084716796875\n",
      "Running Batch 624, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.775749444961548\n",
      "Running Batch 625, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.818364381790161\n",
      "Running Batch 626, Epoch 5, Total Tokens: 188\n",
      "Loss: 3.840616464614868\n",
      "Running Batch 627, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.7992498874664307\n",
      "Running Batch 628, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8318569660186768\n",
      "Running Batch 629, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.822105884552002\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 629, Loss: 3.822105884552002\n",
      "Running Batch 630, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.791250705718994\n",
      "Running Batch 631, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.830132246017456\n",
      "Running Batch 632, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.7907211780548096\n",
      "Running Batch 633, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.7700881958007812\n",
      "Running Batch 634, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8076424598693848\n",
      "Running Batch 635, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8046560287475586\n",
      "Running Batch 636, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.778085947036743\n",
      "Running Batch 637, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8201959133148193\n",
      "Running Batch 638, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.7834668159484863\n",
      "Running Batch 639, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.753648519515991\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 639, Loss: 3.753648519515991\n",
      "Running Batch 640, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8645143508911133\n",
      "Running Batch 641, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.757138252258301\n",
      "Running Batch 642, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.871864080429077\n",
      "Running Batch 643, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.792491912841797\n",
      "Running Batch 644, Epoch 5, Total Tokens: 202\n",
      "Loss: 3.8759677410125732\n",
      "Running Batch 645, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8255934715270996\n",
      "Running Batch 646, Epoch 5, Total Tokens: 172\n",
      "Loss: 3.7597615718841553\n",
      "Running Batch 647, Epoch 5, Total Tokens: 282\n",
      "Loss: 3.7336647510528564\n",
      "Running Batch 648, Epoch 5, Total Tokens: 219\n",
      "Loss: 3.814575433731079\n",
      "Running Batch 649, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.7552661895751953\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 649, Loss: 3.7552661895751953\n",
      "Running Batch 650, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.82332706451416\n",
      "Running Batch 651, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.718128204345703\n",
      "Running Batch 652, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.771075487136841\n",
      "Running Batch 653, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8813564777374268\n",
      "Running Batch 654, Epoch 5, Total Tokens: 100\n",
      "Loss: 3.862834930419922\n",
      "Running Batch 655, Epoch 5, Total Tokens: 195\n",
      "Loss: 3.877558946609497\n",
      "Running Batch 656, Epoch 5, Total Tokens: 274\n",
      "Loss: 3.804501533508301\n",
      "Running Batch 657, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8770432472229004\n",
      "Running Batch 658, Epoch 5, Total Tokens: 203\n",
      "Loss: 3.7071266174316406\n",
      "Running Batch 659, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.8569729328155518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 659, Loss: 3.8569729328155518\n",
      "Running Batch 660, Epoch 5, Total Tokens: 167\n",
      "Loss: 3.778829336166382\n",
      "Running Batch 661, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7660608291625977\n",
      "Running Batch 662, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8011248111724854\n",
      "Running Batch 663, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.822496175765991\n",
      "Running Batch 664, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.6892220973968506\n",
      "Running Batch 665, Epoch 5, Total Tokens: 220\n",
      "Loss: 3.762967348098755\n",
      "Running Batch 666, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7849035263061523\n",
      "Running Batch 667, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8624885082244873\n",
      "Running Batch 668, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8329579830169678\n",
      "Running Batch 669, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8286752700805664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 669, Loss: 3.8286752700805664\n",
      "Running Batch 670, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7926769256591797\n",
      "Running Batch 671, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.7739126682281494\n",
      "Running Batch 672, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8527109622955322\n",
      "Running Batch 673, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.78375506401062\n",
      "Running Batch 674, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.822632074356079\n",
      "Running Batch 675, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.7485358715057373\n",
      "Running Batch 676, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.836972951889038\n",
      "Running Batch 677, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.69919753074646\n",
      "Running Batch 678, Epoch 5, Total Tokens: 193\n",
      "Loss: 3.824370861053467\n",
      "Running Batch 679, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8143362998962402\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 679, Loss: 3.8143362998962402\n",
      "Running Batch 680, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.7977540493011475\n",
      "Running Batch 681, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8287227153778076\n",
      "Running Batch 682, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.8073313236236572\n",
      "Running Batch 683, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8356058597564697\n",
      "Running Batch 684, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.8431503772735596\n",
      "Running Batch 685, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8105061054229736\n",
      "Running Batch 686, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.775031805038452\n",
      "Running Batch 687, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.858858823776245\n",
      "Running Batch 688, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7510159015655518\n",
      "Running Batch 689, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8362314701080322\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 689, Loss: 3.8362314701080322\n",
      "Running Batch 690, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.778427839279175\n",
      "Running Batch 691, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7967417240142822\n",
      "Running Batch 692, Epoch 5, Total Tokens: 158\n",
      "Loss: 3.7502810955047607\n",
      "Running Batch 693, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8097050189971924\n",
      "Running Batch 694, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.7259671688079834\n",
      "Running Batch 695, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.874746799468994\n",
      "Running Batch 696, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7443995475769043\n",
      "Running Batch 697, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.7956740856170654\n",
      "Running Batch 698, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.845172166824341\n",
      "Running Batch 699, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.781677722930908\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 699, Loss: 3.781677722930908\n",
      "Running Batch 700, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7456064224243164\n",
      "Running Batch 701, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7212066650390625\n",
      "Running Batch 702, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.80086350440979\n",
      "Running Batch 703, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7909364700317383\n",
      "Running Batch 704, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.769371747970581\n",
      "Running Batch 705, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8352510929107666\n",
      "Running Batch 706, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7324628829956055\n",
      "Running Batch 707, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.7803869247436523\n",
      "Running Batch 708, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.760859489440918\n",
      "Running Batch 709, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8034892082214355\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 709, Loss: 3.8034892082214355\n",
      "Running Batch 710, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.8544507026672363\n",
      "Running Batch 711, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.850069046020508\n",
      "Running Batch 712, Epoch 5, Total Tokens: 224\n",
      "Loss: 3.8022408485412598\n",
      "Running Batch 713, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.8090479373931885\n",
      "Running Batch 714, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.841921329498291\n",
      "Running Batch 715, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8310606479644775\n",
      "Running Batch 716, Epoch 5, Total Tokens: 115\n",
      "Loss: 3.835114002227783\n",
      "Running Batch 717, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.8319551944732666\n",
      "Running Batch 718, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8095014095306396\n",
      "Running Batch 719, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8203415870666504\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 719, Loss: 3.8203415870666504\n",
      "Running Batch 720, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8151893615722656\n",
      "Running Batch 721, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8445305824279785\n",
      "Running Batch 722, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8069651126861572\n",
      "Running Batch 723, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8389108180999756\n",
      "Running Batch 724, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.805004358291626\n",
      "Running Batch 725, Epoch 5, Total Tokens: 266\n",
      "Loss: 3.7853801250457764\n",
      "Running Batch 726, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7866992950439453\n",
      "Running Batch 727, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.771914482116699\n",
      "Running Batch 728, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7928740978240967\n",
      "Running Batch 729, Epoch 5, Total Tokens: 287\n",
      "Loss: 3.797501802444458\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 729, Loss: 3.797501802444458\n",
      "Running Batch 730, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.790635585784912\n",
      "Running Batch 731, Epoch 5, Total Tokens: 296\n",
      "Loss: 3.856462001800537\n",
      "Running Batch 732, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8001515865325928\n",
      "Running Batch 733, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.8587889671325684\n",
      "Running Batch 734, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.803065538406372\n",
      "Running Batch 735, Epoch 5, Total Tokens: 181\n",
      "Loss: 3.807894229888916\n",
      "Running Batch 736, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.753669023513794\n",
      "Running Batch 737, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.770449161529541\n",
      "Running Batch 738, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.775167942047119\n",
      "Running Batch 739, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.82523250579834\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 739, Loss: 3.82523250579834\n",
      "Running Batch 740, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.799813747406006\n",
      "Running Batch 741, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8388023376464844\n",
      "Running Batch 742, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.85819149017334\n",
      "Running Batch 743, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8071818351745605\n",
      "Running Batch 744, Epoch 5, Total Tokens: 111\n",
      "Loss: 3.8139679431915283\n",
      "Running Batch 745, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.746687650680542\n",
      "Running Batch 746, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.7766644954681396\n",
      "Running Batch 747, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8172991275787354\n",
      "Running Batch 748, Epoch 5, Total Tokens: 281\n",
      "Loss: 3.8187451362609863\n",
      "Running Batch 749, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.8129875659942627\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 749, Loss: 3.8129875659942627\n",
      "Running Batch 750, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.779641628265381\n",
      "Running Batch 751, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7725424766540527\n",
      "Running Batch 752, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7784955501556396\n",
      "Running Batch 753, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.7488110065460205\n",
      "Running Batch 754, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.8060460090637207\n",
      "Running Batch 755, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.8038158416748047\n",
      "Running Batch 756, Epoch 5, Total Tokens: 237\n",
      "Loss: 3.736422300338745\n",
      "Running Batch 757, Epoch 5, Total Tokens: 258\n",
      "Loss: 3.80959153175354\n",
      "Running Batch 758, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8510959148406982\n",
      "Running Batch 759, Epoch 5, Total Tokens: 170\n",
      "Loss: 3.765944004058838\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 759, Loss: 3.765944004058838\n",
      "Running Batch 760, Epoch 5, Total Tokens: 295\n",
      "Loss: 3.821941375732422\n",
      "Running Batch 761, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.819782257080078\n",
      "Running Batch 762, Epoch 5, Total Tokens: 178\n",
      "Loss: 3.8059122562408447\n",
      "Running Batch 763, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.776906728744507\n",
      "Running Batch 764, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7930121421813965\n",
      "Running Batch 765, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7947349548339844\n",
      "Running Batch 766, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8438470363616943\n",
      "Running Batch 767, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.786848545074463\n",
      "Running Batch 768, Epoch 5, Total Tokens: 182\n",
      "Loss: 3.8465139865875244\n",
      "Running Batch 769, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.756844997406006\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 769, Loss: 3.756844997406006\n",
      "Running Batch 770, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.762416362762451\n",
      "Running Batch 771, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.802990198135376\n",
      "Running Batch 772, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8379833698272705\n",
      "Running Batch 773, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.783940553665161\n",
      "Running Batch 774, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.850750207901001\n",
      "Running Batch 775, Epoch 5, Total Tokens: 174\n",
      "Loss: 3.7551627159118652\n",
      "Running Batch 776, Epoch 5, Total Tokens: 361\n",
      "Loss: 3.7668166160583496\n",
      "Running Batch 777, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8461129665374756\n",
      "Running Batch 778, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.806926727294922\n",
      "Running Batch 779, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.730851888656616\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 779, Loss: 3.730851888656616\n",
      "Running Batch 780, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.682873010635376\n",
      "Running Batch 781, Epoch 5, Total Tokens: 171\n",
      "Loss: 3.836412191390991\n",
      "Running Batch 782, Epoch 5, Total Tokens: 285\n",
      "Loss: 3.7970833778381348\n",
      "Running Batch 783, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.762742280960083\n",
      "Running Batch 784, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.788355827331543\n",
      "Running Batch 785, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8401455879211426\n",
      "Running Batch 786, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.8396620750427246\n",
      "Running Batch 787, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.7705390453338623\n",
      "Running Batch 788, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.7801244258880615\n",
      "Running Batch 789, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7630116939544678\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 789, Loss: 3.7630116939544678\n",
      "Running Batch 790, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7957653999328613\n",
      "Running Batch 791, Epoch 5, Total Tokens: 242\n",
      "Loss: 3.782600164413452\n",
      "Running Batch 792, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.843050956726074\n",
      "Running Batch 793, Epoch 5, Total Tokens: 167\n",
      "Loss: 3.7804341316223145\n",
      "Running Batch 794, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8450539112091064\n",
      "Running Batch 795, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7907559871673584\n",
      "Running Batch 796, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8460845947265625\n",
      "Running Batch 797, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.80985689163208\n",
      "Running Batch 798, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7814228534698486\n",
      "Running Batch 799, Epoch 5, Total Tokens: 173\n",
      "Loss: 3.777252197265625\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 799, Loss: 3.777252197265625\n",
      "Running Batch 800, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7889771461486816\n",
      "Running Batch 801, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.836458921432495\n",
      "Running Batch 802, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.8275063037872314\n",
      "Running Batch 803, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.824328660964966\n",
      "Running Batch 804, Epoch 5, Total Tokens: 205\n",
      "Loss: 3.7717583179473877\n",
      "Running Batch 805, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.738560199737549\n",
      "Running Batch 806, Epoch 5, Total Tokens: 199\n",
      "Loss: 3.7376043796539307\n",
      "Running Batch 807, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.7641475200653076\n",
      "Running Batch 808, Epoch 5, Total Tokens: 568\n",
      "Loss: 3.724860668182373\n",
      "Running Batch 809, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.7794742584228516\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 809, Loss: 3.7794742584228516\n",
      "Running Batch 810, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8167014122009277\n",
      "Running Batch 811, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.8201324939727783\n",
      "Running Batch 812, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.789594888687134\n",
      "Running Batch 813, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8378183841705322\n",
      "Running Batch 814, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.784468412399292\n",
      "Running Batch 815, Epoch 5, Total Tokens: 112\n",
      "Loss: 3.8150477409362793\n",
      "Running Batch 816, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.740638494491577\n",
      "Running Batch 817, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.792738437652588\n",
      "Running Batch 818, Epoch 5, Total Tokens: 231\n",
      "Loss: 3.751551389694214\n",
      "Running Batch 819, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7300004959106445\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 819, Loss: 3.7300004959106445\n",
      "Running Batch 820, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.854095220565796\n",
      "Running Batch 821, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.793949604034424\n",
      "Running Batch 822, Epoch 5, Total Tokens: 286\n",
      "Loss: 3.766388177871704\n",
      "Running Batch 823, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7847366333007812\n",
      "Running Batch 824, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.8273723125457764\n",
      "Running Batch 825, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7650129795074463\n",
      "Running Batch 826, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.771904945373535\n",
      "Running Batch 827, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8570680618286133\n",
      "Running Batch 828, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.766144037246704\n",
      "Running Batch 829, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.734243392944336\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 829, Loss: 3.734243392944336\n",
      "Running Batch 830, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.801363945007324\n",
      "Running Batch 831, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.806642532348633\n",
      "Running Batch 832, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8227949142456055\n",
      "Running Batch 833, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.847843647003174\n",
      "Running Batch 834, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7389440536499023\n",
      "Running Batch 835, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.6913492679595947\n",
      "Running Batch 836, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.7200777530670166\n",
      "Running Batch 837, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.80074143409729\n",
      "Running Batch 838, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.807743787765503\n",
      "Running Batch 839, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8220267295837402\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 839, Loss: 3.8220267295837402\n",
      "Running Batch 840, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.806760787963867\n",
      "Running Batch 841, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.838975667953491\n",
      "Running Batch 842, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8927435874938965\n",
      "Running Batch 843, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.7469899654388428\n",
      "Running Batch 844, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.7946617603302\n",
      "Running Batch 845, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.7641348838806152\n",
      "Running Batch 846, Epoch 5, Total Tokens: 244\n",
      "Loss: 3.824608087539673\n",
      "Running Batch 847, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8146238327026367\n",
      "Running Batch 848, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.798811912536621\n",
      "Running Batch 849, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8320746421813965\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 849, Loss: 3.8320746421813965\n",
      "Running Batch 850, Epoch 5, Total Tokens: 95\n",
      "Loss: 3.869274139404297\n",
      "Running Batch 851, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.81731915473938\n",
      "Running Batch 852, Epoch 5, Total Tokens: 224\n",
      "Loss: 3.792325258255005\n",
      "Running Batch 853, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.7816872596740723\n",
      "Running Batch 854, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7969770431518555\n",
      "Running Batch 855, Epoch 5, Total Tokens: 231\n",
      "Loss: 3.8157196044921875\n",
      "Running Batch 856, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.867222309112549\n",
      "Running Batch 857, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8053624629974365\n",
      "Running Batch 858, Epoch 5, Total Tokens: 186\n",
      "Loss: 3.8291096687316895\n",
      "Running Batch 859, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7524161338806152\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 859, Loss: 3.7524161338806152\n",
      "Running Batch 860, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.8105976581573486\n",
      "Running Batch 861, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7160396575927734\n",
      "Running Batch 862, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.8324482440948486\n",
      "Running Batch 863, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.759608030319214\n",
      "Running Batch 864, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.786860466003418\n",
      "Running Batch 865, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.8240649700164795\n",
      "Running Batch 866, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.813075304031372\n",
      "Running Batch 867, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7673070430755615\n",
      "Running Batch 868, Epoch 5, Total Tokens: 254\n",
      "Loss: 3.8074822425842285\n",
      "Running Batch 869, Epoch 5, Total Tokens: 181\n",
      "Loss: 3.9057834148406982\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 869, Loss: 3.9057834148406982\n",
      "Running Batch 870, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.716434955596924\n",
      "Running Batch 871, Epoch 5, Total Tokens: 209\n",
      "Loss: 3.8065803050994873\n",
      "Running Batch 872, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.750317335128784\n",
      "Running Batch 873, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.774320602416992\n",
      "Running Batch 874, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8251965045928955\n",
      "Running Batch 875, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.7994325160980225\n",
      "Running Batch 876, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.773452043533325\n",
      "Running Batch 877, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.865691900253296\n",
      "Running Batch 878, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.771256923675537\n",
      "Running Batch 879, Epoch 5, Total Tokens: 257\n",
      "Loss: 3.8193747997283936\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 879, Loss: 3.8193747997283936\n",
      "Running Batch 880, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7817928791046143\n",
      "Running Batch 881, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7936654090881348\n",
      "Running Batch 882, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.7377374172210693\n",
      "Running Batch 883, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8513169288635254\n",
      "Running Batch 884, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.769947052001953\n",
      "Running Batch 885, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.8653299808502197\n",
      "Running Batch 886, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.813239097595215\n",
      "Running Batch 887, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.853940010070801\n",
      "Running Batch 888, Epoch 5, Total Tokens: 178\n",
      "Loss: 3.7340831756591797\n",
      "Running Batch 889, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.784167766571045\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 889, Loss: 3.784167766571045\n",
      "Running Batch 890, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.715365409851074\n",
      "Running Batch 891, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.8249027729034424\n",
      "Running Batch 892, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.752211570739746\n",
      "Running Batch 893, Epoch 5, Total Tokens: 211\n",
      "Loss: 3.831850528717041\n",
      "Running Batch 894, Epoch 5, Total Tokens: 183\n",
      "Loss: 3.7649941444396973\n",
      "Running Batch 895, Epoch 5, Total Tokens: 254\n",
      "Loss: 3.7604708671569824\n",
      "Running Batch 896, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.8009915351867676\n",
      "Running Batch 897, Epoch 5, Total Tokens: 285\n",
      "Loss: 3.771662950515747\n",
      "Running Batch 898, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8227014541625977\n",
      "Running Batch 899, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.760528326034546\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 899, Loss: 3.760528326034546\n",
      "Running Batch 900, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.852088451385498\n",
      "Running Batch 901, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8230912685394287\n",
      "Running Batch 902, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.7513325214385986\n",
      "Running Batch 903, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.8119876384735107\n",
      "Running Batch 904, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.8000028133392334\n",
      "Running Batch 905, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.826340436935425\n",
      "Running Batch 906, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.823209762573242\n",
      "Running Batch 907, Epoch 5, Total Tokens: 206\n",
      "Loss: 3.811936855316162\n",
      "Running Batch 908, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.8569414615631104\n",
      "Running Batch 909, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.839567184448242\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 909, Loss: 3.839567184448242\n",
      "Running Batch 910, Epoch 5, Total Tokens: 221\n",
      "Loss: 3.7493557929992676\n",
      "Running Batch 911, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.754854917526245\n",
      "Running Batch 912, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.809601068496704\n",
      "Running Batch 913, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8253047466278076\n",
      "Running Batch 914, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8247060775756836\n",
      "Running Batch 915, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.7306902408599854\n",
      "Running Batch 916, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8266408443450928\n",
      "Running Batch 917, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.7133896350860596\n",
      "Running Batch 918, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8210840225219727\n",
      "Running Batch 919, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8252615928649902\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 919, Loss: 3.8252615928649902\n",
      "Running Batch 920, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.804837703704834\n",
      "Running Batch 921, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7513844966888428\n",
      "Running Batch 922, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.7614476680755615\n",
      "Running Batch 923, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.9056639671325684\n",
      "Running Batch 924, Epoch 5, Total Tokens: 187\n",
      "Loss: 3.8441052436828613\n",
      "Running Batch 925, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8473076820373535\n",
      "Running Batch 926, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.7481179237365723\n",
      "Running Batch 927, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8169405460357666\n",
      "Running Batch 928, Epoch 5, Total Tokens: 176\n",
      "Loss: 3.75942325592041\n",
      "Running Batch 929, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.7978079319000244\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 929, Loss: 3.7978079319000244\n",
      "Running Batch 930, Epoch 5, Total Tokens: 117\n",
      "Loss: 3.846691370010376\n",
      "Running Batch 931, Epoch 5, Total Tokens: 197\n",
      "Loss: 3.8071937561035156\n",
      "Running Batch 932, Epoch 5, Total Tokens: 187\n",
      "Loss: 3.8100528717041016\n",
      "Running Batch 933, Epoch 5, Total Tokens: 172\n",
      "Loss: 3.8440701961517334\n",
      "Running Batch 934, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.776165246963501\n",
      "Running Batch 935, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.841974973678589\n",
      "Running Batch 936, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.792128801345825\n",
      "Running Batch 937, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7984232902526855\n",
      "Running Batch 938, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.7492237091064453\n",
      "Running Batch 939, Epoch 5, Total Tokens: 170\n",
      "Loss: 3.828812599182129\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 939, Loss: 3.828812599182129\n",
      "Running Batch 940, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.861755847930908\n",
      "Running Batch 941, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.7694666385650635\n",
      "Running Batch 942, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8171703815460205\n",
      "Running Batch 943, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.780413866043091\n",
      "Running Batch 944, Epoch 5, Total Tokens: 107\n",
      "Loss: 3.8964340686798096\n",
      "Running Batch 945, Epoch 5, Total Tokens: 165\n",
      "Loss: 3.887235164642334\n",
      "Running Batch 946, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.935990571975708\n",
      "Running Batch 947, Epoch 5, Total Tokens: 161\n",
      "Loss: 3.992563486099243\n",
      "Running Batch 948, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.858860731124878\n",
      "Running Batch 949, Epoch 5, Total Tokens: 418\n",
      "Loss: 3.961557388305664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 949, Loss: 3.961557388305664\n",
      "Running Batch 950, Epoch 5, Total Tokens: 299\n",
      "Loss: 3.8542487621307373\n",
      "Running Batch 951, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.9505350589752197\n",
      "Running Batch 952, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.9540135860443115\n",
      "Running Batch 953, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.912355661392212\n",
      "Running Batch 954, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.9728622436523438\n",
      "Running Batch 955, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.915691375732422\n",
      "Running Batch 956, Epoch 5, Total Tokens: 119\n",
      "Loss: 3.9342405796051025\n",
      "Running Batch 957, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.9554836750030518\n",
      "Running Batch 958, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8635430335998535\n",
      "Running Batch 959, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.9393553733825684\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 959, Loss: 3.9393553733825684\n",
      "Running Batch 960, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8791229724884033\n",
      "Running Batch 961, Epoch 5, Total Tokens: 104\n",
      "Loss: 3.872180938720703\n",
      "Running Batch 962, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.882200241088867\n",
      "Running Batch 963, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.926220417022705\n",
      "Running Batch 964, Epoch 5, Total Tokens: 155\n",
      "Loss: 3.8771302700042725\n",
      "Running Batch 965, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8520026206970215\n",
      "Running Batch 966, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.849301815032959\n",
      "Running Batch 967, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.845904588699341\n",
      "Running Batch 968, Epoch 5, Total Tokens: 334\n",
      "Loss: 3.8870697021484375\n",
      "Running Batch 969, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.9494824409484863\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 969, Loss: 3.9494824409484863\n",
      "Running Batch 970, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.8679440021514893\n",
      "Running Batch 971, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.8987672328948975\n",
      "Running Batch 972, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.815419912338257\n",
      "Running Batch 973, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.9568943977355957\n",
      "Running Batch 974, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.8689026832580566\n",
      "Running Batch 975, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.8597779273986816\n",
      "Running Batch 976, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8097336292266846\n",
      "Running Batch 977, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.8093791007995605\n",
      "Running Batch 978, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.826383113861084\n",
      "Running Batch 979, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.896120548248291\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 979, Loss: 3.896120548248291\n",
      "Running Batch 980, Epoch 5, Total Tokens: 147\n",
      "Loss: 3.819396734237671\n",
      "Running Batch 981, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8663570880889893\n",
      "Running Batch 982, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.80015230178833\n",
      "Running Batch 983, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8406338691711426\n",
      "Running Batch 984, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.860614061355591\n",
      "Running Batch 985, Epoch 5, Total Tokens: 284\n",
      "Loss: 3.8730647563934326\n",
      "Running Batch 986, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.826573610305786\n",
      "Running Batch 987, Epoch 5, Total Tokens: 185\n",
      "Loss: 3.763557195663452\n",
      "Running Batch 988, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.835932970046997\n",
      "Running Batch 989, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.797682285308838\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 989, Loss: 3.797682285308838\n",
      "Running Batch 990, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.8060574531555176\n",
      "Running Batch 991, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8038477897644043\n",
      "Running Batch 992, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8454880714416504\n",
      "Running Batch 993, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.824648141860962\n",
      "Running Batch 994, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8950986862182617\n",
      "Running Batch 995, Epoch 5, Total Tokens: 337\n",
      "Loss: 3.699458360671997\n",
      "Running Batch 996, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7799623012542725\n",
      "Running Batch 997, Epoch 5, Total Tokens: 220\n",
      "Loss: 3.860341787338257\n",
      "Running Batch 998, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7642934322357178\n",
      "Running Batch 999, Epoch 5, Total Tokens: 183\n",
      "Loss: 3.841200828552246\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 999, Loss: 3.841200828552246\n",
      "Running Batch 1000, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.8643181324005127\n",
      "Running Batch 1001, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.847618818283081\n",
      "Running Batch 1002, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.77138090133667\n",
      "Running Batch 1003, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8823516368865967\n",
      "Running Batch 1004, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.824902057647705\n",
      "Running Batch 1005, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8031082153320312\n",
      "Running Batch 1006, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.9069769382476807\n",
      "Running Batch 1007, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.7972943782806396\n",
      "Running Batch 1008, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.8124749660491943\n",
      "Running Batch 1009, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.795529842376709\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1009, Loss: 3.795529842376709\n",
      "Running Batch 1010, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.810009717941284\n",
      "Running Batch 1011, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.7610127925872803\n",
      "Running Batch 1012, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8309736251831055\n",
      "Running Batch 1013, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.920029878616333\n",
      "Running Batch 1014, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.798954486846924\n",
      "Running Batch 1015, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8078365325927734\n",
      "Running Batch 1016, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8773605823516846\n",
      "Running Batch 1017, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.767204523086548\n",
      "Running Batch 1018, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8820059299468994\n",
      "Running Batch 1019, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8625497817993164\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1019, Loss: 3.8625497817993164\n",
      "Running Batch 1020, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.767479181289673\n",
      "Running Batch 1021, Epoch 5, Total Tokens: 326\n",
      "Loss: 3.7751142978668213\n",
      "Running Batch 1022, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.901315212249756\n",
      "Running Batch 1023, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8433520793914795\n",
      "Running Batch 1024, Epoch 5, Total Tokens: 112\n",
      "Loss: 3.8209149837493896\n",
      "Running Batch 1025, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.7485203742980957\n",
      "Running Batch 1026, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.861245632171631\n",
      "Running Batch 1027, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.835489273071289\n",
      "Running Batch 1028, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.7899065017700195\n",
      "Running Batch 1029, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.8948264122009277\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1029, Loss: 3.8948264122009277\n",
      "Running Batch 1030, Epoch 5, Total Tokens: 192\n",
      "Loss: 3.8681716918945312\n",
      "Running Batch 1031, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.8476080894470215\n",
      "Running Batch 1032, Epoch 5, Total Tokens: 174\n",
      "Loss: 3.8298983573913574\n",
      "Running Batch 1033, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.7937581539154053\n",
      "Running Batch 1034, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.800020694732666\n",
      "Running Batch 1035, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.827669858932495\n",
      "Running Batch 1036, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.855914354324341\n",
      "Running Batch 1037, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.757530689239502\n",
      "Running Batch 1038, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8381078243255615\n",
      "Running Batch 1039, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.7754616737365723\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1039, Loss: 3.7754616737365723\n",
      "Running Batch 1040, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.9071390628814697\n",
      "Running Batch 1041, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8704335689544678\n",
      "Running Batch 1042, Epoch 5, Total Tokens: 168\n",
      "Loss: 3.795053720474243\n",
      "Running Batch 1043, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8583719730377197\n",
      "Running Batch 1044, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8367700576782227\n",
      "Running Batch 1045, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.815338134765625\n",
      "Running Batch 1046, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7502448558807373\n",
      "Running Batch 1047, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.8017334938049316\n",
      "Running Batch 1048, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.757174015045166\n",
      "Running Batch 1049, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.726154088973999\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1049, Loss: 3.726154088973999\n",
      "Running Batch 1050, Epoch 5, Total Tokens: 188\n",
      "Loss: 3.8312995433807373\n",
      "Running Batch 1051, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.754423141479492\n",
      "Running Batch 1052, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.9336771965026855\n",
      "Running Batch 1053, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.815814733505249\n",
      "Running Batch 1054, Epoch 5, Total Tokens: 322\n",
      "Loss: 3.763195514678955\n",
      "Running Batch 1055, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.768242597579956\n",
      "Running Batch 1056, Epoch 5, Total Tokens: 164\n",
      "Loss: 3.8641839027404785\n",
      "Running Batch 1057, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.8385279178619385\n",
      "Running Batch 1058, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.8310720920562744\n",
      "Running Batch 1059, Epoch 5, Total Tokens: 118\n",
      "Loss: 3.7065987586975098\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1059, Loss: 3.7065987586975098\n",
      "Running Batch 1060, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.8276875019073486\n",
      "Running Batch 1061, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.752063035964966\n",
      "Running Batch 1062, Epoch 5, Total Tokens: 181\n",
      "Loss: 3.725031852722168\n",
      "Running Batch 1063, Epoch 5, Total Tokens: 172\n",
      "Loss: 3.8312511444091797\n",
      "Running Batch 1064, Epoch 5, Total Tokens: 169\n",
      "Loss: 3.766362190246582\n",
      "Running Batch 1065, Epoch 5, Total Tokens: 157\n",
      "Loss: 3.7918291091918945\n",
      "Running Batch 1066, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.809753656387329\n",
      "Running Batch 1067, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.821295738220215\n",
      "Running Batch 1068, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8110251426696777\n",
      "Running Batch 1069, Epoch 5, Total Tokens: 494\n",
      "Loss: 3.7001099586486816\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1069, Loss: 3.7001099586486816\n",
      "Running Batch 1070, Epoch 5, Total Tokens: 241\n",
      "Loss: 3.856912612915039\n",
      "Running Batch 1071, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.8275136947631836\n",
      "Running Batch 1072, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.7989377975463867\n",
      "Running Batch 1073, Epoch 5, Total Tokens: 184\n",
      "Loss: 3.7577128410339355\n",
      "Running Batch 1074, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.792145013809204\n",
      "Running Batch 1075, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.7928600311279297\n",
      "Running Batch 1076, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.8225860595703125\n",
      "Running Batch 1077, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.689788818359375\n",
      "Running Batch 1078, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.8932151794433594\n",
      "Running Batch 1079, Epoch 5, Total Tokens: 114\n",
      "Loss: 3.818953514099121\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1079, Loss: 3.818953514099121\n",
      "Running Batch 1080, Epoch 5, Total Tokens: 178\n",
      "Loss: 3.844222068786621\n",
      "Running Batch 1081, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.878408432006836\n",
      "Running Batch 1082, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.81958270072937\n",
      "Running Batch 1083, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8812501430511475\n",
      "Running Batch 1084, Epoch 5, Total Tokens: 139\n",
      "Loss: 3.871269702911377\n",
      "Running Batch 1085, Epoch 5, Total Tokens: 128\n",
      "Loss: 3.7471511363983154\n",
      "Running Batch 1086, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7850723266601562\n",
      "Running Batch 1087, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8377323150634766\n",
      "Running Batch 1088, Epoch 5, Total Tokens: 149\n",
      "Loss: 3.79144287109375\n",
      "Running Batch 1089, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.777620792388916\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1089, Loss: 3.777620792388916\n",
      "Running Batch 1090, Epoch 5, Total Tokens: 146\n",
      "Loss: 3.832075357437134\n",
      "Running Batch 1091, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.8355937004089355\n",
      "Running Batch 1092, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.8349761962890625\n",
      "Running Batch 1093, Epoch 5, Total Tokens: 126\n",
      "Loss: 3.7214672565460205\n",
      "Running Batch 1094, Epoch 5, Total Tokens: 122\n",
      "Loss: 3.844020128250122\n",
      "Running Batch 1095, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8997697830200195\n",
      "Running Batch 1096, Epoch 5, Total Tokens: 130\n",
      "Loss: 3.775052785873413\n",
      "Running Batch 1097, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.802438259124756\n",
      "Running Batch 1098, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.761395215988159\n",
      "Running Batch 1099, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.8388421535491943\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1099, Loss: 3.8388421535491943\n",
      "Running Batch 1100, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.8154096603393555\n",
      "Running Batch 1101, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8060805797576904\n",
      "Running Batch 1102, Epoch 5, Total Tokens: 162\n",
      "Loss: 3.808051586151123\n",
      "Running Batch 1103, Epoch 5, Total Tokens: 288\n",
      "Loss: 3.8141207695007324\n",
      "Running Batch 1104, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7421188354492188\n",
      "Running Batch 1105, Epoch 5, Total Tokens: 120\n",
      "Loss: 3.793461322784424\n",
      "Running Batch 1106, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.8633878231048584\n",
      "Running Batch 1107, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.747079610824585\n",
      "Running Batch 1108, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8138997554779053\n",
      "Running Batch 1109, Epoch 5, Total Tokens: 234\n",
      "Loss: 3.8395135402679443\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1109, Loss: 3.8395135402679443\n",
      "Running Batch 1110, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.901176929473877\n",
      "Running Batch 1111, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.842702627182007\n",
      "Running Batch 1112, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.745388984680176\n",
      "Running Batch 1113, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.816326379776001\n",
      "Running Batch 1114, Epoch 5, Total Tokens: 223\n",
      "Loss: 3.830681562423706\n",
      "Running Batch 1115, Epoch 5, Total Tokens: 107\n",
      "Loss: 3.8659119606018066\n",
      "Running Batch 1116, Epoch 5, Total Tokens: 145\n",
      "Loss: 3.8941092491149902\n",
      "Running Batch 1117, Epoch 5, Total Tokens: 133\n",
      "Loss: 3.7784767150878906\n",
      "Running Batch 1118, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.8408291339874268\n",
      "Running Batch 1119, Epoch 5, Total Tokens: 171\n",
      "Loss: 3.7854790687561035\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1119, Loss: 3.7854790687561035\n",
      "Running Batch 1120, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.824873685836792\n",
      "Running Batch 1121, Epoch 5, Total Tokens: 140\n",
      "Loss: 3.8310985565185547\n",
      "Running Batch 1122, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.8359713554382324\n",
      "Running Batch 1123, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.830183982849121\n",
      "Running Batch 1124, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.8083667755126953\n",
      "Running Batch 1125, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.873823881149292\n",
      "Running Batch 1126, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.75172758102417\n",
      "Running Batch 1127, Epoch 5, Total Tokens: 273\n",
      "Loss: 3.791651964187622\n",
      "Running Batch 1128, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.810917377471924\n",
      "Running Batch 1129, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.880483388900757\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1129, Loss: 3.880483388900757\n",
      "Running Batch 1130, Epoch 5, Total Tokens: 132\n",
      "Loss: 3.840904712677002\n",
      "Running Batch 1131, Epoch 5, Total Tokens: 142\n",
      "Loss: 3.83986496925354\n",
      "Running Batch 1132, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.815932035446167\n",
      "Running Batch 1133, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.81146502494812\n",
      "Running Batch 1134, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.7824597358703613\n",
      "Running Batch 1135, Epoch 5, Total Tokens: 156\n",
      "Loss: 3.7646148204803467\n",
      "Running Batch 1136, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.834359645843506\n",
      "Running Batch 1137, Epoch 5, Total Tokens: 138\n",
      "Loss: 3.832160234451294\n",
      "Running Batch 1138, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.7877368927001953\n",
      "Running Batch 1139, Epoch 5, Total Tokens: 125\n",
      "Loss: 3.9082958698272705\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1139, Loss: 3.9082958698272705\n",
      "Running Batch 1140, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.87654972076416\n",
      "Running Batch 1141, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.8665175437927246\n",
      "Running Batch 1142, Epoch 5, Total Tokens: 187\n",
      "Loss: 3.767613649368286\n",
      "Running Batch 1143, Epoch 5, Total Tokens: 136\n",
      "Loss: 3.797351837158203\n",
      "Running Batch 1144, Epoch 5, Total Tokens: 116\n",
      "Loss: 3.7610177993774414\n",
      "Running Batch 1145, Epoch 5, Total Tokens: 163\n",
      "Loss: 3.746398448944092\n",
      "Running Batch 1146, Epoch 5, Total Tokens: 134\n",
      "Loss: 3.9055442810058594\n",
      "Running Batch 1147, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8612916469573975\n",
      "Running Batch 1148, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.768068313598633\n",
      "Running Batch 1149, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.9037177562713623\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1149, Loss: 3.9037177562713623\n",
      "Running Batch 1150, Epoch 5, Total Tokens: 121\n",
      "Loss: 3.8676774501800537\n",
      "Running Batch 1151, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.790656089782715\n",
      "Running Batch 1152, Epoch 5, Total Tokens: 152\n",
      "Loss: 3.8081488609313965\n",
      "Running Batch 1153, Epoch 5, Total Tokens: 143\n",
      "Loss: 3.730457067489624\n",
      "Running Batch 1154, Epoch 5, Total Tokens: 135\n",
      "Loss: 3.766880989074707\n",
      "Running Batch 1155, Epoch 5, Total Tokens: 124\n",
      "Loss: 3.7858216762542725\n",
      "Running Batch 1156, Epoch 5, Total Tokens: 150\n",
      "Loss: 3.8656790256500244\n",
      "Running Batch 1157, Epoch 5, Total Tokens: 131\n",
      "Loss: 3.7939841747283936\n",
      "Running Batch 1158, Epoch 5, Total Tokens: 127\n",
      "Loss: 3.783780813217163\n",
      "Running Batch 1159, Epoch 5, Total Tokens: 144\n",
      "Loss: 3.7033286094665527\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1159, Loss: 3.7033286094665527\n",
      "Running Batch 1160, Epoch 5, Total Tokens: 153\n",
      "Loss: 3.8478329181671143\n",
      "Running Batch 1161, Epoch 5, Total Tokens: 151\n",
      "Loss: 3.704071044921875\n",
      "Running Batch 1162, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.856893539428711\n",
      "Running Batch 1163, Epoch 5, Total Tokens: 148\n",
      "Loss: 3.8254406452178955\n",
      "Running Batch 1164, Epoch 5, Total Tokens: 214\n",
      "Loss: 3.7819318771362305\n",
      "Running Batch 1165, Epoch 5, Total Tokens: 129\n",
      "Loss: 3.833204984664917\n",
      "Running Batch 1166, Epoch 5, Total Tokens: 186\n",
      "Loss: 3.8323135375976562\n",
      "Running Batch 1167, Epoch 5, Total Tokens: 159\n",
      "Loss: 3.8974266052246094\n",
      "Running Batch 1168, Epoch 5, Total Tokens: 137\n",
      "Loss: 3.8082852363586426\n",
      "Running Batch 1169, Epoch 5, Total Tokens: 123\n",
      "Loss: 3.886996269226074\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 1169, Loss: 3.886996269226074\n",
      "Running Batch 1170, Epoch 5, Total Tokens: 154\n",
      "Loss: 3.8037185668945312\n",
      "Running Batch 1171, Epoch 5, Total Tokens: 141\n",
      "Loss: 3.8093366622924805\n",
      "AVG LOSS: 3.809721659678241, Epoch: 6\n",
      "Running Batch 0, Epoch 6, Total Tokens: 150\n",
      "Loss: 3.753958225250244\n",
      "Running Batch 1, Epoch 6, Total Tokens: 173\n",
      "Loss: 3.7394392490386963\n",
      "Running Batch 2, Epoch 6, Total Tokens: 123\n",
      "Loss: 3.8829505443573\n",
      "Running Batch 3, Epoch 6, Total Tokens: 138\n",
      "Loss: 3.7939586639404297\n",
      "Running Batch 4, Epoch 6, Total Tokens: 131\n",
      "Loss: 3.8125462532043457\n",
      "Running Batch 5, Epoch 6, Total Tokens: 140\n",
      "Loss: 3.8300294876098633\n",
      "Running Batch 6, Epoch 6, Total Tokens: 153\n",
      "Loss: 3.7504146099090576\n",
      "Running Batch 7, Epoch 6, Total Tokens: 153\n",
      "Loss: 3.8185477256774902\n",
      "Running Batch 8, Epoch 6, Total Tokens: 138\n",
      "Loss: 3.797373056411743\n",
      "Running Batch 9, Epoch 6, Total Tokens: 131\n",
      "Loss: 3.8373019695281982\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 9, Loss: 3.8373019695281982\n",
      "Running Batch 10, Epoch 6, Total Tokens: 118\n",
      "Loss: 3.8432884216308594\n",
      "Running Batch 11, Epoch 6, Total Tokens: 119\n",
      "Loss: 3.8848683834075928\n",
      "Running Batch 12, Epoch 6, Total Tokens: 131\n",
      "Loss: 3.8053364753723145\n",
      "Running Batch 13, Epoch 6, Total Tokens: 157\n",
      "Loss: 3.800096035003662\n",
      "Running Batch 14, Epoch 6, Total Tokens: 140\n",
      "Loss: 3.7696211338043213\n",
      "Running Batch 15, Epoch 6, Total Tokens: 135\n",
      "Loss: 3.8557000160217285\n",
      "Running Batch 16, Epoch 6, Total Tokens: 150\n",
      "Loss: 3.718552827835083\n",
      "Running Batch 17, Epoch 6, Total Tokens: 150\n",
      "Loss: 3.8212943077087402\n",
      "Running Batch 18, Epoch 6, Total Tokens: 139\n",
      "Loss: 3.811527967453003\n",
      "Running Batch 19, Epoch 6, Total Tokens: 141\n",
      "Loss: 3.7808804512023926\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 19, Loss: 3.7808804512023926\n",
      "Running Batch 20, Epoch 6, Total Tokens: 145\n",
      "Loss: 3.8547067642211914\n",
      "Running Batch 21, Epoch 6, Total Tokens: 351\n",
      "Loss: 3.8818202018737793\n",
      "Running Batch 22, Epoch 6, Total Tokens: 191\n",
      "Loss: 3.8438684940338135\n",
      "Running Batch 23, Epoch 6, Total Tokens: 133\n",
      "Loss: 3.881744384765625\n",
      "Running Batch 24, Epoch 6, Total Tokens: 152\n",
      "Loss: 3.816239356994629\n",
      "Running Batch 25, Epoch 6, Total Tokens: 157\n",
      "Loss: 3.775458574295044\n",
      "Running Batch 26, Epoch 6, Total Tokens: 133\n",
      "Loss: 3.905381679534912\n",
      "Running Batch 27, Epoch 6, Total Tokens: 138\n",
      "Loss: 3.85268497467041\n",
      "Running Batch 28, Epoch 6, Total Tokens: 143\n",
      "Loss: 3.7877283096313477\n",
      "Running Batch 29, Epoch 6, Total Tokens: 128\n",
      "Loss: 3.8335957527160645\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 29, Loss: 3.8335957527160645\n",
      "Running Batch 30, Epoch 6, Total Tokens: 146\n",
      "Loss: 3.7967774868011475\n",
      "Running Batch 31, Epoch 6, Total Tokens: 126\n",
      "Loss: 3.9345734119415283\n",
      "Running Batch 32, Epoch 6, Total Tokens: 151\n",
      "Loss: 3.873215913772583\n",
      "Running Batch 33, Epoch 6, Total Tokens: 428\n",
      "Loss: 3.73675799369812\n",
      "Running Batch 34, Epoch 6, Total Tokens: 151\n",
      "Loss: 3.7663729190826416\n",
      "Running Batch 35, Epoch 6, Total Tokens: 122\n",
      "Loss: 3.871126890182495\n",
      "Running Batch 36, Epoch 6, Total Tokens: 154\n",
      "Loss: 3.7445733547210693\n",
      "Running Batch 37, Epoch 6, Total Tokens: 119\n",
      "Loss: 3.808077096939087\n",
      "Running Batch 38, Epoch 6, Total Tokens: 146\n",
      "Loss: 3.8312933444976807\n",
      "Running Batch 39, Epoch 6, Total Tokens: 154\n",
      "Loss: 3.9564599990844727\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 39, Loss: 3.9564599990844727\n",
      "Running Batch 40, Epoch 6, Total Tokens: 494\n",
      "Loss: 3.7814769744873047\n",
      "Running Batch 41, Epoch 6, Total Tokens: 140\n",
      "Loss: 3.7915146350860596\n",
      "Running Batch 42, Epoch 6, Total Tokens: 142\n",
      "Loss: 3.8502116203308105\n",
      "Running Batch 43, Epoch 6, Total Tokens: 127\n",
      "Loss: 3.851698160171509\n",
      "Running Batch 44, Epoch 6, Total Tokens: 144\n",
      "Loss: 3.814743757247925\n",
      "Running Batch 45, Epoch 6, Total Tokens: 384\n",
      "Loss: 3.803037643432617\n",
      "Running Batch 46, Epoch 6, Total Tokens: 112\n",
      "Loss: 3.84966778755188\n",
      "Running Batch 47, Epoch 6, Total Tokens: 145\n",
      "Loss: 3.850886344909668\n",
      "Running Batch 48, Epoch 6, Total Tokens: 220\n",
      "Loss: 3.7945854663848877\n",
      "Running Batch 49, Epoch 6, Total Tokens: 144\n",
      "Loss: 3.8635988235473633\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 49, Loss: 3.8635988235473633\n",
      "Running Batch 50, Epoch 6, Total Tokens: 184\n",
      "Loss: 3.7630624771118164\n",
      "Running Batch 51, Epoch 6, Total Tokens: 157\n",
      "Loss: 3.822622776031494\n",
      "Running Batch 52, Epoch 6, Total Tokens: 127\n",
      "Loss: 3.8296422958374023\n",
      "Running Batch 53, Epoch 6, Total Tokens: 169\n",
      "Loss: 3.779538631439209\n",
      "Running Batch 54, Epoch 6, Total Tokens: 130\n",
      "Loss: 3.8221371173858643\n",
      "Running Batch 55, Epoch 6, Total Tokens: 140\n",
      "Loss: 3.88870906829834\n",
      "Running Batch 56, Epoch 6, Total Tokens: 149\n",
      "Loss: 3.833935022354126\n",
      "Running Batch 57, Epoch 6, Total Tokens: 139\n",
      "Loss: 3.7832398414611816\n",
      "Running Batch 58, Epoch 6, Total Tokens: 367\n",
      "Loss: 3.773179531097412\n",
      "Running Batch 59, Epoch 6, Total Tokens: 119\n",
      "Loss: 3.87974214553833\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 59, Loss: 3.87974214553833\n",
      "Running Batch 60, Epoch 6, Total Tokens: 156\n",
      "Loss: 3.836254358291626\n",
      "Running Batch 61, Epoch 6, Total Tokens: 129\n",
      "Loss: 3.8191373348236084\n",
      "Running Batch 62, Epoch 6, Total Tokens: 147\n",
      "Loss: 3.821869134902954\n",
      "Running Batch 63, Epoch 6, Total Tokens: 126\n",
      "Loss: 3.8165509700775146\n",
      "Running Batch 64, Epoch 6, Total Tokens: 143\n",
      "Loss: 3.84385347366333\n",
      "Running Batch 65, Epoch 6, Total Tokens: 135\n",
      "Loss: 3.802318811416626\n",
      "Running Batch 66, Epoch 6, Total Tokens: 229\n",
      "Loss: 3.830106019973755\n",
      "Running Batch 67, Epoch 6, Total Tokens: 154\n",
      "Loss: 3.7691547870635986\n",
      "Running Batch 68, Epoch 6, Total Tokens: 128\n",
      "Loss: 3.8397252559661865\n",
      "Running Batch 69, Epoch 6, Total Tokens: 145\n",
      "Loss: 3.7647998332977295\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 69, Loss: 3.7647998332977295\n",
      "Running Batch 70, Epoch 6, Total Tokens: 527\n",
      "Loss: 3.7203783988952637\n",
      "Running Batch 71, Epoch 6, Total Tokens: 141\n",
      "Loss: 3.795982837677002\n",
      "Running Batch 72, Epoch 6, Total Tokens: 126\n",
      "Loss: 3.808544635772705\n",
      "Running Batch 73, Epoch 6, Total Tokens: 143\n",
      "Loss: 3.8986589908599854\n",
      "Running Batch 74, Epoch 6, Total Tokens: 142\n",
      "Loss: 3.834240198135376\n",
      "Running Batch 75, Epoch 6, Total Tokens: 134\n",
      "Loss: 3.7881197929382324\n",
      "Running Batch 76, Epoch 6, Total Tokens: 220\n",
      "Loss: 3.80767560005188\n",
      "Running Batch 77, Epoch 6, Total Tokens: 141\n",
      "Loss: 3.81144380569458\n",
      "Running Batch 78, Epoch 6, Total Tokens: 143\n",
      "Loss: 3.8198277950286865\n",
      "Running Batch 79, Epoch 6, Total Tokens: 130\n",
      "Loss: 3.8193705081939697\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 79, Loss: 3.8193705081939697\n",
      "Running Batch 80, Epoch 6, Total Tokens: 139\n",
      "Loss: 3.7417571544647217\n",
      "Running Batch 81, Epoch 6, Total Tokens: 148\n",
      "Loss: 3.8332314491271973\n",
      "Running Batch 82, Epoch 6, Total Tokens: 145\n",
      "Loss: 3.7888333797454834\n",
      "Running Batch 83, Epoch 6, Total Tokens: 152\n",
      "Loss: 3.824875831604004\n",
      "Running Batch 84, Epoch 6, Total Tokens: 127\n",
      "Loss: 3.853832244873047\n",
      "Running Batch 85, Epoch 6, Total Tokens: 119\n",
      "Loss: 3.8021163940429688\n",
      "Running Batch 86, Epoch 6, Total Tokens: 137\n",
      "Loss: 3.730034351348877\n",
      "Running Batch 87, Epoch 6, Total Tokens: 149\n",
      "Loss: 3.8505496978759766\n",
      "Running Batch 88, Epoch 6, Total Tokens: 147\n",
      "Loss: 3.7392873764038086\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(f\"Longest formula in training: {max([len(formula) for formula in dataset.data_frame['IndexList']])}\")\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0]\n",
    "\n",
    "   return labels[:, :len(non_pad_cols)]\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = enc.hp[\"batch_size\"], shuffle = True)\n",
    "print(len(loader))\n",
    "model_path = \"./models/model.pt\"\n",
    "model_backup_path = \"./models/model_backup.pt\"\n",
    "current_params_path = \"./models/current_params.txt\" \n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "torch.save((state_dict), model_backup_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.train()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "prev_loss = 100\n",
    "for epoch in range(3):\n",
    "    curr_loss = 0\n",
    "    for bidx, batch in enumerate(loader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels = remove_trailing_pads(labels)\n",
    "        context_vec = model.encoder(images).squeeze()\n",
    "\n",
    "        inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2)\n",
    "        print(f\"Running Batch {bidx}, Epoch {epoch}, Total Tokens: {labels.shape[1]}\")\n",
    "        output, _ = model.decoder(inputs, None)\n",
    "\n",
    "        # output[labels == PAD_IDX] = 0\n",
    "        # output = F.normalize(output, dim=2, p=1)\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "        target = nn.functional.one_hot(labels[:,1:], num_classes=len(dataset.tokens)).float().to(device)\n",
    "        # target[labels == PAD_IDX] = 0\n",
    "        \n",
    "        # print(f\"Output shape: {output.shape}, Labels shape: {labels.shape}, Target shape: {target.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.transpose(1, 2), target.transpose(1, 2))\n",
    "        loss = loss[labels[:,1:] != PAD_IDX].mean()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        curr_loss += loss.item()\n",
    "        if bidx % 10 == 9:\n",
    "            print(f\"SAVING MODEL to {model_path}\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"SAVED MODEL\")\n",
    "            print(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            try:\n",
    "                with open(current_params_path, 'w') as f:\n",
    "                    f.write(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            except:\n",
    "                print(\"\\n Could not write to file \\n\")\n",
    "    print(f\"AVG LOSS: {(curr_loss)/len(loader)}, Epoch: {epoch+1}\")\n",
    "    prev_loss = curr_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
