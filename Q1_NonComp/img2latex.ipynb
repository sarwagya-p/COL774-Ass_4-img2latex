{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, layers, hparams):\n",
    "        '''\n",
    "        Args:\n",
    "            layers: Description of all layers in the Encoder: [(layer_type, {layer_params})]\n",
    "                - layer types - ['conv1d', 'conv2d', 'maxpool1d', 'maxpool2d', 'avgpool2d', 'avgpool2d', 'linear', 'dropout']\n",
    "                - layer_params - dict of parameters for the layer\n",
    "\n",
    "            hparams: Hyperparameters for the model\n",
    "        '''\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hp = hparams\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for layer_type, layer_params in layers:\n",
    "            if layer_type == 'conv1d':\n",
    "                self.layers.append(nn.Conv1d(**layer_params))\n",
    "            elif layer_type == 'conv2d':\n",
    "                self.layers.append(nn.Conv2d(**layer_params))\n",
    "            elif layer_type == 'maxpool1d':\n",
    "                self.layers.append(nn.MaxPool1d(**layer_params))\n",
    "            elif layer_type == 'maxpool2d':\n",
    "                self.layers.append(nn.MaxPool2d(**layer_params))\n",
    "            elif layer_type == 'avgpool1d':\n",
    "                self.layers.append(nn.AvgPool1d(**layer_params))\n",
    "            elif layer_type == 'avgpool2d':\n",
    "                self.layers.append(nn.AvgPool2d(**layer_params))\n",
    "            elif layer_type == 'linear':\n",
    "                self.layers.append(nn.Linear(**layer_params))\n",
    "            elif layer_type == 'dropout':\n",
    "                self.layers.append(nn.Dropout(**layer_params))\n",
    "            else:\n",
    "                raise ValueError(f'Invalid layer type: {layer_type}')\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers:\n",
    "            input = layer(input)\n",
    "        return input\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab, vocab_dict, input_size, embedding_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        '''\n",
    "        Args:\n",
    "            vocabulary_size: Size of the vocabulary\n",
    "            embedding_size: Size of the embedding vector\n",
    "        '''\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_dict = vocab_dict\n",
    "\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm = nn.LSTM(input_size+embedding_size, embedding_size, batch_first=True)\n",
    "        self.output = nn.Linear(embedding_size, len(vocab))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "        Args:\n",
    "            input: Input to the decoder\n",
    "            hidden: Hidden state of the previous time step\n",
    "        '''\n",
    "        # prev_embed = self.embedding(prev_tokens)\n",
    "        # concated_inp = torch.cat((input, prev_embed), dim=1)\n",
    "        if hidden is None:\n",
    "            output, hidden = self.lstm(input)\n",
    "        else:\n",
    "            output, hidden = self.lstm(input, hidden)\n",
    "        output = self.output(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder=None, decoder=None, device = None):\n",
    "        if device is None:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        self.device = device\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder.cuda()\n",
    "        self.decoder = decoder.cuda()\n",
    "\n",
    "    def forward(self, input):\n",
    "        context_vec = self.encoder(input).squeeze().to(self.device)\n",
    "        prev_token = torch.tensor([self.decoder.vocab_dict[\"<sos>\"]], device=self.device)\n",
    "\n",
    "        input = torch.cat([context_vec.unsqueeze(0).to(self.device), self.decoder.embedding(prev_token).to(self.device)], dim=1).to(self.device)\n",
    "        hidden = None\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for i in range(629):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            prev_token = torch.argmax(output, dim=1)\n",
    "\n",
    "            if prev_token.item() == self.decoder.vocab_dict[\"<eos>\"]:\n",
    "                break\n",
    "            \n",
    "            outputs.append(self.decoder.vocab[prev_token.item()])\n",
    "            input = torch.cat((context_vec.unsqueeze(0), self.decoder.embedding(prev_token)), dim=1).to(self.device)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PAD = \"<pad>\"\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\"\n",
    "\n",
    "def load_img(path, size = (224, 224)):\n",
    "    img = transforms.ToTensor()(Image.open(path))\n",
    "\n",
    "    if img.shape[0] == 1:\n",
    "        img = img.repeat(3, 1, 1)\n",
    "\n",
    "    transform = transforms.Compose([transforms.Resize(size, antialias=True), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "    im = transform(img).detach()\n",
    "    im = 1 - im\n",
    "    return im\n",
    "\n",
    "class Img2LatexDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, formula_path, img_size = (224, 224), tokens = None, token_to_idx = None):\n",
    "        self.data_frame = pd.read_csv(formula_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        if tokens is None:\n",
    "            self.token_to_idx = {}\n",
    "            self.tokens = []\n",
    "\n",
    "            for row in self.data_frame[\"formula\"]:\n",
    "                row = row.split()\n",
    "\n",
    "                for token in row:\n",
    "                    if token not in self.token_to_idx:\n",
    "                        self.token_to_idx[token] = len(self.token_to_idx)\n",
    "                        self.tokens.append(token)\n",
    "            \n",
    "            for special_token in [SOS, EOS, PAD]:\n",
    "                self.token_to_idx[special_token] = len(self.token_to_idx)\n",
    "                self.tokens.append(special_token)\n",
    "        else:\n",
    "            self.token_to_idx = token_to_idx\n",
    "            self.tokens = tokens\n",
    "\n",
    "        max_len = max([len(row.split()) for row in self.data_frame[\"formula\"]])+2\n",
    "        def indexer(row):\n",
    "            index_list = [self.token_to_idx[SOS]]\n",
    "            index_list.extend([self.token_to_idx.get(token, 0) for token in row.split()])\n",
    "            index_list.append(self.token_to_idx[EOS])\n",
    "            index_list.extend([self.token_to_idx[PAD]] * (max_len - len(index_list)))\n",
    "\n",
    "            return index_list\n",
    "        \n",
    "        self.data_frame[\"IndexList\"] = self.data_frame[\"formula\"].apply(indexer)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = load_img(self.img_dir + self.data_frame[\"image\"][index], self.img_size)\n",
    "        if img.shape == (1, 224, 244):\n",
    "            img = img.repeat(3, 1, 1)\n",
    "            \n",
    "        return img, torch.tensor(self.data_frame[\"IndexList\"][index], requires_grad=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.token_to_idx, self.tokens\n",
    "\n",
    "img_dir = \"../data/SyntheticData/images/\"\n",
    "formula_dir = \"../data/SyntheticData/train.csv\"\n",
    "\n",
    "dataset = Img2LatexDataset(img_dir, formula_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"lr\" : 0.0001,\n",
    "    \"batch_size\" : 96,\n",
    "    \"epochs\" : 10\n",
    "}\n",
    "\n",
    "channel_seq = [3, 32, 64, 128, 256, 512]\n",
    "num_conv_pool = 5\n",
    "\n",
    "enc_layers = []\n",
    "\n",
    "for i in range(num_conv_pool):\n",
    "    enc_layers.append(('conv2d', {'in_channels': channel_seq[i], 'out_channels': channel_seq[i+1], 'kernel_size': 5}))\n",
    "    enc_layers.append(('maxpool2d', {'kernel_size': 2}))\n",
    "\n",
    "enc_layers.append(('avgpool2d', {'kernel_size': (3,3)}))\n",
    "\n",
    "enc = EncoderCNN(enc_layers, hparams).to(device)\n",
    "dec = DecoderRNN(dataset.tokens, dataset.token_to_idx, 512, 512).to(device)\n",
    "\n",
    "model = EncoderDecoder(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([32, 3, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([128, 64, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([256, 128, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([512, 256, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 1024])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([549])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "LOADED MODEL to cuda\n",
      "Running Batch 0, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.763729214668274\n",
      "Running Batch 1, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.8656095266342163\n",
      "Running Batch 2, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.8388088941574097\n",
      "Running Batch 3, Epoch 0, Total Tokens: 210\n",
      "Loss: 1.8059329986572266\n",
      "Running Batch 4, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.8003063201904297\n",
      "Running Batch 5, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.757496953010559\n",
      "Running Batch 6, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.8271548748016357\n",
      "Running Batch 7, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.732083797454834\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\0Sem5\\774\\A4\\COL774-Ass_4-img2latex\\Q1_NonComp\\img2latex.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     curr_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mfor\u001b[39;00m bidx, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         images, labels \u001b[39m=\u001b[39m batch\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[1;32me:\\0Sem5\\774\\A4\\COL774-Ass_4-img2latex\\Q1_NonComp\\img2latex.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, index):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     img \u001b[39m=\u001b[39m load_img(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_dir \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_frame[\u001b[39m\"\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m\"\u001b[39;49m][index], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimg_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m img, torch\u001b[39m.\u001b[39mtensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_frame[\u001b[39m\"\u001b[39m\u001b[39mIndexList\u001b[39m\u001b[39m\"\u001b[39m][index], requires_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)\n",
      "\u001b[1;32me:\\0Sem5\\774\\A4\\COL774-Ass_4-img2latex\\Q1_NonComp\\img2latex.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(path, size \u001b[39m=\u001b[39m (\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m)):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     img \u001b[39m=\u001b[39m (Image\u001b[39m.\u001b[39;49mopen(path))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([transforms\u001b[39m.\u001b[39mResize(size, antialias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), transforms\u001b[39m.\u001b[39mToTensor(), transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.5\u001b[39m])])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     im \u001b[39m=\u001b[39m transform(img)\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39mopen(filename, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(f\"Longest formula in training: {max([len(formula) for formula in dataset.data_frame['IndexList']])}\")\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0).to(device)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0].to(device)\n",
    "\n",
    "   return labels[:, :len(non_pad_cols)].to(device)\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = enc.hp[\"batch_size\"], shuffle = True)\n",
    "print(len(loader))\n",
    "model_path = \"./models/model.pt\"\n",
    "model_backup_path = \"./models/model_backup.pt\"\n",
    "current_params_path = \"./models/current_params.txt\" \n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "torch.save((state_dict), model_backup_path)\n",
    "model.load_state_dict(state_dict)\n",
    "if device == \"cuda\":\n",
    "    model.cuda()\n",
    "model.train()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "fifty_fifty = False\n",
    "teacher_forcing = True\n",
    "\n",
    "prev_loss = 100\n",
    "for epoch in range(2):\n",
    "    curr_loss = 0\n",
    "    for bidx, batch in enumerate(loader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels = remove_trailing_pads(labels).to(device)\n",
    "        context_vec = model.encoder(images).squeeze()\n",
    "        if (bidx%2 and fifty_fifty) or teacher_forcing:\n",
    "            inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2).to(device)\n",
    "            print(f\"Running Batch {bidx}, Epoch {epoch}, Total Tokens: {labels.shape[1]}\")\n",
    "            output, _ = model.decoder(inputs, None)\n",
    "\n",
    "            # output[labels == PAD_IDX] = 0\n",
    "            # output = F.normalize(output, dim=2, p=1)\n",
    "            output = output[:, :-1, :].to(device)\n",
    "\n",
    "        else:\n",
    "            output = torch.zeros((labels.shape[0], labels.shape[1]-1, len(dataset.tokens))).to(device)\n",
    "\n",
    "            prev_token = torch.ones(labels.shape[0], dtype=int).to(device) * dataset.token_to_idx[SOS]\n",
    "            prev_token_embed = model.decoder.embedding(prev_token)\n",
    "\n",
    "            input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            hidden = None\n",
    "\n",
    "            for i in range(labels.shape[1]-1):\n",
    "                output[:, i, :], hidden = model.decoder(input, hidden)\n",
    "                prev_token = output[:, i, :].argmax(dim=1).to(device)\n",
    "                prev_token_embed = model.decoder.embedding(prev_token)\n",
    "                input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            \n",
    "        target = nn.functional.one_hot(labels[:,1:], num_classes=len(dataset.tokens)).float().to(device)\n",
    "        # target[labels == PAD_IDX] = 0\n",
    "        mask = (labels[:,1:] != PAD_IDX).to(device)\n",
    "        \n",
    "        # print(f\"Output shape: {output.shape}, Labels shape: {labels.shape}, Target shape: {target.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.transpose(1, 2), target.transpose(1, 2))\n",
    "        loss = loss * mask\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        curr_loss += loss.item()\n",
    "        if bidx % 10 == 9:\n",
    "            print(f\"SAVING MODEL to {model_path}\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"SAVED MODEL\")\n",
    "            print(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            try:\n",
    "                with open(current_params_path, 'w') as f:\n",
    "                    f.write(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            except:\n",
    "                print(\"\\n Could not write to file \\n\")\n",
    "    print(f\"AVG LOSS: {(curr_loss)/len(loader)}, Epoch: {epoch+1}\")\n",
    "    prev_loss = curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/model_tf50synth.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "LOADED MODEL to cuda\n",
      "Loss: 3.594938278198242\n",
      "Running Batch 1, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.8626039028167725\n",
      "Loss: 3.634227752685547\n",
      "Running Batch 3, Epoch 0, Total Tokens: 129\n",
      "Loss: 1.811421275138855\n",
      "Loss: 3.633286476135254\n",
      "Running Batch 5, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7713159322738647\n",
      "Loss: 3.5988612174987793\n",
      "Running Batch 7, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7561284303665161\n",
      "Loss: 3.6209053993225098\n",
      "Running Batch 9, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.8816109895706177\n",
      "Loss: 3.584625720977783\n",
      "Running Batch 11, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7774806022644043\n",
      "Loss: 3.598578453063965\n",
      "Running Batch 13, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7046562433242798\n",
      "Loss: 3.616481065750122\n",
      "Running Batch 15, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7203930616378784\n",
      "Loss: 3.627641439437866\n",
      "Running Batch 17, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.8201730251312256\n",
      "Loss: 3.5373871326446533\n",
      "Running Batch 19, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7848466634750366\n",
      "Loss: 3.5948145389556885\n",
      "Running Batch 21, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7546252012252808\n",
      "Loss: 3.56192684173584\n",
      "Running Batch 23, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.781459093093872\n",
      "Loss: 3.59350323677063\n",
      "Running Batch 25, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.7155981063842773\n",
      "Loss: 3.57464337348938\n",
      "Running Batch 27, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7719868421554565\n",
      "Loss: 3.617504596710205\n",
      "Running Batch 29, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.720353126525879\n",
      "Loss: 3.6264562606811523\n",
      "Running Batch 31, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.793775200843811\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 31, Loss: 1.793775200843811\n",
      "Loss: 3.5137171745300293\n",
      "Running Batch 33, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7296013832092285\n",
      "Loss: 3.5628294944763184\n",
      "Running Batch 35, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7427419424057007\n",
      "Loss: 3.558814525604248\n",
      "Running Batch 37, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7834712266921997\n",
      "Loss: 3.5346689224243164\n",
      "Running Batch 39, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.762474536895752\n",
      "Loss: 3.5479516983032227\n",
      "Running Batch 41, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7157833576202393\n",
      "Loss: 3.559842348098755\n",
      "Running Batch 43, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7465124130249023\n",
      "Loss: 3.6173412799835205\n",
      "Running Batch 45, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.721714973449707\n",
      "Loss: 3.602140426635742\n",
      "Running Batch 47, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.721159815788269\n",
      "Loss: 3.577693223953247\n",
      "Running Batch 49, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.741742730140686\n",
      "Loss: 3.586956739425659\n",
      "Running Batch 51, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7060657739639282\n",
      "Loss: 3.6356472969055176\n",
      "Running Batch 53, Epoch 0, Total Tokens: 220\n",
      "Loss: 1.8342539072036743\n",
      "Loss: 3.623386859893799\n",
      "Running Batch 55, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7716509103775024\n",
      "Loss: 3.5780467987060547\n",
      "Running Batch 57, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7558513879776\n",
      "Loss: 3.5747342109680176\n",
      "Running Batch 59, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.7636018991470337\n",
      "Loss: 3.6071579456329346\n",
      "Running Batch 61, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.741504192352295\n",
      "Loss: 3.572903871536255\n",
      "Running Batch 63, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.7880280017852783\n",
      "Loss: 3.5619115829467773\n",
      "Running Batch 65, Epoch 0, Total Tokens: 205\n",
      "Loss: 1.851672887802124\n",
      "Loss: 3.607154130935669\n",
      "Running Batch 67, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7768380641937256\n",
      "Loss: 3.5386812686920166\n",
      "Running Batch 69, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7159072160720825\n",
      "Loss: 3.589266300201416\n",
      "Running Batch 71, Epoch 0, Total Tokens: 572\n",
      "Loss: 1.6846587657928467\n",
      "Loss: 3.572753429412842\n",
      "Running Batch 73, Epoch 0, Total Tokens: 186\n",
      "Loss: 1.72935950756073\n",
      "Loss: 3.58988881111145\n",
      "Running Batch 75, Epoch 0, Total Tokens: 184\n",
      "Loss: 1.7754993438720703\n",
      "Loss: 3.5564608573913574\n",
      "Running Batch 77, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7649083137512207\n",
      "Loss: 3.6358683109283447\n",
      "Running Batch 79, Epoch 0, Total Tokens: 360\n",
      "Loss: 1.8070769309997559\n",
      "Loss: 3.5808982849121094\n",
      "Running Batch 81, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7543953657150269\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 81, Loss: 1.7543953657150269\n",
      "Loss: 3.5681703090667725\n",
      "Running Batch 83, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.748823881149292\n",
      "Loss: 3.616792678833008\n",
      "Running Batch 85, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6735656261444092\n",
      "Loss: 3.6381418704986572\n",
      "Running Batch 87, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7081564664840698\n",
      "Loss: 3.5434205532073975\n",
      "Running Batch 89, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6869430541992188\n",
      "Loss: 3.547943592071533\n",
      "Running Batch 91, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.8221932649612427\n",
      "Loss: 3.6023306846618652\n",
      "Running Batch 93, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7346175909042358\n",
      "Loss: 3.6148600578308105\n",
      "Running Batch 95, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.829805612564087\n",
      "Loss: 3.587920665740967\n",
      "Running Batch 97, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6961922645568848\n",
      "Loss: 3.5155863761901855\n",
      "Running Batch 99, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7253917455673218\n",
      "Loss: 3.6052699089050293\n",
      "Running Batch 101, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.7633247375488281\n",
      "Loss: 3.571972131729126\n",
      "Running Batch 103, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7788690328598022\n",
      "Loss: 3.644526720046997\n",
      "Running Batch 105, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7586619853973389\n",
      "Loss: 3.5951836109161377\n",
      "Running Batch 107, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7581839561462402\n",
      "Loss: 3.5530107021331787\n",
      "Running Batch 109, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7207602262496948\n",
      "Loss: 3.5882318019866943\n",
      "Running Batch 111, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7348153591156006\n",
      "Loss: 3.5900213718414307\n",
      "Running Batch 113, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.7429567575454712\n",
      "Loss: 3.485029458999634\n",
      "Running Batch 115, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6847354173660278\n",
      "Loss: 3.5597891807556152\n",
      "Running Batch 117, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7303050756454468\n",
      "Loss: 3.5794968605041504\n",
      "Running Batch 119, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.818129301071167\n",
      "Loss: 3.5243067741394043\n",
      "Running Batch 121, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.7591397762298584\n",
      "Loss: 3.532264471054077\n",
      "Running Batch 123, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.810990810394287\n",
      "Loss: 3.598747491836548\n",
      "Running Batch 125, Epoch 0, Total Tokens: 214\n",
      "Loss: 1.7284590005874634\n",
      "Loss: 3.5379655361175537\n",
      "Running Batch 127, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7220227718353271\n",
      "Loss: 3.561121702194214\n",
      "Running Batch 129, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7774511575698853\n",
      "Loss: 3.583230972290039\n",
      "Running Batch 131, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7628120183944702\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 131, Loss: 1.7628120183944702\n",
      "Loss: 3.539682388305664\n",
      "Running Batch 133, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.8476135730743408\n",
      "Loss: 3.5372719764709473\n",
      "Running Batch 135, Epoch 0, Total Tokens: 294\n",
      "Loss: 1.7966831922531128\n",
      "Loss: 3.553347587585449\n",
      "Running Batch 137, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.725772500038147\n",
      "Loss: 3.57619309425354\n",
      "Running Batch 139, Epoch 0, Total Tokens: 361\n",
      "Loss: 1.7260265350341797\n",
      "Loss: 3.6404004096984863\n",
      "Running Batch 141, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7387291193008423\n",
      "Loss: 3.604170560836792\n",
      "Running Batch 143, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7723584175109863\n",
      "Loss: 3.6061089038848877\n",
      "Running Batch 145, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.8061507940292358\n",
      "Loss: 3.5975968837738037\n",
      "Running Batch 147, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.8485089540481567\n",
      "Loss: 3.571134090423584\n",
      "Running Batch 149, Epoch 0, Total Tokens: 237\n",
      "Loss: 1.7627919912338257\n",
      "Loss: 3.622889757156372\n",
      "Running Batch 151, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.750135898590088\n",
      "Loss: 3.5865468978881836\n",
      "Running Batch 153, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.7614737749099731\n",
      "Loss: 3.593240261077881\n",
      "Running Batch 155, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7832926511764526\n",
      "Loss: 3.5810234546661377\n",
      "Running Batch 157, Epoch 0, Total Tokens: 171\n",
      "Loss: 1.699151635169983\n",
      "Loss: 3.5362277030944824\n",
      "Running Batch 159, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.808572769165039\n",
      "Loss: 3.6495726108551025\n",
      "Running Batch 161, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7523342370986938\n",
      "Loss: 3.5786290168762207\n",
      "Running Batch 163, Epoch 0, Total Tokens: 126\n",
      "Loss: 1.6878207921981812\n",
      "Loss: 3.547849655151367\n",
      "Running Batch 165, Epoch 0, Total Tokens: 234\n",
      "Loss: 1.6792080402374268\n",
      "Loss: 3.569232702255249\n",
      "Running Batch 167, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.781509518623352\n",
      "Loss: 3.6073825359344482\n",
      "Running Batch 169, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7949297428131104\n",
      "Loss: 3.5924038887023926\n",
      "Running Batch 171, Epoch 0, Total Tokens: 266\n",
      "Loss: 1.695726752281189\n",
      "Loss: 3.5939509868621826\n",
      "Running Batch 173, Epoch 0, Total Tokens: 160\n",
      "Loss: 1.7737927436828613\n",
      "Loss: 3.645719289779663\n",
      "Running Batch 175, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.8047029972076416\n",
      "Loss: 3.614682197570801\n",
      "Running Batch 177, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7207845449447632\n",
      "Loss: 3.598273515701294\n",
      "Running Batch 179, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7584086656570435\n",
      "Loss: 3.546825647354126\n",
      "Running Batch 181, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.7158517837524414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 181, Loss: 1.7158517837524414\n",
      "Loss: 3.547508716583252\n",
      "Running Batch 183, Epoch 0, Total Tokens: 250\n",
      "Loss: 1.7446998357772827\n",
      "Loss: 3.5678253173828125\n",
      "Running Batch 185, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.687389612197876\n",
      "Loss: 3.5784106254577637\n",
      "Running Batch 187, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.7624388933181763\n",
      "Loss: 3.524851083755493\n",
      "Running Batch 189, Epoch 0, Total Tokens: 190\n",
      "Loss: 1.7679944038391113\n",
      "Loss: 3.5297093391418457\n",
      "Running Batch 191, Epoch 0, Total Tokens: 202\n",
      "Loss: 1.7431180477142334\n",
      "Loss: 3.538994789123535\n",
      "Running Batch 193, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7960792779922485\n",
      "Loss: 3.564883232116699\n",
      "Running Batch 195, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7460875511169434\n",
      "Loss: 3.5794565677642822\n",
      "Running Batch 197, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.8296910524368286\n",
      "Loss: 3.570770502090454\n",
      "Running Batch 199, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.775213599205017\n",
      "Loss: 3.5964927673339844\n",
      "Running Batch 201, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7202892303466797\n",
      "Loss: 3.6015024185180664\n",
      "Running Batch 203, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7338980436325073\n",
      "Loss: 3.5212435722351074\n",
      "Running Batch 205, Epoch 0, Total Tokens: 158\n",
      "Loss: 1.7735780477523804\n",
      "Loss: 3.552856206893921\n",
      "Running Batch 207, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7175732851028442\n",
      "Loss: 3.6167044639587402\n",
      "Running Batch 209, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.669695496559143\n",
      "Loss: 3.5117268562316895\n",
      "Running Batch 211, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6853362321853638\n",
      "Loss: 3.566053628921509\n",
      "Running Batch 213, Epoch 0, Total Tokens: 452\n",
      "Loss: 1.7840238809585571\n",
      "Loss: 3.567673921585083\n",
      "Running Batch 215, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7114734649658203\n",
      "Loss: 3.5461394786834717\n",
      "Running Batch 217, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7622267007827759\n",
      "Loss: 3.52817964553833\n",
      "Running Batch 219, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7221519947052002\n",
      "Loss: 3.5634686946868896\n",
      "Running Batch 221, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7734326124191284\n",
      "Loss: 3.5309247970581055\n",
      "Running Batch 223, Epoch 0, Total Tokens: 177\n",
      "Loss: 1.7166472673416138\n",
      "Loss: 3.614659309387207\n",
      "Running Batch 225, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.699156641960144\n",
      "Loss: 3.607483148574829\n",
      "Running Batch 227, Epoch 0, Total Tokens: 178\n",
      "Loss: 1.7195110321044922\n",
      "Loss: 3.562063455581665\n",
      "Running Batch 229, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7573856115341187\n",
      "Loss: 3.5885424613952637\n",
      "Running Batch 231, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7934337854385376\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 231, Loss: 1.7934337854385376\n",
      "Loss: 3.545015335083008\n",
      "Running Batch 233, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7677648067474365\n",
      "Loss: 3.5882456302642822\n",
      "Running Batch 235, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.72279691696167\n",
      "Loss: 3.573641061782837\n",
      "Running Batch 237, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.8085038661956787\n",
      "Loss: 3.57857084274292\n",
      "Running Batch 239, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7310121059417725\n",
      "Loss: 3.5574474334716797\n",
      "Running Batch 241, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7719351053237915\n",
      "Loss: 3.559523820877075\n",
      "Running Batch 243, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7308481931686401\n",
      "Loss: 3.607093334197998\n",
      "Running Batch 245, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7085391283035278\n",
      "Loss: 3.601228713989258\n",
      "Running Batch 247, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6837117671966553\n",
      "Loss: 3.556593656539917\n",
      "Running Batch 249, Epoch 0, Total Tokens: 188\n",
      "Loss: 1.7887767553329468\n",
      "Loss: 3.581876516342163\n",
      "Running Batch 251, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7854042053222656\n",
      "Loss: 3.638812780380249\n",
      "Running Batch 253, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.7439192533493042\n",
      "Loss: 3.5956170558929443\n",
      "Running Batch 255, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.745859146118164\n",
      "Loss: 3.6422226428985596\n",
      "Running Batch 257, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7282910346984863\n",
      "Loss: 3.5898189544677734\n",
      "Running Batch 259, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7227962017059326\n",
      "Loss: 3.604970932006836\n",
      "Running Batch 261, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7729507684707642\n",
      "Loss: 3.5988218784332275\n",
      "Running Batch 263, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.705970048904419\n",
      "Loss: 3.5455169677734375\n",
      "Running Batch 265, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6854764223098755\n",
      "Loss: 3.5372297763824463\n",
      "Running Batch 267, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7311625480651855\n",
      "Loss: 3.5780673027038574\n",
      "Running Batch 269, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.6550142765045166\n",
      "Loss: 3.5116727352142334\n",
      "Running Batch 271, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7709919214248657\n",
      "Loss: 3.6136186122894287\n",
      "Running Batch 273, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.759884238243103\n",
      "Loss: 3.5150020122528076\n",
      "Running Batch 275, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.727264642715454\n",
      "Loss: 3.577615737915039\n",
      "Running Batch 277, Epoch 0, Total Tokens: 171\n",
      "Loss: 1.7510793209075928\n",
      "Loss: 3.520435333251953\n",
      "Running Batch 279, Epoch 0, Total Tokens: 220\n",
      "Loss: 1.776822805404663\n",
      "Loss: 3.5205557346343994\n",
      "Running Batch 281, Epoch 0, Total Tokens: 181\n",
      "Loss: 1.7157081365585327\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 281, Loss: 1.7157081365585327\n",
      "Loss: 3.541198968887329\n",
      "Running Batch 283, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7448478937149048\n",
      "Loss: 3.558924913406372\n",
      "Running Batch 285, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7857937812805176\n",
      "Loss: 3.56615948677063\n",
      "Running Batch 287, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7529675960540771\n",
      "Loss: 3.5947821140289307\n",
      "Running Batch 289, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.8060648441314697\n",
      "Loss: 3.5905704498291016\n",
      "Running Batch 291, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.772314429283142\n",
      "Loss: 3.5644962787628174\n",
      "Running Batch 293, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7891459465026855\n",
      "Loss: 3.589151620864868\n",
      "Running Batch 295, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.6875892877578735\n",
      "Loss: 3.515428066253662\n",
      "Running Batch 297, Epoch 0, Total Tokens: 190\n",
      "Loss: 1.7123221158981323\n",
      "Loss: 3.480323553085327\n",
      "Running Batch 299, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7888681888580322\n",
      "Loss: 3.554208993911743\n",
      "Running Batch 301, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6916825771331787\n",
      "Loss: 3.5427262783050537\n",
      "Running Batch 303, Epoch 0, Total Tokens: 219\n",
      "Loss: 1.7609779834747314\n",
      "Loss: 3.599289655685425\n",
      "Running Batch 305, Epoch 0, Total Tokens: 262\n",
      "Loss: 1.7093210220336914\n",
      "Loss: 3.5765562057495117\n",
      "Running Batch 307, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7849427461624146\n",
      "Loss: 3.5551626682281494\n",
      "Running Batch 309, Epoch 0, Total Tokens: 180\n",
      "Loss: 1.720951795578003\n",
      "Loss: 3.631072759628296\n",
      "Running Batch 311, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7302736043930054\n",
      "Loss: 3.58941912651062\n",
      "Running Batch 313, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7043144702911377\n",
      "Loss: 3.529867172241211\n",
      "Running Batch 315, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7468613386154175\n",
      "Loss: 3.5160207748413086\n",
      "Running Batch 317, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7603906393051147\n",
      "Loss: 3.5275144577026367\n",
      "Running Batch 319, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7959723472595215\n",
      "Loss: 3.5134289264678955\n",
      "Running Batch 321, Epoch 0, Total Tokens: 210\n",
      "Loss: 1.8011603355407715\n",
      "Loss: 3.5035288333892822\n",
      "Running Batch 323, Epoch 0, Total Tokens: 176\n",
      "Loss: 1.773806095123291\n",
      "Loss: 3.5966076850891113\n",
      "Running Batch 325, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6721066236495972\n",
      "Loss: 3.556312084197998\n",
      "Running Batch 327, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7672492265701294\n",
      "Loss: 3.516162633895874\n",
      "Running Batch 329, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7797209024429321\n",
      "Loss: 3.5901637077331543\n",
      "Running Batch 331, Epoch 0, Total Tokens: 267\n",
      "Loss: 1.8010404109954834\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 331, Loss: 1.8010404109954834\n",
      "Loss: 3.5627567768096924\n",
      "Running Batch 333, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.718161702156067\n",
      "Loss: 3.592038631439209\n",
      "Running Batch 335, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.8044543266296387\n",
      "Loss: 3.567246675491333\n",
      "Running Batch 337, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.7925676107406616\n",
      "Loss: 3.5924999713897705\n",
      "Running Batch 339, Epoch 0, Total Tokens: 155\n",
      "Loss: 1.7115341424942017\n",
      "Loss: 3.512162685394287\n",
      "Running Batch 341, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.818307638168335\n",
      "Loss: 3.5920159816741943\n",
      "Running Batch 343, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7915830612182617\n",
      "Loss: 3.5687179565429688\n",
      "Running Batch 345, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7912622690200806\n",
      "Loss: 3.5377471446990967\n",
      "Running Batch 347, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7618244886398315\n",
      "Loss: 3.5645573139190674\n",
      "Running Batch 349, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7072644233703613\n",
      "Loss: 3.5377941131591797\n",
      "Running Batch 351, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.7940053939819336\n",
      "Loss: 3.5246853828430176\n",
      "Running Batch 353, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7404297590255737\n",
      "Loss: 3.56044864654541\n",
      "Running Batch 355, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7529027462005615\n",
      "Loss: 3.533681869506836\n",
      "Running Batch 357, Epoch 0, Total Tokens: 494\n",
      "Loss: 1.6794666051864624\n",
      "Loss: 3.5331850051879883\n",
      "Running Batch 359, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.703273892402649\n",
      "Loss: 3.6674563884735107\n",
      "Running Batch 361, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7434853315353394\n",
      "Loss: 3.5777831077575684\n",
      "Running Batch 363, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.7273287773132324\n",
      "Loss: 3.5642552375793457\n",
      "Running Batch 365, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.816222071647644\n",
      "Loss: 3.5553297996520996\n",
      "Running Batch 367, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7550289630889893\n",
      "Loss: 3.5517380237579346\n",
      "Running Batch 369, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.7750962972640991\n",
      "Loss: 3.5540010929107666\n",
      "Running Batch 371, Epoch 0, Total Tokens: 164\n",
      "Loss: 1.7637346982955933\n",
      "Loss: 3.564940929412842\n",
      "Running Batch 373, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7661221027374268\n",
      "Loss: 3.5709643363952637\n",
      "Running Batch 375, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6949849128723145\n",
      "Loss: 3.6495003700256348\n",
      "Running Batch 377, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6859065294265747\n",
      "Loss: 3.620128870010376\n",
      "Running Batch 379, Epoch 0, Total Tokens: 220\n",
      "Loss: 1.7141914367675781\n",
      "Loss: 3.630359649658203\n",
      "Running Batch 381, Epoch 0, Total Tokens: 273\n",
      "Loss: 1.738625407218933\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 381, Loss: 1.738625407218933\n",
      "Loss: 3.5951426029205322\n",
      "Running Batch 383, Epoch 0, Total Tokens: 228\n",
      "Loss: 1.7436566352844238\n",
      "Loss: 3.5682528018951416\n",
      "Running Batch 385, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7054927349090576\n",
      "Loss: 3.6100502014160156\n",
      "Running Batch 387, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.794669508934021\n",
      "Loss: 3.5733487606048584\n",
      "Running Batch 389, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7038019895553589\n",
      "Loss: 3.5629801750183105\n",
      "Running Batch 391, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7548999786376953\n",
      "Loss: 3.5757157802581787\n",
      "Running Batch 393, Epoch 0, Total Tokens: 125\n",
      "Loss: 1.7188550233840942\n",
      "Loss: 3.571118116378784\n",
      "Running Batch 395, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7279551029205322\n",
      "Loss: 3.5137012004852295\n",
      "Running Batch 397, Epoch 0, Total Tokens: 527\n",
      "Loss: 1.7452834844589233\n",
      "Loss: 3.570673704147339\n",
      "Running Batch 399, Epoch 0, Total Tokens: 172\n",
      "Loss: 1.7180745601654053\n",
      "Loss: 3.536898374557495\n",
      "Running Batch 401, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7573598623275757\n",
      "Loss: 3.6117684841156006\n",
      "Running Batch 403, Epoch 0, Total Tokens: 183\n",
      "Loss: 1.6937239170074463\n",
      "Loss: 3.563965320587158\n",
      "Running Batch 405, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7712483406066895\n",
      "Loss: 3.5536835193634033\n",
      "Running Batch 407, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7269182205200195\n",
      "Loss: 3.5276849269866943\n",
      "Running Batch 409, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.787441611289978\n",
      "Loss: 3.537797212600708\n",
      "Running Batch 411, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7287921905517578\n",
      "Loss: 3.607241630554199\n",
      "Running Batch 413, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.7548279762268066\n",
      "Loss: 3.5454275608062744\n",
      "Running Batch 415, Epoch 0, Total Tokens: 288\n",
      "Loss: 1.7564412355422974\n",
      "Loss: 3.5230722427368164\n",
      "Running Batch 417, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7966676950454712\n",
      "Loss: 3.5414183139801025\n",
      "Running Batch 419, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.6930947303771973\n",
      "Loss: 3.6129748821258545\n",
      "Running Batch 421, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.8045181035995483\n",
      "Loss: 3.5597646236419678\n",
      "Running Batch 423, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6877084970474243\n",
      "Loss: 3.599435329437256\n",
      "Running Batch 425, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.8193445205688477\n",
      "Loss: 3.5969083309173584\n",
      "Running Batch 427, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7770589590072632\n",
      "Loss: 3.518754482269287\n",
      "Running Batch 429, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7404398918151855\n",
      "Loss: 3.5617330074310303\n",
      "Running Batch 431, Epoch 0, Total Tokens: 167\n",
      "Loss: 1.764886498451233\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 431, Loss: 1.764886498451233\n",
      "Loss: 3.5352423191070557\n",
      "Running Batch 433, Epoch 0, Total Tokens: 225\n",
      "Loss: 1.729621171951294\n",
      "Loss: 3.646958351135254\n",
      "Running Batch 435, Epoch 0, Total Tokens: 201\n",
      "Loss: 1.6816623210906982\n",
      "Loss: 3.6104440689086914\n",
      "Running Batch 437, Epoch 0, Total Tokens: 124\n",
      "Loss: 1.7111340761184692\n",
      "Loss: 3.5603089332580566\n",
      "Running Batch 439, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.6356741189956665\n",
      "Loss: 3.5681099891662598\n",
      "Running Batch 441, Epoch 0, Total Tokens: 384\n",
      "Loss: 1.6981632709503174\n",
      "Loss: 3.5473976135253906\n",
      "Running Batch 443, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7912923097610474\n",
      "Loss: 3.4909915924072266\n",
      "Running Batch 445, Epoch 0, Total Tokens: 223\n",
      "Loss: 1.7919812202453613\n",
      "Loss: 3.5986077785491943\n",
      "Running Batch 447, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7556235790252686\n",
      "Loss: 3.5588016510009766\n",
      "Running Batch 449, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.671363115310669\n",
      "Loss: 3.5504677295684814\n",
      "Running Batch 451, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.760918140411377\n",
      "Loss: 3.5753848552703857\n",
      "Running Batch 453, Epoch 0, Total Tokens: 285\n",
      "Loss: 1.6893025636672974\n",
      "Loss: 3.6190531253814697\n",
      "Running Batch 455, Epoch 0, Total Tokens: 123\n",
      "Loss: 1.6610419750213623\n",
      "Loss: 3.569155693054199\n",
      "Running Batch 457, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.8019264936447144\n",
      "Loss: 3.5493903160095215\n",
      "Running Batch 459, Epoch 0, Total Tokens: 119\n",
      "Loss: 1.711077094078064\n",
      "Loss: 3.5582361221313477\n",
      "Running Batch 461, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7546957731246948\n",
      "Loss: 3.5637378692626953\n",
      "Running Batch 463, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6778526306152344\n",
      "Loss: 3.606895685195923\n",
      "Running Batch 465, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.8552684783935547\n",
      "Loss: 3.539839744567871\n",
      "Running Batch 467, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7566189765930176\n",
      "Loss: 3.575476884841919\n",
      "Running Batch 469, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.8026349544525146\n",
      "Loss: 3.6475930213928223\n",
      "Running Batch 471, Epoch 0, Total Tokens: 249\n",
      "Loss: 1.755903720855713\n",
      "Loss: 3.573089599609375\n",
      "Running Batch 473, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7635679244995117\n",
      "Loss: 3.5207018852233887\n",
      "Running Batch 475, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7585115432739258\n",
      "Loss: 3.5356247425079346\n",
      "Running Batch 477, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7682056427001953\n",
      "Loss: 3.5864996910095215\n",
      "Running Batch 479, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7222589254379272\n",
      "Loss: 3.58945369720459\n",
      "Running Batch 481, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.746060848236084\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 481, Loss: 1.746060848236084\n",
      "Loss: 3.525465965270996\n",
      "Running Batch 483, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.692320466041565\n",
      "Loss: 3.499633312225342\n",
      "Running Batch 485, Epoch 0, Total Tokens: 162\n",
      "Loss: 1.6559925079345703\n",
      "Loss: 3.614257574081421\n",
      "Running Batch 487, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7709773778915405\n",
      "Loss: 3.60384202003479\n",
      "Running Batch 489, Epoch 0, Total Tokens: 214\n",
      "Loss: 1.6782441139221191\n",
      "Loss: 3.5540413856506348\n",
      "Running Batch 491, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7045212984085083\n",
      "Loss: 3.538814067840576\n",
      "Running Batch 493, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.693177342414856\n",
      "Loss: 3.522439479827881\n",
      "Running Batch 495, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.8177682161331177\n",
      "Loss: 3.5270638465881348\n",
      "Running Batch 497, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7074133157730103\n",
      "Loss: 3.5737884044647217\n",
      "Running Batch 499, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.6727492809295654\n",
      "Loss: 3.588937759399414\n",
      "Running Batch 501, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.731865406036377\n",
      "Loss: 3.542299747467041\n",
      "Running Batch 503, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.772496223449707\n",
      "Loss: 3.5526585578918457\n",
      "Running Batch 505, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7550915479660034\n",
      "Loss: 3.578256130218506\n",
      "Running Batch 507, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7179780006408691\n",
      "Loss: 3.506070137023926\n",
      "Running Batch 509, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.7145544290542603\n",
      "Loss: 3.49664568901062\n",
      "Running Batch 511, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7678354978561401\n",
      "Loss: 3.5396034717559814\n",
      "Running Batch 513, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.6905570030212402\n",
      "Loss: 3.545858860015869\n",
      "Running Batch 515, Epoch 0, Total Tokens: 224\n",
      "Loss: 1.6448863744735718\n",
      "Loss: 3.565749168395996\n",
      "Running Batch 517, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.7424863576889038\n",
      "Loss: 3.5976240634918213\n",
      "Running Batch 519, Epoch 0, Total Tokens: 120\n",
      "Loss: 1.728699803352356\n",
      "Loss: 3.5300111770629883\n",
      "Running Batch 521, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7984628677368164\n",
      "Loss: 3.6370489597320557\n",
      "Running Batch 523, Epoch 0, Total Tokens: 169\n",
      "Loss: 1.7464656829833984\n",
      "Loss: 3.5486819744110107\n",
      "Running Batch 525, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.6733567714691162\n",
      "Loss: 3.5159456729888916\n",
      "Running Batch 527, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7147585153579712\n",
      "Loss: 3.5416879653930664\n",
      "Running Batch 529, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7360849380493164\n",
      "Loss: 3.5368244647979736\n",
      "Running Batch 531, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.7463726997375488\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 531, Loss: 1.7463726997375488\n",
      "Loss: 3.5552027225494385\n",
      "Running Batch 533, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.7028955221176147\n",
      "Loss: 3.5697293281555176\n",
      "Running Batch 535, Epoch 0, Total Tokens: 629\n",
      "Loss: 1.6734137535095215\n",
      "Loss: 3.5158169269561768\n",
      "Running Batch 537, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6935534477233887\n",
      "Loss: 3.5290091037750244\n",
      "Running Batch 539, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.7271325588226318\n",
      "Loss: 3.5561060905456543\n",
      "Running Batch 541, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.82728111743927\n",
      "Loss: 3.5783917903900146\n",
      "Running Batch 543, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7501542568206787\n",
      "Loss: 3.549016237258911\n",
      "Running Batch 545, Epoch 0, Total Tokens: 163\n",
      "Loss: 1.745786190032959\n",
      "Loss: 3.537846088409424\n",
      "Running Batch 547, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6887726783752441\n",
      "Loss: 3.5305137634277344\n",
      "Running Batch 549, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7059273719787598\n",
      "Loss: 3.5972707271575928\n",
      "Running Batch 551, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.745030164718628\n",
      "Loss: 3.531191349029541\n",
      "Running Batch 553, Epoch 0, Total Tokens: 138\n",
      "Loss: 1.7155567407608032\n",
      "Loss: 3.5689282417297363\n",
      "Running Batch 555, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7542080879211426\n",
      "Loss: 3.5656518936157227\n",
      "Running Batch 557, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7736196517944336\n",
      "Loss: 3.570638656616211\n",
      "Running Batch 559, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7733585834503174\n",
      "Loss: 3.5667152404785156\n",
      "Running Batch 561, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.8180328607559204\n",
      "Loss: 3.5897927284240723\n",
      "Running Batch 563, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.8050976991653442\n",
      "Loss: 3.5495710372924805\n",
      "Running Batch 565, Epoch 0, Total Tokens: 217\n",
      "Loss: 1.7313728332519531\n",
      "Loss: 3.5687448978424072\n",
      "Running Batch 567, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.69111967086792\n",
      "Loss: 3.5483391284942627\n",
      "Running Batch 569, Epoch 0, Total Tokens: 241\n",
      "Loss: 1.8062801361083984\n",
      "Loss: 3.605905055999756\n",
      "Running Batch 571, Epoch 0, Total Tokens: 334\n",
      "Loss: 1.7884349822998047\n",
      "Loss: 3.5406384468078613\n",
      "Running Batch 573, Epoch 0, Total Tokens: 154\n",
      "Loss: 1.750064492225647\n",
      "Loss: 3.5776679515838623\n",
      "Running Batch 575, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7045422792434692\n",
      "Loss: 3.533470630645752\n",
      "Running Batch 577, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7755340337753296\n",
      "Loss: 3.5157361030578613\n",
      "Running Batch 579, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.690201759338379\n",
      "Loss: 3.498627185821533\n",
      "Running Batch 581, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.730691909790039\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 581, Loss: 1.730691909790039\n",
      "Loss: 3.6090400218963623\n",
      "Running Batch 583, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7718509435653687\n",
      "Loss: 3.553694725036621\n",
      "Running Batch 585, Epoch 0, Total Tokens: 139\n",
      "Loss: 1.6506412029266357\n",
      "Loss: 3.4601187705993652\n",
      "Running Batch 587, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6953842639923096\n",
      "Loss: 3.5240349769592285\n",
      "Running Batch 589, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.7789851427078247\n",
      "Loss: 3.5618224143981934\n",
      "Running Batch 591, Epoch 0, Total Tokens: 156\n",
      "Loss: 1.7978678941726685\n",
      "Loss: 3.5556845664978027\n",
      "Running Batch 593, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7489290237426758\n",
      "Loss: 3.5519039630889893\n",
      "Running Batch 595, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7045783996582031\n",
      "Loss: 3.5165812969207764\n",
      "Running Batch 597, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.7861212491989136\n",
      "Loss: 3.5545711517333984\n",
      "Running Batch 599, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.7020970582962036\n",
      "Loss: 3.5669186115264893\n",
      "Running Batch 601, Epoch 0, Total Tokens: 230\n",
      "Loss: 1.7034227848052979\n",
      "Loss: 3.5334088802337646\n",
      "Running Batch 603, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.6716715097427368\n",
      "Loss: 3.5223140716552734\n",
      "Running Batch 605, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.756311058998108\n",
      "Loss: 3.6195192337036133\n",
      "Running Batch 607, Epoch 0, Total Tokens: 202\n",
      "Loss: 1.7985243797302246\n",
      "Loss: 3.532895565032959\n",
      "Running Batch 609, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7666549682617188\n",
      "Loss: 3.646867513656616\n",
      "Running Batch 611, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.6584945917129517\n",
      "Loss: 3.605036973953247\n",
      "Running Batch 613, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7418737411499023\n",
      "Loss: 3.646261215209961\n",
      "Running Batch 615, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.757880687713623\n",
      "Loss: 3.5209598541259766\n",
      "Running Batch 617, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.6829607486724854\n",
      "Loss: 3.566655158996582\n",
      "Running Batch 619, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.6021685600280762\n",
      "Loss: 3.569725275039673\n",
      "Running Batch 621, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7579846382141113\n",
      "Loss: 3.562704086303711\n",
      "Running Batch 623, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7385600805282593\n",
      "Loss: 3.601611614227295\n",
      "Running Batch 625, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7654926776885986\n",
      "Loss: 3.5611772537231445\n",
      "Running Batch 627, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.7087819576263428\n",
      "Loss: 3.5005948543548584\n",
      "Running Batch 629, Epoch 0, Total Tokens: 224\n",
      "Loss: 1.7977452278137207\n",
      "Loss: 3.525815963745117\n",
      "Running Batch 631, Epoch 0, Total Tokens: 296\n",
      "Loss: 1.6279089450836182\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 631, Loss: 1.6279089450836182\n",
      "Loss: 3.530637502670288\n",
      "Running Batch 633, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.7928152084350586\n",
      "Loss: 3.547374725341797\n",
      "Running Batch 635, Epoch 0, Total Tokens: 206\n",
      "Loss: 1.7572126388549805\n",
      "Loss: 3.498584508895874\n",
      "Running Batch 637, Epoch 0, Total Tokens: 136\n",
      "Loss: 1.745491862297058\n",
      "Loss: 3.5541274547576904\n",
      "Running Batch 639, Epoch 0, Total Tokens: 258\n",
      "Loss: 1.7636979818344116\n",
      "Loss: 3.567293167114258\n",
      "Running Batch 641, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.730247974395752\n",
      "Loss: 3.5838756561279297\n",
      "Running Batch 643, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7106989622116089\n",
      "Loss: 3.572256565093994\n",
      "Running Batch 645, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7533056735992432\n",
      "Loss: 3.51393461227417\n",
      "Running Batch 647, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.6821506023406982\n",
      "Loss: 3.540639638900757\n",
      "Running Batch 649, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.6987895965576172\n",
      "Loss: 3.5645785331726074\n",
      "Running Batch 651, Epoch 0, Total Tokens: 165\n",
      "Loss: 1.7600679397583008\n",
      "Loss: 3.562584638595581\n",
      "Running Batch 653, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.7361327409744263\n",
      "Loss: 3.569756269454956\n",
      "Running Batch 655, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.714460849761963\n",
      "Loss: 3.551020860671997\n",
      "Running Batch 657, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.7385435104370117\n",
      "Loss: 3.560948371887207\n",
      "Running Batch 659, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.7400670051574707\n",
      "Loss: 3.5258798599243164\n",
      "Running Batch 661, Epoch 0, Total Tokens: 195\n",
      "Loss: 1.7224472761154175\n",
      "Loss: 3.5313148498535156\n",
      "Running Batch 663, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7547399997711182\n",
      "Loss: 3.526583194732666\n",
      "Running Batch 665, Epoch 0, Total Tokens: 127\n",
      "Loss: 1.7435451745986938\n",
      "Loss: 3.534623146057129\n",
      "Running Batch 667, Epoch 0, Total Tokens: 205\n",
      "Loss: 1.8289903402328491\n",
      "Loss: 3.5443038940429688\n",
      "Running Batch 669, Epoch 0, Total Tokens: 130\n",
      "Loss: 1.6993087530136108\n",
      "Loss: 3.5272140502929688\n",
      "Running Batch 671, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.7137267589569092\n",
      "Loss: 3.618238687515259\n",
      "Running Batch 673, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.7808712720870972\n",
      "Loss: 3.5526278018951416\n",
      "Running Batch 675, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.690136432647705\n",
      "Loss: 3.5316832065582275\n",
      "Running Batch 677, Epoch 0, Total Tokens: 144\n",
      "Loss: 1.7067029476165771\n",
      "Loss: 3.5526978969573975\n",
      "Running Batch 679, Epoch 0, Total Tokens: 173\n",
      "Loss: 1.7196036577224731\n",
      "Loss: 3.54844069480896\n",
      "Running Batch 681, Epoch 0, Total Tokens: 203\n",
      "Loss: 1.787652611732483\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 681, Loss: 1.787652611732483\n",
      "Loss: 3.5040993690490723\n",
      "Running Batch 683, Epoch 0, Total Tokens: 231\n",
      "Loss: 1.7980502843856812\n",
      "Loss: 3.5056216716766357\n",
      "Running Batch 685, Epoch 0, Total Tokens: 199\n",
      "Loss: 1.7421218156814575\n",
      "Loss: 3.560767650604248\n",
      "Running Batch 687, Epoch 0, Total Tokens: 184\n",
      "Loss: 1.689544916152954\n",
      "Loss: 3.5387275218963623\n",
      "Running Batch 689, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.755557894706726\n",
      "Loss: 3.565399169921875\n",
      "Running Batch 691, Epoch 0, Total Tokens: 351\n",
      "Loss: 1.7980754375457764\n",
      "Loss: 3.555562973022461\n",
      "Running Batch 693, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.837395191192627\n",
      "Loss: 3.534548282623291\n",
      "Running Batch 695, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.7458431720733643\n",
      "Loss: 3.5182862281799316\n",
      "Running Batch 697, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.7590913772583008\n",
      "Loss: 3.6203620433807373\n",
      "Running Batch 699, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.811890959739685\n",
      "Loss: 3.533249616622925\n",
      "Running Batch 701, Epoch 0, Total Tokens: 132\n",
      "Loss: 1.7108362913131714\n",
      "Loss: 3.56421160697937\n",
      "Running Batch 703, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7057812213897705\n",
      "Loss: 3.5501036643981934\n",
      "Running Batch 705, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.7008183002471924\n",
      "Loss: 3.552353620529175\n",
      "Running Batch 707, Epoch 0, Total Tokens: 146\n",
      "Loss: 1.7365654706954956\n",
      "Loss: 3.529014825820923\n",
      "Running Batch 709, Epoch 0, Total Tokens: 179\n",
      "Loss: 1.7353349924087524\n",
      "Loss: 3.5300920009613037\n",
      "Running Batch 711, Epoch 0, Total Tokens: 324\n",
      "Loss: 1.6809165477752686\n",
      "Loss: 3.5273525714874268\n",
      "Running Batch 713, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.75322425365448\n",
      "Loss: 3.5563666820526123\n",
      "Running Batch 715, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.761439561843872\n",
      "Loss: 3.4814095497131348\n",
      "Running Batch 717, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.7771222591400146\n",
      "Loss: 3.5919716358184814\n",
      "Running Batch 719, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7323628664016724\n",
      "Loss: 3.5517873764038086\n",
      "Running Batch 721, Epoch 0, Total Tokens: 143\n",
      "Loss: 1.7898274660110474\n",
      "Loss: 3.561678171157837\n",
      "Running Batch 723, Epoch 0, Total Tokens: 141\n",
      "Loss: 1.7621848583221436\n",
      "Loss: 3.509398937225342\n",
      "Running Batch 725, Epoch 0, Total Tokens: 380\n",
      "Loss: 1.764553189277649\n",
      "Loss: 3.540799140930176\n",
      "Running Batch 727, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.8054934740066528\n",
      "Loss: 3.5647122859954834\n",
      "Running Batch 729, Epoch 0, Total Tokens: 161\n",
      "Loss: 1.7609479427337646\n",
      "Loss: 3.5698444843292236\n",
      "Running Batch 731, Epoch 0, Total Tokens: 140\n",
      "Loss: 1.753594994544983\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 731, Loss: 1.753594994544983\n",
      "Loss: 3.587066411972046\n",
      "Running Batch 733, Epoch 0, Total Tokens: 153\n",
      "Loss: 1.761707067489624\n",
      "Loss: 3.5366623401641846\n",
      "Running Batch 735, Epoch 0, Total Tokens: 157\n",
      "Loss: 1.723225712776184\n",
      "Loss: 3.5118088722229004\n",
      "Running Batch 737, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7583482265472412\n",
      "Loss: 3.630014657974243\n",
      "Running Batch 739, Epoch 0, Total Tokens: 299\n",
      "Loss: 1.7517762184143066\n",
      "Loss: 3.5605592727661133\n",
      "Running Batch 741, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.6754977703094482\n",
      "Loss: 3.583042621612549\n",
      "Running Batch 743, Epoch 0, Total Tokens: 166\n",
      "Loss: 1.6606780290603638\n",
      "Loss: 3.5369200706481934\n",
      "Running Batch 745, Epoch 0, Total Tokens: 367\n",
      "Loss: 1.715928077697754\n",
      "Loss: 3.5399680137634277\n",
      "Running Batch 747, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.7731657028198242\n",
      "Loss: 3.555227041244507\n",
      "Running Batch 749, Epoch 0, Total Tokens: 286\n",
      "Loss: 1.663650631904602\n",
      "Loss: 3.5494613647460938\n",
      "Running Batch 751, Epoch 0, Total Tokens: 135\n",
      "Loss: 1.641798496246338\n",
      "Loss: 3.5586023330688477\n",
      "Running Batch 753, Epoch 0, Total Tokens: 164\n",
      "Loss: 1.7998250722885132\n",
      "Loss: 3.5264599323272705\n",
      "Running Batch 755, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.7096186876296997\n",
      "Loss: 3.544353485107422\n",
      "Running Batch 757, Epoch 0, Total Tokens: 175\n",
      "Loss: 1.681535243988037\n",
      "Loss: 3.555868625640869\n",
      "Running Batch 759, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.7524579763412476\n",
      "Loss: 3.593815803527832\n",
      "Running Batch 761, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.713485836982727\n",
      "Loss: 3.5146613121032715\n",
      "Running Batch 763, Epoch 0, Total Tokens: 147\n",
      "Loss: 1.705055594444275\n",
      "Loss: 3.501467704772949\n",
      "Running Batch 765, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.6462796926498413\n",
      "Loss: 3.520275592803955\n",
      "Running Batch 767, Epoch 0, Total Tokens: 254\n",
      "Loss: 1.7727361917495728\n",
      "Loss: 3.53124737739563\n",
      "Running Batch 769, Epoch 0, Total Tokens: 128\n",
      "Loss: 1.76706063747406\n",
      "Loss: 3.5549051761627197\n",
      "Running Batch 771, Epoch 0, Total Tokens: 159\n",
      "Loss: 1.6957911252975464\n",
      "Loss: 3.50588321685791\n",
      "Running Batch 773, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.7640318870544434\n",
      "Loss: 3.505131483078003\n",
      "Running Batch 775, Epoch 0, Total Tokens: 149\n",
      "Loss: 1.7830700874328613\n",
      "Loss: 3.5162856578826904\n",
      "Running Batch 777, Epoch 0, Total Tokens: 131\n",
      "Loss: 1.6540645360946655\n",
      "Loss: 3.5858407020568848\n",
      "Running Batch 779, Epoch 0, Total Tokens: 170\n",
      "Loss: 1.7398669719696045\n",
      "Loss: 3.5410356521606445\n",
      "Running Batch 781, Epoch 0, Total Tokens: 115\n",
      "Loss: 1.7131601572036743\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 781, Loss: 1.7131601572036743\n",
      "AVG LOSS: 2.654348035145294, Epoch: 1\n",
      "Loss: 3.5409982204437256\n",
      "Running Batch 1, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.7459712028503418\n",
      "Loss: 3.548175573348999\n",
      "Running Batch 3, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.741866946220398\n",
      "Loss: 3.5110831260681152\n",
      "Running Batch 5, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.725239872932434\n",
      "Loss: 3.5501708984375\n",
      "Running Batch 7, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7785104513168335\n",
      "Loss: 3.5373339653015137\n",
      "Running Batch 9, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.6504608392715454\n",
      "Loss: 3.584165573120117\n",
      "Running Batch 11, Epoch 1, Total Tokens: 285\n",
      "Loss: 1.7838422060012817\n",
      "Loss: 3.537381649017334\n",
      "Running Batch 13, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6644926071166992\n",
      "Loss: 3.567819118499756\n",
      "Running Batch 15, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.7424381971359253\n",
      "Loss: 3.532768726348877\n",
      "Running Batch 17, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.7195041179656982\n",
      "Loss: 3.509807586669922\n",
      "Running Batch 19, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6706355810165405\n",
      "Loss: 3.509826183319092\n",
      "Running Batch 21, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.705034852027893\n",
      "Loss: 3.48750638961792\n",
      "Running Batch 23, Epoch 1, Total Tokens: 205\n",
      "Loss: 1.7092636823654175\n",
      "Loss: 3.5336687564849854\n",
      "Running Batch 25, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.7711920738220215\n",
      "Loss: 3.574000835418701\n",
      "Running Batch 27, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.6761186122894287\n",
      "Loss: 3.504321575164795\n",
      "Running Batch 29, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.724577784538269\n",
      "Loss: 3.548626184463501\n",
      "Running Batch 31, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.702280044555664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 31, Loss: 1.702280044555664\n",
      "Loss: 3.5316498279571533\n",
      "Running Batch 33, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6895352602005005\n",
      "Loss: 3.5038342475891113\n",
      "Running Batch 35, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.7868527173995972\n",
      "Loss: 3.5376968383789062\n",
      "Running Batch 37, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.7185261249542236\n",
      "Loss: 3.572216272354126\n",
      "Running Batch 39, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.754199743270874\n",
      "Loss: 3.533276081085205\n",
      "Running Batch 41, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6945090293884277\n",
      "Loss: 3.5395798683166504\n",
      "Running Batch 43, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.8423724174499512\n",
      "Loss: 3.5545880794525146\n",
      "Running Batch 45, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.6889899969100952\n",
      "Loss: 3.6261327266693115\n",
      "Running Batch 47, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.7462431192398071\n",
      "Loss: 3.606839656829834\n",
      "Running Batch 49, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.6711902618408203\n",
      "Loss: 3.507474899291992\n",
      "Running Batch 51, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.647540807723999\n",
      "Loss: 3.517967939376831\n",
      "Running Batch 53, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.6981420516967773\n",
      "Loss: 3.5646114349365234\n",
      "Running Batch 55, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.7737877368927002\n",
      "Loss: 3.582594394683838\n",
      "Running Batch 57, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.801643967628479\n",
      "Loss: 3.5432205200195312\n",
      "Running Batch 59, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.6726093292236328\n",
      "Loss: 3.544193744659424\n",
      "Running Batch 61, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.7053403854370117\n",
      "Loss: 3.5391933917999268\n",
      "Running Batch 63, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.735224962234497\n",
      "Loss: 3.6016340255737305\n",
      "Running Batch 65, Epoch 1, Total Tokens: 418\n",
      "Loss: 1.7109142541885376\n",
      "Loss: 3.5163867473602295\n",
      "Running Batch 67, Epoch 1, Total Tokens: 360\n",
      "Loss: 1.7341598272323608\n",
      "Loss: 3.5792641639709473\n",
      "Running Batch 69, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.7279438972473145\n",
      "Loss: 3.515516519546509\n",
      "Running Batch 71, Epoch 1, Total Tokens: 294\n",
      "Loss: 1.6796643733978271\n",
      "Loss: 3.475567579269409\n",
      "Running Batch 73, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.7324236631393433\n",
      "Loss: 3.518934488296509\n",
      "Running Batch 75, Epoch 1, Total Tokens: 428\n",
      "Loss: 1.6888391971588135\n",
      "Loss: 3.5770556926727295\n",
      "Running Batch 77, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7343157529830933\n",
      "Loss: 3.4492623805999756\n",
      "Running Batch 79, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.6790581941604614\n",
      "Loss: 3.5584402084350586\n",
      "Running Batch 81, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.7123380899429321\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 81, Loss: 1.7123380899429321\n",
      "Loss: 3.5292394161224365\n",
      "Running Batch 83, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.699141502380371\n",
      "Loss: 3.558682918548584\n",
      "Running Batch 85, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.6772961616516113\n",
      "Loss: 3.4946823120117188\n",
      "Running Batch 87, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.709903359413147\n",
      "Loss: 3.5413966178894043\n",
      "Running Batch 89, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7073605060577393\n",
      "Loss: 3.5551817417144775\n",
      "Running Batch 91, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7110989093780518\n",
      "Loss: 3.5411641597747803\n",
      "Running Batch 93, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7111124992370605\n",
      "Loss: 3.509226083755493\n",
      "Running Batch 95, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7743204832077026\n",
      "Loss: 3.5502090454101562\n",
      "Running Batch 97, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.7419376373291016\n",
      "Loss: 3.541369915008545\n",
      "Running Batch 99, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7158108949661255\n",
      "Loss: 3.5093607902526855\n",
      "Running Batch 101, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.7290213108062744\n",
      "Loss: 3.5815629959106445\n",
      "Running Batch 103, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.6883914470672607\n",
      "Loss: 3.545415163040161\n",
      "Running Batch 105, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.7332111597061157\n",
      "Loss: 3.5508532524108887\n",
      "Running Batch 107, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.7149677276611328\n",
      "Loss: 3.5244665145874023\n",
      "Running Batch 109, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.723067045211792\n",
      "Loss: 3.5431716442108154\n",
      "Running Batch 111, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7478504180908203\n",
      "Loss: 3.5485079288482666\n",
      "Running Batch 113, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7177759408950806\n",
      "Loss: 3.579282760620117\n",
      "Running Batch 115, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.680350422859192\n",
      "Loss: 3.4832534790039062\n",
      "Running Batch 117, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.7083836793899536\n",
      "Loss: 3.519286632537842\n",
      "Running Batch 119, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.777976393699646\n",
      "Loss: 3.5851736068725586\n",
      "Running Batch 121, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.7172319889068604\n",
      "Loss: 3.5278565883636475\n",
      "Running Batch 123, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6895767450332642\n",
      "Loss: 3.526188373565674\n",
      "Running Batch 125, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6792546510696411\n",
      "Loss: 3.4679059982299805\n",
      "Running Batch 127, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.6703555583953857\n",
      "Loss: 3.517469644546509\n",
      "Running Batch 129, Epoch 1, Total Tokens: 251\n",
      "Loss: 1.6984628438949585\n",
      "Loss: 3.5472047328948975\n",
      "Running Batch 131, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.7446879148483276\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 131, Loss: 1.7446879148483276\n",
      "Loss: 3.597567319869995\n",
      "Running Batch 133, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.7024933099746704\n",
      "Loss: 3.5252225399017334\n",
      "Running Batch 135, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.686195969581604\n",
      "Loss: 3.575671672821045\n",
      "Running Batch 137, Epoch 1, Total Tokens: 174\n",
      "Loss: 1.675256609916687\n",
      "Loss: 3.483346462249756\n",
      "Running Batch 139, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.7344940900802612\n",
      "Loss: 3.5521209239959717\n",
      "Running Batch 141, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6633998155593872\n",
      "Loss: 3.475907325744629\n",
      "Running Batch 143, Epoch 1, Total Tokens: 202\n",
      "Loss: 1.694225788116455\n",
      "Loss: 3.550408363342285\n",
      "Running Batch 145, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6921274662017822\n",
      "Loss: 3.512024164199829\n",
      "Running Batch 147, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.7293510437011719\n",
      "Loss: 3.5102484226226807\n",
      "Running Batch 149, Epoch 1, Total Tokens: 282\n",
      "Loss: 1.6801098585128784\n",
      "Loss: 3.545611619949341\n",
      "Running Batch 151, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6795446872711182\n",
      "Loss: 3.4783201217651367\n",
      "Running Batch 153, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6505094766616821\n",
      "Loss: 3.56950306892395\n",
      "Running Batch 155, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.699735403060913\n",
      "Loss: 3.510910987854004\n",
      "Running Batch 157, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.720116138458252\n",
      "Loss: 3.5286295413970947\n",
      "Running Batch 159, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.6566476821899414\n",
      "Loss: 3.505622625350952\n",
      "Running Batch 161, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8255897760391235\n",
      "Loss: 3.547283172607422\n",
      "Running Batch 163, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.7396807670593262\n",
      "Loss: 3.5615429878234863\n",
      "Running Batch 165, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.7456512451171875\n",
      "Loss: 3.4970264434814453\n",
      "Running Batch 167, Epoch 1, Total Tokens: 196\n",
      "Loss: 1.7061333656311035\n",
      "Loss: 3.5593056678771973\n",
      "Running Batch 169, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6878325939178467\n",
      "Loss: 3.534778356552124\n",
      "Running Batch 171, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.7118984460830688\n",
      "Loss: 3.5200347900390625\n",
      "Running Batch 173, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7945799827575684\n",
      "Loss: 3.5795907974243164\n",
      "Running Batch 175, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.7250316143035889\n",
      "Loss: 3.5307843685150146\n",
      "Running Batch 177, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.7199686765670776\n",
      "Loss: 3.565647840499878\n",
      "Running Batch 179, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.6734673976898193\n",
      "Loss: 3.485811948776245\n",
      "Running Batch 181, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7577506303787231\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 181, Loss: 1.7577506303787231\n",
      "Loss: 3.5562002658843994\n",
      "Running Batch 183, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.7661844491958618\n",
      "Loss: 3.483964681625366\n",
      "Running Batch 185, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.6987758874893188\n",
      "Loss: 3.501701593399048\n",
      "Running Batch 187, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.7174112796783447\n",
      "Loss: 3.490358829498291\n",
      "Running Batch 189, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.701157808303833\n",
      "Loss: 3.5851776599884033\n",
      "Running Batch 191, Epoch 1, Total Tokens: 262\n",
      "Loss: 1.7360814809799194\n",
      "Loss: 3.525334596633911\n",
      "Running Batch 193, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.7085977792739868\n",
      "Loss: 3.4898769855499268\n",
      "Running Batch 195, Epoch 1, Total Tokens: 223\n",
      "Loss: 1.7213386297225952\n",
      "Loss: 3.5497024059295654\n",
      "Running Batch 197, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7824020385742188\n",
      "Loss: 3.5657095909118652\n",
      "Running Batch 199, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.7108595371246338\n",
      "Loss: 3.4834115505218506\n",
      "Running Batch 201, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.7365880012512207\n",
      "Loss: 3.4862782955169678\n",
      "Running Batch 203, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.7190122604370117\n",
      "Loss: 3.5114927291870117\n",
      "Running Batch 205, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6924046277999878\n",
      "Loss: 3.5873677730560303\n",
      "Running Batch 207, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7707250118255615\n",
      "Loss: 3.5846352577209473\n",
      "Running Batch 209, Epoch 1, Total Tokens: 234\n",
      "Loss: 1.6596962213516235\n",
      "Loss: 3.5350406169891357\n",
      "Running Batch 211, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.7207039594650269\n",
      "Loss: 3.517104387283325\n",
      "Running Batch 213, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.74690580368042\n",
      "Loss: 3.4863646030426025\n",
      "Running Batch 215, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7417776584625244\n",
      "Loss: 3.5744361877441406\n",
      "Running Batch 217, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7459745407104492\n",
      "Loss: 3.5506715774536133\n",
      "Running Batch 219, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.7085829973220825\n",
      "Loss: 3.525155782699585\n",
      "Running Batch 221, Epoch 1, Total Tokens: 219\n",
      "Loss: 1.7144429683685303\n",
      "Loss: 3.583645820617676\n",
      "Running Batch 223, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7032651901245117\n",
      "Loss: 3.542224884033203\n",
      "Running Batch 225, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.740356206893921\n",
      "Loss: 3.547569513320923\n",
      "Running Batch 227, Epoch 1, Total Tokens: 273\n",
      "Loss: 1.711035966873169\n",
      "Loss: 3.53436541557312\n",
      "Running Batch 229, Epoch 1, Total Tokens: 285\n",
      "Loss: 1.7210969924926758\n",
      "Loss: 3.514957904815674\n",
      "Running Batch 231, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.7701517343521118\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 231, Loss: 1.7701517343521118\n",
      "Loss: 3.4940719604492188\n",
      "Running Batch 233, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.7695343494415283\n",
      "Loss: 3.537377119064331\n",
      "Running Batch 235, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6714175939559937\n",
      "Loss: 3.5722200870513916\n",
      "Running Batch 237, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.7019010782241821\n",
      "Loss: 3.5482051372528076\n",
      "Running Batch 239, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.6518405675888062\n",
      "Loss: 3.5848824977874756\n",
      "Running Batch 241, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.7250653505325317\n",
      "Loss: 3.5480260848999023\n",
      "Running Batch 243, Epoch 1, Total Tokens: 288\n",
      "Loss: 1.6453721523284912\n",
      "Loss: 3.5240981578826904\n",
      "Running Batch 245, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.739834189414978\n",
      "Loss: 3.506488800048828\n",
      "Running Batch 247, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.7022565603256226\n",
      "Loss: 3.5613553524017334\n",
      "Running Batch 249, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7396974563598633\n",
      "Loss: 3.567039966583252\n",
      "Running Batch 251, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6838302612304688\n",
      "Loss: 3.4940896034240723\n",
      "Running Batch 253, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.758518934249878\n",
      "Loss: 3.576479911804199\n",
      "Running Batch 255, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.6883094310760498\n",
      "Loss: 3.526921272277832\n",
      "Running Batch 257, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.7430731058120728\n",
      "Loss: 3.505556344985962\n",
      "Running Batch 259, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.722762107849121\n",
      "Loss: 3.5369725227355957\n",
      "Running Batch 261, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.6750013828277588\n",
      "Loss: 3.5329127311706543\n",
      "Running Batch 263, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.7577375173568726\n",
      "Loss: 3.472858190536499\n",
      "Running Batch 265, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.650352954864502\n",
      "Loss: 3.510632276535034\n",
      "Running Batch 267, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.665822148323059\n",
      "Loss: 3.6250898838043213\n",
      "Running Batch 269, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.7168344259262085\n",
      "Loss: 3.5864410400390625\n",
      "Running Batch 271, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.7269355058670044\n",
      "Loss: 3.5771708488464355\n",
      "Running Batch 273, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7067540884017944\n",
      "Loss: 3.494023084640503\n",
      "Running Batch 275, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7301489114761353\n",
      "Loss: 3.5304901599884033\n",
      "Running Batch 277, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.7172366380691528\n",
      "Loss: 3.557859420776367\n",
      "Running Batch 279, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.6870577335357666\n",
      "Loss: 3.496905565261841\n",
      "Running Batch 281, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.7170164585113525\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 281, Loss: 1.7170164585113525\n",
      "Loss: 3.5264265537261963\n",
      "Running Batch 283, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.7100787162780762\n",
      "Loss: 3.537097215652466\n",
      "Running Batch 285, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6908290386199951\n",
      "Loss: 3.4831736087799072\n",
      "Running Batch 287, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.6357781887054443\n",
      "Loss: 3.5593128204345703\n",
      "Running Batch 289, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.69856595993042\n",
      "Loss: 3.4802005290985107\n",
      "Running Batch 291, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.6462370157241821\n",
      "Loss: 3.5212602615356445\n",
      "Running Batch 293, Epoch 1, Total Tokens: 219\n",
      "Loss: 1.7612863779067993\n",
      "Loss: 3.486633777618408\n",
      "Running Batch 295, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.635593295097351\n",
      "Loss: 3.5549368858337402\n",
      "Running Batch 297, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.6920607089996338\n",
      "Loss: 3.5730984210968018\n",
      "Running Batch 299, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.6444424390792847\n",
      "Loss: 3.5881736278533936\n",
      "Running Batch 301, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.7156068086624146\n",
      "Loss: 3.5367798805236816\n",
      "Running Batch 303, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7126445770263672\n",
      "Loss: 3.4888548851013184\n",
      "Running Batch 305, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.7329765558242798\n",
      "Loss: 3.5337207317352295\n",
      "Running Batch 307, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.7306156158447266\n",
      "Loss: 3.4739556312561035\n",
      "Running Batch 309, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.6802074909210205\n",
      "Loss: 3.518486738204956\n",
      "Running Batch 311, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.7390999794006348\n",
      "Loss: 3.497912645339966\n",
      "Running Batch 313, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.727917194366455\n",
      "Loss: 3.5436346530914307\n",
      "Running Batch 315, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.7622694969177246\n",
      "Loss: 3.4672458171844482\n",
      "Running Batch 317, Epoch 1, Total Tokens: 337\n",
      "Loss: 1.6982635259628296\n",
      "Loss: 3.489281415939331\n",
      "Running Batch 319, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.7157957553863525\n",
      "Loss: 3.4862987995147705\n",
      "Running Batch 321, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.752970814704895\n",
      "Loss: 3.5673491954803467\n",
      "Running Batch 323, Epoch 1, Total Tokens: 204\n",
      "Loss: 1.691260814666748\n",
      "Loss: 3.561103343963623\n",
      "Running Batch 325, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.7436485290527344\n",
      "Loss: 3.558520793914795\n",
      "Running Batch 327, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.685963749885559\n",
      "Loss: 3.634047746658325\n",
      "Running Batch 329, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.7371245622634888\n",
      "Loss: 3.4743332862854004\n",
      "Running Batch 331, Epoch 1, Total Tokens: 225\n",
      "Loss: 1.7177152633666992\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 331, Loss: 1.7177152633666992\n",
      "Loss: 3.5477921962738037\n",
      "Running Batch 333, Epoch 1, Total Tokens: 340\n",
      "Loss: 1.715158462524414\n",
      "Loss: 3.559978723526001\n",
      "Running Batch 335, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7582812309265137\n",
      "Loss: 3.5309770107269287\n",
      "Running Batch 337, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.7423020601272583\n",
      "Loss: 3.5024302005767822\n",
      "Running Batch 339, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.6958765983581543\n",
      "Loss: 3.5272979736328125\n",
      "Running Batch 341, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.6657218933105469\n",
      "Loss: 3.5368459224700928\n",
      "Running Batch 343, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.732978343963623\n",
      "Loss: 3.5580971240997314\n",
      "Running Batch 345, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.7039923667907715\n",
      "Loss: 3.5376691818237305\n",
      "Running Batch 347, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.7423033714294434\n",
      "Loss: 3.570140838623047\n",
      "Running Batch 349, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.6850634813308716\n",
      "Loss: 3.5249836444854736\n",
      "Running Batch 351, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6512527465820312\n",
      "Loss: 3.537032127380371\n",
      "Running Batch 353, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.7494381666183472\n",
      "Loss: 3.5152580738067627\n",
      "Running Batch 355, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6891248226165771\n",
      "Loss: 3.5638062953948975\n",
      "Running Batch 357, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.7273000478744507\n",
      "Loss: 3.6044912338256836\n",
      "Running Batch 359, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.7363554239273071\n",
      "Loss: 3.5174033641815186\n",
      "Running Batch 361, Epoch 1, Total Tokens: 160\n",
      "Loss: 1.6936975717544556\n",
      "Loss: 3.4574129581451416\n",
      "Running Batch 363, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.765233039855957\n",
      "Loss: 3.4629905223846436\n",
      "Running Batch 365, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.665390968322754\n",
      "Loss: 3.603148937225342\n",
      "Running Batch 367, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.690956711769104\n",
      "Loss: 3.566723585128784\n",
      "Running Batch 369, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.617676854133606\n",
      "Loss: 3.4839460849761963\n",
      "Running Batch 371, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6500842571258545\n",
      "Loss: 3.586693048477173\n",
      "Running Batch 373, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.683648705482483\n",
      "Loss: 3.525567054748535\n",
      "Running Batch 375, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.6679941415786743\n",
      "Loss: 3.584242343902588\n",
      "Running Batch 377, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.666519284248352\n",
      "Loss: 3.5145697593688965\n",
      "Running Batch 379, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.741828203201294\n",
      "Loss: 3.5599780082702637\n",
      "Running Batch 381, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.673490285873413\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 381, Loss: 1.673490285873413\n",
      "Loss: 3.544264793395996\n",
      "Running Batch 383, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.7388063669204712\n",
      "Loss: 3.561821222305298\n",
      "Running Batch 385, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.761391043663025\n",
      "Loss: 3.5569839477539062\n",
      "Running Batch 387, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.687658667564392\n",
      "Loss: 3.5422396659851074\n",
      "Running Batch 389, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.792702555656433\n",
      "Loss: 3.5764198303222656\n",
      "Running Batch 391, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.7152485847473145\n",
      "Loss: 3.492170572280884\n",
      "Running Batch 393, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.7283883094787598\n",
      "Loss: 3.54653263092041\n",
      "Running Batch 395, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7432096004486084\n",
      "Loss: 3.5698373317718506\n",
      "Running Batch 397, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.7085226774215698\n",
      "Loss: 3.5007081031799316\n",
      "Running Batch 399, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.7119885683059692\n",
      "Loss: 3.556255340576172\n",
      "Running Batch 401, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.7281303405761719\n",
      "Loss: 3.5473766326904297\n",
      "Running Batch 403, Epoch 1, Total Tokens: 185\n",
      "Loss: 1.6947463750839233\n",
      "Loss: 3.482980489730835\n",
      "Running Batch 405, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.816880226135254\n",
      "Loss: 3.517742872238159\n",
      "Running Batch 407, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.7634748220443726\n",
      "Loss: 3.5407185554504395\n",
      "Running Batch 409, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.721955418586731\n",
      "Loss: 3.3611176013946533\n",
      "Running Batch 411, Epoch 1, Total Tokens: 214\n",
      "Loss: 1.6182290315628052\n",
      "Loss: 3.52514386177063\n",
      "Running Batch 413, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.816353440284729\n",
      "Loss: 3.555299997329712\n",
      "Running Batch 415, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6911152601242065\n",
      "Loss: 3.4869418144226074\n",
      "Running Batch 417, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.6960564851760864\n",
      "Loss: 3.4473466873168945\n",
      "Running Batch 419, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.730369210243225\n",
      "Loss: 3.4492547512054443\n",
      "Running Batch 421, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.7111917734146118\n",
      "Loss: 3.4798686504364014\n",
      "Running Batch 423, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.643971562385559\n",
      "Loss: 3.5259451866149902\n",
      "Running Batch 425, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.7574025392532349\n",
      "Loss: 3.5339221954345703\n",
      "Running Batch 427, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.6390652656555176\n",
      "Loss: 3.480349540710449\n",
      "Running Batch 429, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.6390775442123413\n",
      "Loss: 3.559366464614868\n",
      "Running Batch 431, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.6586346626281738\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 431, Loss: 1.6586346626281738\n",
      "Loss: 3.5348317623138428\n",
      "Running Batch 433, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.649201512336731\n",
      "Loss: 3.5115737915039062\n",
      "Running Batch 435, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.7614108324050903\n",
      "Loss: 3.5119564533233643\n",
      "Running Batch 437, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.706706166267395\n",
      "Loss: 3.553879499435425\n",
      "Running Batch 439, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.7147209644317627\n",
      "Loss: 3.505662679672241\n",
      "Running Batch 441, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.692443609237671\n",
      "Loss: 3.531341791152954\n",
      "Running Batch 443, Epoch 1, Total Tokens: 234\n",
      "Loss: 1.6872570514678955\n",
      "Loss: 3.522378444671631\n",
      "Running Batch 445, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6708898544311523\n",
      "Loss: 3.5210254192352295\n",
      "Running Batch 447, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.7123873233795166\n",
      "Loss: 3.487355947494507\n",
      "Running Batch 449, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.5965532064437866\n",
      "Loss: 3.505392074584961\n",
      "Running Batch 451, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.7232847213745117\n",
      "Loss: 3.446930408477783\n",
      "Running Batch 453, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.732334852218628\n",
      "Loss: 3.5695836544036865\n",
      "Running Batch 455, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6763211488723755\n",
      "Loss: 3.5938405990600586\n",
      "Running Batch 457, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.7368656396865845\n",
      "Loss: 3.502990484237671\n",
      "Running Batch 459, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7798467874526978\n",
      "Loss: 3.559122085571289\n",
      "Running Batch 461, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.7047388553619385\n",
      "Loss: 3.5079355239868164\n",
      "Running Batch 463, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.7268146276474\n",
      "Loss: 3.5561182498931885\n",
      "Running Batch 465, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.69667649269104\n",
      "Loss: 3.5179805755615234\n",
      "Running Batch 467, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.7250481843948364\n",
      "Loss: 3.4238407611846924\n",
      "Running Batch 469, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.7746046781539917\n",
      "Loss: 3.585284948348999\n",
      "Running Batch 471, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.5725361108779907\n",
      "Loss: 3.558073043823242\n",
      "Running Batch 473, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.626663088798523\n",
      "Loss: 3.546994686126709\n",
      "Running Batch 475, Epoch 1, Total Tokens: 334\n",
      "Loss: 1.6875635385513306\n",
      "Loss: 3.585620164871216\n",
      "Running Batch 477, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6506447792053223\n",
      "Loss: 3.522228717803955\n",
      "Running Batch 479, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.668149709701538\n",
      "Loss: 3.560208559036255\n",
      "Running Batch 481, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.6666574478149414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 481, Loss: 1.6666574478149414\n",
      "Loss: 3.483290195465088\n",
      "Running Batch 483, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.6333948373794556\n",
      "Loss: 3.512148857116699\n",
      "Running Batch 485, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.6589698791503906\n",
      "Loss: 3.564645767211914\n",
      "Running Batch 487, Epoch 1, Total Tokens: 242\n",
      "Loss: 1.7373161315917969\n",
      "Loss: 3.5098981857299805\n",
      "Running Batch 489, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.6903311014175415\n",
      "Loss: 3.4991953372955322\n",
      "Running Batch 491, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.7174346446990967\n",
      "Loss: 3.4876444339752197\n",
      "Running Batch 493, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.7195711135864258\n",
      "Loss: 3.505298614501953\n",
      "Running Batch 495, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.7387105226516724\n",
      "Loss: 3.5610198974609375\n",
      "Running Batch 497, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.6758028268814087\n",
      "Loss: 3.5474884510040283\n",
      "Running Batch 499, Epoch 1, Total Tokens: 624\n",
      "Loss: 1.700956106185913\n",
      "Loss: 3.559098958969116\n",
      "Running Batch 501, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.6089609861373901\n",
      "Loss: 3.547666549682617\n",
      "Running Batch 503, Epoch 1, Total Tokens: 261\n",
      "Loss: 1.7081676721572876\n",
      "Loss: 3.5343964099884033\n",
      "Running Batch 505, Epoch 1, Total Tokens: 356\n",
      "Loss: 1.7198354005813599\n",
      "Loss: 3.446430206298828\n",
      "Running Batch 507, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.7414131164550781\n",
      "Loss: 3.6408841609954834\n",
      "Running Batch 509, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.7673722505569458\n",
      "Loss: 3.617403984069824\n",
      "Running Batch 511, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8165773153305054\n",
      "Loss: 3.5880632400512695\n",
      "Running Batch 513, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.8207957744598389\n",
      "Loss: 3.6257293224334717\n",
      "Running Batch 515, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9000139236450195\n",
      "Loss: 3.6967461109161377\n",
      "Running Batch 517, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.7484633922576904\n",
      "Loss: 3.544384717941284\n",
      "Running Batch 519, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8577641248703003\n",
      "Loss: 3.570362091064453\n",
      "Running Batch 521, Epoch 1, Total Tokens: 287\n",
      "Loss: 1.7330461740493774\n",
      "Loss: 3.5948424339294434\n",
      "Running Batch 523, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.7630982398986816\n",
      "Loss: 3.588900327682495\n",
      "Running Batch 525, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.6866859197616577\n",
      "Loss: 3.5828909873962402\n",
      "Running Batch 527, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7372666597366333\n",
      "Loss: 3.5613768100738525\n",
      "Running Batch 529, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7902517318725586\n",
      "Loss: 3.5815324783325195\n",
      "Running Batch 531, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.7178969383239746\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 531, Loss: 1.7178969383239746\n",
      "Loss: 3.569706678390503\n",
      "Running Batch 533, Epoch 1, Total Tokens: 367\n",
      "Loss: 1.7593258619308472\n",
      "Loss: 3.5600218772888184\n",
      "Running Batch 535, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.7757322788238525\n",
      "Loss: 3.571173906326294\n",
      "Running Batch 537, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.7206575870513916\n",
      "Loss: 3.5556628704071045\n",
      "Running Batch 539, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.7695473432540894\n",
      "Loss: 3.576974868774414\n",
      "Running Batch 541, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6866836547851562\n",
      "Loss: 3.519949197769165\n",
      "Running Batch 543, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.7348318099975586\n",
      "Loss: 3.6010348796844482\n",
      "Running Batch 545, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7304983139038086\n",
      "Loss: 3.5359156131744385\n",
      "Running Batch 547, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.8103951215744019\n",
      "Loss: 3.5708279609680176\n",
      "Running Batch 549, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.7809938192367554\n",
      "Loss: 3.52278733253479\n",
      "Running Batch 551, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.788949728012085\n",
      "Loss: 3.5622103214263916\n",
      "Running Batch 553, Epoch 1, Total Tokens: 452\n",
      "Loss: 1.7543565034866333\n",
      "Loss: 3.543630361557007\n",
      "Running Batch 555, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.7250351905822754\n",
      "Loss: 3.498046636581421\n",
      "Running Batch 557, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7559324502944946\n",
      "Loss: 3.498032808303833\n",
      "Running Batch 559, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.671985149383545\n",
      "Loss: 3.479006052017212\n",
      "Running Batch 561, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.7478536367416382\n",
      "Loss: 3.590946912765503\n",
      "Running Batch 563, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.7615687847137451\n",
      "Loss: 3.582953691482544\n",
      "Running Batch 565, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.6992305517196655\n",
      "Loss: 3.5996689796447754\n",
      "Running Batch 567, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.7126319408416748\n",
      "Loss: 3.5237066745758057\n",
      "Running Batch 569, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7152364253997803\n",
      "Loss: 3.5486772060394287\n",
      "Running Batch 571, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.73947274684906\n",
      "Loss: 3.5435101985931396\n",
      "Running Batch 573, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.7073493003845215\n",
      "Loss: 3.5442464351654053\n",
      "Running Batch 575, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.727808952331543\n",
      "Loss: 3.476498603820801\n",
      "Running Batch 577, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.6706135272979736\n",
      "Loss: 3.541980504989624\n",
      "Running Batch 579, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6300996541976929\n",
      "Loss: 3.4564030170440674\n",
      "Running Batch 581, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.700161099433899\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 581, Loss: 1.700161099433899\n",
      "Loss: 3.5295729637145996\n",
      "Running Batch 583, Epoch 1, Total Tokens: 299\n",
      "Loss: 1.7251728773117065\n",
      "Loss: 3.546738386154175\n",
      "Running Batch 585, Epoch 1, Total Tokens: 203\n",
      "Loss: 1.664193868637085\n",
      "Loss: 3.458250045776367\n",
      "Running Batch 587, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.626786708831787\n",
      "Loss: 3.5234830379486084\n",
      "Running Batch 589, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.6339471340179443\n",
      "Loss: 3.52520489692688\n",
      "Running Batch 591, Epoch 1, Total Tokens: 295\n",
      "Loss: 1.7273259162902832\n",
      "Loss: 3.5274360179901123\n",
      "Running Batch 593, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6589171886444092\n",
      "Loss: 3.5229437351226807\n",
      "Running Batch 595, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.7148172855377197\n",
      "Loss: 3.5249440670013428\n",
      "Running Batch 597, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.7367172241210938\n",
      "Loss: 3.624325752258301\n",
      "Running Batch 599, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.7460973262786865\n",
      "Loss: 3.4777584075927734\n",
      "Running Batch 601, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.6649326086044312\n",
      "Loss: 3.504490613937378\n",
      "Running Batch 603, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6596599817276\n",
      "Loss: 3.518296480178833\n",
      "Running Batch 605, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.705566644668579\n",
      "Loss: 3.491090774536133\n",
      "Running Batch 607, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6894294023513794\n",
      "Loss: 3.510864734649658\n",
      "Running Batch 609, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7606534957885742\n",
      "Loss: 3.5322182178497314\n",
      "Running Batch 611, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.673362374305725\n",
      "Loss: 3.4843966960906982\n",
      "Running Batch 613, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.6131500005722046\n",
      "Loss: 3.551718235015869\n",
      "Running Batch 615, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.679113745689392\n",
      "Loss: 3.5308632850646973\n",
      "Running Batch 617, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.756523609161377\n",
      "Loss: 3.48221492767334\n",
      "Running Batch 619, Epoch 1, Total Tokens: 104\n",
      "Loss: 1.685947299003601\n",
      "Loss: 3.621035099029541\n",
      "Running Batch 621, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7187831401824951\n",
      "Loss: 3.5766634941101074\n",
      "Running Batch 623, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.8208988904953003\n",
      "Loss: 3.5482804775238037\n",
      "Running Batch 625, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.6695387363433838\n",
      "Loss: 3.5488836765289307\n",
      "Running Batch 627, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.673919439315796\n",
      "Loss: 3.4644246101379395\n",
      "Running Batch 629, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.763696551322937\n",
      "Loss: 3.535163640975952\n",
      "Running Batch 631, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.701180100440979\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 631, Loss: 1.701180100440979\n",
      "Loss: 3.621917963027954\n",
      "Running Batch 633, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.650682806968689\n",
      "Loss: 3.5031118392944336\n",
      "Running Batch 635, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.7234418392181396\n",
      "Loss: 3.4959211349487305\n",
      "Running Batch 637, Epoch 1, Total Tokens: 351\n",
      "Loss: 1.706119179725647\n",
      "Loss: 3.4635331630706787\n",
      "Running Batch 639, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.669454574584961\n",
      "Loss: 3.5095901489257812\n",
      "Running Batch 641, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6562474966049194\n",
      "Loss: 3.544250011444092\n",
      "Running Batch 643, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.8091470003128052\n",
      "Loss: 3.5393898487091064\n",
      "Running Batch 645, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6397693157196045\n",
      "Loss: 3.487441301345825\n",
      "Running Batch 647, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.6727408170700073\n",
      "Loss: 3.6044750213623047\n",
      "Running Batch 649, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.7406233549118042\n",
      "Loss: 3.530151128768921\n",
      "Running Batch 651, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.7786240577697754\n",
      "Loss: 3.5527708530426025\n",
      "Running Batch 653, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6734658479690552\n",
      "Loss: 3.48130202293396\n",
      "Running Batch 655, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.6616132259368896\n",
      "Loss: 3.5307328701019287\n",
      "Running Batch 657, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.705765962600708\n",
      "Loss: 3.5845420360565186\n",
      "Running Batch 659, Epoch 1, Total Tokens: 186\n",
      "Loss: 1.7554142475128174\n",
      "Loss: 3.545581817626953\n",
      "Running Batch 661, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.7560224533081055\n",
      "Loss: 3.563284397125244\n",
      "Running Batch 663, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.7069616317749023\n",
      "Loss: 3.510526418685913\n",
      "Running Batch 665, Epoch 1, Total Tokens: 237\n",
      "Loss: 1.813406229019165\n",
      "Loss: 3.517237663269043\n",
      "Running Batch 667, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.708927869796753\n",
      "Loss: 3.5265958309173584\n",
      "Running Batch 669, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.6626156568527222\n",
      "Loss: 3.4834234714508057\n",
      "Running Batch 671, Epoch 1, Total Tokens: 197\n",
      "Loss: 1.658573031425476\n",
      "Loss: 3.55942440032959\n",
      "Running Batch 673, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.6540616750717163\n",
      "Loss: 3.4935810565948486\n",
      "Running Batch 675, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.6733323335647583\n",
      "Loss: 3.494295597076416\n",
      "Running Batch 677, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.7492934465408325\n",
      "Loss: 3.515265941619873\n",
      "Running Batch 679, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.7317429780960083\n",
      "Loss: 3.5445878505706787\n",
      "Running Batch 681, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.644922137260437\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 681, Loss: 1.644922137260437\n",
      "Loss: 3.481001377105713\n",
      "Running Batch 683, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.6041533946990967\n",
      "Loss: 3.4343769550323486\n",
      "Running Batch 685, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.6254777908325195\n",
      "Loss: 3.506709337234497\n",
      "Running Batch 687, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.691125750541687\n",
      "Loss: 3.5203585624694824\n",
      "Running Batch 689, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.7154724597930908\n",
      "Loss: 3.4840636253356934\n",
      "Running Batch 691, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.7005665302276611\n",
      "Loss: 3.446009635925293\n",
      "Running Batch 693, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.6740528345108032\n",
      "Loss: 3.5123987197875977\n",
      "Running Batch 695, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.7179900407791138\n",
      "Loss: 3.557058095932007\n",
      "Running Batch 697, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.69005286693573\n",
      "Loss: 3.48659348487854\n",
      "Running Batch 699, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6295428276062012\n",
      "Loss: 3.5422184467315674\n",
      "Running Batch 701, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.6815767288208008\n",
      "Loss: 3.5282578468322754\n",
      "Running Batch 703, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.7395304441452026\n",
      "Loss: 3.564035177230835\n",
      "Running Batch 705, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.672055721282959\n",
      "Loss: 3.578683376312256\n",
      "Running Batch 707, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.695059895515442\n",
      "Loss: 3.5046420097351074\n",
      "Running Batch 709, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.701940894126892\n",
      "Loss: 3.461716651916504\n",
      "Running Batch 711, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.7620503902435303\n",
      "Loss: 3.5447521209716797\n",
      "Running Batch 713, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.6497639417648315\n",
      "Loss: 3.4584498405456543\n",
      "Running Batch 715, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.6426582336425781\n",
      "Loss: 3.502784252166748\n",
      "Running Batch 717, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.7459237575531006\n",
      "Loss: 3.496126174926758\n",
      "Running Batch 719, Epoch 1, Total Tokens: 568\n",
      "Loss: 1.6966582536697388\n",
      "Loss: 3.476247787475586\n",
      "Running Batch 721, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.681884765625\n",
      "Loss: 3.5139827728271484\n",
      "Running Batch 723, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.7100826501846313\n",
      "Loss: 3.529784679412842\n",
      "Running Batch 725, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.7289584875106812\n",
      "Loss: 3.51387619972229\n",
      "Running Batch 727, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.647823452949524\n",
      "Loss: 3.539057970046997\n",
      "Running Batch 729, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.7427856922149658\n",
      "Loss: 3.5243067741394043\n",
      "Running Batch 731, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.6539673805236816\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 731, Loss: 1.6539673805236816\n",
      "Loss: 3.4779138565063477\n",
      "Running Batch 733, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.6855525970458984\n",
      "Loss: 3.493936538696289\n",
      "Running Batch 735, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.7013211250305176\n",
      "Loss: 3.541642904281616\n",
      "Running Batch 737, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.6789896488189697\n",
      "Loss: 3.5030672550201416\n",
      "Running Batch 739, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.7835133075714111\n",
      "Loss: 3.5712711811065674\n",
      "Running Batch 741, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.661788821220398\n",
      "Loss: 3.4906606674194336\n",
      "Running Batch 743, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7657333612442017\n",
      "Loss: 3.5142664909362793\n",
      "Running Batch 745, Epoch 1, Total Tokens: 250\n",
      "Loss: 1.6214946508407593\n",
      "Loss: 3.506382942199707\n",
      "Running Batch 747, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.6800999641418457\n",
      "Loss: 3.5276598930358887\n",
      "Running Batch 749, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6209908723831177\n",
      "Loss: 3.523998260498047\n",
      "Running Batch 751, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.698634147644043\n",
      "Loss: 3.5564961433410645\n",
      "Running Batch 753, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.6927118301391602\n",
      "Loss: 3.501631021499634\n",
      "Running Batch 755, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.695696473121643\n",
      "Loss: 3.5204918384552\n",
      "Running Batch 757, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.7233092784881592\n",
      "Loss: 3.4725184440612793\n",
      "Running Batch 759, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.7202003002166748\n",
      "Loss: 3.574822425842285\n",
      "Running Batch 761, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.7165586948394775\n",
      "Loss: 3.577671766281128\n",
      "Running Batch 763, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.7829461097717285\n",
      "Loss: 3.504694938659668\n",
      "Running Batch 765, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.7295869588851929\n",
      "Loss: 3.493300437927246\n",
      "Running Batch 767, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.645912766456604\n",
      "Loss: 3.519859790802002\n",
      "Running Batch 769, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.6443581581115723\n",
      "Loss: 3.559725522994995\n",
      "Running Batch 771, Epoch 1, Total Tokens: 572\n",
      "Loss: 1.664586067199707\n",
      "Loss: 3.4542431831359863\n",
      "Running Batch 773, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.6488338708877563\n",
      "Loss: 3.5316197872161865\n",
      "Running Batch 775, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.6757420301437378\n",
      "Loss: 3.5491116046905518\n",
      "Running Batch 777, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.7499943971633911\n",
      "Loss: 3.5553345680236816\n",
      "Running Batch 779, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.7343881130218506\n",
      "Loss: 3.4611973762512207\n",
      "Running Batch 781, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.6639955043792725\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 781, Loss: 1.6639955043792725\n",
      "AVG LOSS: 2.621167339784715, Epoch: 2\n",
      "Loss: 3.492858648300171\n",
      "Running Batch 1, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.62460458278656\n",
      "Loss: 3.559328556060791\n",
      "Running Batch 3, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6714129447937012\n",
      "Loss: 3.5733978748321533\n",
      "Running Batch 5, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.6798638105392456\n",
      "Loss: 3.51242733001709\n",
      "Running Batch 7, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.689604640007019\n",
      "Loss: 3.5518956184387207\n",
      "Running Batch 9, Epoch 2, Total Tokens: 527\n",
      "Loss: 1.6689002513885498\n",
      "Loss: 3.481926679611206\n",
      "Running Batch 11, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.6953411102294922\n",
      "Loss: 3.511606454849243\n",
      "Running Batch 13, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6819889545440674\n",
      "Loss: 3.525852918624878\n",
      "Running Batch 15, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8252596855163574\n",
      "Loss: 3.476154327392578\n",
      "Running Batch 17, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.697830319404602\n",
      "Loss: 3.5314974784851074\n",
      "Running Batch 19, Epoch 2, Total Tokens: 209\n",
      "Loss: 1.672776222229004\n",
      "Loss: 3.5096447467803955\n",
      "Running Batch 21, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.7335364818572998\n",
      "Loss: 3.527210235595703\n",
      "Running Batch 23, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6032795906066895\n",
      "Loss: 3.498157501220703\n",
      "Running Batch 25, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.6770224571228027\n",
      "Loss: 3.443408966064453\n",
      "Running Batch 27, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6731632947921753\n",
      "Loss: 3.5136947631835938\n",
      "Running Batch 29, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6379146575927734\n",
      "Loss: 3.535175323486328\n",
      "Running Batch 31, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6848647594451904\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 31, Loss: 1.6848647594451904\n",
      "Loss: 3.514620304107666\n",
      "Running Batch 33, Epoch 2, Total Tokens: 168\n",
      "Loss: 1.7074609994888306\n",
      "Loss: 3.551290273666382\n",
      "Running Batch 35, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.713613510131836\n",
      "Loss: 3.4761416912078857\n",
      "Running Batch 37, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.6708624362945557\n",
      "Loss: 3.526895046234131\n",
      "Running Batch 39, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.680354118347168\n",
      "Loss: 3.5630056858062744\n",
      "Running Batch 41, Epoch 2, Total Tokens: 205\n",
      "Loss: 1.6369415521621704\n",
      "Loss: 3.497239351272583\n",
      "Running Batch 43, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.6724082231521606\n",
      "Loss: 3.577422618865967\n",
      "Running Batch 45, Epoch 2, Total Tokens: 217\n",
      "Loss: 1.6287035942077637\n",
      "Loss: 3.5275633335113525\n",
      "Running Batch 47, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.648693323135376\n",
      "Loss: 3.4874329566955566\n",
      "Running Batch 49, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.6267457008361816\n",
      "Loss: 3.548491954803467\n",
      "Running Batch 51, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.6884061098098755\n",
      "Loss: 3.5136802196502686\n",
      "Running Batch 53, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6142935752868652\n",
      "Loss: 3.4999938011169434\n",
      "Running Batch 55, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7079557180404663\n",
      "Loss: 3.480630874633789\n",
      "Running Batch 57, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7263604402542114\n",
      "Loss: 3.5171897411346436\n",
      "Running Batch 59, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.6714630126953125\n",
      "Loss: 3.5037834644317627\n",
      "Running Batch 61, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.7836816310882568\n",
      "Loss: 3.5539321899414062\n",
      "Running Batch 63, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.7223124504089355\n",
      "Loss: 3.4991273880004883\n",
      "Running Batch 65, Epoch 2, Total Tokens: 204\n",
      "Loss: 1.7055838108062744\n",
      "Loss: 3.484776020050049\n",
      "Running Batch 67, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.6407701969146729\n",
      "Loss: 3.462808132171631\n",
      "Running Batch 69, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7026840448379517\n",
      "Loss: 3.506481170654297\n",
      "Running Batch 71, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6671626567840576\n",
      "Loss: 3.5005948543548584\n",
      "Running Batch 73, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7326421737670898\n",
      "Loss: 3.5754032135009766\n",
      "Running Batch 75, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.6672419309616089\n",
      "Loss: 3.4518356323242188\n",
      "Running Batch 77, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.713493824005127\n",
      "Loss: 3.5535645484924316\n",
      "Running Batch 79, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.618729829788208\n",
      "Loss: 3.5130765438079834\n",
      "Running Batch 81, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6948233842849731\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 81, Loss: 1.6948233842849731\n",
      "Loss: 3.5206708908081055\n",
      "Running Batch 83, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.6753474473953247\n",
      "Loss: 3.5576558113098145\n",
      "Running Batch 85, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.5940027236938477\n",
      "Loss: 3.522712469100952\n",
      "Running Batch 87, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7357208728790283\n",
      "Loss: 3.4742815494537354\n",
      "Running Batch 89, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.6476359367370605\n",
      "Loss: 3.5166051387786865\n",
      "Running Batch 91, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7034051418304443\n",
      "Loss: 3.5424787998199463\n",
      "Running Batch 93, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6900148391723633\n",
      "Loss: 3.455422878265381\n",
      "Running Batch 95, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.742841362953186\n",
      "Loss: 3.488455295562744\n",
      "Running Batch 97, Epoch 2, Total Tokens: 428\n",
      "Loss: 1.6938625574111938\n",
      "Loss: 3.493879556655884\n",
      "Running Batch 99, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8123606443405151\n",
      "Loss: 3.5039074420928955\n",
      "Running Batch 101, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.647434949874878\n",
      "Loss: 3.5130481719970703\n",
      "Running Batch 103, Epoch 2, Total Tokens: 175\n",
      "Loss: 1.7154945135116577\n",
      "Loss: 3.446176528930664\n",
      "Running Batch 105, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.6742677688598633\n",
      "Loss: 3.4941253662109375\n",
      "Running Batch 107, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.702962040901184\n",
      "Loss: 3.4308996200561523\n",
      "Running Batch 109, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6245157718658447\n",
      "Loss: 3.5367865562438965\n",
      "Running Batch 111, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6443471908569336\n",
      "Loss: 3.442798614501953\n",
      "Running Batch 113, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.617292046546936\n",
      "Loss: 3.5365238189697266\n",
      "Running Batch 115, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.674601674079895\n",
      "Loss: 3.443204402923584\n",
      "Running Batch 117, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.703595519065857\n",
      "Loss: 3.5266690254211426\n",
      "Running Batch 119, Epoch 2, Total Tokens: 196\n",
      "Loss: 1.6385672092437744\n",
      "Loss: 3.5134267807006836\n",
      "Running Batch 121, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7196815013885498\n",
      "Loss: 3.4947073459625244\n",
      "Running Batch 123, Epoch 2, Total Tokens: 180\n",
      "Loss: 1.6927475929260254\n",
      "Loss: 3.534546375274658\n",
      "Running Batch 125, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6050288677215576\n",
      "Loss: 3.4889514446258545\n",
      "Running Batch 127, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.7111566066741943\n",
      "Loss: 3.489135503768921\n",
      "Running Batch 129, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.6588771343231201\n",
      "Loss: 3.505401134490967\n",
      "Running Batch 131, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7654436826705933\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 131, Loss: 1.7654436826705933\n",
      "Loss: 3.4930479526519775\n",
      "Running Batch 133, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6397569179534912\n",
      "Loss: 3.5648651123046875\n",
      "Running Batch 135, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6460820436477661\n",
      "Loss: 3.5285332202911377\n",
      "Running Batch 137, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.7397899627685547\n",
      "Loss: 3.49649977684021\n",
      "Running Batch 139, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7290102243423462\n",
      "Loss: 3.4979658126831055\n",
      "Running Batch 141, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.6904020309448242\n",
      "Loss: 3.525381565093994\n",
      "Running Batch 143, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6383183002471924\n",
      "Loss: 3.5485029220581055\n",
      "Running Batch 145, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6742523908615112\n",
      "Loss: 3.471400499343872\n",
      "Running Batch 147, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.6928311586380005\n",
      "Loss: 3.49985671043396\n",
      "Running Batch 149, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.7171666622161865\n",
      "Loss: 3.5207178592681885\n",
      "Running Batch 151, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6648539304733276\n",
      "Loss: 3.5453567504882812\n",
      "Running Batch 153, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.654659390449524\n",
      "Loss: 3.580379009246826\n",
      "Running Batch 155, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6583281755447388\n",
      "Loss: 3.471625804901123\n",
      "Running Batch 157, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7285784482955933\n",
      "Loss: 3.5501482486724854\n",
      "Running Batch 159, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.7136931419372559\n",
      "Loss: 3.4505674839019775\n",
      "Running Batch 161, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7244552373886108\n",
      "Loss: 3.491302251815796\n",
      "Running Batch 163, Epoch 2, Total Tokens: 244\n",
      "Loss: 1.717457890510559\n",
      "Loss: 3.514488935470581\n",
      "Running Batch 165, Epoch 2, Total Tokens: 192\n",
      "Loss: 1.7092273235321045\n",
      "Loss: 3.535808801651001\n",
      "Running Batch 167, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.7199875116348267\n",
      "Loss: 3.4951157569885254\n",
      "Running Batch 169, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6674704551696777\n",
      "Loss: 3.4652230739593506\n",
      "Running Batch 171, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6688975095748901\n",
      "Loss: 3.5281314849853516\n",
      "Running Batch 173, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.7196910381317139\n",
      "Loss: 3.5033106803894043\n",
      "Running Batch 175, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.726148247718811\n",
      "Loss: 3.4942054748535156\n",
      "Running Batch 177, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.725880742073059\n",
      "Loss: 3.4962708950042725\n",
      "Running Batch 179, Epoch 2, Total Tokens: 192\n",
      "Loss: 1.6610674858093262\n",
      "Loss: 3.5332067012786865\n",
      "Running Batch 181, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.7012767791748047\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 181, Loss: 1.7012767791748047\n",
      "Loss: 3.4870800971984863\n",
      "Running Batch 183, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.6635712385177612\n",
      "Loss: 3.507230520248413\n",
      "Running Batch 185, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.6468676328659058\n",
      "Loss: 3.512814521789551\n",
      "Running Batch 187, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6625003814697266\n",
      "Loss: 3.528928756713867\n",
      "Running Batch 189, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.6091428995132446\n",
      "Loss: 3.520904064178467\n",
      "Running Batch 191, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.672702670097351\n",
      "Loss: 3.5305752754211426\n",
      "Running Batch 193, Epoch 2, Total Tokens: 206\n",
      "Loss: 1.6366719007492065\n",
      "Loss: 3.5046546459198\n",
      "Running Batch 195, Epoch 2, Total Tokens: 357\n",
      "Loss: 1.7122501134872437\n",
      "Loss: 3.522313356399536\n",
      "Running Batch 197, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6459661722183228\n",
      "Loss: 3.5523085594177246\n",
      "Running Batch 199, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.6614413261413574\n",
      "Loss: 3.5244812965393066\n",
      "Running Batch 201, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.6582483053207397\n",
      "Loss: 3.4151058197021484\n",
      "Running Batch 203, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.7157162427902222\n",
      "Loss: 3.5389792919158936\n",
      "Running Batch 205, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.6607190370559692\n",
      "Loss: 3.4590463638305664\n",
      "Running Batch 207, Epoch 2, Total Tokens: 214\n",
      "Loss: 1.7154796123504639\n",
      "Loss: 3.5653128623962402\n",
      "Running Batch 209, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6797127723693848\n",
      "Loss: 3.5004985332489014\n",
      "Running Batch 211, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7043087482452393\n",
      "Loss: 3.465414524078369\n",
      "Running Batch 213, Epoch 2, Total Tokens: 284\n",
      "Loss: 1.646367073059082\n",
      "Loss: 3.5168824195861816\n",
      "Running Batch 215, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.72592294216156\n",
      "Loss: 3.4542698860168457\n",
      "Running Batch 217, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7633111476898193\n",
      "Loss: 3.51629638671875\n",
      "Running Batch 219, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.7150349617004395\n",
      "Loss: 3.5147135257720947\n",
      "Running Batch 221, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6773616075515747\n",
      "Loss: 3.505181312561035\n",
      "Running Batch 223, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.6169958114624023\n",
      "Loss: 3.486694812774658\n",
      "Running Batch 225, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.604023814201355\n",
      "Loss: 3.5383365154266357\n",
      "Running Batch 227, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.5770102739334106\n",
      "Loss: 3.466731548309326\n",
      "Running Batch 229, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.6575539112091064\n",
      "Loss: 3.4997923374176025\n",
      "Running Batch 231, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7109715938568115\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 231, Loss: 1.7109715938568115\n",
      "Loss: 3.5139732360839844\n",
      "Running Batch 233, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.7262239456176758\n",
      "Loss: 3.5488932132720947\n",
      "Running Batch 235, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.667318344116211\n",
      "Loss: 3.52974271774292\n",
      "Running Batch 237, Epoch 2, Total Tokens: 237\n",
      "Loss: 1.6132175922393799\n",
      "Loss: 3.530442714691162\n",
      "Running Batch 239, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7327464818954468\n",
      "Loss: 3.4605748653411865\n",
      "Running Batch 241, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.6194666624069214\n",
      "Loss: 3.5367565155029297\n",
      "Running Batch 243, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7003732919692993\n",
      "Loss: 3.435152769088745\n",
      "Running Batch 245, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6650193929672241\n",
      "Loss: 3.515603542327881\n",
      "Running Batch 247, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.6108977794647217\n",
      "Loss: 3.5111207962036133\n",
      "Running Batch 249, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.658600926399231\n",
      "Loss: 3.4869837760925293\n",
      "Running Batch 251, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.6277252435684204\n",
      "Loss: 3.5427358150482178\n",
      "Running Batch 253, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.605514645576477\n",
      "Loss: 3.5384128093719482\n",
      "Running Batch 255, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.6830012798309326\n",
      "Loss: 3.540562391281128\n",
      "Running Batch 257, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.6544795036315918\n",
      "Loss: 3.5135645866394043\n",
      "Running Batch 259, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.6625423431396484\n",
      "Loss: 3.4650075435638428\n",
      "Running Batch 261, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.6881026029586792\n",
      "Loss: 3.5237581729888916\n",
      "Running Batch 263, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.6587284803390503\n",
      "Loss: 3.5296430587768555\n",
      "Running Batch 265, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.7542484998703003\n",
      "Loss: 3.4802908897399902\n",
      "Running Batch 267, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6532269716262817\n",
      "Loss: 3.5793724060058594\n",
      "Running Batch 269, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.6518800258636475\n",
      "Loss: 3.5018045902252197\n",
      "Running Batch 271, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.6815367937088013\n",
      "Loss: 3.50350284576416\n",
      "Running Batch 273, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6648775339126587\n",
      "Loss: 3.4711222648620605\n",
      "Running Batch 275, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6914536952972412\n",
      "Loss: 3.5253727436065674\n",
      "Running Batch 277, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.6956281661987305\n",
      "Loss: 3.41995906829834\n",
      "Running Batch 279, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7806826829910278\n",
      "Loss: 3.48783016204834\n",
      "Running Batch 281, Epoch 2, Total Tokens: 629\n",
      "Loss: 1.5875908136367798\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 281, Loss: 1.5875908136367798\n",
      "Loss: 3.5732643604278564\n",
      "Running Batch 283, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7166833877563477\n",
      "Loss: 3.4666006565093994\n",
      "Running Batch 285, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6470800638198853\n",
      "Loss: 3.4693374633789062\n",
      "Running Batch 287, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.600233793258667\n",
      "Loss: 3.5051429271698\n",
      "Running Batch 289, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.6169530153274536\n",
      "Loss: 3.4546124935150146\n",
      "Running Batch 291, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7374271154403687\n",
      "Loss: 3.5258519649505615\n",
      "Running Batch 293, Epoch 2, Total Tokens: 293\n",
      "Loss: 1.7062262296676636\n",
      "Loss: 3.5573112964630127\n",
      "Running Batch 295, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.7103557586669922\n",
      "Loss: 3.4293153285980225\n",
      "Running Batch 297, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6842687129974365\n",
      "Loss: 3.512244939804077\n",
      "Running Batch 299, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.7328706979751587\n",
      "Loss: 3.5010793209075928\n",
      "Running Batch 301, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.6664785146713257\n",
      "Loss: 3.508347749710083\n",
      "Running Batch 303, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.6510273218154907\n",
      "Loss: 3.4524402618408203\n",
      "Running Batch 305, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6704285144805908\n",
      "Loss: 3.472703456878662\n",
      "Running Batch 307, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.630843162536621\n",
      "Loss: 3.4066622257232666\n",
      "Running Batch 309, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.6550712585449219\n",
      "Loss: 3.5382602214813232\n",
      "Running Batch 311, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.5912830829620361\n",
      "Loss: 3.4769997596740723\n",
      "Running Batch 313, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.5690865516662598\n",
      "Loss: 3.547933340072632\n",
      "Running Batch 315, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.665031909942627\n",
      "Loss: 3.498297691345215\n",
      "Running Batch 317, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.679696798324585\n",
      "Loss: 3.503749132156372\n",
      "Running Batch 319, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.674783706665039\n",
      "Loss: 3.4717886447906494\n",
      "Running Batch 321, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7063896656036377\n",
      "Loss: 3.5602266788482666\n",
      "Running Batch 323, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.68728506565094\n",
      "Loss: 3.479020357131958\n",
      "Running Batch 325, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7371286153793335\n",
      "Loss: 3.438124179840088\n",
      "Running Batch 327, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6597537994384766\n",
      "Loss: 3.525991916656494\n",
      "Running Batch 329, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6854939460754395\n",
      "Loss: 3.4395933151245117\n",
      "Running Batch 331, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6807111501693726\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 331, Loss: 1.6807111501693726\n",
      "Loss: 3.499965190887451\n",
      "Running Batch 333, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6421469449996948\n",
      "Loss: 3.556330442428589\n",
      "Running Batch 335, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6011419296264648\n",
      "Loss: 3.4733662605285645\n",
      "Running Batch 337, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.719464659690857\n",
      "Loss: 3.471282958984375\n",
      "Running Batch 339, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6633151769638062\n",
      "Loss: 3.482860803604126\n",
      "Running Batch 341, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6870018243789673\n",
      "Loss: 3.5361390113830566\n",
      "Running Batch 343, Epoch 2, Total Tokens: 334\n",
      "Loss: 1.725661277770996\n",
      "Loss: 3.492886781692505\n",
      "Running Batch 345, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.675529956817627\n",
      "Loss: 3.4911231994628906\n",
      "Running Batch 347, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.6972060203552246\n",
      "Loss: 3.5180742740631104\n",
      "Running Batch 349, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.673046588897705\n",
      "Loss: 3.5175940990448\n",
      "Running Batch 351, Epoch 2, Total Tokens: 237\n",
      "Loss: 1.6971147060394287\n",
      "Loss: 3.483146905899048\n",
      "Running Batch 353, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6744635105133057\n",
      "Loss: 3.4710352420806885\n",
      "Running Batch 355, Epoch 2, Total Tokens: 624\n",
      "Loss: 1.681487798690796\n",
      "Loss: 3.5031940937042236\n",
      "Running Batch 357, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.6170859336853027\n",
      "Loss: 3.5118772983551025\n",
      "Running Batch 359, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6506251096725464\n",
      "Loss: 3.537040948867798\n",
      "Running Batch 361, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.722700595855713\n",
      "Loss: 3.561979055404663\n",
      "Running Batch 363, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.6872750520706177\n",
      "Loss: 3.447554349899292\n",
      "Running Batch 365, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6787583827972412\n",
      "Loss: 3.4824531078338623\n",
      "Running Batch 367, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.6581780910491943\n",
      "Loss: 3.4813613891601562\n",
      "Running Batch 369, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.657446265220642\n",
      "Loss: 3.4962098598480225\n",
      "Running Batch 371, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6403913497924805\n",
      "Loss: 3.564866542816162\n",
      "Running Batch 373, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.5964149236679077\n",
      "Loss: 3.483992338180542\n",
      "Running Batch 375, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6880197525024414\n",
      "Loss: 3.4502151012420654\n",
      "Running Batch 377, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.7573878765106201\n",
      "Loss: 3.5220441818237305\n",
      "Running Batch 379, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7519030570983887\n",
      "Loss: 3.518380641937256\n",
      "Running Batch 381, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7359501123428345\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 381, Loss: 1.7359501123428345\n",
      "Loss: 3.474853277206421\n",
      "Running Batch 383, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6798211336135864\n",
      "Loss: 3.5433738231658936\n",
      "Running Batch 385, Epoch 2, Total Tokens: 380\n",
      "Loss: 1.6871761083602905\n",
      "Loss: 3.491543769836426\n",
      "Running Batch 387, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6595497131347656\n",
      "Loss: 3.486299753189087\n",
      "Running Batch 389, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.6191784143447876\n",
      "Loss: 3.4694647789001465\n",
      "Running Batch 391, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.639052391052246\n",
      "Loss: 3.500847339630127\n",
      "Running Batch 393, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.682382345199585\n",
      "Loss: 3.525031089782715\n",
      "Running Batch 395, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.5817947387695312\n",
      "Loss: 3.469587802886963\n",
      "Running Batch 397, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.7189439535140991\n",
      "Loss: 3.592876672744751\n",
      "Running Batch 399, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.687880277633667\n",
      "Loss: 3.5129072666168213\n",
      "Running Batch 401, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6471964120864868\n",
      "Loss: 3.521937847137451\n",
      "Running Batch 403, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.6007293462753296\n",
      "Loss: 3.4557924270629883\n",
      "Running Batch 405, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6951457262039185\n",
      "Loss: 3.5093905925750732\n",
      "Running Batch 407, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.703126311302185\n",
      "Loss: 3.47849440574646\n",
      "Running Batch 409, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.6512962579727173\n",
      "Loss: 3.5369067192077637\n",
      "Running Batch 411, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.752398133277893\n",
      "Loss: 3.454821825027466\n",
      "Running Batch 413, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7360498905181885\n",
      "Loss: 3.560336112976074\n",
      "Running Batch 415, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.6275371313095093\n",
      "Loss: 3.5071017742156982\n",
      "Running Batch 417, Epoch 2, Total Tokens: 351\n",
      "Loss: 1.7575129270553589\n",
      "Loss: 3.4700303077697754\n",
      "Running Batch 419, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.649495005607605\n",
      "Loss: 3.4926891326904297\n",
      "Running Batch 421, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7290630340576172\n",
      "Loss: 3.5465471744537354\n",
      "Running Batch 423, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.6360268592834473\n",
      "Loss: 3.510664701461792\n",
      "Running Batch 425, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.659962773323059\n",
      "Loss: 3.430553674697876\n",
      "Running Batch 427, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6601104736328125\n",
      "Loss: 3.516885995864868\n",
      "Running Batch 429, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.68106210231781\n",
      "Loss: 3.44427227973938\n",
      "Running Batch 431, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6310348510742188\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 431, Loss: 1.6310348510742188\n",
      "Loss: 3.519273519515991\n",
      "Running Batch 433, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.6565006971359253\n",
      "Loss: 3.4883599281311035\n",
      "Running Batch 435, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7048858404159546\n",
      "Loss: 3.466353416442871\n",
      "Running Batch 437, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.6740604639053345\n",
      "Loss: 3.565946340560913\n",
      "Running Batch 439, Epoch 2, Total Tokens: 177\n",
      "Loss: 1.6146175861358643\n",
      "Loss: 3.483182191848755\n",
      "Running Batch 441, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6751036643981934\n",
      "Loss: 3.5336225032806396\n",
      "Running Batch 443, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6949348449707031\n",
      "Loss: 3.528299331665039\n",
      "Running Batch 445, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6311973333358765\n",
      "Loss: 3.5445969104766846\n",
      "Running Batch 447, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.7391281127929688\n",
      "Loss: 3.561047315597534\n",
      "Running Batch 449, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6799581050872803\n",
      "Loss: 3.485891819000244\n",
      "Running Batch 451, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.6769766807556152\n",
      "Loss: 3.4962692260742188\n",
      "Running Batch 453, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7302484512329102\n",
      "Loss: 3.4585182666778564\n",
      "Running Batch 455, Epoch 2, Total Tokens: 168\n",
      "Loss: 1.6258636713027954\n",
      "Loss: 3.5555946826934814\n",
      "Running Batch 457, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.6911991834640503\n",
      "Loss: 3.539870023727417\n",
      "Running Batch 459, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6922051906585693\n",
      "Loss: 3.545422077178955\n",
      "Running Batch 461, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.711900234222412\n",
      "Loss: 3.460923910140991\n",
      "Running Batch 463, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6666043996810913\n",
      "Loss: 3.4902944564819336\n",
      "Running Batch 465, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.6378294229507446\n",
      "Loss: 3.5337324142456055\n",
      "Running Batch 467, Epoch 2, Total Tokens: 568\n",
      "Loss: 1.6455379724502563\n",
      "Loss: 3.457491397857666\n",
      "Running Batch 469, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.7222789525985718\n",
      "Loss: 3.484592914581299\n",
      "Running Batch 471, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6305317878723145\n",
      "Loss: 3.4609954357147217\n",
      "Running Batch 473, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.732287883758545\n",
      "Loss: 3.442438840866089\n",
      "Running Batch 475, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.613490343093872\n",
      "Loss: 3.5164716243743896\n",
      "Running Batch 477, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7414720058441162\n",
      "Loss: 3.501131057739258\n",
      "Running Batch 479, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.6645253896713257\n",
      "Loss: 3.4984474182128906\n",
      "Running Batch 481, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.616477608680725\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 481, Loss: 1.616477608680725\n",
      "Loss: 3.4901235103607178\n",
      "Running Batch 483, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.6475744247436523\n",
      "Loss: 3.454564332962036\n",
      "Running Batch 485, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7235010862350464\n",
      "Loss: 3.4918532371520996\n",
      "Running Batch 487, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6838173866271973\n",
      "Loss: 3.498706817626953\n",
      "Running Batch 489, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.6284147500991821\n",
      "Loss: 3.483840227127075\n",
      "Running Batch 491, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.6664305925369263\n",
      "Loss: 3.5987401008605957\n",
      "Running Batch 493, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6762140989303589\n",
      "Loss: 3.5467586517333984\n",
      "Running Batch 495, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6300463676452637\n",
      "Loss: 3.583993911743164\n",
      "Running Batch 497, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.631881833076477\n",
      "Loss: 3.4664018154144287\n",
      "Running Batch 499, Epoch 2, Total Tokens: 205\n",
      "Loss: 1.6211841106414795\n",
      "Loss: 3.482398748397827\n",
      "Running Batch 501, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6622644662857056\n",
      "Loss: 3.5164432525634766\n",
      "Running Batch 503, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.7363368272781372\n",
      "Loss: 3.5342824459075928\n",
      "Running Batch 505, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.6889103651046753\n",
      "Loss: 3.46687650680542\n",
      "Running Batch 507, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.7028342485427856\n",
      "Loss: 3.4422264099121094\n",
      "Running Batch 509, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.6852881908416748\n",
      "Loss: 3.4800453186035156\n",
      "Running Batch 511, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6623882055282593\n",
      "Loss: 3.4245996475219727\n",
      "Running Batch 513, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.6819374561309814\n",
      "Loss: 3.4650206565856934\n",
      "Running Batch 515, Epoch 2, Total Tokens: 288\n",
      "Loss: 1.668373942375183\n",
      "Loss: 3.49411940574646\n",
      "Running Batch 517, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.6375558376312256\n",
      "Loss: 3.498577356338501\n",
      "Running Batch 519, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.712159276008606\n",
      "Loss: 3.516514301300049\n",
      "Running Batch 521, Epoch 2, Total Tokens: 324\n",
      "Loss: 1.7296555042266846\n",
      "Loss: 3.4850611686706543\n",
      "Running Batch 523, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6908072233200073\n",
      "Loss: 3.495414972305298\n",
      "Running Batch 525, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7113302946090698\n",
      "Loss: 3.46142840385437\n",
      "Running Batch 527, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.6478089094161987\n",
      "Loss: 3.51928973197937\n",
      "Running Batch 529, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.6574221849441528\n",
      "Loss: 3.5509085655212402\n",
      "Running Batch 531, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.695277452468872\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 531, Loss: 1.695277452468872\n",
      "Loss: 3.428823947906494\n",
      "Running Batch 533, Epoch 2, Total Tokens: 337\n",
      "Loss: 1.703222393989563\n",
      "Loss: 3.495785713195801\n",
      "Running Batch 535, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.655308723449707\n",
      "Loss: 3.517045259475708\n",
      "Running Batch 537, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6082392930984497\n",
      "Loss: 3.53029465675354\n",
      "Running Batch 539, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6218549013137817\n",
      "Loss: 3.4891130924224854\n",
      "Running Batch 541, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.658747911453247\n",
      "Loss: 3.5000407695770264\n",
      "Running Batch 543, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.6409459114074707\n",
      "Loss: 3.514333486557007\n",
      "Running Batch 545, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.730865716934204\n",
      "Loss: 3.5392656326293945\n",
      "Running Batch 547, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6494059562683105\n",
      "Loss: 3.526482105255127\n",
      "Running Batch 549, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6467070579528809\n",
      "Loss: 3.532413959503174\n",
      "Running Batch 551, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6786903142929077\n",
      "Loss: 3.567533493041992\n",
      "Running Batch 553, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6068120002746582\n",
      "Loss: 3.550614833831787\n",
      "Running Batch 555, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.7078875303268433\n",
      "Loss: 3.4717190265655518\n",
      "Running Batch 557, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6857842206954956\n",
      "Loss: 3.550969123840332\n",
      "Running Batch 559, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.5890402793884277\n",
      "Loss: 3.5340402126312256\n",
      "Running Batch 561, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.5667316913604736\n",
      "Loss: 3.4598371982574463\n",
      "Running Batch 563, Epoch 2, Total Tokens: 372\n",
      "Loss: 1.6781628131866455\n",
      "Loss: 3.4849956035614014\n",
      "Running Batch 565, Epoch 2, Total Tokens: 418\n",
      "Loss: 1.6147297620773315\n",
      "Loss: 3.5657546520233154\n",
      "Running Batch 567, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.7521296739578247\n",
      "Loss: 3.5056159496307373\n",
      "Running Batch 569, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7355589866638184\n",
      "Loss: 3.5389292240142822\n",
      "Running Batch 571, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6853828430175781\n",
      "Loss: 3.458484649658203\n",
      "Running Batch 573, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.6731292009353638\n",
      "Loss: 3.535639524459839\n",
      "Running Batch 575, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6811168193817139\n",
      "Loss: 3.490422487258911\n",
      "Running Batch 577, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.5149227380752563\n",
      "Loss: 3.526470422744751\n",
      "Running Batch 579, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.6867505311965942\n",
      "Loss: 3.5112500190734863\n",
      "Running Batch 581, Epoch 2, Total Tokens: 229\n",
      "Loss: 1.665571928024292\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 581, Loss: 1.665571928024292\n",
      "Loss: 3.4948790073394775\n",
      "Running Batch 583, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.6147470474243164\n",
      "Loss: 3.5066654682159424\n",
      "Running Batch 585, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.6028401851654053\n",
      "Loss: 3.4972853660583496\n",
      "Running Batch 587, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.6721771955490112\n",
      "Loss: 3.460050106048584\n",
      "Running Batch 589, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.5961161851882935\n",
      "Loss: 3.4707529544830322\n",
      "Running Batch 591, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.631492018699646\n",
      "Loss: 3.5467207431793213\n",
      "Running Batch 593, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.6335680484771729\n",
      "Loss: 3.4744739532470703\n",
      "Running Batch 595, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.7587502002716064\n",
      "Loss: 3.5225303173065186\n",
      "Running Batch 597, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6045161485671997\n",
      "Loss: 3.50152587890625\n",
      "Running Batch 599, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6073322296142578\n",
      "Loss: 3.557086944580078\n",
      "Running Batch 601, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7095962762832642\n",
      "Loss: 3.5243353843688965\n",
      "Running Batch 603, Epoch 2, Total Tokens: 281\n",
      "Loss: 1.672861099243164\n",
      "Loss: 3.4827585220336914\n",
      "Running Batch 605, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.5808030366897583\n",
      "Loss: 3.4833786487579346\n",
      "Running Batch 607, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.6935019493103027\n",
      "Loss: 3.543365001678467\n",
      "Running Batch 609, Epoch 2, Total Tokens: 452\n",
      "Loss: 1.7058401107788086\n",
      "Loss: 3.516174793243408\n",
      "Running Batch 611, Epoch 2, Total Tokens: 266\n",
      "Loss: 1.6181074380874634\n",
      "Loss: 3.5268990993499756\n",
      "Running Batch 613, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6073068380355835\n",
      "Loss: 3.5185186862945557\n",
      "Running Batch 615, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.642440915107727\n",
      "Loss: 3.499924659729004\n",
      "Running Batch 617, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6655502319335938\n",
      "Loss: 3.4373812675476074\n",
      "Running Batch 619, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.6575556993484497\n",
      "Loss: 3.4876232147216797\n",
      "Running Batch 621, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.6473281383514404\n",
      "Loss: 3.571420192718506\n",
      "Running Batch 623, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.5914582014083862\n",
      "Loss: 3.499194860458374\n",
      "Running Batch 625, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.687930941581726\n",
      "Loss: 3.5119545459747314\n",
      "Running Batch 627, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6720792055130005\n",
      "Loss: 3.5499067306518555\n",
      "Running Batch 629, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6366310119628906\n",
      "Loss: 3.492506980895996\n",
      "Running Batch 631, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.6765388250350952\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 631, Loss: 1.6765388250350952\n",
      "Loss: 3.491990327835083\n",
      "Running Batch 633, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.6756591796875\n",
      "Loss: 3.507643222808838\n",
      "Running Batch 635, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.634866714477539\n",
      "Loss: 3.5090808868408203\n",
      "Running Batch 637, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6266329288482666\n",
      "Loss: 3.483459711074829\n",
      "Running Batch 639, Epoch 2, Total Tokens: 299\n",
      "Loss: 1.655880093574524\n",
      "Loss: 3.496152877807617\n",
      "Running Batch 641, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.6943217515945435\n",
      "Loss: 3.5033721923828125\n",
      "Running Batch 643, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.699819803237915\n",
      "Loss: 3.463582754135132\n",
      "Running Batch 645, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.655240535736084\n",
      "Loss: 3.52750825881958\n",
      "Running Batch 647, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.6839860677719116\n",
      "Loss: 3.526414632797241\n",
      "Running Batch 649, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.7221630811691284\n",
      "Loss: 3.5194778442382812\n",
      "Running Batch 651, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.6188373565673828\n",
      "Loss: 3.459799289703369\n",
      "Running Batch 653, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.5687159299850464\n",
      "Loss: 3.4743313789367676\n",
      "Running Batch 655, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.6239641904830933\n",
      "Loss: 3.4315125942230225\n",
      "Running Batch 657, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.6418190002441406\n",
      "Loss: 3.498439311981201\n",
      "Running Batch 659, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.7037343978881836\n",
      "Loss: 3.54522705078125\n",
      "Running Batch 661, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6164741516113281\n",
      "Loss: 3.472992420196533\n",
      "Running Batch 663, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.6781448125839233\n",
      "Loss: 3.4822607040405273\n",
      "Running Batch 665, Epoch 2, Total Tokens: 261\n",
      "Loss: 1.7381818294525146\n",
      "Loss: 3.481995105743408\n",
      "Running Batch 667, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6566674709320068\n",
      "Loss: 3.5479187965393066\n",
      "Running Batch 669, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6548198461532593\n",
      "Loss: 3.4819753170013428\n",
      "Running Batch 671, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.6577056646347046\n",
      "Loss: 3.5105373859405518\n",
      "Running Batch 673, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6207315921783447\n",
      "Loss: 3.4551897048950195\n",
      "Running Batch 675, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6192203760147095\n",
      "Loss: 3.5185770988464355\n",
      "Running Batch 677, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.721641182899475\n",
      "Loss: 3.51688289642334\n",
      "Running Batch 679, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7004525661468506\n",
      "Loss: 3.5444252490997314\n",
      "Running Batch 681, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.5789538621902466\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 681, Loss: 1.5789538621902466\n",
      "Loss: 3.470834255218506\n",
      "Running Batch 683, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6515270471572876\n",
      "Loss: 3.465735673904419\n",
      "Running Batch 685, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.6494165658950806\n",
      "Loss: 3.498835563659668\n",
      "Running Batch 687, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6611051559448242\n",
      "Loss: 3.54233980178833\n",
      "Running Batch 689, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.6288846731185913\n",
      "Loss: 3.519003391265869\n",
      "Running Batch 691, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6904715299606323\n",
      "Loss: 3.5247488021850586\n",
      "Running Batch 693, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.597781777381897\n",
      "Loss: 3.465703248977661\n",
      "Running Batch 695, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.6775239706039429\n",
      "Loss: 3.4465243816375732\n",
      "Running Batch 697, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.6720987558364868\n",
      "Loss: 3.517944812774658\n",
      "Running Batch 699, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6373786926269531\n",
      "Loss: 3.4850964546203613\n",
      "Running Batch 701, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.5832927227020264\n",
      "Loss: 3.5376577377319336\n",
      "Running Batch 703, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7110068798065186\n",
      "Loss: 3.4565694332122803\n",
      "Running Batch 705, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.6627646684646606\n",
      "Loss: 3.4457767009735107\n",
      "Running Batch 707, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.6593010425567627\n",
      "Loss: 3.4772098064422607\n",
      "Running Batch 709, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.62584388256073\n",
      "Loss: 3.51530122756958\n",
      "Running Batch 711, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7259695529937744\n",
      "Loss: 3.4339728355407715\n",
      "Running Batch 713, Epoch 2, Total Tokens: 219\n",
      "Loss: 1.679714560508728\n",
      "Loss: 3.5621609687805176\n",
      "Running Batch 715, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.6961625814437866\n",
      "Loss: 3.439873456954956\n",
      "Running Batch 717, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.6786130666732788\n",
      "Loss: 3.4792263507843018\n",
      "Running Batch 719, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.633798599243164\n",
      "Loss: 3.4670228958129883\n",
      "Running Batch 721, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6557368040084839\n",
      "Loss: 3.4654176235198975\n",
      "Running Batch 723, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.6294467449188232\n",
      "Loss: 3.590113401412964\n",
      "Running Batch 725, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.6256334781646729\n",
      "Loss: 3.478459596633911\n",
      "Running Batch 727, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.6435636281967163\n",
      "Loss: 3.5915300846099854\n",
      "Running Batch 729, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.65121328830719\n",
      "Loss: 3.4810407161712646\n",
      "Running Batch 731, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.676257610321045\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 731, Loss: 1.676257610321045\n",
      "Loss: 3.4415218830108643\n",
      "Running Batch 733, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.650258183479309\n",
      "Loss: 3.447312355041504\n",
      "Running Batch 735, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.7034573554992676\n",
      "Loss: 3.5234642028808594\n",
      "Running Batch 737, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.6717699766159058\n",
      "Loss: 3.4886817932128906\n",
      "Running Batch 739, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.666727900505066\n",
      "Loss: 3.4457945823669434\n",
      "Running Batch 741, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7013927698135376\n",
      "Loss: 3.5145821571350098\n",
      "Running Batch 743, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.6675455570220947\n",
      "Loss: 3.4997289180755615\n",
      "Running Batch 745, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7188036441802979\n",
      "Loss: 3.550492525100708\n",
      "Running Batch 747, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.60326087474823\n",
      "Loss: 3.45967698097229\n",
      "Running Batch 749, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.6155893802642822\n",
      "Loss: 3.483595848083496\n",
      "Running Batch 751, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.5986623764038086\n",
      "Loss: 3.4933362007141113\n",
      "Running Batch 753, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.731152892112732\n",
      "Loss: 3.4468493461608887\n",
      "Running Batch 755, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.573053002357483\n",
      "Loss: 3.4924614429473877\n",
      "Running Batch 757, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7557038068771362\n",
      "Loss: 3.4673681259155273\n",
      "Running Batch 759, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.684177041053772\n",
      "Loss: 3.5520243644714355\n",
      "Running Batch 761, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7148948907852173\n",
      "Loss: 3.4654347896575928\n",
      "Running Batch 763, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.637378215789795\n",
      "Loss: 3.4593088626861572\n",
      "Running Batch 765, Epoch 2, Total Tokens: 322\n",
      "Loss: 1.646584153175354\n",
      "Loss: 3.4728684425354004\n",
      "Running Batch 767, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.657861351966858\n",
      "Loss: 3.4799346923828125\n",
      "Running Batch 769, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.663141131401062\n",
      "Loss: 3.470885992050171\n",
      "Running Batch 771, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.6438448429107666\n",
      "Loss: 3.482668161392212\n",
      "Running Batch 773, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.6343905925750732\n",
      "Loss: 3.4774675369262695\n",
      "Running Batch 775, Epoch 2, Total Tokens: 197\n",
      "Loss: 1.6830940246582031\n",
      "Loss: 3.5058891773223877\n",
      "Running Batch 777, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.661460280418396\n",
      "Loss: 3.504305124282837\n",
      "Running Batch 779, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6371419429779053\n",
      "Loss: 3.5252833366394043\n",
      "Running Batch 781, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.6666988134384155\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 781, Loss: 1.6666988134384155\n",
      "AVG LOSS: 2.5867295935940557, Epoch: 3\n",
      "Loss: 3.4899260997772217\n",
      "Running Batch 1, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6059861183166504\n",
      "Loss: 3.4683635234832764\n",
      "Running Batch 3, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7194838523864746\n",
      "Loss: 3.4891605377197266\n",
      "Running Batch 5, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.5940876007080078\n",
      "Loss: 3.5103721618652344\n",
      "Running Batch 7, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6438634395599365\n",
      "Loss: 3.4675729274749756\n",
      "Running Batch 9, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.592539668083191\n",
      "Loss: 3.5024986267089844\n",
      "Running Batch 11, Epoch 3, Total Tokens: 188\n",
      "Loss: 1.681197166442871\n",
      "Loss: 3.457045555114746\n",
      "Running Batch 13, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.5796327590942383\n",
      "Loss: 3.4658946990966797\n",
      "Running Batch 15, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.5772316455841064\n",
      "Loss: 3.5256707668304443\n",
      "Running Batch 17, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.6928601264953613\n",
      "Loss: 3.4652833938598633\n",
      "Running Batch 19, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6406786441802979\n",
      "Loss: 3.390984058380127\n",
      "Running Batch 21, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.6188238859176636\n",
      "Loss: 3.4846670627593994\n",
      "Running Batch 23, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.58859384059906\n",
      "Loss: 3.4537720680236816\n",
      "Running Batch 25, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6584346294403076\n",
      "Loss: 3.4570980072021484\n",
      "Running Batch 27, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6517170667648315\n",
      "Loss: 3.531371593475342\n",
      "Running Batch 29, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6563606262207031\n",
      "Loss: 3.5092978477478027\n",
      "Running Batch 31, Epoch 3, Total Tokens: 202\n",
      "Loss: 1.6691296100616455\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 31, Loss: 1.6691296100616455\n",
      "Loss: 3.4375863075256348\n",
      "Running Batch 33, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7030425071716309\n",
      "Loss: 3.464468479156494\n",
      "Running Batch 35, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6587918996810913\n",
      "Loss: 3.4810116291046143\n",
      "Running Batch 37, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6064739227294922\n",
      "Loss: 3.5070133209228516\n",
      "Running Batch 39, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6291242837905884\n",
      "Loss: 3.4759907722473145\n",
      "Running Batch 41, Epoch 3, Total Tokens: 182\n",
      "Loss: 1.6529816389083862\n",
      "Loss: 3.4587197303771973\n",
      "Running Batch 43, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.641586184501648\n",
      "Loss: 3.4613940715789795\n",
      "Running Batch 45, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.663908839225769\n",
      "Loss: 3.500685453414917\n",
      "Running Batch 47, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.665067195892334\n",
      "Loss: 3.456657648086548\n",
      "Running Batch 49, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6619890928268433\n",
      "Loss: 3.505526304244995\n",
      "Running Batch 51, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.5929827690124512\n",
      "Loss: 3.466414213180542\n",
      "Running Batch 53, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.647757649421692\n",
      "Loss: 3.4955310821533203\n",
      "Running Batch 55, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6348239183425903\n",
      "Loss: 3.4707248210906982\n",
      "Running Batch 57, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.602281093597412\n",
      "Loss: 3.477782726287842\n",
      "Running Batch 59, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.5600064992904663\n",
      "Loss: 3.4670002460479736\n",
      "Running Batch 61, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.602229118347168\n",
      "Loss: 3.484074592590332\n",
      "Running Batch 63, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6724653244018555\n",
      "Loss: 3.492269515991211\n",
      "Running Batch 65, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.5628256797790527\n",
      "Loss: 3.482937812805176\n",
      "Running Batch 67, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.5743111371994019\n",
      "Loss: 3.5195908546447754\n",
      "Running Batch 69, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.628944993019104\n",
      "Loss: 3.5362396240234375\n",
      "Running Batch 71, Epoch 3, Total Tokens: 193\n",
      "Loss: 1.630648136138916\n",
      "Loss: 3.4787681102752686\n",
      "Running Batch 73, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6926181316375732\n",
      "Loss: 3.4983303546905518\n",
      "Running Batch 75, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6188440322875977\n",
      "Loss: 3.530383586883545\n",
      "Running Batch 77, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6237529516220093\n",
      "Loss: 3.5354623794555664\n",
      "Running Batch 79, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.5627855062484741\n",
      "Loss: 3.4584524631500244\n",
      "Running Batch 81, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.631122350692749\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 81, Loss: 1.631122350692749\n",
      "Loss: 3.451382637023926\n",
      "Running Batch 83, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.592362403869629\n",
      "Loss: 3.518897771835327\n",
      "Running Batch 85, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6621273756027222\n",
      "Loss: 3.4805245399475098\n",
      "Running Batch 87, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.5935977697372437\n",
      "Loss: 3.5519607067108154\n",
      "Running Batch 89, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.6695326566696167\n",
      "Loss: 3.501849889755249\n",
      "Running Batch 91, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.602179765701294\n",
      "Loss: 3.5153965950012207\n",
      "Running Batch 93, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.678995132446289\n",
      "Loss: 3.5004281997680664\n",
      "Running Batch 95, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6729466915130615\n",
      "Loss: 3.4101662635803223\n",
      "Running Batch 97, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6037672758102417\n",
      "Loss: 3.5487473011016846\n",
      "Running Batch 99, Epoch 3, Total Tokens: 166\n",
      "Loss: 1.673471212387085\n",
      "Loss: 3.4513189792633057\n",
      "Running Batch 101, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.7118980884552002\n",
      "Loss: 3.509960889816284\n",
      "Running Batch 103, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.596871018409729\n",
      "Loss: 3.4858133792877197\n",
      "Running Batch 105, Epoch 3, Total Tokens: 360\n",
      "Loss: 1.6418848037719727\n",
      "Loss: 3.5052490234375\n",
      "Running Batch 107, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.5936659574508667\n",
      "Loss: 3.5702106952667236\n",
      "Running Batch 109, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6402740478515625\n",
      "Loss: 3.5155463218688965\n",
      "Running Batch 111, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.706452488899231\n",
      "Loss: 3.510550022125244\n",
      "Running Batch 113, Epoch 3, Total Tokens: 234\n",
      "Loss: 1.623942255973816\n",
      "Loss: 3.453108787536621\n",
      "Running Batch 115, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6511775255203247\n",
      "Loss: 3.4609880447387695\n",
      "Running Batch 117, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6250358819961548\n",
      "Loss: 3.5260660648345947\n",
      "Running Batch 119, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6969513893127441\n",
      "Loss: 3.4676942825317383\n",
      "Running Batch 121, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.6953078508377075\n",
      "Loss: 3.536012887954712\n",
      "Running Batch 123, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.6256890296936035\n",
      "Loss: 3.4640166759490967\n",
      "Running Batch 125, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6633862257003784\n",
      "Loss: 3.4393246173858643\n",
      "Running Batch 127, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.633462905883789\n",
      "Loss: 3.5180914402008057\n",
      "Running Batch 129, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6964808702468872\n",
      "Loss: 3.4446775913238525\n",
      "Running Batch 131, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.636283040046692\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 131, Loss: 1.636283040046692\n",
      "Loss: 3.515186309814453\n",
      "Running Batch 133, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6993917226791382\n",
      "Loss: 3.4793248176574707\n",
      "Running Batch 135, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6269596815109253\n",
      "Loss: 3.4717235565185547\n",
      "Running Batch 137, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6144007444381714\n",
      "Loss: 3.4313244819641113\n",
      "Running Batch 139, Epoch 3, Total Tokens: 168\n",
      "Loss: 1.6771000623703003\n",
      "Loss: 3.4789609909057617\n",
      "Running Batch 141, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.6283129453659058\n",
      "Loss: 3.514526844024658\n",
      "Running Batch 143, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6377205848693848\n",
      "Loss: 3.484196901321411\n",
      "Running Batch 145, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.655255913734436\n",
      "Loss: 3.514050006866455\n",
      "Running Batch 147, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.5941685438156128\n",
      "Loss: 3.494201898574829\n",
      "Running Batch 149, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.653831958770752\n",
      "Loss: 3.4822676181793213\n",
      "Running Batch 151, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6293232440948486\n",
      "Loss: 3.529747247695923\n",
      "Running Batch 153, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6377068758010864\n",
      "Loss: 3.4791200160980225\n",
      "Running Batch 155, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6303958892822266\n",
      "Loss: 3.46652889251709\n",
      "Running Batch 157, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6976754665374756\n",
      "Loss: 3.4630942344665527\n",
      "Running Batch 159, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6145869493484497\n",
      "Loss: 3.4656982421875\n",
      "Running Batch 161, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.6583285331726074\n",
      "Loss: 3.518158435821533\n",
      "Running Batch 163, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.5542007684707642\n",
      "Loss: 3.612212896347046\n",
      "Running Batch 165, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6264891624450684\n",
      "Loss: 3.4793035984039307\n",
      "Running Batch 167, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.622755765914917\n",
      "Loss: 3.54740571975708\n",
      "Running Batch 169, Epoch 3, Total Tokens: 209\n",
      "Loss: 1.7486698627471924\n",
      "Loss: 3.4787580966949463\n",
      "Running Batch 171, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.5864495038986206\n",
      "Loss: 3.465208053588867\n",
      "Running Batch 173, Epoch 3, Total Tokens: 171\n",
      "Loss: 1.6371408700942993\n",
      "Loss: 3.5579674243927\n",
      "Running Batch 175, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6736117601394653\n",
      "Loss: 3.491846799850464\n",
      "Running Batch 177, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.733283281326294\n",
      "Loss: 3.459728240966797\n",
      "Running Batch 179, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6346131563186646\n",
      "Loss: 3.5127170085906982\n",
      "Running Batch 181, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.6624821424484253\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 181, Loss: 1.6624821424484253\n",
      "Loss: 3.565868854522705\n",
      "Running Batch 183, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.5850834846496582\n",
      "Loss: 3.553931474685669\n",
      "Running Batch 185, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7411268949508667\n",
      "Loss: 3.4669768810272217\n",
      "Running Batch 187, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6329466104507446\n",
      "Loss: 3.4932661056518555\n",
      "Running Batch 189, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.6192708015441895\n",
      "Loss: 3.424644947052002\n",
      "Running Batch 191, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6907719373703003\n",
      "Loss: 3.5169780254364014\n",
      "Running Batch 193, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.566369891166687\n",
      "Loss: 3.51721453666687\n",
      "Running Batch 195, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.638948917388916\n",
      "Loss: 3.5242879390716553\n",
      "Running Batch 197, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.5685350894927979\n",
      "Loss: 3.4216883182525635\n",
      "Running Batch 199, Epoch 3, Total Tokens: 230\n",
      "Loss: 1.5616568326950073\n",
      "Loss: 3.571798086166382\n",
      "Running Batch 201, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6564850807189941\n",
      "Loss: 3.4587037563323975\n",
      "Running Batch 203, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6651818752288818\n",
      "Loss: 3.4932854175567627\n",
      "Running Batch 205, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.690922737121582\n",
      "Loss: 3.511749267578125\n",
      "Running Batch 207, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6359539031982422\n",
      "Loss: 3.5256195068359375\n",
      "Running Batch 209, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7106584310531616\n",
      "Loss: 3.4373903274536133\n",
      "Running Batch 211, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6468958854675293\n",
      "Loss: 3.5000596046447754\n",
      "Running Batch 213, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.600694179534912\n",
      "Loss: 3.4577579498291016\n",
      "Running Batch 215, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.5967340469360352\n",
      "Loss: 3.5216634273529053\n",
      "Running Batch 217, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7083920240402222\n",
      "Loss: 3.4684112071990967\n",
      "Running Batch 219, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6223770380020142\n",
      "Loss: 3.4685585498809814\n",
      "Running Batch 221, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6522095203399658\n",
      "Loss: 3.4810760021209717\n",
      "Running Batch 223, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6175072193145752\n",
      "Loss: 3.4364216327667236\n",
      "Running Batch 225, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.5783222913742065\n",
      "Loss: 3.455420970916748\n",
      "Running Batch 227, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6236423254013062\n",
      "Loss: 3.462503433227539\n",
      "Running Batch 229, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.6900944709777832\n",
      "Loss: 3.4884958267211914\n",
      "Running Batch 231, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7029470205307007\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 231, Loss: 1.7029470205307007\n",
      "Loss: 3.501988172531128\n",
      "Running Batch 233, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6452516317367554\n",
      "Loss: 3.4563190937042236\n",
      "Running Batch 235, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6619203090667725\n",
      "Loss: 3.4507086277008057\n",
      "Running Batch 237, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6454721689224243\n",
      "Loss: 3.5123400688171387\n",
      "Running Batch 239, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6586405038833618\n",
      "Loss: 3.497492551803589\n",
      "Running Batch 241, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6235707998275757\n",
      "Loss: 3.4871912002563477\n",
      "Running Batch 243, Epoch 3, Total Tokens: 220\n",
      "Loss: 1.6465559005737305\n",
      "Loss: 3.4568979740142822\n",
      "Running Batch 245, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6674671173095703\n",
      "Loss: 3.427335023880005\n",
      "Running Batch 247, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6227781772613525\n",
      "Loss: 3.467029571533203\n",
      "Running Batch 249, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6770912408828735\n",
      "Loss: 3.493584632873535\n",
      "Running Batch 251, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.6656794548034668\n",
      "Loss: 3.504439353942871\n",
      "Running Batch 253, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.631186604499817\n",
      "Loss: 3.4994914531707764\n",
      "Running Batch 255, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6066683530807495\n",
      "Loss: 3.489306688308716\n",
      "Running Batch 257, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6890661716461182\n",
      "Loss: 3.4535155296325684\n",
      "Running Batch 259, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.655257225036621\n",
      "Loss: 3.533832550048828\n",
      "Running Batch 261, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7109795808792114\n",
      "Loss: 3.4301016330718994\n",
      "Running Batch 263, Epoch 3, Total Tokens: 273\n",
      "Loss: 1.7312490940093994\n",
      "Loss: 3.497706890106201\n",
      "Running Batch 265, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.640982985496521\n",
      "Loss: 3.499255418777466\n",
      "Running Batch 267, Epoch 3, Total Tokens: 191\n",
      "Loss: 1.5805518627166748\n",
      "Loss: 3.467665195465088\n",
      "Running Batch 269, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6850312948226929\n",
      "Loss: 3.471405029296875\n",
      "Running Batch 271, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6549981832504272\n",
      "Loss: 3.5144684314727783\n",
      "Running Batch 273, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6323599815368652\n",
      "Loss: 3.5097177028656006\n",
      "Running Batch 275, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6287685632705688\n",
      "Loss: 3.5315802097320557\n",
      "Running Batch 277, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.661803126335144\n",
      "Loss: 3.560694932937622\n",
      "Running Batch 279, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6677758693695068\n",
      "Loss: 3.5559473037719727\n",
      "Running Batch 281, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6381399631500244\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 281, Loss: 1.6381399631500244\n",
      "Loss: 3.488971471786499\n",
      "Running Batch 283, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6465954780578613\n",
      "Loss: 3.4969253540039062\n",
      "Running Batch 285, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.555851936340332\n",
      "Loss: 3.439387798309326\n",
      "Running Batch 287, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6553837060928345\n",
      "Loss: 3.540834665298462\n",
      "Running Batch 289, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.5751893520355225\n",
      "Loss: 3.524982452392578\n",
      "Running Batch 291, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6507232189178467\n",
      "Loss: 3.503204822540283\n",
      "Running Batch 293, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6493829488754272\n",
      "Loss: 3.5131397247314453\n",
      "Running Batch 295, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6168744564056396\n",
      "Loss: 3.4524784088134766\n",
      "Running Batch 297, Epoch 3, Total Tokens: 224\n",
      "Loss: 1.6807615756988525\n",
      "Loss: 3.431889772415161\n",
      "Running Batch 299, Epoch 3, Total Tokens: 191\n",
      "Loss: 1.690145492553711\n",
      "Loss: 3.49311900138855\n",
      "Running Batch 301, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.6956579685211182\n",
      "Loss: 3.421454668045044\n",
      "Running Batch 303, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6494547128677368\n",
      "Loss: 3.4877872467041016\n",
      "Running Batch 305, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.595155119895935\n",
      "Loss: 3.533998727798462\n",
      "Running Batch 307, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.5875060558319092\n",
      "Loss: 3.4737894535064697\n",
      "Running Batch 309, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.592275857925415\n",
      "Loss: 3.5087828636169434\n",
      "Running Batch 311, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6455578804016113\n",
      "Loss: 3.467198371887207\n",
      "Running Batch 313, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6006674766540527\n",
      "Loss: 3.4459588527679443\n",
      "Running Batch 315, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.7453131675720215\n",
      "Loss: 3.5555403232574463\n",
      "Running Batch 317, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.5771982669830322\n",
      "Loss: 3.534708261489868\n",
      "Running Batch 319, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6567487716674805\n",
      "Loss: 3.5315942764282227\n",
      "Running Batch 321, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6742783784866333\n",
      "Loss: 3.5275299549102783\n",
      "Running Batch 323, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6449811458587646\n",
      "Loss: 3.5519614219665527\n",
      "Running Batch 325, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.5765990018844604\n",
      "Loss: 3.5167620182037354\n",
      "Running Batch 327, Epoch 3, Total Tokens: 201\n",
      "Loss: 1.6599884033203125\n",
      "Loss: 3.4876792430877686\n",
      "Running Batch 329, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.5532368421554565\n",
      "Loss: 3.5280234813690186\n",
      "Running Batch 331, Epoch 3, Total Tokens: 266\n",
      "Loss: 1.6075254678726196\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 331, Loss: 1.6075254678726196\n",
      "Loss: 3.5285990238189697\n",
      "Running Batch 333, Epoch 3, Total Tokens: 242\n",
      "Loss: 1.6557841300964355\n",
      "Loss: 3.536242723464966\n",
      "Running Batch 335, Epoch 3, Total Tokens: 192\n",
      "Loss: 1.5991886854171753\n",
      "Loss: 3.503127336502075\n",
      "Running Batch 337, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6014453172683716\n",
      "Loss: 3.487109899520874\n",
      "Running Batch 339, Epoch 3, Total Tokens: 294\n",
      "Loss: 1.6568180322647095\n",
      "Loss: 3.5155467987060547\n",
      "Running Batch 341, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6122455596923828\n",
      "Loss: 3.4212026596069336\n",
      "Running Batch 343, Epoch 3, Total Tokens: 322\n",
      "Loss: 1.547167420387268\n",
      "Loss: 3.374227523803711\n",
      "Running Batch 345, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.640236496925354\n",
      "Loss: 3.47983717918396\n",
      "Running Batch 347, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.628975749015808\n",
      "Loss: 3.342782974243164\n",
      "Running Batch 349, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.676448941230774\n",
      "Loss: 3.478487730026245\n",
      "Running Batch 351, Epoch 3, Total Tokens: 183\n",
      "Loss: 1.6348050832748413\n",
      "Loss: 3.4516186714172363\n",
      "Running Batch 353, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6360223293304443\n",
      "Loss: 3.4467673301696777\n",
      "Running Batch 355, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.603576898574829\n",
      "Loss: 3.473003387451172\n",
      "Running Batch 357, Epoch 3, Total Tokens: 171\n",
      "Loss: 1.6842631101608276\n",
      "Loss: 3.4630730152130127\n",
      "Running Batch 359, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.5966007709503174\n",
      "Loss: 3.4338762760162354\n",
      "Running Batch 361, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.6151065826416016\n",
      "Loss: 3.4468331336975098\n",
      "Running Batch 363, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.5673452615737915\n",
      "Loss: 3.5007026195526123\n",
      "Running Batch 365, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.626753568649292\n",
      "Loss: 3.488582134246826\n",
      "Running Batch 367, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6550230979919434\n",
      "Loss: 3.523216485977173\n",
      "Running Batch 369, Epoch 3, Total Tokens: 223\n",
      "Loss: 1.6848397254943848\n",
      "Loss: 3.475308418273926\n",
      "Running Batch 371, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.631335973739624\n",
      "Loss: 3.4623351097106934\n",
      "Running Batch 373, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.6346710920333862\n",
      "Loss: 3.519458293914795\n",
      "Running Batch 375, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.722306728363037\n",
      "Loss: 3.4513914585113525\n",
      "Running Batch 377, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6864162683486938\n",
      "Loss: 3.464524745941162\n",
      "Running Batch 379, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6670217514038086\n",
      "Loss: 3.4098503589630127\n",
      "Running Batch 381, Epoch 3, Total Tokens: 185\n",
      "Loss: 1.5997629165649414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 381, Loss: 1.5997629165649414\n",
      "Loss: 3.3968217372894287\n",
      "Running Batch 383, Epoch 3, Total Tokens: 196\n",
      "Loss: 1.6853594779968262\n",
      "Loss: 3.443307399749756\n",
      "Running Batch 385, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6704939603805542\n",
      "Loss: 3.49924898147583\n",
      "Running Batch 387, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6255639791488647\n",
      "Loss: 3.4804887771606445\n",
      "Running Batch 389, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.5531171560287476\n",
      "Loss: 3.459841728210449\n",
      "Running Batch 391, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.528287410736084\n",
      "Loss: 3.4836840629577637\n",
      "Running Batch 393, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.5367240905761719\n",
      "Loss: 3.4956016540527344\n",
      "Running Batch 395, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.5893875360488892\n",
      "Loss: 3.5092873573303223\n",
      "Running Batch 397, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.637068748474121\n",
      "Loss: 3.45703387260437\n",
      "Running Batch 399, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6298457384109497\n",
      "Loss: 3.4745030403137207\n",
      "Running Batch 401, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7194557189941406\n",
      "Loss: 3.413451910018921\n",
      "Running Batch 403, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6184998750686646\n",
      "Loss: 3.526431083679199\n",
      "Running Batch 405, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.5785610675811768\n",
      "Loss: 3.455167055130005\n",
      "Running Batch 407, Epoch 3, Total Tokens: 224\n",
      "Loss: 1.664866328239441\n",
      "Loss: 3.461181640625\n",
      "Running Batch 409, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6678917407989502\n",
      "Loss: 3.513545513153076\n",
      "Running Batch 411, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6587086915969849\n",
      "Loss: 3.483821392059326\n",
      "Running Batch 413, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.5885694026947021\n",
      "Loss: 3.4086692333221436\n",
      "Running Batch 415, Epoch 3, Total Tokens: 237\n",
      "Loss: 1.6566452980041504\n",
      "Loss: 3.492156744003296\n",
      "Running Batch 417, Epoch 3, Total Tokens: 527\n",
      "Loss: 1.649417519569397\n",
      "Loss: 3.4371707439422607\n",
      "Running Batch 419, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6843515634536743\n",
      "Loss: 3.565582513809204\n",
      "Running Batch 421, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.598768949508667\n",
      "Loss: 3.5473732948303223\n",
      "Running Batch 423, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.6821008920669556\n",
      "Loss: 3.5051889419555664\n",
      "Running Batch 425, Epoch 3, Total Tokens: 324\n",
      "Loss: 1.6257025003433228\n",
      "Loss: 3.4911303520202637\n",
      "Running Batch 427, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6128791570663452\n",
      "Loss: 3.5214908123016357\n",
      "Running Batch 429, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6453582048416138\n",
      "Loss: 3.46511173248291\n",
      "Running Batch 431, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.5995246171951294\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 431, Loss: 1.5995246171951294\n",
      "Loss: 3.462226152420044\n",
      "Running Batch 433, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6047407388687134\n",
      "Loss: 3.491457462310791\n",
      "Running Batch 435, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.587162971496582\n",
      "Loss: 3.4410593509674072\n",
      "Running Batch 437, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6708098649978638\n",
      "Loss: 3.4832427501678467\n",
      "Running Batch 439, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.5769609212875366\n",
      "Loss: 3.509920835494995\n",
      "Running Batch 441, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.643637776374817\n",
      "Loss: 3.5445873737335205\n",
      "Running Batch 443, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.579128623008728\n",
      "Loss: 3.4992141723632812\n",
      "Running Batch 445, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7578388452529907\n",
      "Loss: 3.494070053100586\n",
      "Running Batch 447, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6316263675689697\n",
      "Loss: 3.4613327980041504\n",
      "Running Batch 449, Epoch 3, Total Tokens: 205\n",
      "Loss: 1.5934103727340698\n",
      "Loss: 3.437028408050537\n",
      "Running Batch 451, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.648036241531372\n",
      "Loss: 3.4750876426696777\n",
      "Running Batch 453, Epoch 3, Total Tokens: 184\n",
      "Loss: 1.6165480613708496\n",
      "Loss: 3.4407825469970703\n",
      "Running Batch 455, Epoch 3, Total Tokens: 179\n",
      "Loss: 1.6908433437347412\n",
      "Loss: 3.4790902137756348\n",
      "Running Batch 457, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6633062362670898\n",
      "Loss: 3.503734588623047\n",
      "Running Batch 459, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.661056399345398\n",
      "Loss: 3.4742918014526367\n",
      "Running Batch 461, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6347298622131348\n",
      "Loss: 3.4428775310516357\n",
      "Running Batch 463, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6432127952575684\n",
      "Loss: 3.468217372894287\n",
      "Running Batch 465, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.5749398469924927\n",
      "Loss: 3.484915018081665\n",
      "Running Batch 467, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.6587867736816406\n",
      "Loss: 3.504711389541626\n",
      "Running Batch 469, Epoch 3, Total Tokens: 356\n",
      "Loss: 1.6296167373657227\n",
      "Loss: 3.470632553100586\n",
      "Running Batch 471, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6465375423431396\n",
      "Loss: 3.4871506690979004\n",
      "Running Batch 473, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6760586500167847\n",
      "Loss: 3.4588921070098877\n",
      "Running Batch 475, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.5613634586334229\n",
      "Loss: 3.491239070892334\n",
      "Running Batch 477, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.5932308435440063\n",
      "Loss: 3.4977996349334717\n",
      "Running Batch 479, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.5813599824905396\n",
      "Loss: 3.4990932941436768\n",
      "Running Batch 481, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6140873432159424\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 481, Loss: 1.6140873432159424\n",
      "Loss: 3.5446078777313232\n",
      "Running Batch 483, Epoch 3, Total Tokens: 183\n",
      "Loss: 1.6835838556289673\n",
      "Loss: 3.482670307159424\n",
      "Running Batch 485, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.696338415145874\n",
      "Loss: 3.518404245376587\n",
      "Running Batch 487, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6153392791748047\n",
      "Loss: 3.4828057289123535\n",
      "Running Batch 489, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.5832490921020508\n",
      "Loss: 3.515831232070923\n",
      "Running Batch 491, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6035311222076416\n",
      "Loss: 3.4997494220733643\n",
      "Running Batch 493, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.580064296722412\n",
      "Loss: 3.446683883666992\n",
      "Running Batch 495, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.629809856414795\n",
      "Loss: 3.4311890602111816\n",
      "Running Batch 497, Epoch 3, Total Tokens: 384\n",
      "Loss: 1.6505708694458008\n",
      "Loss: 3.424618721008301\n",
      "Running Batch 499, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.560822606086731\n",
      "Loss: 3.5118601322174072\n",
      "Running Batch 501, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6442772150039673\n",
      "Loss: 3.432692527770996\n",
      "Running Batch 503, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7340924739837646\n",
      "Loss: 3.495131731033325\n",
      "Running Batch 505, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6440919637680054\n",
      "Loss: 3.442446231842041\n",
      "Running Batch 507, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.648550271987915\n",
      "Loss: 3.4522857666015625\n",
      "Running Batch 509, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6676188707351685\n",
      "Loss: 3.475339889526367\n",
      "Running Batch 511, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.653621792793274\n",
      "Loss: 3.471189022064209\n",
      "Running Batch 513, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.60414719581604\n",
      "Loss: 3.5110039710998535\n",
      "Running Batch 515, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6172409057617188\n",
      "Loss: 3.4708375930786133\n",
      "Running Batch 517, Epoch 3, Total Tokens: 262\n",
      "Loss: 1.6229792833328247\n",
      "Loss: 3.4916040897369385\n",
      "Running Batch 519, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.683370590209961\n",
      "Loss: 3.445082902908325\n",
      "Running Batch 521, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.556429147720337\n",
      "Loss: 3.4608662128448486\n",
      "Running Batch 523, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.51166570186615\n",
      "Loss: 3.5363850593566895\n",
      "Running Batch 525, Epoch 3, Total Tokens: 284\n",
      "Loss: 1.720278263092041\n",
      "Loss: 3.479349136352539\n",
      "Running Batch 527, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6553335189819336\n",
      "Loss: 3.5170485973358154\n",
      "Running Batch 529, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.688228726387024\n",
      "Loss: 3.500627279281616\n",
      "Running Batch 531, Epoch 3, Total Tokens: 180\n",
      "Loss: 1.7026034593582153\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 531, Loss: 1.7026034593582153\n",
      "Loss: 3.4847359657287598\n",
      "Running Batch 533, Epoch 3, Total Tokens: 175\n",
      "Loss: 1.6899042129516602\n",
      "Loss: 3.4589433670043945\n",
      "Running Batch 535, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.5923898220062256\n",
      "Loss: 3.4217052459716797\n",
      "Running Batch 537, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6439266204833984\n",
      "Loss: 3.4790337085723877\n",
      "Running Batch 539, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6611708402633667\n",
      "Loss: 3.468888282775879\n",
      "Running Batch 541, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6240440607070923\n",
      "Loss: 3.5601131916046143\n",
      "Running Batch 543, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6422266960144043\n",
      "Loss: 3.4069631099700928\n",
      "Running Batch 545, Epoch 3, Total Tokens: 351\n",
      "Loss: 1.6753162145614624\n",
      "Loss: 3.525393009185791\n",
      "Running Batch 547, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6349689960479736\n",
      "Loss: 3.521148204803467\n",
      "Running Batch 549, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.5762364864349365\n",
      "Loss: 3.5369138717651367\n",
      "Running Batch 551, Epoch 3, Total Tokens: 281\n",
      "Loss: 1.6214829683303833\n",
      "Loss: 3.482846260070801\n",
      "Running Batch 553, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6762323379516602\n",
      "Loss: 3.438391923904419\n",
      "Running Batch 555, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6259788274765015\n",
      "Loss: 3.4792609214782715\n",
      "Running Batch 557, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6810091733932495\n",
      "Loss: 3.47772479057312\n",
      "Running Batch 559, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.5553704500198364\n",
      "Loss: 3.479353189468384\n",
      "Running Batch 561, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6360447406768799\n",
      "Loss: 3.507406234741211\n",
      "Running Batch 563, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.5873559713363647\n",
      "Loss: 3.556238889694214\n",
      "Running Batch 565, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6432069540023804\n",
      "Loss: 3.418023109436035\n",
      "Running Batch 567, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6215935945510864\n",
      "Loss: 3.470379114151001\n",
      "Running Batch 569, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.609013557434082\n",
      "Loss: 3.478050470352173\n",
      "Running Batch 571, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6870849132537842\n",
      "Loss: 3.4727866649627686\n",
      "Running Batch 573, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6917879581451416\n",
      "Loss: 3.452193260192871\n",
      "Running Batch 575, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.6601413488388062\n",
      "Loss: 3.4310731887817383\n",
      "Running Batch 577, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6540746688842773\n",
      "Loss: 3.38828444480896\n",
      "Running Batch 579, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.5930511951446533\n",
      "Loss: 3.4865550994873047\n",
      "Running Batch 581, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6521648168563843\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 581, Loss: 1.6521648168563843\n",
      "Loss: 3.4408681392669678\n",
      "Running Batch 583, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6383949518203735\n",
      "Loss: 3.5155844688415527\n",
      "Running Batch 585, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6338927745819092\n",
      "Loss: 3.4397025108337402\n",
      "Running Batch 587, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.615604281425476\n",
      "Loss: 3.4400131702423096\n",
      "Running Batch 589, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6673823595046997\n",
      "Loss: 3.4626545906066895\n",
      "Running Batch 591, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.5983730554580688\n",
      "Loss: 3.4574735164642334\n",
      "Running Batch 593, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.5315842628479004\n",
      "Loss: 3.473644971847534\n",
      "Running Batch 595, Epoch 3, Total Tokens: 257\n",
      "Loss: 1.6626142263412476\n",
      "Loss: 3.450695753097534\n",
      "Running Batch 597, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.668104887008667\n",
      "Loss: 3.5108602046966553\n",
      "Running Batch 599, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.634889841079712\n",
      "Loss: 3.418433427810669\n",
      "Running Batch 601, Epoch 3, Total Tokens: 340\n",
      "Loss: 1.5758568048477173\n",
      "Loss: 3.458066701889038\n",
      "Running Batch 603, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6284185647964478\n",
      "Loss: 3.4704761505126953\n",
      "Running Batch 605, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.5155109167099\n",
      "Loss: 3.5136725902557373\n",
      "Running Batch 607, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.5805084705352783\n",
      "Loss: 3.439988374710083\n",
      "Running Batch 609, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6171709299087524\n",
      "Loss: 3.4681806564331055\n",
      "Running Batch 611, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7414026260375977\n",
      "Loss: 3.450361967086792\n",
      "Running Batch 613, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6753425598144531\n",
      "Loss: 3.39090895652771\n",
      "Running Batch 615, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.691545009613037\n",
      "Loss: 3.486248254776001\n",
      "Running Batch 617, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.6319260597229004\n",
      "Loss: 3.5049219131469727\n",
      "Running Batch 619, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6041324138641357\n",
      "Loss: 3.4792637825012207\n",
      "Running Batch 621, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6879347562789917\n",
      "Loss: 3.3972156047821045\n",
      "Running Batch 623, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.604112982749939\n",
      "Loss: 3.4800236225128174\n",
      "Running Batch 625, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6145246028900146\n",
      "Loss: 3.505375385284424\n",
      "Running Batch 627, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6256986856460571\n",
      "Loss: 3.4490084648132324\n",
      "Running Batch 629, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6747609376907349\n",
      "Loss: 3.476107597351074\n",
      "Running Batch 631, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6070642471313477\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 631, Loss: 1.6070642471313477\n",
      "Loss: 3.5365896224975586\n",
      "Running Batch 633, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6382057666778564\n",
      "Loss: 3.467386484146118\n",
      "Running Batch 635, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6332204341888428\n",
      "Loss: 3.435861587524414\n",
      "Running Batch 637, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6215777397155762\n",
      "Loss: 3.424041509628296\n",
      "Running Batch 639, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6561989784240723\n",
      "Loss: 3.5206992626190186\n",
      "Running Batch 641, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6420122385025024\n",
      "Loss: 3.4795544147491455\n",
      "Running Batch 643, Epoch 3, Total Tokens: 197\n",
      "Loss: 1.6116737127304077\n",
      "Loss: 3.4460415840148926\n",
      "Running Batch 645, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6195319890975952\n",
      "Loss: 3.477945566177368\n",
      "Running Batch 647, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7383054494857788\n",
      "Loss: 3.4435954093933105\n",
      "Running Batch 649, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.599141001701355\n",
      "Loss: 3.49509596824646\n",
      "Running Batch 651, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6458526849746704\n",
      "Loss: 3.5174591541290283\n",
      "Running Batch 653, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.5898733139038086\n",
      "Loss: 3.4421727657318115\n",
      "Running Batch 655, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6623934507369995\n",
      "Loss: 3.4435486793518066\n",
      "Running Batch 657, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6739580631256104\n",
      "Loss: 3.391064167022705\n",
      "Running Batch 659, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6914136409759521\n",
      "Loss: 3.4908876419067383\n",
      "Running Batch 661, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6772738695144653\n",
      "Loss: 3.496736526489258\n",
      "Running Batch 663, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6881563663482666\n",
      "Loss: 3.4741082191467285\n",
      "Running Batch 665, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.653418779373169\n",
      "Loss: 3.474219799041748\n",
      "Running Batch 667, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.6177449226379395\n",
      "Loss: 3.5299718379974365\n",
      "Running Batch 669, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6338828802108765\n",
      "Loss: 3.4982869625091553\n",
      "Running Batch 671, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.5626697540283203\n",
      "Loss: 3.452707290649414\n",
      "Running Batch 673, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.5652989149093628\n",
      "Loss: 3.4468464851379395\n",
      "Running Batch 675, Epoch 3, Total Tokens: 195\n",
      "Loss: 1.6908485889434814\n",
      "Loss: 3.543210506439209\n",
      "Running Batch 677, Epoch 3, Total Tokens: 258\n",
      "Loss: 1.6819254159927368\n",
      "Loss: 3.527376890182495\n",
      "Running Batch 679, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6650112867355347\n",
      "Loss: 3.4177486896514893\n",
      "Running Batch 681, Epoch 3, Total Tokens: 285\n",
      "Loss: 1.6623704433441162\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 681, Loss: 1.6623704433441162\n",
      "Loss: 3.453659772872925\n",
      "Running Batch 683, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6735979318618774\n",
      "Loss: 3.483131170272827\n",
      "Running Batch 685, Epoch 3, Total Tokens: 225\n",
      "Loss: 1.6073981523513794\n",
      "Loss: 3.468519449234009\n",
      "Running Batch 687, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6182502508163452\n",
      "Loss: 3.4939708709716797\n",
      "Running Batch 689, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6233450174331665\n",
      "Loss: 3.5048155784606934\n",
      "Running Batch 691, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.608559250831604\n",
      "Loss: 3.47619366645813\n",
      "Running Batch 693, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6903934478759766\n",
      "Loss: 3.4716761112213135\n",
      "Running Batch 695, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6919955015182495\n",
      "Loss: 3.472752332687378\n",
      "Running Batch 697, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6223652362823486\n",
      "Loss: 3.465053081512451\n",
      "Running Batch 699, Epoch 3, Total Tokens: 220\n",
      "Loss: 1.6649268865585327\n",
      "Loss: 3.424044370651245\n",
      "Running Batch 701, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.6608198881149292\n",
      "Loss: 3.444149971008301\n",
      "Running Batch 703, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6439688205718994\n",
      "Loss: 3.488804817199707\n",
      "Running Batch 705, Epoch 3, Total Tokens: 367\n",
      "Loss: 1.6083122491836548\n",
      "Loss: 3.497816324234009\n",
      "Running Batch 707, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.630195140838623\n",
      "Loss: 3.5570549964904785\n",
      "Running Batch 709, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.5974793434143066\n",
      "Loss: 3.4784297943115234\n",
      "Running Batch 711, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6772809028625488\n",
      "Loss: 3.4688515663146973\n",
      "Running Batch 713, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.5943759679794312\n",
      "Loss: 3.4497482776641846\n",
      "Running Batch 715, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6554011106491089\n",
      "Loss: 3.4534835815429688\n",
      "Running Batch 717, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6569371223449707\n",
      "Loss: 3.4663732051849365\n",
      "Running Batch 719, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.5987204313278198\n",
      "Loss: 3.4943299293518066\n",
      "Running Batch 721, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.5812968015670776\n",
      "Loss: 3.458468437194824\n",
      "Running Batch 723, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.6097447872161865\n",
      "Loss: 3.4503304958343506\n",
      "Running Batch 725, Epoch 3, Total Tokens: 228\n",
      "Loss: 1.5784366130828857\n",
      "Loss: 3.5068323612213135\n",
      "Running Batch 727, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.6350127458572388\n",
      "Loss: 3.430617094039917\n",
      "Running Batch 729, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6144276857376099\n",
      "Loss: 3.4813568592071533\n",
      "Running Batch 731, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.6413580179214478\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 731, Loss: 1.6413580179214478\n",
      "Loss: 3.5113027095794678\n",
      "Running Batch 733, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6417676210403442\n",
      "Loss: 3.4548091888427734\n",
      "Running Batch 735, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.5757020711898804\n",
      "Loss: 3.5278592109680176\n",
      "Running Batch 737, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.5847550630569458\n",
      "Loss: 3.473482847213745\n",
      "Running Batch 739, Epoch 3, Total Tokens: 293\n",
      "Loss: 1.6239699125289917\n",
      "Loss: 3.41329026222229\n",
      "Running Batch 741, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.5945185422897339\n",
      "Loss: 3.4424257278442383\n",
      "Running Batch 743, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6808828115463257\n",
      "Loss: 3.4889702796936035\n",
      "Running Batch 745, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.7020301818847656\n",
      "Loss: 3.484408378601074\n",
      "Running Batch 747, Epoch 3, Total Tokens: 326\n",
      "Loss: 1.6250367164611816\n",
      "Loss: 3.541529893875122\n",
      "Running Batch 749, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.6766202449798584\n",
      "Loss: 3.4930121898651123\n",
      "Running Batch 751, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6801666021347046\n",
      "Loss: 3.504542350769043\n",
      "Running Batch 753, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6844741106033325\n",
      "Loss: 3.497653007507324\n",
      "Running Batch 755, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7358328104019165\n",
      "Loss: 3.4579787254333496\n",
      "Running Batch 757, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6815105676651\n",
      "Loss: 3.4550540447235107\n",
      "Running Batch 759, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6345356702804565\n",
      "Loss: 3.4715182781219482\n",
      "Running Batch 761, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.5673880577087402\n",
      "Loss: 3.4137027263641357\n",
      "Running Batch 763, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7122220993041992\n",
      "Loss: 3.547339916229248\n",
      "Running Batch 765, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6141175031661987\n",
      "Loss: 3.492654323577881\n",
      "Running Batch 767, Epoch 3, Total Tokens: 286\n",
      "Loss: 1.7065907716751099\n",
      "Loss: 3.4644360542297363\n",
      "Running Batch 769, Epoch 3, Total Tokens: 192\n",
      "Loss: 1.6546224355697632\n",
      "Loss: 3.4536406993865967\n",
      "Running Batch 771, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.6690953969955444\n",
      "Loss: 3.4814186096191406\n",
      "Running Batch 773, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6934921741485596\n",
      "Loss: 3.505964994430542\n",
      "Running Batch 775, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6166949272155762\n",
      "Loss: 3.414515972137451\n",
      "Running Batch 777, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6243423223495483\n",
      "Loss: 3.456312417984009\n",
      "Running Batch 779, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.6582818031311035\n",
      "Loss: 3.4298245906829834\n",
      "Running Batch 781, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6332168579101562\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 781, Loss: 1.6332168579101562\n",
      "AVG LOSS: 2.5597133776720833, Epoch: 4\n",
      "Loss: 3.4719536304473877\n",
      "Running Batch 1, Epoch 4, Total Tokens: 156\n",
      "Loss: 1.6057219505310059\n",
      "Loss: 3.4325785636901855\n",
      "Running Batch 3, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.5831888914108276\n",
      "Loss: 3.455125331878662\n",
      "Running Batch 5, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.6576751470565796\n",
      "Loss: 3.454340934753418\n",
      "Running Batch 7, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.5613069534301758\n",
      "Loss: 3.4924814701080322\n",
      "Running Batch 9, Epoch 4, Total Tokens: 322\n",
      "Loss: 1.5232298374176025\n",
      "Loss: 3.4647343158721924\n",
      "Running Batch 11, Epoch 4, Total Tokens: 138\n",
      "Loss: 1.6650195121765137\n",
      "Loss: 3.522148847579956\n",
      "Running Batch 13, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.6698822975158691\n",
      "Loss: 3.4638049602508545\n",
      "Running Batch 15, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5987321138381958\n",
      "Loss: 3.4729373455047607\n",
      "Running Batch 17, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.606701135635376\n",
      "Loss: 3.5090320110321045\n",
      "Running Batch 19, Epoch 4, Total Tokens: 237\n",
      "Loss: 1.5933942794799805\n",
      "Loss: 3.433417320251465\n",
      "Running Batch 21, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.6758958101272583\n",
      "Loss: 3.435610771179199\n",
      "Running Batch 23, Epoch 4, Total Tokens: 143\n",
      "Loss: 1.6058623790740967\n",
      "Loss: 3.534923791885376\n",
      "Running Batch 25, Epoch 4, Total Tokens: 237\n",
      "Loss: 1.5673056840896606\n",
      "Loss: 3.4245171546936035\n",
      "Running Batch 27, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.6247673034667969\n",
      "Loss: 3.4807748794555664\n",
      "Running Batch 29, Epoch 4, Total Tokens: 205\n",
      "Loss: 1.5805914402008057\n",
      "Loss: 3.502128839492798\n",
      "Running Batch 31, Epoch 4, Total Tokens: 257\n",
      "Loss: 1.584245204925537\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 31, Loss: 1.584245204925537\n",
      "Loss: 3.4666495323181152\n",
      "Running Batch 33, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.5193203687667847\n",
      "Loss: 3.4524214267730713\n",
      "Running Batch 35, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5700331926345825\n",
      "Loss: 3.4785664081573486\n",
      "Running Batch 37, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.6347479820251465\n",
      "Loss: 3.4920425415039062\n",
      "Running Batch 39, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5880612134933472\n",
      "Loss: 3.428725481033325\n",
      "Running Batch 41, Epoch 4, Total Tokens: 173\n",
      "Loss: 1.5947177410125732\n",
      "Loss: 3.404498338699341\n",
      "Running Batch 43, Epoch 4, Total Tokens: 142\n",
      "Loss: 1.5519647598266602\n",
      "Loss: 3.45538330078125\n",
      "Running Batch 45, Epoch 4, Total Tokens: 169\n",
      "Loss: 1.609004259109497\n",
      "Loss: 3.447136163711548\n",
      "Running Batch 47, Epoch 4, Total Tokens: 134\n",
      "Loss: 1.5853116512298584\n",
      "Loss: 3.4489498138427734\n",
      "Running Batch 49, Epoch 4, Total Tokens: 172\n",
      "Loss: 1.5862500667572021\n",
      "Loss: 3.4235668182373047\n",
      "Running Batch 51, Epoch 4, Total Tokens: 241\n",
      "Loss: 1.6330058574676514\n",
      "Loss: 3.475198984146118\n",
      "Running Batch 53, Epoch 4, Total Tokens: 258\n",
      "Loss: 1.6128751039505005\n",
      "Loss: 3.464031934738159\n",
      "Running Batch 55, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.681774616241455\n",
      "Loss: 3.44987154006958\n",
      "Running Batch 57, Epoch 4, Total Tokens: 152\n",
      "Loss: 1.6075834035873413\n",
      "Loss: 3.444819688796997\n",
      "Running Batch 59, Epoch 4, Total Tokens: 151\n",
      "Loss: 1.5839813947677612\n",
      "Loss: 3.467223644256592\n",
      "Running Batch 61, Epoch 4, Total Tokens: 293\n",
      "Loss: 1.6039514541625977\n",
      "Loss: 3.461357831954956\n",
      "Running Batch 63, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.5925438404083252\n",
      "Loss: 3.4169466495513916\n",
      "Running Batch 65, Epoch 4, Total Tokens: 251\n",
      "Loss: 1.5911509990692139\n",
      "Loss: 3.473968029022217\n",
      "Running Batch 67, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.665952444076538\n",
      "Loss: 3.424593687057495\n",
      "Running Batch 69, Epoch 4, Total Tokens: 195\n",
      "Loss: 1.5984934568405151\n",
      "Loss: 3.445493459701538\n",
      "Running Batch 71, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.650244116783142\n",
      "Loss: 3.4181673526763916\n",
      "Running Batch 73, Epoch 4, Total Tokens: 143\n",
      "Loss: 1.5936287641525269\n",
      "Loss: 3.448439359664917\n",
      "Running Batch 75, Epoch 4, Total Tokens: 134\n",
      "Loss: 1.6301583051681519\n",
      "Loss: 3.4748735427856445\n",
      "Running Batch 77, Epoch 4, Total Tokens: 360\n",
      "Loss: 1.6275533437728882\n",
      "Loss: 3.5135316848754883\n",
      "Running Batch 79, Epoch 4, Total Tokens: 159\n",
      "Loss: 1.5727479457855225\n",
      "Loss: 3.5175323486328125\n",
      "Running Batch 81, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.5855993032455444\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 81, Loss: 1.5855993032455444\n",
      "Loss: 3.4348316192626953\n",
      "Running Batch 83, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.5650690793991089\n",
      "Loss: 3.4819958209991455\n",
      "Running Batch 85, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.611211895942688\n",
      "Loss: 3.423602819442749\n",
      "Running Batch 87, Epoch 4, Total Tokens: 220\n",
      "Loss: 1.5995415449142456\n",
      "Loss: 3.462038993835449\n",
      "Running Batch 89, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.6267714500427246\n",
      "Loss: 3.4329993724823\n",
      "Running Batch 91, Epoch 4, Total Tokens: 267\n",
      "Loss: 1.6997729539871216\n",
      "Loss: 3.4547550678253174\n",
      "Running Batch 93, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.646953821182251\n",
      "Loss: 3.4497714042663574\n",
      "Running Batch 95, Epoch 4, Total Tokens: 132\n",
      "Loss: 1.5905958414077759\n",
      "Loss: 3.5083816051483154\n",
      "Running Batch 97, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6553963422775269\n",
      "Loss: 3.4729819297790527\n",
      "Running Batch 99, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.6996840238571167\n",
      "Loss: 3.449064254760742\n",
      "Running Batch 101, Epoch 4, Total Tokens: 151\n",
      "Loss: 1.5709832906723022\n",
      "Loss: 3.419525384902954\n",
      "Running Batch 103, Epoch 4, Total Tokens: 230\n",
      "Loss: 1.556304931640625\n",
      "Loss: 3.4508235454559326\n",
      "Running Batch 105, Epoch 4, Total Tokens: 143\n",
      "Loss: 1.6761550903320312\n",
      "Loss: 3.4980671405792236\n",
      "Running Batch 107, Epoch 4, Total Tokens: 199\n",
      "Loss: 1.692878007888794\n",
      "Loss: 3.497957706451416\n",
      "Running Batch 109, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6179229021072388\n",
      "Loss: 3.4894349575042725\n",
      "Running Batch 111, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.6977581977844238\n",
      "Loss: 3.424900531768799\n",
      "Running Batch 113, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6114481687545776\n",
      "Loss: 3.415342092514038\n",
      "Running Batch 115, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.6150211095809937\n",
      "Loss: 3.4311647415161133\n",
      "Running Batch 117, Epoch 4, Total Tokens: 135\n",
      "Loss: 1.5881699323654175\n",
      "Loss: 3.4509034156799316\n",
      "Running Batch 119, Epoch 4, Total Tokens: 120\n",
      "Loss: 1.6617463827133179\n",
      "Loss: 3.4671871662139893\n",
      "Running Batch 121, Epoch 4, Total Tokens: 170\n",
      "Loss: 1.6316556930541992\n",
      "Loss: 3.474809408187866\n",
      "Running Batch 123, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.6355514526367188\n",
      "Loss: 3.5008389949798584\n",
      "Running Batch 125, Epoch 4, Total Tokens: 136\n",
      "Loss: 1.639980673789978\n",
      "Loss: 3.4709086418151855\n",
      "Running Batch 127, Epoch 4, Total Tokens: 141\n",
      "Loss: 1.5496892929077148\n",
      "Loss: 3.4394032955169678\n",
      "Running Batch 129, Epoch 4, Total Tokens: 152\n",
      "Loss: 1.6144870519638062\n",
      "Loss: 3.4883313179016113\n",
      "Running Batch 131, Epoch 4, Total Tokens: 162\n",
      "Loss: 1.6167845726013184\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 131, Loss: 1.6167845726013184\n",
      "Loss: 3.4165656566619873\n",
      "Running Batch 133, Epoch 4, Total Tokens: 134\n",
      "Loss: 1.5647737979888916\n",
      "Loss: 3.4766323566436768\n",
      "Running Batch 135, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6004856824874878\n",
      "Loss: 3.485722303390503\n",
      "Running Batch 137, Epoch 4, Total Tokens: 228\n",
      "Loss: 1.5573525428771973\n",
      "Loss: 3.413594961166382\n",
      "Running Batch 139, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.617354154586792\n",
      "Loss: 3.4451091289520264\n",
      "Running Batch 141, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.590428113937378\n",
      "Loss: 3.4214601516723633\n",
      "Running Batch 143, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.580794334411621\n",
      "Loss: 3.471496343612671\n",
      "Running Batch 145, Epoch 4, Total Tokens: 299\n",
      "Loss: 1.6168757677078247\n",
      "Loss: 3.464792251586914\n",
      "Running Batch 147, Epoch 4, Total Tokens: 158\n",
      "Loss: 1.6200156211853027\n",
      "Loss: 3.447474241256714\n",
      "Running Batch 149, Epoch 4, Total Tokens: 131\n",
      "Loss: 1.5639699697494507\n",
      "Loss: 3.4173457622528076\n",
      "Running Batch 151, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.6175897121429443\n",
      "Loss: 3.4207451343536377\n",
      "Running Batch 153, Epoch 4, Total Tokens: 199\n",
      "Loss: 1.648491621017456\n",
      "Loss: 3.4717867374420166\n",
      "Running Batch 155, Epoch 4, Total Tokens: 225\n",
      "Loss: 1.6567002534866333\n",
      "Loss: 3.424720048904419\n",
      "Running Batch 157, Epoch 4, Total Tokens: 173\n",
      "Loss: 1.637130856513977\n",
      "Loss: 3.4165234565734863\n",
      "Running Batch 159, Epoch 4, Total Tokens: 157\n",
      "Loss: 1.7118200063705444\n",
      "Loss: 3.4746718406677246\n",
      "Running Batch 161, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.5872794389724731\n",
      "Loss: 3.4899332523345947\n",
      "Running Batch 163, Epoch 4, Total Tokens: 206\n",
      "Loss: 1.626576542854309\n",
      "Loss: 3.546875\n",
      "Running Batch 165, Epoch 4, Total Tokens: 206\n",
      "Loss: 1.6021414995193481\n",
      "Loss: 3.462146282196045\n",
      "Running Batch 167, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.61906099319458\n",
      "Loss: 3.4983785152435303\n",
      "Running Batch 169, Epoch 4, Total Tokens: 117\n",
      "Loss: 1.5691355466842651\n",
      "Loss: 3.497206687927246\n",
      "Running Batch 171, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6443721055984497\n",
      "Loss: 3.4367902278900146\n",
      "Running Batch 173, Epoch 4, Total Tokens: 122\n",
      "Loss: 1.5480103492736816\n",
      "Loss: 3.4631268978118896\n",
      "Running Batch 175, Epoch 4, Total Tokens: 142\n",
      "Loss: 1.6547753810882568\n",
      "Loss: 3.4576165676116943\n",
      "Running Batch 177, Epoch 4, Total Tokens: 138\n",
      "Loss: 1.6713342666625977\n",
      "Loss: 3.4583382606506348\n",
      "Running Batch 179, Epoch 4, Total Tokens: 143\n",
      "Loss: 1.6427514553070068\n",
      "Loss: 3.470452308654785\n",
      "Running Batch 181, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5897645950317383\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 181, Loss: 1.5897645950317383\n",
      "Loss: 3.439258575439453\n",
      "Running Batch 183, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6225405931472778\n",
      "Loss: 3.4216833114624023\n",
      "Running Batch 185, Epoch 4, Total Tokens: 156\n",
      "Loss: 1.6469922065734863\n",
      "Loss: 3.425612688064575\n",
      "Running Batch 187, Epoch 4, Total Tokens: 122\n",
      "Loss: 1.5495450496673584\n",
      "Loss: 3.4041950702667236\n",
      "Running Batch 189, Epoch 4, Total Tokens: 196\n",
      "Loss: 1.6455116271972656\n",
      "Loss: 3.4469504356384277\n",
      "Running Batch 191, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.6644178628921509\n",
      "Loss: 3.441279172897339\n",
      "Running Batch 193, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6336510181427002\n",
      "Loss: 3.4987549781799316\n",
      "Running Batch 195, Epoch 4, Total Tokens: 182\n",
      "Loss: 1.600796103477478\n",
      "Loss: 3.423182487487793\n",
      "Running Batch 197, Epoch 4, Total Tokens: 219\n",
      "Loss: 1.5608880519866943\n",
      "Loss: 3.4618592262268066\n",
      "Running Batch 199, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.673319935798645\n",
      "Loss: 3.485089063644409\n",
      "Running Batch 201, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.655696153640747\n",
      "Loss: 3.4965219497680664\n",
      "Running Batch 203, Epoch 4, Total Tokens: 141\n",
      "Loss: 1.5656789541244507\n",
      "Loss: 3.4678945541381836\n",
      "Running Batch 205, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.5455266237258911\n",
      "Loss: 3.5050508975982666\n",
      "Running Batch 207, Epoch 4, Total Tokens: 188\n",
      "Loss: 1.6308481693267822\n",
      "Loss: 3.4656896591186523\n",
      "Running Batch 209, Epoch 4, Total Tokens: 136\n",
      "Loss: 1.586459755897522\n",
      "Loss: 3.3811936378479004\n",
      "Running Batch 211, Epoch 4, Total Tokens: 164\n",
      "Loss: 1.5844844579696655\n",
      "Loss: 3.4780054092407227\n",
      "Running Batch 213, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.599646806716919\n",
      "Loss: 3.464296340942383\n",
      "Running Batch 215, Epoch 4, Total Tokens: 152\n",
      "Loss: 1.6006276607513428\n",
      "Loss: 3.414405345916748\n",
      "Running Batch 217, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.541067361831665\n",
      "Loss: 3.4566218852996826\n",
      "Running Batch 219, Epoch 4, Total Tokens: 176\n",
      "Loss: 1.6683719158172607\n",
      "Loss: 3.4799654483795166\n",
      "Running Batch 221, Epoch 4, Total Tokens: 179\n",
      "Loss: 1.6241886615753174\n",
      "Loss: 3.475663900375366\n",
      "Running Batch 223, Epoch 4, Total Tokens: 172\n",
      "Loss: 1.6017212867736816\n",
      "Loss: 3.505441427230835\n",
      "Running Batch 225, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.575695514678955\n",
      "Loss: 3.4739573001861572\n",
      "Running Batch 227, Epoch 4, Total Tokens: 219\n",
      "Loss: 1.6359827518463135\n",
      "Loss: 3.4760022163391113\n",
      "Running Batch 229, Epoch 4, Total Tokens: 143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\0Sem5\\774\\A4\\COL774-Ass_4-img2latex\\Q1_NonComp\\img2latex.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39m# for name, param in model.named_parameters():\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39m#     if param.requires_grad:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m#         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39;49mitem()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m curr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/0Sem5/774/A4/COL774-Ass_4-img2latex/Q1_NonComp/img2latex.ipynb#W6sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39mif\u001b[39;00m bidx \u001b[39m%\u001b[39m \u001b[39m50\u001b[39m \u001b[39m==\u001b[39m \u001b[39m31\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# print(f\"Longest formula in training: {max([len(formula) for formula in dataset.data_frame['IndexList']])}\")\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0).to(device)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0].to(device)\n",
    "\n",
    "   return labels[:, :len(non_pad_cols)].to(device)\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = enc.hp[\"batch_size\"], shuffle = True)\n",
    "print(len(loader))\n",
    "model_path = \"./models/model.pt\"\n",
    "model_backup_path = \"./models/model_backup.pt\"\n",
    "current_params_path = \"./models/current_params.txt\" \n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "torch.save((state_dict), model_backup_path)\n",
    "model.load_state_dict(state_dict)\n",
    "if device == \"cuda\":\n",
    "    model.cuda()\n",
    "model.train()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "fifty_fifty = True\n",
    "teacher_forcing = False\n",
    "#5\n",
    "prev_loss = 100\n",
    "for epoch in range(5):\n",
    "    curr_loss = 0\n",
    "    for bidx, batch in enumerate(loader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels = remove_trailing_pads(labels).to(device)\n",
    "        context_vec = model.encoder(images).squeeze()\n",
    "        if (bidx%2 and fifty_fifty) or teacher_forcing:\n",
    "            inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2).to(device)\n",
    "            print(f\"Running Batch {bidx}, Epoch {epoch}, Total Tokens: {labels.shape[1]}\")\n",
    "            output, _ = model.decoder(inputs, None)\n",
    "\n",
    "            # output[labels == PAD_IDX] = 0\n",
    "            # output = F.normalize(output, dim=2, p=1)\n",
    "            output = output[:, :-1, :].to(device)\n",
    "\n",
    "        else:\n",
    "            output = torch.zeros((labels.shape[0], labels.shape[1]-1, len(dataset.tokens))).to(device)\n",
    "\n",
    "            prev_token = torch.ones(labels.shape[0], dtype=int).to(device) * dataset.token_to_idx[SOS]\n",
    "            prev_token_embed = model.decoder.embedding(prev_token)\n",
    "\n",
    "            input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            hidden = None\n",
    "\n",
    "            for i in range(labels.shape[1]-1):\n",
    "                output[:, i, :], hidden = model.decoder(input, hidden)\n",
    "                prev_token = output[:, i, :].argmax(dim=1).to(device)\n",
    "                prev_token_embed = model.decoder.embedding(prev_token)\n",
    "                input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            \n",
    "        target = nn.functional.one_hot(labels[:,1:], num_classes=len(dataset.tokens)).float().to(device)\n",
    "        # target[labels == PAD_IDX] = 0\n",
    "        mask = (labels[:,1:] != PAD_IDX).to(device)\n",
    "        \n",
    "        # print(f\"Output shape: {output.shape}, Labels shape: {labels.shape}, Target shape: {target.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.transpose(1, 2), target.transpose(1, 2))\n",
    "        loss = loss * mask\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        curr_loss += loss.item()\n",
    "        if bidx % 50 == 31:\n",
    "            print(f\"SAVING MODEL to {model_path}\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"SAVED MODEL\")\n",
    "            print(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            try:\n",
    "                with open(current_params_path, 'w') as f:\n",
    "                    f.write(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            except:\n",
    "                print(\"\\n Could not write to file \\n\")\n",
    "    print(f\"AVG LOSS: {(curr_loss)/len(loader)}, Epoch: {epoch+1}\")\n",
    "    prev_loss = curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/model_5050synth.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "LOADED MODEL to cuda\n",
      "Loss: 3.360403060913086\n",
      "Running Batch 1, Epoch 0, Total Tokens: 47\n",
      "Loss: 2.326866865158081\n",
      "Loss: 3.342487096786499\n",
      "Running Batch 3, Epoch 0, Total Tokens: 62\n",
      "Loss: 2.3777458667755127\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 3, Loss: 2.3777458667755127\n",
      "Loss: 3.4200334548950195\n",
      "Running Batch 5, Epoch 0, Total Tokens: 41\n",
      "Loss: 2.2986724376678467\n",
      "Loss: 3.3513641357421875\n",
      "Running Batch 7, Epoch 0, Total Tokens: 67\n",
      "Loss: 2.219982862472534\n",
      "Loss: 3.358943462371826\n",
      "Running Batch 9, Epoch 0, Total Tokens: 49\n",
      "Loss: 2.2783100605010986\n",
      "Loss: 3.3715741634368896\n",
      "Running Batch 11, Epoch 0, Total Tokens: 68\n",
      "Loss: 2.3097708225250244\n",
      "Loss: 3.4539377689361572\n",
      "Running Batch 13, Epoch 0, Total Tokens: 63\n",
      "Loss: 2.262005090713501\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 13, Loss: 2.262005090713501\n",
      "Loss: 3.5153329372406006\n",
      "Running Batch 15, Epoch 0, Total Tokens: 52\n",
      "Loss: 2.3101136684417725\n",
      "Loss: 3.2356104850769043\n",
      "Running Batch 17, Epoch 0, Total Tokens: 51\n",
      "Loss: 2.324134588241577\n",
      "Loss: 3.3241682052612305\n",
      "Running Batch 19, Epoch 0, Total Tokens: 63\n",
      "Loss: 2.3393683433532715\n",
      "Loss: 3.22208833694458\n",
      "Running Batch 21, Epoch 0, Total Tokens: 59\n",
      "Loss: 2.205688238143921\n",
      "Loss: 3.3803398609161377\n",
      "Running Batch 23, Epoch 0, Total Tokens: 53\n",
      "Loss: 2.4237070083618164\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 23, Loss: 2.4237070083618164\n",
      "Loss: 3.429542064666748\n",
      "Running Batch 25, Epoch 0, Total Tokens: 45\n",
      "Loss: 2.2955567836761475\n",
      "Loss: 3.2666537761688232\n",
      "Running Batch 27, Epoch 0, Total Tokens: 85\n",
      "Loss: 2.120985507965088\n",
      "Loss: 3.3067214488983154\n",
      "Running Batch 29, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.2899580001831055\n",
      "Loss: 3.342559576034546\n",
      "Running Batch 31, Epoch 0, Total Tokens: 80\n",
      "Loss: 2.2876317501068115\n",
      "Loss: 3.3147101402282715\n",
      "Running Batch 33, Epoch 0, Total Tokens: 68\n",
      "Loss: 2.2468020915985107\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 33, Loss: 2.2468020915985107\n",
      "Loss: 3.4043521881103516\n",
      "Running Batch 35, Epoch 0, Total Tokens: 48\n",
      "Loss: 2.381270408630371\n",
      "Loss: 3.3531322479248047\n",
      "Running Batch 37, Epoch 0, Total Tokens: 47\n",
      "Loss: 2.2905752658843994\n",
      "Loss: 3.350146532058716\n",
      "Running Batch 39, Epoch 0, Total Tokens: 60\n",
      "Loss: 2.1753594875335693\n",
      "Loss: 3.3509299755096436\n",
      "Running Batch 41, Epoch 0, Total Tokens: 68\n",
      "Loss: 2.209080457687378\n",
      "Loss: 3.3531925678253174\n",
      "Running Batch 43, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.168055295944214\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 43, Loss: 2.168055295944214\n",
      "Loss: 3.4565718173980713\n",
      "Running Batch 45, Epoch 0, Total Tokens: 57\n",
      "Loss: 2.3301708698272705\n",
      "Loss: 3.4060192108154297\n",
      "Running Batch 47, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.22983455657959\n",
      "Loss: 3.3772685527801514\n",
      "Running Batch 49, Epoch 0, Total Tokens: 59\n",
      "Loss: 2.1961100101470947\n",
      "Loss: 3.2541792392730713\n",
      "Running Batch 51, Epoch 0, Total Tokens: 48\n",
      "Loss: 2.3280019760131836\n",
      "Loss: 3.2881481647491455\n",
      "Running Batch 53, Epoch 0, Total Tokens: 50\n",
      "Loss: 2.2250304222106934\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 53, Loss: 2.2250304222106934\n",
      "Loss: 3.4228785037994385\n",
      "Running Batch 55, Epoch 0, Total Tokens: 62\n",
      "Loss: 2.333462715148926\n",
      "Loss: 3.33427095413208\n",
      "Running Batch 57, Epoch 0, Total Tokens: 55\n",
      "Loss: 2.1897168159484863\n",
      "Loss: 3.375459671020508\n",
      "Running Batch 59, Epoch 0, Total Tokens: 60\n",
      "Loss: 2.1781654357910156\n",
      "Loss: 3.407684803009033\n",
      "Running Batch 61, Epoch 0, Total Tokens: 60\n",
      "Loss: 2.1548290252685547\n",
      "Loss: 3.392469882965088\n",
      "Running Batch 63, Epoch 0, Total Tokens: 59\n",
      "Loss: 2.1523244380950928\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 63, Loss: 2.1523244380950928\n",
      "Loss: 3.489039421081543\n",
      "Running Batch 65, Epoch 0, Total Tokens: 76\n",
      "Loss: 2.328400135040283\n",
      "Loss: 3.3536500930786133\n",
      "Running Batch 67, Epoch 0, Total Tokens: 85\n",
      "Loss: 2.146305799484253\n",
      "Loss: 3.3851466178894043\n",
      "Running Batch 69, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.2579505443573\n",
      "Loss: 3.306020736694336\n",
      "Running Batch 71, Epoch 0, Total Tokens: 74\n",
      "Loss: 2.2817821502685547\n",
      "Loss: 3.3871982097625732\n",
      "Running Batch 73, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.2509706020355225\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 73, Loss: 2.2509706020355225\n",
      "Loss: 3.4498233795166016\n",
      "Running Batch 75, Epoch 0, Total Tokens: 52\n",
      "Loss: 2.3444266319274902\n",
      "Loss: 3.3012242317199707\n",
      "Running Batch 77, Epoch 0, Total Tokens: 60\n",
      "Loss: 2.181297540664673\n",
      "Loss: 3.390230894088745\n",
      "Running Batch 79, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.220290184020996\n",
      "Loss: 3.2307136058807373\n",
      "Running Batch 81, Epoch 0, Total Tokens: 59\n",
      "Loss: 2.239744186401367\n",
      "Loss: 3.278264045715332\n",
      "Running Batch 83, Epoch 0, Total Tokens: 85\n",
      "Loss: 2.2603251934051514\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 83, Loss: 2.2603251934051514\n",
      "Loss: 3.397301435470581\n",
      "Running Batch 85, Epoch 0, Total Tokens: 47\n",
      "Loss: 2.277956247329712\n",
      "Loss: 3.360790967941284\n",
      "Running Batch 87, Epoch 0, Total Tokens: 60\n",
      "Loss: 2.3065345287323\n",
      "Loss: 3.3389298915863037\n",
      "Running Batch 89, Epoch 0, Total Tokens: 88\n",
      "Loss: 2.2338316440582275\n",
      "Loss: 3.313471794128418\n",
      "Running Batch 91, Epoch 0, Total Tokens: 56\n",
      "Loss: 2.1616005897521973\n",
      "Loss: 3.315131902694702\n",
      "Running Batch 93, Epoch 0, Total Tokens: 48\n",
      "Loss: 2.365865707397461\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 93, Loss: 2.365865707397461\n",
      "AVG LOSS: 2.8099646847298803, Epoch: 1\n",
      "Loss: 3.362652063369751\n",
      "Running Batch 1, Epoch 1, Total Tokens: 60\n",
      "Loss: 2.382877826690674\n",
      "Loss: 3.248654842376709\n",
      "Running Batch 3, Epoch 1, Total Tokens: 47\n",
      "Loss: 2.230940580368042\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 3, Loss: 2.230940580368042\n",
      "Loss: 3.3193318843841553\n",
      "Running Batch 5, Epoch 1, Total Tokens: 85\n",
      "Loss: 2.140791416168213\n",
      "Loss: 3.319697141647339\n",
      "Running Batch 7, Epoch 1, Total Tokens: 56\n",
      "Loss: 2.102961778640747\n",
      "Loss: 3.3257715702056885\n",
      "Running Batch 9, Epoch 1, Total Tokens: 51\n",
      "Loss: 2.297478199005127\n",
      "Loss: 3.288201093673706\n",
      "Running Batch 11, Epoch 1, Total Tokens: 49\n",
      "Loss: 2.2890093326568604\n",
      "Loss: 3.192025661468506\n",
      "Running Batch 13, Epoch 1, Total Tokens: 52\n",
      "Loss: 2.301992177963257\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 13, Loss: 2.301992177963257\n",
      "Loss: 3.3090577125549316\n",
      "Running Batch 15, Epoch 1, Total Tokens: 60\n",
      "Loss: 2.2289230823516846\n",
      "Loss: 3.4103360176086426\n",
      "Running Batch 17, Epoch 1, Total Tokens: 85\n",
      "Loss: 2.390683650970459\n",
      "Loss: 3.391937017440796\n",
      "Running Batch 19, Epoch 1, Total Tokens: 68\n",
      "Loss: 2.185391902923584\n",
      "Loss: 3.4319045543670654\n",
      "Running Batch 21, Epoch 1, Total Tokens: 76\n",
      "Loss: 2.2381458282470703\n",
      "Loss: 3.3480422496795654\n",
      "Running Batch 23, Epoch 1, Total Tokens: 52\n",
      "Loss: 2.1482911109924316\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 23, Loss: 2.1482911109924316\n",
      "Loss: 3.292403221130371\n",
      "Running Batch 25, Epoch 1, Total Tokens: 62\n",
      "Loss: 2.202954053878784\n",
      "Loss: 3.380362033843994\n",
      "Running Batch 27, Epoch 1, Total Tokens: 59\n",
      "Loss: 2.2516517639160156\n",
      "Loss: 3.382932186126709\n",
      "Running Batch 29, Epoch 1, Total Tokens: 74\n",
      "Loss: 2.278650999069214\n",
      "Loss: 3.3593523502349854\n",
      "Running Batch 31, Epoch 1, Total Tokens: 71\n",
      "Loss: 2.2646727561950684\n",
      "Loss: 3.3400955200195312\n",
      "Running Batch 33, Epoch 1, Total Tokens: 50\n",
      "Loss: 2.233950614929199\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 33, Loss: 2.233950614929199\n",
      "Loss: 3.3461291790008545\n",
      "Running Batch 35, Epoch 1, Total Tokens: 68\n",
      "Loss: 2.3153796195983887\n",
      "Loss: 3.308950901031494\n",
      "Running Batch 37, Epoch 1, Total Tokens: 49\n",
      "Loss: 2.327169418334961\n",
      "Loss: 3.3026952743530273\n",
      "Running Batch 39, Epoch 1, Total Tokens: 59\n",
      "Loss: 2.199312925338745\n",
      "Loss: 3.2442381381988525\n",
      "Running Batch 41, Epoch 1, Total Tokens: 48\n",
      "Loss: 2.1749470233917236\n",
      "Loss: 3.254330635070801\n",
      "Running Batch 43, Epoch 1, Total Tokens: 62\n",
      "Loss: 2.176795482635498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 43, Loss: 2.176795482635498\n",
      "Loss: 3.3099310398101807\n",
      "Running Batch 45, Epoch 1, Total Tokens: 60\n",
      "Loss: 2.298553705215454\n",
      "Loss: 3.405684471130371\n",
      "Running Batch 47, Epoch 1, Total Tokens: 54\n",
      "Loss: 2.2500743865966797\n",
      "Loss: 3.4203109741210938\n",
      "Running Batch 49, Epoch 1, Total Tokens: 52\n",
      "Loss: 2.358830213546753\n",
      "Loss: 3.354311227798462\n",
      "Running Batch 51, Epoch 1, Total Tokens: 60\n",
      "Loss: 2.2247049808502197\n",
      "Loss: 3.3581342697143555\n",
      "Running Batch 53, Epoch 1, Total Tokens: 80\n",
      "Loss: 2.030219316482544\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 53, Loss: 2.030219316482544\n",
      "Loss: 3.398555040359497\n",
      "Running Batch 55, Epoch 1, Total Tokens: 55\n",
      "Loss: 2.314760446548462\n",
      "Loss: 3.472215414047241\n",
      "Running Batch 57, Epoch 1, Total Tokens: 49\n",
      "Loss: 2.2710158824920654\n",
      "Loss: 3.333163022994995\n",
      "Running Batch 59, Epoch 1, Total Tokens: 56\n",
      "Loss: 2.2085089683532715\n",
      "Loss: 3.238638162612915\n",
      "Running Batch 61, Epoch 1, Total Tokens: 85\n",
      "Loss: 2.1819405555725098\n",
      "Loss: 3.449204921722412\n",
      "Running Batch 63, Epoch 1, Total Tokens: 47\n",
      "Loss: 2.1998496055603027\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 63, Loss: 2.1998496055603027\n",
      "Loss: 3.4236936569213867\n",
      "Running Batch 65, Epoch 1, Total Tokens: 85\n",
      "Loss: 2.24733829498291\n",
      "Loss: 3.2578036785125732\n",
      "Running Batch 67, Epoch 1, Total Tokens: 59\n",
      "Loss: 2.255251169204712\n",
      "Loss: 3.2665367126464844\n",
      "Running Batch 69, Epoch 1, Total Tokens: 57\n",
      "Loss: 2.187896490097046\n",
      "Loss: 3.3028650283813477\n",
      "Running Batch 71, Epoch 1, Total Tokens: 67\n",
      "Loss: 2.1418087482452393\n",
      "Loss: 3.3048272132873535\n",
      "Running Batch 73, Epoch 1, Total Tokens: 49\n",
      "Loss: 2.217881679534912\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 73, Loss: 2.217881679534912\n",
      "Loss: 3.448953151702881\n",
      "Running Batch 75, Epoch 1, Total Tokens: 51\n",
      "Loss: 2.363025188446045\n",
      "Loss: 3.237436056137085\n",
      "Running Batch 77, Epoch 1, Total Tokens: 48\n",
      "Loss: 2.110302448272705\n",
      "Loss: 3.3923985958099365\n",
      "Running Batch 79, Epoch 1, Total Tokens: 46\n",
      "Loss: 2.2309396266937256\n",
      "Loss: 3.4032363891601562\n",
      "Running Batch 81, Epoch 1, Total Tokens: 63\n",
      "Loss: 2.3375468254089355\n",
      "Loss: 3.336604595184326\n",
      "Running Batch 83, Epoch 1, Total Tokens: 85\n",
      "Loss: 2.1116180419921875\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 83, Loss: 2.1116180419921875\n",
      "Loss: 3.1377038955688477\n",
      "Running Batch 85, Epoch 1, Total Tokens: 63\n",
      "Loss: 2.2322206497192383\n",
      "Loss: 3.294463634490967\n",
      "Running Batch 87, Epoch 1, Total Tokens: 56\n",
      "Loss: 2.224374532699585\n",
      "Loss: 3.2976861000061035\n",
      "Running Batch 89, Epoch 1, Total Tokens: 68\n",
      "Loss: 2.1175742149353027\n",
      "Loss: 3.4161250591278076\n",
      "Running Batch 91, Epoch 1, Total Tokens: 53\n",
      "Loss: 2.202197551727295\n",
      "Loss: 3.3242251873016357\n",
      "Running Batch 93, Epoch 1, Total Tokens: 48\n",
      "Loss: 2.245609760284424\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 93, Loss: 2.245609760284424\n",
      "AVG LOSS: 2.783732165681555, Epoch: 2\n",
      "Loss: 3.3534483909606934\n",
      "Running Batch 1, Epoch 2, Total Tokens: 57\n",
      "Loss: 2.226038694381714\n",
      "Loss: 3.312363862991333\n",
      "Running Batch 3, Epoch 2, Total Tokens: 63\n",
      "Loss: 2.2719662189483643\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 3, Loss: 2.2719662189483643\n",
      "Loss: 3.279142379760742\n",
      "Running Batch 5, Epoch 2, Total Tokens: 60\n",
      "Loss: 2.254074811935425\n",
      "Loss: 3.3274548053741455\n",
      "Running Batch 7, Epoch 2, Total Tokens: 68\n",
      "Loss: 2.062358856201172\n",
      "Loss: 3.4102039337158203\n",
      "Running Batch 9, Epoch 2, Total Tokens: 84\n",
      "Loss: 2.209841728210449\n",
      "Loss: 3.2957961559295654\n",
      "Running Batch 11, Epoch 2, Total Tokens: 80\n",
      "Loss: 2.2022929191589355\n",
      "Loss: 3.4121804237365723\n",
      "Running Batch 13, Epoch 2, Total Tokens: 85\n",
      "Loss: 2.1656346321105957\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 13, Loss: 2.1656346321105957\n",
      "Loss: 3.3144772052764893\n",
      "Running Batch 15, Epoch 2, Total Tokens: 56\n",
      "Loss: 2.1860926151275635\n",
      "Loss: 3.350536823272705\n",
      "Running Batch 17, Epoch 2, Total Tokens: 49\n",
      "Loss: 2.212132453918457\n",
      "Loss: 3.2087182998657227\n",
      "Running Batch 19, Epoch 2, Total Tokens: 56\n",
      "Loss: 2.295711040496826\n",
      "Loss: 3.315560817718506\n",
      "Running Batch 21, Epoch 2, Total Tokens: 59\n",
      "Loss: 2.179090738296509\n",
      "Loss: 3.4560210704803467\n",
      "Running Batch 23, Epoch 2, Total Tokens: 60\n",
      "Loss: 2.2572221755981445\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 23, Loss: 2.2572221755981445\n",
      "Loss: 3.229839563369751\n",
      "Running Batch 25, Epoch 2, Total Tokens: 56\n",
      "Loss: 2.2123429775238037\n",
      "Loss: 3.2974114418029785\n",
      "Running Batch 27, Epoch 2, Total Tokens: 52\n",
      "Loss: 2.3454158306121826\n",
      "Loss: 3.2255754470825195\n",
      "Running Batch 29, Epoch 2, Total Tokens: 43\n",
      "Loss: 2.1329309940338135\n",
      "Loss: 3.346712589263916\n",
      "Running Batch 31, Epoch 2, Total Tokens: 85\n",
      "Loss: 2.2794077396392822\n",
      "Loss: 3.259169578552246\n",
      "Running Batch 33, Epoch 2, Total Tokens: 53\n",
      "Loss: 2.2924187183380127\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 33, Loss: 2.2924187183380127\n",
      "Loss: 3.3626298904418945\n",
      "Running Batch 35, Epoch 2, Total Tokens: 68\n",
      "Loss: 2.267859935760498\n",
      "Loss: 3.189545154571533\n",
      "Running Batch 37, Epoch 2, Total Tokens: 48\n",
      "Loss: 2.194645404815674\n",
      "Loss: 3.267940044403076\n",
      "Running Batch 39, Epoch 2, Total Tokens: 68\n",
      "Loss: 2.2795891761779785\n",
      "Loss: 3.360433578491211\n",
      "Running Batch 41, Epoch 2, Total Tokens: 62\n",
      "Loss: 2.303393602371216\n",
      "Loss: 3.3241653442382812\n",
      "Running Batch 43, Epoch 2, Total Tokens: 42\n",
      "Loss: 2.3063809871673584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 43, Loss: 2.3063809871673584\n",
      "Loss: 3.364319324493408\n",
      "Running Batch 45, Epoch 2, Total Tokens: 45\n",
      "Loss: 2.2093563079833984\n",
      "Loss: 3.3406054973602295\n",
      "Running Batch 47, Epoch 2, Total Tokens: 85\n",
      "Loss: 2.1946752071380615\n",
      "Loss: 3.3651959896087646\n",
      "Running Batch 49, Epoch 2, Total Tokens: 48\n",
      "Loss: 2.242929220199585\n",
      "Loss: 3.33123779296875\n",
      "Running Batch 51, Epoch 2, Total Tokens: 45\n",
      "Loss: 2.339437246322632\n",
      "Loss: 3.256450653076172\n",
      "Running Batch 53, Epoch 2, Total Tokens: 60\n",
      "Loss: 2.2052571773529053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 53, Loss: 2.2052571773529053\n",
      "Loss: 3.3339569568634033\n",
      "Running Batch 55, Epoch 2, Total Tokens: 63\n",
      "Loss: 2.268789768218994\n",
      "Loss: 3.3435113430023193\n",
      "Running Batch 57, Epoch 2, Total Tokens: 48\n",
      "Loss: 2.0514278411865234\n",
      "Loss: 3.3146793842315674\n",
      "Running Batch 59, Epoch 2, Total Tokens: 52\n",
      "Loss: 2.225278377532959\n",
      "Loss: 3.391914129257202\n",
      "Running Batch 61, Epoch 2, Total Tokens: 60\n",
      "Loss: 2.1928749084472656\n",
      "Loss: 3.315943956375122\n",
      "Running Batch 63, Epoch 2, Total Tokens: 63\n",
      "Loss: 2.1739237308502197\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 63, Loss: 2.1739237308502197\n",
      "Loss: 3.295839548110962\n",
      "Running Batch 65, Epoch 2, Total Tokens: 51\n",
      "Loss: 2.3019323348999023\n",
      "Loss: 3.3285329341888428\n",
      "Running Batch 67, Epoch 2, Total Tokens: 52\n",
      "Loss: 2.1266965866088867\n",
      "Loss: 3.2335612773895264\n",
      "Running Batch 69, Epoch 2, Total Tokens: 46\n",
      "Loss: 2.215327739715576\n",
      "Loss: 3.32287859916687\n",
      "Running Batch 71, Epoch 2, Total Tokens: 60\n",
      "Loss: 2.2124814987182617\n",
      "Loss: 3.1871743202209473\n",
      "Running Batch 73, Epoch 2, Total Tokens: 59\n",
      "Loss: 2.185760736465454\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 73, Loss: 2.185760736465454\n",
      "Loss: 3.4190964698791504\n",
      "Running Batch 75, Epoch 2, Total Tokens: 71\n",
      "Loss: 2.1605818271636963\n",
      "Loss: 3.258500814437866\n",
      "Running Batch 77, Epoch 2, Total Tokens: 59\n",
      "Loss: 2.21569561958313\n",
      "Loss: 3.20352840423584\n",
      "Running Batch 79, Epoch 2, Total Tokens: 66\n",
      "Loss: 2.1751954555511475\n",
      "Loss: 3.3279664516448975\n",
      "Running Batch 81, Epoch 2, Total Tokens: 76\n",
      "Loss: 2.2003042697906494\n",
      "Loss: 3.375555992126465\n",
      "Running Batch 83, Epoch 2, Total Tokens: 62\n",
      "Loss: 2.251986265182495\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 83, Loss: 2.251986265182495\n",
      "Loss: 3.299152374267578\n",
      "Running Batch 85, Epoch 2, Total Tokens: 57\n",
      "Loss: 2.2918691635131836\n",
      "Loss: 3.4859676361083984\n",
      "Running Batch 87, Epoch 2, Total Tokens: 58\n",
      "Loss: 2.071932792663574\n",
      "Loss: 3.2110183238983154\n",
      "Running Batch 89, Epoch 2, Total Tokens: 56\n",
      "Loss: 2.3426895141601562\n",
      "Loss: 3.189887046813965\n",
      "Running Batch 91, Epoch 2, Total Tokens: 63\n",
      "Loss: 2.2491517066955566\n",
      "Loss: 3.3090121746063232\n",
      "Running Batch 93, Epoch 2, Total Tokens: 55\n",
      "Loss: 2.2999515533447266\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 93, Loss: 2.2999515533447266\n",
      "AVG LOSS: 2.7685868435717644, Epoch: 3\n",
      "Loss: 3.203977108001709\n",
      "Running Batch 1, Epoch 3, Total Tokens: 59\n",
      "Loss: 2.2255795001983643\n",
      "Loss: 3.28694748878479\n",
      "Running Batch 3, Epoch 3, Total Tokens: 71\n",
      "Loss: 2.2135748863220215\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 3, Loss: 2.2135748863220215\n",
      "Loss: 3.332061290740967\n",
      "Running Batch 5, Epoch 3, Total Tokens: 85\n",
      "Loss: 2.2002274990081787\n",
      "Loss: 3.3842036724090576\n",
      "Running Batch 7, Epoch 3, Total Tokens: 63\n",
      "Loss: 2.170300006866455\n",
      "Loss: 3.3197312355041504\n",
      "Running Batch 9, Epoch 3, Total Tokens: 66\n",
      "Loss: 2.175332546234131\n",
      "Loss: 3.2686986923217773\n",
      "Running Batch 11, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.1647939682006836\n",
      "Loss: 3.316279172897339\n",
      "Running Batch 13, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.2859060764312744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 13, Loss: 2.2859060764312744\n",
      "Loss: 3.2296736240386963\n",
      "Running Batch 15, Epoch 3, Total Tokens: 44\n",
      "Loss: 2.162504196166992\n",
      "Loss: 3.2881569862365723\n",
      "Running Batch 17, Epoch 3, Total Tokens: 63\n",
      "Loss: 2.2818167209625244\n",
      "Loss: 3.281956195831299\n",
      "Running Batch 19, Epoch 3, Total Tokens: 59\n",
      "Loss: 2.2324979305267334\n",
      "Loss: 3.328735113143921\n",
      "Running Batch 21, Epoch 3, Total Tokens: 48\n",
      "Loss: 2.2189698219299316\n",
      "Loss: 3.3307130336761475\n",
      "Running Batch 23, Epoch 3, Total Tokens: 53\n",
      "Loss: 2.2769601345062256\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 23, Loss: 2.2769601345062256\n",
      "Loss: 3.345745325088501\n",
      "Running Batch 25, Epoch 3, Total Tokens: 71\n",
      "Loss: 2.2535593509674072\n",
      "Loss: 3.295056104660034\n",
      "Running Batch 27, Epoch 3, Total Tokens: 68\n",
      "Loss: 2.1275441646575928\n",
      "Loss: 3.17685866355896\n",
      "Running Batch 29, Epoch 3, Total Tokens: 62\n",
      "Loss: 2.2669641971588135\n",
      "Loss: 3.31805419921875\n",
      "Running Batch 31, Epoch 3, Total Tokens: 46\n",
      "Loss: 2.3451411724090576\n",
      "Loss: 3.356916666030884\n",
      "Running Batch 33, Epoch 3, Total Tokens: 68\n",
      "Loss: 2.1089162826538086\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 33, Loss: 2.1089162826538086\n",
      "Loss: 3.2835817337036133\n",
      "Running Batch 35, Epoch 3, Total Tokens: 57\n",
      "Loss: 2.187307357788086\n",
      "Loss: 3.2277579307556152\n",
      "Running Batch 37, Epoch 3, Total Tokens: 67\n",
      "Loss: 2.2156283855438232\n",
      "Loss: 3.2995121479034424\n",
      "Running Batch 39, Epoch 3, Total Tokens: 63\n",
      "Loss: 2.17736554145813\n",
      "Loss: 3.288191318511963\n",
      "Running Batch 41, Epoch 3, Total Tokens: 85\n",
      "Loss: 2.295090913772583\n",
      "Loss: 3.242478132247925\n",
      "Running Batch 43, Epoch 3, Total Tokens: 55\n",
      "Loss: 2.298067808151245\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 43, Loss: 2.298067808151245\n",
      "Loss: 3.4290008544921875\n",
      "Running Batch 45, Epoch 3, Total Tokens: 47\n",
      "Loss: 2.2474348545074463\n",
      "Loss: 3.2938930988311768\n",
      "Running Batch 47, Epoch 3, Total Tokens: 49\n",
      "Loss: 2.2483532428741455\n",
      "Loss: 3.220578670501709\n",
      "Running Batch 49, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.1856751441955566\n",
      "Loss: 3.2561967372894287\n",
      "Running Batch 51, Epoch 3, Total Tokens: 48\n",
      "Loss: 2.1936120986938477\n",
      "Loss: 3.260928153991699\n",
      "Running Batch 53, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.0678389072418213\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 53, Loss: 2.0678389072418213\n",
      "Loss: 3.2849137783050537\n",
      "Running Batch 55, Epoch 3, Total Tokens: 68\n",
      "Loss: 2.1683905124664307\n",
      "Loss: 3.243138551712036\n",
      "Running Batch 57, Epoch 3, Total Tokens: 63\n",
      "Loss: 2.212177038192749\n",
      "Loss: 3.3387417793273926\n",
      "Running Batch 59, Epoch 3, Total Tokens: 57\n",
      "Loss: 2.1072659492492676\n",
      "Loss: 3.4036567211151123\n",
      "Running Batch 61, Epoch 3, Total Tokens: 62\n",
      "Loss: 2.133402109146118\n",
      "Loss: 3.300248146057129\n",
      "Running Batch 63, Epoch 3, Total Tokens: 57\n",
      "Loss: 2.128459930419922\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 63, Loss: 2.128459930419922\n",
      "Loss: 3.30389666557312\n",
      "Running Batch 65, Epoch 3, Total Tokens: 62\n",
      "Loss: 2.198669672012329\n",
      "Loss: 3.385862350463867\n",
      "Running Batch 67, Epoch 3, Total Tokens: 60\n",
      "Loss: 2.2520599365234375\n",
      "Loss: 3.264409303665161\n",
      "Running Batch 69, Epoch 3, Total Tokens: 88\n",
      "Loss: 2.2726612091064453\n",
      "Loss: 3.2683966159820557\n",
      "Running Batch 71, Epoch 3, Total Tokens: 48\n",
      "Loss: 2.2893621921539307\n",
      "Loss: 3.2635936737060547\n",
      "Running Batch 73, Epoch 3, Total Tokens: 59\n",
      "Loss: 2.0555641651153564\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 73, Loss: 2.0555641651153564\n",
      "Loss: 3.328510046005249\n",
      "Running Batch 75, Epoch 3, Total Tokens: 63\n",
      "Loss: 2.2619025707244873\n",
      "Loss: 3.2076029777526855\n",
      "Running Batch 77, Epoch 3, Total Tokens: 46\n",
      "Loss: 2.2020280361175537\n",
      "Loss: 3.284428358078003\n",
      "Running Batch 79, Epoch 3, Total Tokens: 60\n",
      "Loss: 2.210148572921753\n",
      "Loss: 3.2954399585723877\n",
      "Running Batch 81, Epoch 3, Total Tokens: 59\n",
      "Loss: 2.229597806930542\n",
      "Loss: 3.341161012649536\n",
      "Running Batch 83, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.1598942279815674\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 83, Loss: 2.1598942279815674\n",
      "Loss: 3.3109865188598633\n",
      "Running Batch 85, Epoch 3, Total Tokens: 48\n",
      "Loss: 2.1232614517211914\n",
      "Loss: 3.247997522354126\n",
      "Running Batch 87, Epoch 3, Total Tokens: 82\n",
      "Loss: 2.230891466140747\n",
      "Loss: 3.2933998107910156\n",
      "Running Batch 89, Epoch 3, Total Tokens: 56\n",
      "Loss: 2.123660087585449\n",
      "Loss: 3.214357614517212\n",
      "Running Batch 91, Epoch 3, Total Tokens: 46\n",
      "Loss: 2.246673822402954\n",
      "Loss: 3.270857095718384\n",
      "Running Batch 93, Epoch 3, Total Tokens: 44\n",
      "Loss: 2.172553777694702\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 93, Loss: 2.172553777694702\n",
      "AVG LOSS: 2.7481177563362933, Epoch: 4\n",
      "Loss: 3.151421308517456\n",
      "Running Batch 1, Epoch 4, Total Tokens: 62\n",
      "Loss: 2.1670830249786377\n",
      "Loss: 3.207169771194458\n",
      "Running Batch 3, Epoch 4, Total Tokens: 55\n",
      "Loss: 2.0336759090423584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 3, Loss: 2.0336759090423584\n",
      "Loss: 3.210674285888672\n",
      "Running Batch 5, Epoch 4, Total Tokens: 85\n",
      "Loss: 2.203132152557373\n",
      "Loss: 3.4024622440338135\n",
      "Running Batch 7, Epoch 4, Total Tokens: 56\n",
      "Loss: 2.1323394775390625\n",
      "Loss: 3.2912774085998535\n",
      "Running Batch 9, Epoch 4, Total Tokens: 44\n",
      "Loss: 2.0116758346557617\n",
      "Loss: 3.3117597103118896\n",
      "Running Batch 11, Epoch 4, Total Tokens: 56\n",
      "Loss: 2.1208858489990234\n",
      "Loss: 3.2729010581970215\n",
      "Running Batch 13, Epoch 4, Total Tokens: 59\n",
      "Loss: 2.1214468479156494\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 13, Loss: 2.1214468479156494\n",
      "Loss: 3.230027198791504\n",
      "Running Batch 15, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.1149284839630127\n",
      "Loss: 3.3091416358947754\n",
      "Running Batch 17, Epoch 4, Total Tokens: 85\n",
      "Loss: 2.132788896560669\n",
      "Loss: 3.212341547012329\n",
      "Running Batch 19, Epoch 4, Total Tokens: 48\n",
      "Loss: 2.2538511753082275\n",
      "Loss: 3.20302677154541\n",
      "Running Batch 21, Epoch 4, Total Tokens: 85\n",
      "Loss: 2.150054693222046\n",
      "Loss: 3.259066581726074\n",
      "Running Batch 23, Epoch 4, Total Tokens: 63\n",
      "Loss: 2.120549201965332\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 23, Loss: 2.120549201965332\n",
      "Loss: 3.2551703453063965\n",
      "Running Batch 25, Epoch 4, Total Tokens: 62\n",
      "Loss: 2.094632148742676\n",
      "Loss: 3.350306749343872\n",
      "Running Batch 27, Epoch 4, Total Tokens: 53\n",
      "Loss: 2.291316509246826\n",
      "Loss: 3.288625955581665\n",
      "Running Batch 29, Epoch 4, Total Tokens: 55\n",
      "Loss: 2.221160411834717\n",
      "Loss: 3.1923017501831055\n",
      "Running Batch 31, Epoch 4, Total Tokens: 57\n",
      "Loss: 2.3179450035095215\n",
      "Loss: 3.347951889038086\n",
      "Running Batch 33, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.28728985786438\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 33, Loss: 2.28728985786438\n",
      "Loss: 3.3309764862060547\n",
      "Running Batch 35, Epoch 4, Total Tokens: 62\n",
      "Loss: 2.182084798812866\n",
      "Loss: 3.2524819374084473\n",
      "Running Batch 37, Epoch 4, Total Tokens: 66\n",
      "Loss: 2.199310302734375\n",
      "Loss: 3.235868453979492\n",
      "Running Batch 39, Epoch 4, Total Tokens: 57\n",
      "Loss: 2.218212842941284\n",
      "Loss: 3.345827579498291\n",
      "Running Batch 41, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.1096842288970947\n",
      "Loss: 3.306295394897461\n",
      "Running Batch 43, Epoch 4, Total Tokens: 56\n",
      "Loss: 2.1765787601470947\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 43, Loss: 2.1765787601470947\n",
      "Loss: 3.2179102897644043\n",
      "Running Batch 45, Epoch 4, Total Tokens: 54\n",
      "Loss: 2.1603269577026367\n",
      "Loss: 3.221508264541626\n",
      "Running Batch 47, Epoch 4, Total Tokens: 48\n",
      "Loss: 2.2832484245300293\n",
      "Loss: 3.252361536026001\n",
      "Running Batch 49, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.170196533203125\n",
      "Loss: 3.2385618686676025\n",
      "Running Batch 51, Epoch 4, Total Tokens: 42\n",
      "Loss: 2.2095963954925537\n",
      "Loss: 3.264846086502075\n",
      "Running Batch 53, Epoch 4, Total Tokens: 55\n",
      "Loss: 2.283600091934204\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 53, Loss: 2.283600091934204\n",
      "Loss: 3.239755392074585\n",
      "Running Batch 55, Epoch 4, Total Tokens: 48\n",
      "Loss: 2.18860125541687\n",
      "Loss: 3.352395534515381\n",
      "Running Batch 57, Epoch 4, Total Tokens: 56\n",
      "Loss: 2.186843156814575\n",
      "Loss: 3.2500829696655273\n",
      "Running Batch 59, Epoch 4, Total Tokens: 44\n",
      "Loss: 2.172246217727661\n",
      "Loss: 3.186051368713379\n",
      "Running Batch 61, Epoch 4, Total Tokens: 71\n",
      "Loss: 2.249953508377075\n",
      "Loss: 3.141862154006958\n",
      "Running Batch 63, Epoch 4, Total Tokens: 88\n",
      "Loss: 2.2460529804229736\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 63, Loss: 2.2460529804229736\n",
      "Loss: 3.2824997901916504\n",
      "Running Batch 65, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.1951394081115723\n",
      "Loss: 3.2931995391845703\n",
      "Running Batch 67, Epoch 4, Total Tokens: 60\n",
      "Loss: 2.144270181655884\n",
      "Loss: 3.3192574977874756\n",
      "Running Batch 69, Epoch 4, Total Tokens: 74\n",
      "Loss: 2.269827127456665\n",
      "Loss: 3.265935182571411\n",
      "Running Batch 71, Epoch 4, Total Tokens: 43\n",
      "Loss: 2.3267436027526855\n",
      "Loss: 3.2544350624084473\n",
      "Running Batch 73, Epoch 4, Total Tokens: 49\n",
      "Loss: 2.1465609073638916\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 73, Loss: 2.1465609073638916\n",
      "Loss: 3.357534885406494\n",
      "Running Batch 75, Epoch 4, Total Tokens: 67\n",
      "Loss: 2.140132188796997\n",
      "Loss: 3.2201414108276367\n",
      "Running Batch 77, Epoch 4, Total Tokens: 53\n",
      "Loss: 2.1593246459960938\n",
      "Loss: 3.295400619506836\n",
      "Running Batch 79, Epoch 4, Total Tokens: 44\n",
      "Loss: 2.2001729011535645\n",
      "Loss: 3.254599094390869\n",
      "Running Batch 81, Epoch 4, Total Tokens: 68\n",
      "Loss: 2.2634589672088623\n",
      "Loss: 3.2990705966949463\n",
      "Running Batch 83, Epoch 4, Total Tokens: 59\n",
      "Loss: 2.162731409072876\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 83, Loss: 2.162731409072876\n",
      "Loss: 3.3301000595092773\n",
      "Running Batch 85, Epoch 4, Total Tokens: 52\n",
      "Loss: 2.221308469772339\n",
      "Loss: 3.21728515625\n",
      "Running Batch 87, Epoch 4, Total Tokens: 59\n",
      "Loss: 2.1916303634643555\n",
      "Loss: 3.2639987468719482\n",
      "Running Batch 89, Epoch 4, Total Tokens: 63\n",
      "Loss: 2.1907382011413574\n",
      "Loss: 3.264122486114502\n",
      "Running Batch 91, Epoch 4, Total Tokens: 58\n",
      "Loss: 2.1545631885528564\n",
      "Loss: 3.268876791000366\n",
      "Running Batch 93, Epoch 4, Total Tokens: 44\n",
      "Loss: 2.1714465618133545\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 93, Loss: 2.1714465618133545\n",
      "AVG LOSS: 2.7262575372736504, Epoch: 5\n",
      "Loss: 3.185091733932495\n",
      "Running Batch 1, Epoch 5, Total Tokens: 59\n",
      "Loss: 2.103534698486328\n",
      "Loss: 3.200733184814453\n",
      "Running Batch 3, Epoch 5, Total Tokens: 48\n",
      "Loss: 2.060445547103882\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 3, Loss: 2.060445547103882\n",
      "Loss: 3.1420061588287354\n",
      "Running Batch 5, Epoch 5, Total Tokens: 51\n",
      "Loss: 2.1979541778564453\n",
      "Loss: 3.2924435138702393\n",
      "Running Batch 7, Epoch 5, Total Tokens: 67\n",
      "Loss: 2.280195951461792\n",
      "Loss: 3.2551109790802\n",
      "Running Batch 9, Epoch 5, Total Tokens: 68\n",
      "Loss: 2.2287845611572266\n",
      "Loss: 3.2157974243164062\n",
      "Running Batch 11, Epoch 5, Total Tokens: 71\n",
      "Loss: 2.1152963638305664\n",
      "Loss: 3.2560839653015137\n",
      "Running Batch 13, Epoch 5, Total Tokens: 42\n",
      "Loss: 2.133648157119751\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 13, Loss: 2.133648157119751\n",
      "Loss: 3.173330068588257\n",
      "Running Batch 15, Epoch 5, Total Tokens: 68\n",
      "Loss: 2.123774528503418\n",
      "Loss: 3.268782138824463\n",
      "Running Batch 17, Epoch 5, Total Tokens: 46\n",
      "Loss: 2.0731332302093506\n",
      "Loss: 3.323274850845337\n",
      "Running Batch 19, Epoch 5, Total Tokens: 51\n",
      "Loss: 2.1938600540161133\n",
      "Loss: 3.276156425476074\n",
      "Running Batch 21, Epoch 5, Total Tokens: 62\n",
      "Loss: 2.0681934356689453\n",
      "Loss: 3.2444519996643066\n",
      "Running Batch 23, Epoch 5, Total Tokens: 57\n",
      "Loss: 2.171473264694214\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 23, Loss: 2.171473264694214\n",
      "Loss: 3.306607484817505\n",
      "Running Batch 25, Epoch 5, Total Tokens: 59\n",
      "Loss: 2.10945200920105\n",
      "Loss: 3.318760633468628\n",
      "Running Batch 27, Epoch 5, Total Tokens: 56\n",
      "Loss: 2.1161909103393555\n",
      "Loss: 3.3246383666992188\n",
      "Running Batch 29, Epoch 5, Total Tokens: 85\n",
      "Loss: 2.1673030853271484\n",
      "Loss: 3.33091402053833\n",
      "Running Batch 31, Epoch 5, Total Tokens: 68\n",
      "Loss: 2.265843629837036\n",
      "Loss: 3.17648983001709\n",
      "Running Batch 33, Epoch 5, Total Tokens: 88\n",
      "Loss: 2.187696933746338\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 33, Loss: 2.187696933746338\n",
      "Loss: 3.28936767578125\n",
      "Running Batch 35, Epoch 5, Total Tokens: 55\n",
      "Loss: 2.2157626152038574\n",
      "Loss: 3.082472085952759\n",
      "Running Batch 37, Epoch 5, Total Tokens: 47\n",
      "Loss: 2.2040512561798096\n",
      "Loss: 3.1883492469787598\n",
      "Running Batch 39, Epoch 5, Total Tokens: 57\n",
      "Loss: 2.1731719970703125\n",
      "Loss: 3.2797436714172363\n",
      "Running Batch 41, Epoch 5, Total Tokens: 85\n",
      "Loss: 2.0775039196014404\n",
      "Loss: 3.2122976779937744\n",
      "Running Batch 43, Epoch 5, Total Tokens: 41\n",
      "Loss: 2.1339666843414307\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 43, Loss: 2.1339666843414307\n",
      "Loss: 3.167220115661621\n",
      "Running Batch 45, Epoch 5, Total Tokens: 66\n",
      "Loss: 2.050778388977051\n",
      "Loss: 3.2277491092681885\n",
      "Running Batch 47, Epoch 5, Total Tokens: 56\n",
      "Loss: 2.153386354446411\n",
      "Loss: 3.3818464279174805\n",
      "Running Batch 49, Epoch 5, Total Tokens: 71\n",
      "Loss: 2.098510980606079\n",
      "Loss: 3.2693660259246826\n",
      "Running Batch 51, Epoch 5, Total Tokens: 48\n",
      "Loss: 2.1756319999694824\n",
      "Loss: 3.357198476791382\n",
      "Running Batch 53, Epoch 5, Total Tokens: 68\n",
      "Loss: 2.217674493789673\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 53, Loss: 2.217674493789673\n",
      "Loss: 3.2431156635284424\n",
      "Running Batch 55, Epoch 5, Total Tokens: 66\n",
      "Loss: 2.1674818992614746\n",
      "Loss: 3.4440419673919678\n",
      "Running Batch 57, Epoch 5, Total Tokens: 60\n",
      "Loss: 2.1121132373809814\n",
      "Loss: 3.337307929992676\n",
      "Running Batch 59, Epoch 5, Total Tokens: 57\n",
      "Loss: 2.1630914211273193\n",
      "Loss: 3.3042619228363037\n",
      "Running Batch 61, Epoch 5, Total Tokens: 59\n",
      "Loss: 2.0916731357574463\n",
      "Loss: 3.225031614303589\n",
      "Running Batch 63, Epoch 5, Total Tokens: 48\n",
      "Loss: 2.1829307079315186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 63, Loss: 2.1829307079315186\n",
      "Loss: 3.327927827835083\n",
      "Running Batch 65, Epoch 5, Total Tokens: 68\n",
      "Loss: 2.2409236431121826\n",
      "Loss: 3.3250701427459717\n",
      "Running Batch 67, Epoch 5, Total Tokens: 55\n",
      "Loss: 2.1595373153686523\n",
      "Loss: 3.2166473865509033\n",
      "Running Batch 69, Epoch 5, Total Tokens: 55\n",
      "Loss: 2.1346235275268555\n",
      "Loss: 3.2430851459503174\n",
      "Running Batch 71, Epoch 5, Total Tokens: 62\n",
      "Loss: 2.1799256801605225\n",
      "Loss: 3.307528257369995\n",
      "Running Batch 73, Epoch 5, Total Tokens: 85\n",
      "Loss: 2.0781121253967285\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 73, Loss: 2.0781121253967285\n",
      "Loss: 3.2420098781585693\n",
      "Running Batch 75, Epoch 5, Total Tokens: 47\n",
      "Loss: 2.1266369819641113\n",
      "Loss: 3.2150416374206543\n",
      "Running Batch 77, Epoch 5, Total Tokens: 57\n",
      "Loss: 2.206118583679199\n",
      "Loss: 3.400268316268921\n",
      "Running Batch 79, Epoch 5, Total Tokens: 85\n",
      "Loss: 2.0593857765197754\n",
      "Loss: 3.1237337589263916\n",
      "Running Batch 81, Epoch 5, Total Tokens: 63\n",
      "Loss: 2.1256985664367676\n",
      "Loss: 3.2527763843536377\n",
      "Running Batch 83, Epoch 5, Total Tokens: 60\n",
      "Loss: 2.0810327529907227\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 83, Loss: 2.0810327529907227\n",
      "Loss: 3.151392698287964\n",
      "Running Batch 85, Epoch 5, Total Tokens: 62\n",
      "Loss: 2.2161245346069336\n",
      "Loss: 3.2749969959259033\n",
      "Running Batch 87, Epoch 5, Total Tokens: 48\n",
      "Loss: 2.198446750640869\n",
      "Loss: 3.325899839401245\n",
      "Running Batch 89, Epoch 5, Total Tokens: 82\n",
      "Loss: 2.1998705863952637\n",
      "Loss: 3.244389533996582\n",
      "Running Batch 91, Epoch 5, Total Tokens: 62\n",
      "Loss: 2.0658159255981445\n",
      "Loss: 3.315474271774292\n",
      "Running Batch 93, Epoch 5, Total Tokens: 48\n",
      "Loss: 2.2003207206726074\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 5, Batch: 93, Loss: 2.2003207206726074\n",
      "AVG LOSS: 2.705886889011302, Epoch: 6\n",
      "Loss: 3.326721668243408\n",
      "Running Batch 1, Epoch 6, Total Tokens: 49\n",
      "Loss: 2.029341459274292\n",
      "Loss: 3.2887566089630127\n",
      "Running Batch 3, Epoch 6, Total Tokens: 52\n",
      "Loss: 2.2731964588165283\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 3, Loss: 2.2731964588165283\n",
      "Loss: 3.142791986465454\n",
      "Running Batch 5, Epoch 6, Total Tokens: 66\n",
      "Loss: 2.202119827270508\n",
      "Loss: 3.1725635528564453\n",
      "Running Batch 7, Epoch 6, Total Tokens: 60\n",
      "Loss: 2.143820285797119\n",
      "Loss: 3.2684166431427\n",
      "Running Batch 9, Epoch 6, Total Tokens: 57\n",
      "Loss: 2.1017513275146484\n",
      "Loss: 3.2894318103790283\n",
      "Running Batch 11, Epoch 6, Total Tokens: 61\n",
      "Loss: 2.0048813819885254\n",
      "Loss: 3.3827121257781982\n",
      "Running Batch 13, Epoch 6, Total Tokens: 63\n",
      "Loss: 2.025237560272217\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 13, Loss: 2.025237560272217\n",
      "Loss: 3.3102293014526367\n",
      "Running Batch 15, Epoch 6, Total Tokens: 59\n",
      "Loss: 2.0180411338806152\n",
      "Loss: 3.2453341484069824\n",
      "Running Batch 17, Epoch 6, Total Tokens: 85\n",
      "Loss: 2.125953197479248\n",
      "Loss: 3.188918113708496\n",
      "Running Batch 19, Epoch 6, Total Tokens: 85\n",
      "Loss: 2.10490083694458\n",
      "Loss: 3.3974742889404297\n",
      "Running Batch 21, Epoch 6, Total Tokens: 52\n",
      "Loss: 2.130589485168457\n",
      "Loss: 3.2814862728118896\n",
      "Running Batch 23, Epoch 6, Total Tokens: 62\n",
      "Loss: 2.233004331588745\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 23, Loss: 2.233004331588745\n",
      "Loss: 3.2006871700286865\n",
      "Running Batch 25, Epoch 6, Total Tokens: 67\n",
      "Loss: 2.1263623237609863\n",
      "Loss: 3.191112756729126\n",
      "Running Batch 27, Epoch 6, Total Tokens: 62\n",
      "Loss: 2.104870319366455\n",
      "Loss: 3.251309871673584\n",
      "Running Batch 29, Epoch 6, Total Tokens: 49\n",
      "Loss: 2.229696273803711\n",
      "Loss: 3.286990165710449\n",
      "Running Batch 31, Epoch 6, Total Tokens: 68\n",
      "Loss: 2.0275964736938477\n",
      "Loss: 3.2203712463378906\n",
      "Running Batch 33, Epoch 6, Total Tokens: 41\n",
      "Loss: 2.1620402336120605\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 33, Loss: 2.1620402336120605\n",
      "Loss: 3.3096156120300293\n",
      "Running Batch 35, Epoch 6, Total Tokens: 59\n",
      "Loss: 2.280975580215454\n",
      "Loss: 3.2454118728637695\n",
      "Running Batch 37, Epoch 6, Total Tokens: 68\n",
      "Loss: 2.1123571395874023\n",
      "Loss: 3.37886643409729\n",
      "Running Batch 39, Epoch 6, Total Tokens: 60\n",
      "Loss: 2.071714162826538\n",
      "Loss: 3.1787545680999756\n",
      "Running Batch 41, Epoch 6, Total Tokens: 47\n",
      "Loss: 2.1376428604125977\n",
      "Loss: 3.209400177001953\n",
      "Running Batch 43, Epoch 6, Total Tokens: 56\n",
      "Loss: 2.172053575515747\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 43, Loss: 2.172053575515747\n",
      "Loss: 3.3667404651641846\n",
      "Running Batch 45, Epoch 6, Total Tokens: 82\n",
      "Loss: 2.1985042095184326\n",
      "Loss: 3.1865234375\n",
      "Running Batch 47, Epoch 6, Total Tokens: 62\n",
      "Loss: 2.2364513874053955\n",
      "Loss: 3.1784756183624268\n",
      "Running Batch 49, Epoch 6, Total Tokens: 54\n",
      "Loss: 2.216536521911621\n",
      "Loss: 3.3080875873565674\n",
      "Running Batch 51, Epoch 6, Total Tokens: 66\n",
      "Loss: 2.073899030685425\n",
      "Loss: 3.2642335891723633\n",
      "Running Batch 53, Epoch 6, Total Tokens: 63\n",
      "Loss: 2.246980667114258\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 53, Loss: 2.246980667114258\n",
      "Loss: 3.164689540863037\n",
      "Running Batch 55, Epoch 6, Total Tokens: 44\n",
      "Loss: 2.164355516433716\n",
      "Loss: 3.1919655799865723\n",
      "Running Batch 57, Epoch 6, Total Tokens: 55\n",
      "Loss: 2.1005446910858154\n",
      "Loss: 3.165846347808838\n",
      "Running Batch 59, Epoch 6, Total Tokens: 74\n",
      "Loss: 2.1346492767333984\n",
      "Loss: 3.221855640411377\n",
      "Running Batch 61, Epoch 6, Total Tokens: 49\n",
      "Loss: 2.2284443378448486\n",
      "Loss: 3.287055253982544\n",
      "Running Batch 63, Epoch 6, Total Tokens: 60\n",
      "Loss: 2.1859965324401855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 63, Loss: 2.1859965324401855\n",
      "Loss: 3.2608044147491455\n",
      "Running Batch 65, Epoch 6, Total Tokens: 46\n",
      "Loss: 2.2394332885742188\n",
      "Loss: 3.310384750366211\n",
      "Running Batch 67, Epoch 6, Total Tokens: 49\n",
      "Loss: 2.13700795173645\n",
      "Loss: 3.1697511672973633\n",
      "Running Batch 69, Epoch 6, Total Tokens: 50\n",
      "Loss: 2.0928680896759033\n",
      "Loss: 3.196411371231079\n",
      "Running Batch 71, Epoch 6, Total Tokens: 52\n",
      "Loss: 2.1064929962158203\n",
      "Loss: 3.3064029216766357\n",
      "Running Batch 73, Epoch 6, Total Tokens: 48\n",
      "Loss: 2.1818199157714844\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 73, Loss: 2.1818199157714844\n",
      "Loss: 3.229022264480591\n",
      "Running Batch 75, Epoch 6, Total Tokens: 62\n",
      "Loss: 2.2483410835266113\n",
      "Loss: 3.2386996746063232\n",
      "Running Batch 77, Epoch 6, Total Tokens: 50\n",
      "Loss: 2.0563454627990723\n",
      "Loss: 3.258035182952881\n",
      "Running Batch 79, Epoch 6, Total Tokens: 71\n",
      "Loss: 2.1114518642425537\n",
      "Loss: 3.205615997314453\n",
      "Running Batch 81, Epoch 6, Total Tokens: 60\n",
      "Loss: 2.124246835708618\n",
      "Loss: 3.3143062591552734\n",
      "Running Batch 83, Epoch 6, Total Tokens: 60\n",
      "Loss: 2.1220169067382812\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 83, Loss: 2.1220169067382812\n",
      "Loss: 3.2463815212249756\n",
      "Running Batch 85, Epoch 6, Total Tokens: 59\n",
      "Loss: 2.06404709815979\n",
      "Loss: 3.2326972484588623\n",
      "Running Batch 87, Epoch 6, Total Tokens: 56\n",
      "Loss: 2.168660879135132\n",
      "Loss: 3.304572343826294\n",
      "Running Batch 89, Epoch 6, Total Tokens: 59\n",
      "Loss: 2.0224525928497314\n",
      "Loss: 3.3397603034973145\n",
      "Running Batch 91, Epoch 6, Total Tokens: 56\n",
      "Loss: 2.190086603164673\n",
      "Loss: 3.224555730819702\n",
      "Running Batch 93, Epoch 6, Total Tokens: 59\n",
      "Loss: 2.079630136489868\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 6, Batch: 93, Loss: 2.079630136489868\n",
      "AVG LOSS: 2.69669830545466, Epoch: 7\n",
      "Loss: 3.2322864532470703\n",
      "Running Batch 1, Epoch 7, Total Tokens: 63\n",
      "Loss: 2.181438684463501\n",
      "Loss: 3.4194815158843994\n",
      "Running Batch 3, Epoch 7, Total Tokens: 60\n",
      "Loss: 2.0821287631988525\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 3, Loss: 2.0821287631988525\n",
      "Loss: 3.257955312728882\n",
      "Running Batch 5, Epoch 7, Total Tokens: 53\n",
      "Loss: 2.250847339630127\n",
      "Loss: 3.31093692779541\n",
      "Running Batch 7, Epoch 7, Total Tokens: 74\n",
      "Loss: 2.1037700176239014\n",
      "Loss: 3.2734014987945557\n",
      "Running Batch 9, Epoch 7, Total Tokens: 71\n",
      "Loss: 2.172515869140625\n",
      "Loss: 3.2980868816375732\n",
      "Running Batch 11, Epoch 7, Total Tokens: 39\n",
      "Loss: 2.146695613861084\n",
      "Loss: 3.3226242065429688\n",
      "Running Batch 13, Epoch 7, Total Tokens: 46\n",
      "Loss: 2.138262987136841\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 13, Loss: 2.138262987136841\n",
      "Loss: 3.3953020572662354\n",
      "Running Batch 15, Epoch 7, Total Tokens: 48\n",
      "Loss: 2.08341646194458\n",
      "Loss: 3.2746057510375977\n",
      "Running Batch 17, Epoch 7, Total Tokens: 48\n",
      "Loss: 2.047111988067627\n",
      "Loss: 3.275662660598755\n",
      "Running Batch 19, Epoch 7, Total Tokens: 68\n",
      "Loss: 2.102543354034424\n",
      "Loss: 3.1817662715911865\n",
      "Running Batch 21, Epoch 7, Total Tokens: 47\n",
      "Loss: 2.004443883895874\n",
      "Loss: 3.2122879028320312\n",
      "Running Batch 23, Epoch 7, Total Tokens: 57\n",
      "Loss: 2.105695962905884\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 23, Loss: 2.105695962905884\n",
      "Loss: 3.306354522705078\n",
      "Running Batch 25, Epoch 7, Total Tokens: 60\n",
      "Loss: 2.064009189605713\n",
      "Loss: 3.2902770042419434\n",
      "Running Batch 27, Epoch 7, Total Tokens: 49\n",
      "Loss: 2.2017455101013184\n",
      "Loss: 3.2208049297332764\n",
      "Running Batch 29, Epoch 7, Total Tokens: 82\n",
      "Loss: 2.194154739379883\n",
      "Loss: 3.3258774280548096\n",
      "Running Batch 31, Epoch 7, Total Tokens: 57\n",
      "Loss: 2.1791934967041016\n",
      "Loss: 3.202089548110962\n",
      "Running Batch 33, Epoch 7, Total Tokens: 48\n",
      "Loss: 2.2347819805145264\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 33, Loss: 2.2347819805145264\n",
      "Loss: 3.3600101470947266\n",
      "Running Batch 35, Epoch 7, Total Tokens: 60\n",
      "Loss: 2.1020963191986084\n",
      "Loss: 3.2141401767730713\n",
      "Running Batch 37, Epoch 7, Total Tokens: 57\n",
      "Loss: 2.0265815258026123\n",
      "Loss: 3.203272581100464\n",
      "Running Batch 39, Epoch 7, Total Tokens: 80\n",
      "Loss: 2.154345989227295\n",
      "Loss: 3.2964375019073486\n",
      "Running Batch 41, Epoch 7, Total Tokens: 63\n",
      "Loss: 2.2860960960388184\n",
      "Loss: 3.2690682411193848\n",
      "Running Batch 43, Epoch 7, Total Tokens: 66\n",
      "Loss: 2.121278762817383\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 43, Loss: 2.121278762817383\n",
      "Loss: 3.2969627380371094\n",
      "Running Batch 45, Epoch 7, Total Tokens: 54\n",
      "Loss: 2.0963587760925293\n",
      "Loss: 3.245375394821167\n",
      "Running Batch 47, Epoch 7, Total Tokens: 59\n",
      "Loss: 2.106628656387329\n",
      "Loss: 3.245309352874756\n",
      "Running Batch 49, Epoch 7, Total Tokens: 50\n",
      "Loss: 2.0335159301757812\n",
      "Loss: 3.2289044857025146\n",
      "Running Batch 51, Epoch 7, Total Tokens: 48\n",
      "Loss: 2.054158926010132\n",
      "Loss: 3.1309566497802734\n",
      "Running Batch 53, Epoch 7, Total Tokens: 63\n",
      "Loss: 2.1974382400512695\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 53, Loss: 2.1974382400512695\n",
      "Loss: 3.266117572784424\n",
      "Running Batch 55, Epoch 7, Total Tokens: 85\n",
      "Loss: 2.0975120067596436\n",
      "Loss: 3.1972146034240723\n",
      "Running Batch 57, Epoch 7, Total Tokens: 85\n",
      "Loss: 2.0806777477264404\n",
      "Loss: 3.284935712814331\n",
      "Running Batch 59, Epoch 7, Total Tokens: 62\n",
      "Loss: 2.104527711868286\n",
      "Loss: 3.181427240371704\n",
      "Running Batch 61, Epoch 7, Total Tokens: 52\n",
      "Loss: 2.1901705265045166\n",
      "Loss: 3.26265025138855\n",
      "Running Batch 63, Epoch 7, Total Tokens: 52\n",
      "Loss: 2.109182596206665\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 63, Loss: 2.109182596206665\n",
      "Loss: 3.277412176132202\n",
      "Running Batch 65, Epoch 7, Total Tokens: 68\n",
      "Loss: 2.1667861938476562\n",
      "Loss: 3.189059019088745\n",
      "Running Batch 67, Epoch 7, Total Tokens: 62\n",
      "Loss: 2.049525499343872\n",
      "Loss: 3.215161085128784\n",
      "Running Batch 69, Epoch 7, Total Tokens: 62\n",
      "Loss: 2.0879218578338623\n",
      "Loss: 3.0729682445526123\n",
      "Running Batch 71, Epoch 7, Total Tokens: 68\n",
      "Loss: 2.038764476776123\n",
      "Loss: 3.169079542160034\n",
      "Running Batch 73, Epoch 7, Total Tokens: 44\n",
      "Loss: 2.188511848449707\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 73, Loss: 2.188511848449707\n",
      "Loss: 3.205378770828247\n",
      "Running Batch 75, Epoch 7, Total Tokens: 85\n",
      "Loss: 2.0307347774505615\n",
      "Loss: 3.2898621559143066\n",
      "Running Batch 77, Epoch 7, Total Tokens: 68\n",
      "Loss: 2.1536264419555664\n",
      "Loss: 3.2981905937194824\n",
      "Running Batch 79, Epoch 7, Total Tokens: 49\n",
      "Loss: 2.157682418823242\n",
      "Loss: 3.163607358932495\n",
      "Running Batch 81, Epoch 7, Total Tokens: 53\n",
      "Loss: 2.1806719303131104\n",
      "Loss: 3.2381479740142822\n",
      "Running Batch 83, Epoch 7, Total Tokens: 82\n",
      "Loss: 2.1329896450042725\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 83, Loss: 2.1329896450042725\n",
      "Loss: 3.277003765106201\n",
      "Running Batch 85, Epoch 7, Total Tokens: 44\n",
      "Loss: 2.1397671699523926\n",
      "Loss: 3.302213191986084\n",
      "Running Batch 87, Epoch 7, Total Tokens: 60\n",
      "Loss: 2.143435001373291\n",
      "Loss: 3.2007510662078857\n",
      "Running Batch 89, Epoch 7, Total Tokens: 55\n",
      "Loss: 2.124183416366577\n",
      "Loss: 3.346407651901245\n",
      "Running Batch 91, Epoch 7, Total Tokens: 57\n",
      "Loss: 2.1567342281341553\n",
      "Loss: 3.2143242359161377\n",
      "Running Batch 93, Epoch 7, Total Tokens: 46\n",
      "Loss: 1.9556715488433838\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 7, Batch: 93, Loss: 1.9556715488433838\n",
      "AVG LOSS: 2.6883242815098862, Epoch: 8\n",
      "Loss: 3.225451946258545\n",
      "Running Batch 1, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.0594639778137207\n",
      "Loss: 3.26578950881958\n",
      "Running Batch 3, Epoch 8, Total Tokens: 55\n",
      "Loss: 2.08689022064209\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 3, Loss: 2.08689022064209\n",
      "Loss: 3.2226390838623047\n",
      "Running Batch 5, Epoch 8, Total Tokens: 68\n",
      "Loss: 2.0215840339660645\n",
      "Loss: 3.186724901199341\n",
      "Running Batch 7, Epoch 8, Total Tokens: 60\n",
      "Loss: 2.1341331005096436\n",
      "Loss: 3.313966989517212\n",
      "Running Batch 9, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.2121710777282715\n",
      "Loss: 3.2575743198394775\n",
      "Running Batch 11, Epoch 8, Total Tokens: 53\n",
      "Loss: 2.1433863639831543\n",
      "Loss: 3.1926684379577637\n",
      "Running Batch 13, Epoch 8, Total Tokens: 85\n",
      "Loss: 2.1037487983703613\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 13, Loss: 2.1037487983703613\n",
      "Loss: 3.3160107135772705\n",
      "Running Batch 15, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.1146106719970703\n",
      "Loss: 3.230015993118286\n",
      "Running Batch 17, Epoch 8, Total Tokens: 59\n",
      "Loss: 2.2151176929473877\n",
      "Loss: 3.209254264831543\n",
      "Running Batch 19, Epoch 8, Total Tokens: 88\n",
      "Loss: 2.048846960067749\n",
      "Loss: 3.2156782150268555\n",
      "Running Batch 21, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.0570173263549805\n",
      "Loss: 3.2377078533172607\n",
      "Running Batch 23, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.1012744903564453\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 23, Loss: 2.1012744903564453\n",
      "Loss: 3.283439874649048\n",
      "Running Batch 25, Epoch 8, Total Tokens: 71\n",
      "Loss: 2.0156641006469727\n",
      "Loss: 3.2158925533294678\n",
      "Running Batch 27, Epoch 8, Total Tokens: 54\n",
      "Loss: 2.0163025856018066\n",
      "Loss: 3.29830002784729\n",
      "Running Batch 29, Epoch 8, Total Tokens: 63\n",
      "Loss: 2.109783411026001\n",
      "Loss: 3.407536029815674\n",
      "Running Batch 31, Epoch 8, Total Tokens: 60\n",
      "Loss: 2.1122097969055176\n",
      "Loss: 3.259263753890991\n",
      "Running Batch 33, Epoch 8, Total Tokens: 49\n",
      "Loss: 2.1122329235076904\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 33, Loss: 2.1122329235076904\n",
      "Loss: 3.1249964237213135\n",
      "Running Batch 35, Epoch 8, Total Tokens: 63\n",
      "Loss: 2.1234018802642822\n",
      "Loss: 3.3053529262542725\n",
      "Running Batch 37, Epoch 8, Total Tokens: 45\n",
      "Loss: 2.0818357467651367\n",
      "Loss: 3.222290277481079\n",
      "Running Batch 39, Epoch 8, Total Tokens: 68\n",
      "Loss: 2.029033899307251\n",
      "Loss: 3.298645496368408\n",
      "Running Batch 41, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.1453399658203125\n",
      "Loss: 3.299923896789551\n",
      "Running Batch 43, Epoch 8, Total Tokens: 57\n",
      "Loss: 2.159682512283325\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 43, Loss: 2.159682512283325\n",
      "Loss: 3.2939693927764893\n",
      "Running Batch 45, Epoch 8, Total Tokens: 57\n",
      "Loss: 2.1480095386505127\n",
      "Loss: 3.215526580810547\n",
      "Running Batch 47, Epoch 8, Total Tokens: 62\n",
      "Loss: 2.192941188812256\n",
      "Loss: 3.2950756549835205\n",
      "Running Batch 49, Epoch 8, Total Tokens: 85\n",
      "Loss: 2.0599093437194824\n",
      "Loss: 3.192918539047241\n",
      "Running Batch 51, Epoch 8, Total Tokens: 85\n",
      "Loss: 1.9961040019989014\n",
      "Loss: 3.324208974838257\n",
      "Running Batch 53, Epoch 8, Total Tokens: 54\n",
      "Loss: 2.1074445247650146\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 53, Loss: 2.1074445247650146\n",
      "Loss: 3.236724615097046\n",
      "Running Batch 55, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.049795150756836\n",
      "Loss: 3.263052225112915\n",
      "Running Batch 57, Epoch 8, Total Tokens: 85\n",
      "Loss: 2.0024125576019287\n",
      "Loss: 3.234541893005371\n",
      "Running Batch 59, Epoch 8, Total Tokens: 48\n",
      "Loss: 2.1774747371673584\n",
      "Loss: 3.2022383213043213\n",
      "Running Batch 61, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.0012736320495605\n",
      "Loss: 3.253023147583008\n",
      "Running Batch 63, Epoch 8, Total Tokens: 60\n",
      "Loss: 1.9993948936462402\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 63, Loss: 1.9993948936462402\n",
      "Loss: 3.1966538429260254\n",
      "Running Batch 65, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.1230361461639404\n",
      "Loss: 3.13863468170166\n",
      "Running Batch 67, Epoch 8, Total Tokens: 48\n",
      "Loss: 2.1906235218048096\n",
      "Loss: 3.078296184539795\n",
      "Running Batch 69, Epoch 8, Total Tokens: 66\n",
      "Loss: 2.0963337421417236\n",
      "Loss: 3.2481486797332764\n",
      "Running Batch 71, Epoch 8, Total Tokens: 85\n",
      "Loss: 2.178009510040283\n",
      "Loss: 3.194241523742676\n",
      "Running Batch 73, Epoch 8, Total Tokens: 52\n",
      "Loss: 2.0719716548919678\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 73, Loss: 2.0719716548919678\n",
      "Loss: 3.302600860595703\n",
      "Running Batch 75, Epoch 8, Total Tokens: 56\n",
      "Loss: 2.0622856616973877\n",
      "Loss: 3.1846299171447754\n",
      "Running Batch 77, Epoch 8, Total Tokens: 60\n",
      "Loss: 2.0954999923706055\n",
      "Loss: 3.215869188308716\n",
      "Running Batch 79, Epoch 8, Total Tokens: 47\n",
      "Loss: 2.1810407638549805\n",
      "Loss: 3.172114610671997\n",
      "Running Batch 81, Epoch 8, Total Tokens: 85\n",
      "Loss: 2.1030712127685547\n",
      "Loss: 3.2380471229553223\n",
      "Running Batch 83, Epoch 8, Total Tokens: 47\n",
      "Loss: 2.170970916748047\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 83, Loss: 2.170970916748047\n",
      "Loss: 3.202550172805786\n",
      "Running Batch 85, Epoch 8, Total Tokens: 49\n",
      "Loss: 2.2018301486968994\n",
      "Loss: 3.1798791885375977\n",
      "Running Batch 87, Epoch 8, Total Tokens: 47\n",
      "Loss: 2.1051230430603027\n",
      "Loss: 3.2201173305511475\n",
      "Running Batch 89, Epoch 8, Total Tokens: 59\n",
      "Loss: 2.0240488052368164\n",
      "Loss: 3.3175010681152344\n",
      "Running Batch 91, Epoch 8, Total Tokens: 58\n",
      "Loss: 2.0108096599578857\n",
      "Loss: 3.2502522468566895\n",
      "Running Batch 93, Epoch 8, Total Tokens: 57\n",
      "Loss: 2.0254404544830322\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 8, Batch: 93, Loss: 2.0254404544830322\n",
      "AVG LOSS: 2.668282189267747, Epoch: 9\n",
      "Loss: 3.222568988800049\n",
      "Running Batch 1, Epoch 9, Total Tokens: 59\n",
      "Loss: 2.04386305809021\n",
      "Loss: 3.2413489818573\n",
      "Running Batch 3, Epoch 9, Total Tokens: 59\n",
      "Loss: 1.9044582843780518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 3, Loss: 1.9044582843780518\n",
      "Loss: 3.2342400550842285\n",
      "Running Batch 5, Epoch 9, Total Tokens: 48\n",
      "Loss: 2.1231346130371094\n",
      "Loss: 3.335427761077881\n",
      "Running Batch 7, Epoch 9, Total Tokens: 62\n",
      "Loss: 2.0893049240112305\n",
      "Loss: 3.1407322883605957\n",
      "Running Batch 9, Epoch 9, Total Tokens: 59\n",
      "Loss: 2.0424554347991943\n",
      "Loss: 3.1393120288848877\n",
      "Running Batch 11, Epoch 9, Total Tokens: 57\n",
      "Loss: 2.072303533554077\n",
      "Loss: 3.208509922027588\n",
      "Running Batch 13, Epoch 9, Total Tokens: 48\n",
      "Loss: 2.0970098972320557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 13, Loss: 2.0970098972320557\n",
      "Loss: 3.2964987754821777\n",
      "Running Batch 15, Epoch 9, Total Tokens: 49\n",
      "Loss: 2.0240612030029297\n",
      "Loss: 3.3194549083709717\n",
      "Running Batch 17, Epoch 9, Total Tokens: 62\n",
      "Loss: 2.1639537811279297\n",
      "Loss: 3.0647523403167725\n",
      "Running Batch 19, Epoch 9, Total Tokens: 55\n",
      "Loss: 2.175520658493042\n",
      "Loss: 3.221933126449585\n",
      "Running Batch 21, Epoch 9, Total Tokens: 48\n",
      "Loss: 2.1090333461761475\n",
      "Loss: 3.2311582565307617\n",
      "Running Batch 23, Epoch 9, Total Tokens: 68\n",
      "Loss: 2.061755895614624\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 23, Loss: 2.061755895614624\n",
      "Loss: 3.2858471870422363\n",
      "Running Batch 25, Epoch 9, Total Tokens: 63\n",
      "Loss: 2.0469894409179688\n",
      "Loss: 3.272249221801758\n",
      "Running Batch 27, Epoch 9, Total Tokens: 48\n",
      "Loss: 2.0686628818511963\n",
      "Loss: 3.2035274505615234\n",
      "Running Batch 29, Epoch 9, Total Tokens: 57\n",
      "Loss: 2.122344970703125\n",
      "Loss: 3.2935001850128174\n",
      "Running Batch 31, Epoch 9, Total Tokens: 50\n",
      "Loss: 2.157421112060547\n",
      "Loss: 3.3011817932128906\n",
      "Running Batch 33, Epoch 9, Total Tokens: 85\n",
      "Loss: 2.1533570289611816\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 33, Loss: 2.1533570289611816\n",
      "Loss: 3.3596889972686768\n",
      "Running Batch 35, Epoch 9, Total Tokens: 60\n",
      "Loss: 1.981443166732788\n",
      "Loss: 3.280838966369629\n",
      "Running Batch 37, Epoch 9, Total Tokens: 47\n",
      "Loss: 2.0776963233947754\n",
      "Loss: 3.145962715148926\n",
      "Running Batch 39, Epoch 9, Total Tokens: 66\n",
      "Loss: 2.1027798652648926\n",
      "Loss: 3.252540349960327\n",
      "Running Batch 41, Epoch 9, Total Tokens: 57\n",
      "Loss: 2.002896547317505\n",
      "Loss: 3.279141426086426\n",
      "Running Batch 43, Epoch 9, Total Tokens: 60\n",
      "Loss: 2.0473453998565674\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 43, Loss: 2.0473453998565674\n",
      "Loss: 3.2580394744873047\n",
      "Running Batch 45, Epoch 9, Total Tokens: 60\n",
      "Loss: 2.0669727325439453\n",
      "Loss: 3.17136287689209\n",
      "Running Batch 47, Epoch 9, Total Tokens: 60\n",
      "Loss: 2.138028621673584\n",
      "Loss: 3.2027971744537354\n",
      "Running Batch 49, Epoch 9, Total Tokens: 57\n",
      "Loss: 2.1232550144195557\n",
      "Loss: 3.2276651859283447\n",
      "Running Batch 51, Epoch 9, Total Tokens: 74\n",
      "Loss: 2.158179998397827\n",
      "Loss: 3.3392512798309326\n",
      "Running Batch 53, Epoch 9, Total Tokens: 76\n",
      "Loss: 2.0306105613708496\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 53, Loss: 2.0306105613708496\n",
      "Loss: 3.176450252532959\n",
      "Running Batch 55, Epoch 9, Total Tokens: 85\n",
      "Loss: 1.9658669233322144\n",
      "Loss: 3.1691737174987793\n",
      "Running Batch 57, Epoch 9, Total Tokens: 84\n",
      "Loss: 2.1739306449890137\n",
      "Loss: 3.2966220378875732\n",
      "Running Batch 59, Epoch 9, Total Tokens: 60\n",
      "Loss: 2.124622106552124\n",
      "Loss: 3.1981565952301025\n",
      "Running Batch 61, Epoch 9, Total Tokens: 47\n",
      "Loss: 2.0056958198547363\n",
      "Loss: 3.212198495864868\n",
      "Running Batch 63, Epoch 9, Total Tokens: 47\n",
      "Loss: 2.1223392486572266\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 63, Loss: 2.1223392486572266\n",
      "Loss: 3.193722724914551\n",
      "Running Batch 65, Epoch 9, Total Tokens: 67\n",
      "Loss: 2.1760313510894775\n",
      "Loss: 3.2330739498138428\n",
      "Running Batch 67, Epoch 9, Total Tokens: 63\n",
      "Loss: 2.1072816848754883\n",
      "Loss: 3.2460365295410156\n",
      "Running Batch 69, Epoch 9, Total Tokens: 57\n",
      "Loss: 2.100520133972168\n",
      "Loss: 3.2258737087249756\n",
      "Running Batch 71, Epoch 9, Total Tokens: 62\n",
      "Loss: 1.9810853004455566\n",
      "Loss: 3.2552616596221924\n",
      "Running Batch 73, Epoch 9, Total Tokens: 85\n",
      "Loss: 1.994639277458191\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 73, Loss: 1.994639277458191\n",
      "Loss: 3.1977896690368652\n",
      "Running Batch 75, Epoch 9, Total Tokens: 42\n",
      "Loss: 2.0139412879943848\n",
      "Loss: 3.1739213466644287\n",
      "Running Batch 77, Epoch 9, Total Tokens: 67\n",
      "Loss: 2.0663881301879883\n",
      "Loss: 3.1433794498443604\n",
      "Running Batch 79, Epoch 9, Total Tokens: 54\n",
      "Loss: 2.0294933319091797\n",
      "Loss: 3.242185115814209\n",
      "Running Batch 81, Epoch 9, Total Tokens: 56\n",
      "Loss: 2.059803009033203\n",
      "Loss: 3.2342374324798584\n",
      "Running Batch 83, Epoch 9, Total Tokens: 63\n",
      "Loss: 2.1140387058258057\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 83, Loss: 2.1140387058258057\n",
      "Loss: 3.235117197036743\n",
      "Running Batch 85, Epoch 9, Total Tokens: 88\n",
      "Loss: 1.981803059577942\n",
      "Loss: 3.1865830421447754\n",
      "Running Batch 87, Epoch 9, Total Tokens: 49\n",
      "Loss: 2.2204625606536865\n",
      "Loss: 3.3798744678497314\n",
      "Running Batch 89, Epoch 9, Total Tokens: 49\n",
      "Loss: 2.084257125854492\n",
      "Loss: 3.266998767852783\n",
      "Running Batch 91, Epoch 9, Total Tokens: 68\n",
      "Loss: 1.9986430406570435\n",
      "Loss: 3.203688144683838\n",
      "Running Batch 93, Epoch 9, Total Tokens: 85\n",
      "Loss: 2.008216142654419\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 9, Batch: 93, Loss: 2.008216142654419\n",
      "AVG LOSS: 2.6544018425840012, Epoch: 10\n"
     ]
    }
   ],
   "source": [
    "# fine tuning\n",
    "handwritten_imgs = \"../data/HandwrittenData/images/train/\"\n",
    "handwritten_labels = \"../data/HandwrittenData/train_hw.csv\"\n",
    "\n",
    "handwritten_dataset = Img2LatexDataset(handwritten_imgs, handwritten_labels, tokens=model.decoder.vocab,token_to_idx=model.decoder.vocab_dict)\n",
    "handwritten_loader = data.DataLoader(handwritten_dataset, batch_size=96, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.encoder.parameters(), lr = 0.0001)\n",
    "PAD_IDX = handwritten_dataset.token_to_idx[PAD]\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0]\n",
    "\n",
    "   return labels[:, :len(non_pad_cols)]\n",
    "\n",
    "print(len(handwritten_loader))\n",
    "model_path = \"./models/model.pt\"\n",
    "model_backup_path = \"./models/model_backup.pt\"\n",
    "current_params_path = \"./models/current_params_hw.txt\" \n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "# torch.save((state_dict), model_backup_path)\n",
    "model.load_state_dict(state_dict)\n",
    "if device == \"cuda\":\n",
    "    model.cuda()\n",
    "model.train()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "fifty_fifty = True\n",
    "teacher_forcing = False\n",
    "\n",
    "prev_loss = 100\n",
    "for epoch in range(10):\n",
    "    curr_loss = 0\n",
    "    for bidx, batch in enumerate(handwritten_loader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels = remove_trailing_pads(labels)\n",
    "        context_vec = model.encoder(images).squeeze()\n",
    "        if (bidx%2 and fifty_fifty) or teacher_forcing:\n",
    "            inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2)\n",
    "            print(f\"Running Batch {bidx}, Epoch {epoch}, Total Tokens: {labels.shape[1]}\")\n",
    "            output, _ = model.decoder(inputs, None)\n",
    "\n",
    "            # output[labels == PAD_IDX] = 0\n",
    "            # output = F.normalize(output, dim=2, p=1)\n",
    "            output = output[:, :-1, :]\n",
    "\n",
    "        else:\n",
    "            output = torch.zeros((labels.shape[0], labels.shape[1]-1, len(handwritten_dataset.tokens))).to(device)\n",
    "\n",
    "            prev_token = torch.ones(labels.shape[0], dtype=int).to(device) * handwritten_dataset.token_to_idx[SOS]\n",
    "            prev_token_embed = model.decoder.embedding(prev_token).to(device)\n",
    "\n",
    "            input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            hidden = None\n",
    "\n",
    "            for i in range(labels.shape[1]-1):\n",
    "                output[:, i, :], hidden = model.decoder(input, hidden)\n",
    "                prev_token = output[:, i, :].argmax(dim=1)\n",
    "                prev_token_embed = model.decoder.embedding(prev_token)\n",
    "                input = torch.cat([context_vec, prev_token_embed], dim=1).to(device)\n",
    "            \n",
    "        target = nn.functional.one_hot(labels[:,1:], num_classes=len(handwritten_dataset.tokens)).float().to(device)\n",
    "        # target[labels == PAD_IDX] = 0\n",
    "        mask = labels[:,1:] != PAD_IDX\n",
    "        # print(f\"Output shape: {output.shape}, Labels shape: {labels.shape}, Target shape: {target.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.transpose(1, 2), target.transpose(1, 2))\n",
    "        loss = loss * mask\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        curr_loss += loss.item()\n",
    "        if bidx % 10 == 3:\n",
    "            print(f\"SAVING MODEL to {model_path}\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"SAVED MODEL\")\n",
    "            print(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            try:\n",
    "                with open(current_params_path, 'w') as f:\n",
    "                    f.write(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            except:\n",
    "                print(\"\\n Could not write to file \\n\")\n",
    "    print(f\"AVG LOSS: {(curr_loss)/len(handwritten_loader)}, Epoch: {epoch+1}\")\n",
    "    prev_loss = curr_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./models/model_tfhw3.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
