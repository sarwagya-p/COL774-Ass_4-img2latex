{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, layers, hparams):\n",
    "        '''\n",
    "        Args:\n",
    "            layers: Description of all layers in the Encoder: [(layer_type, {layer_params})]\n",
    "                - layer types - ['conv1d', 'conv2d', 'maxpool1d', 'maxpool2d', 'avgpool2d', 'avgpool2d', 'linear', 'dropout']\n",
    "                - layer_params - dict of parameters for the layer\n",
    "\n",
    "            hparams: Hyperparameters for the model\n",
    "        '''\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.hp = hparams\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for layer_type, layer_params in layers:\n",
    "            if layer_type == 'conv1d':\n",
    "                self.layers.append(nn.Conv1d(**layer_params))\n",
    "            elif layer_type == 'conv2d':\n",
    "                self.layers.append(nn.Conv2d(**layer_params))\n",
    "            elif layer_type == 'maxpool1d':\n",
    "                self.layers.append(nn.MaxPool1d(**layer_params))\n",
    "            elif layer_type == 'maxpool2d':\n",
    "                self.layers.append(nn.MaxPool2d(**layer_params))\n",
    "            elif layer_type == 'avgpool1d':\n",
    "                self.layers.append(nn.AvgPool1d(**layer_params))\n",
    "            elif layer_type == 'avgpool2d':\n",
    "                self.layers.append(nn.AvgPool2d(**layer_params))\n",
    "            elif layer_type == 'linear':\n",
    "                self.layers.append(nn.Linear(**layer_params))\n",
    "            elif layer_type == 'dropout':\n",
    "                self.layers.append(nn.Dropout(**layer_params))\n",
    "            else:\n",
    "                raise ValueError(f'Invalid layer type: {layer_type}')\n",
    "\n",
    "    def forward(self, input):\n",
    "        for layer in self.layers:\n",
    "            input = layer(input)\n",
    "        return input\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, vocab, vocab_dict, input_size, embedding_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        '''\n",
    "        Args:\n",
    "            vocabulary_size: Size of the vocabulary\n",
    "            embedding_size: Size of the embedding vector\n",
    "        '''\n",
    "\n",
    "        self.vocab = vocab\n",
    "        self.vocab_dict = vocab_dict\n",
    "\n",
    "        self.embedding = nn.Embedding(len(vocab), embedding_size)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm = nn.LSTM(input_size+embedding_size, embedding_size, batch_first=True)\n",
    "        self.output = nn.Linear(embedding_size, len(vocab))\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        '''\n",
    "        Args:\n",
    "            input: Input to the decoder\n",
    "            hidden: Hidden state of the previous time step\n",
    "        '''\n",
    "        # prev_embed = self.embedding(prev_tokens)\n",
    "        # concated_inp = torch.cat((input, prev_embed), dim=1)\n",
    "        if hidden is None:\n",
    "            output, hidden = self.lstm(input)\n",
    "        else:\n",
    "            output, hidden = self.lstm(input, hidden)\n",
    "        output = self.output(output)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "PAD = \"<pad>\"\n",
    "SOS = \"<sos>\"\n",
    "EOS = \"<eos>\"\n",
    "\n",
    "def load_img(path, size = (224, 224)):\n",
    "    img = (Image.open(path))\n",
    "    transform = transforms.Compose([transforms.Resize(size, antialias=True), transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "    im = transform(img).detach()\n",
    "    im = 1 - im\n",
    "    return im\n",
    "\n",
    "class Img2LatexDataset(data.Dataset):\n",
    "    def __init__(self, img_dir, formula_path, img_size = (224, 224)):\n",
    "        self.data_frame = pd.read_csv(formula_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "\n",
    "        self.token_to_idx = {}\n",
    "        self.tokens = []\n",
    "\n",
    "        for row in self.data_frame[\"formula\"]:\n",
    "            row = row.split()\n",
    "\n",
    "            for token in row:\n",
    "                if token not in self.token_to_idx:\n",
    "                    self.token_to_idx[token] = len(self.token_to_idx)\n",
    "                    self.tokens.append(token)\n",
    "        \n",
    "        for special_token in [SOS, EOS, PAD]:\n",
    "            self.token_to_idx[special_token] = len(self.token_to_idx)\n",
    "            self.tokens.append(special_token)\n",
    "\n",
    "        max_len = max([len(row.split()) for row in self.data_frame[\"formula\"]])+2\n",
    "        def indexer(row):\n",
    "            index_list = [self.token_to_idx[SOS]]\n",
    "            index_list.extend([self.token_to_idx[token] for token in row.split()])\n",
    "            index_list.append(self.token_to_idx[EOS])\n",
    "            index_list.extend([self.token_to_idx[PAD]] * (max_len - len(index_list)))\n",
    "\n",
    "            return index_list\n",
    "        \n",
    "        self.data_frame[\"IndexList\"] = self.data_frame[\"formula\"].apply(indexer)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = load_img(self.img_dir + self.data_frame[\"image\"][index], self.img_size)\n",
    "        return img, torch.tensor(self.data_frame[\"IndexList\"][index], requires_grad=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self.token_to_idx, self.tokens\n",
    "\n",
    "img_dir = \"../data/SyntheticData/images/\"\n",
    "formula_dir = \"../data/SyntheticData/train.csv\"\n",
    "\n",
    "dataset = Img2LatexDataset(img_dir, formula_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"lr\" : 0.001,\n",
    "    \"batch_size\" : 64,\n",
    "    \"epochs\" : 10\n",
    "}\n",
    "\n",
    "channel_seq = [3, 32, 64, 128, 256, 512]\n",
    "num_conv_pool = 5\n",
    "\n",
    "enc_layers = []\n",
    "\n",
    "for i in range(num_conv_pool):\n",
    "    enc_layers.append(('conv2d', {'in_channels': channel_seq[i], 'out_channels': channel_seq[i+1], 'kernel_size': 5}))\n",
    "    enc_layers.append(('maxpool2d', {'kernel_size': 2}))\n",
    "\n",
    "enc_layers.append(('avgpool2d', {'kernel_size': (3,3)}))\n",
    "\n",
    "enc = EncoderCNN(enc_layers, hparams).to(device)\n",
    "dec = DecoderRNN(dataset.tokens, dataset.token_to_idx, 512, 512).to(device)\n",
    "\n",
    "model = EncoderDecoder(enc, dec).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([32, 3, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([128, 64, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([256, 128, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([512, 256, 5, 5])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 1024])\n",
      "<class 'torch.Tensor'> torch.Size([2048, 512])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([549, 512])\n",
      "<class 'torch.Tensor'> torch.Size([549])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED MODEL to cuda\n",
      "torch.Size([31, 512])\n",
      "tensor([[546,   0,   3,  ..., 548, 548, 548],\n",
      "        [546,   0,  52,  ..., 548, 548, 548],\n",
      "        [546,   0,  40,  ..., 548, 548, 548],\n",
      "        ...,\n",
      "        [546,   0,  21,  ..., 548, 548, 548],\n",
      "        [546,   0,  55,  ..., 548, 548, 548],\n",
      "        [546,   0, 130,  ..., 548, 548, 548]], device='cuda:0')\n",
      "torch.Size([31, 161])\n",
      "torch.Size([31, 161, 512])\n",
      "torch.Size([31, 161, 512])\n",
      "torch.Size([31, 161, 549])\n",
      "H\n",
      "tensor([[False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        ...,\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True],\n",
      "        [False, False, False,  ...,  True,  True,  True]], device='cuda:0')\n",
      "torch.Size([2835, 549])\n",
      "torch.Size([2835, 549])\n",
      "h\n",
      "torch.Size([31, 161, 549])\n",
      "['$', '{', '\\\\cal', '}', '}', '=', '{', '1', '}', '}', '=', '\\\\frac', '{', '1', '}', '{', '2', '}', '{', '{', '_', '{', '2', '}', '}', '_', '{', '2', '}', '}', '_', '{', '1', '}', '^', '_', '\\\\frac', '_', '_', '{', '2', '}', '}', '_', '{', '2', '}', '}', '_', '{', '1', '}', '^', '_', '_', '^', '$', '<eos>', '_', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{']\n",
      "['$', '{', '\\\\cal', 'L', '}', '_', '{', 'K', '\\\\Phi', '}', '=', '\\\\frac', '{', '1', '}', '{', '2', '}', '\\\\left(', '\\\\partial', '^', '{', '\\\\mu', '}', '\\\\Phi', '^', '{', '\\\\dagger', '}', '\\\\partial', '_', '{', '\\\\mu', '}', '\\\\Phi', '-', 'i', '\\\\partial', '^', '{', '\\\\mu', '}', '\\\\Phi', '^', '{', '\\\\dagger', '}', '\\\\partial', '_', '{', '\\\\mu', '}', '\\\\Phi', 'i', '\\\\right)', ',', '$', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0]\n",
    "   \n",
    "   return labels[:, :len(non_pad_cols)]\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = 31, shuffle = True)\n",
    "\n",
    "model_path = \"./models/model.pt\"\n",
    "current_params_path = \"./models/current_params.txt\"\n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "images, labels = next(iter(loader))\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "labels = remove_trailing_pads(labels)\n",
    "context_vec = model.encoder(images).squeeze()\n",
    "if len(context_vec.shape) == 1:\n",
    "    context_vec = context_vec.unsqueeze(0)\n",
    "print(context_vec.shape)\n",
    "print(labels)\n",
    "print(labels.shape)\n",
    "print(context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1).shape)\n",
    "print(model.decoder.embedding(labels).shape)\n",
    "target = nn.functional.one_hot(labels, num_classes=len(dataset.tokens)).float().to(device)\n",
    "inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2)\n",
    "\n",
    "output, _ = model.decoder(inputs, None)\n",
    "print(output.shape)\n",
    "print(\"H\")\n",
    "mask = labels == PAD_IDX\n",
    "print(mask)\n",
    "print(output[labels == PAD_IDX].shape)\n",
    "print(target[labels == PAD_IDX].shape)\n",
    "# output[labels == PAD_IDX] = 0\n",
    "# target[labels == PAD_IDX] = 0\n",
    "print(\"h\")\n",
    "print(output.shape)\n",
    "output = output.argmax(dim=2)\n",
    "output_tokens = [dataset.tokens[token_idx] for token_idx in output[0].tolist()]\n",
    "print(output_tokens)\n",
    "print([dataset.tokens[token_idx] for token_idx in labels[0, 1:].tolist()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', '{', '_', '{', '1', '}', '}', '}', '=', '{', '2', '}', '=', '=', '\\\\frac', '\\\\,', '^', '{', '2', '}', '}', '{', '1', '}', '}', '}', '}', '{', '2', '}', '}', '{', '.', '\\\\frac', '{', '1', '}', '}', '{', '\\\\frac', '}', '{', '{', '\\\\frac', '}', '{', '1', '}', '}', '}', '}', '{', '{', '\\\\frac', '1', '}', '_', '{', '1', '}', '}', '}', '}', '{', '{', '\\\\frac', '}', '^', '{', '\\\\right)', '$', '.', '\\\\frac', '}', '}', '^', '.', '_', '\\\\,', '\\\\frac', '{', '}', '^', '{', 'i', '}', '}', '}', '=', '.', '\\\\frac', '}', '}', '^', '{', '$', '<eos>', '_', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{', '{']\n",
      "['$', 'S', '_', '{', '[', '1', ']', '}', '^', '{', 'c', '}', '\\\\,', '=', '\\\\,', 'e', '^', '{', 'i', '\\\\vartheta', '_', '{', '[', '1', ']', '}', '^', '{', 'c', '}', '}', '\\\\,', '\\\\left(', '\\\\begin{array}', '{', 'c', 'c', '}', '{', '0', '}', '&', '{', '\\\\Theta', '_', '{', '[', '1', ']', '}', '}', '\\\\\\\\', '{', '-', '\\\\,', '\\\\Theta', '_', '{', '[', '1', ']', '}', '}', '&', '{', '0', '}', '\\\\\\\\', '\\\\end{array}', '\\\\right)', '\\\\,', '{', '\\\\cal', 'K', '}', '\\\\,', '\\\\equiv', '\\\\,', '{', '\\\\cal', 'C', '}', '_', '{', '[', '1', ']', '}', '\\\\,', '{', '\\\\cal', 'K', '}', '\\\\quad', '.', '$', '<eos>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "t = 27\n",
    "output_tokens = [dataset.tokens[token_idx] for token_idx in output[t].tolist()]\n",
    "print(output_tokens)\n",
    "print([dataset.tokens[token_idx] for token_idx in labels[t, 1:].tolist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1734.1604, 2072.4707,  252.6192,  215.5585,  217.3692, 1952.0667,\n",
       "        2512.1045,  230.7138,  220.1318, 2070.3169, 1944.1429, 1655.5834,\n",
       "         178.0718,  213.9041, 1245.3400, 2149.6555, 1944.7310, 1942.9019,\n",
       "         374.3238, 1622.1216,  504.0812,  623.3975,  214.0963,  230.4600,\n",
       "        1964.6390,  205.6519,  273.4448,  226.8584, 1580.5632, 1955.5258,\n",
       "         233.6819,  261.7012, 1666.2042, 1623.9436, 1670.8289, 1598.0292,\n",
       "         243.2216,  220.0372, 1949.1882,  222.4726, 1978.6477, 1937.8784,\n",
       "         302.8336,  217.6581, 1967.6904, 2024.3748, 1591.1747, 1569.5627,\n",
       "        3150.0876,  218.5603,  216.4439, 1637.1022,  217.0717,  164.1452,\n",
       "        1994.8130, 1587.9167, 1956.4849,  203.3632,  200.6049,  311.7800,\n",
       "        1585.7943, 1646.0098, 1944.4889, 1584.9890, 1602.2743,  194.7858,\n",
       "        1958.3536,  444.8534, 1958.7516, 1928.8143, 1658.7949, 1406.0608,\n",
       "        2660.7786,  210.7152, 1591.8102, 2446.9768, 1605.8856,  199.1292,\n",
       "        2092.7134, 1621.6423, 1997.4701, 1983.5083,  127.8232, 1623.2202,\n",
       "         216.8455, 1962.4543, 1954.1826,  187.6516, 1621.3401, 2014.3300,\n",
       "        1957.6008,  191.0217,  191.1535, 1600.9648, 2047.5240, 2084.0117,\n",
       "         596.5546,  427.6954,  186.0078, 2033.2334,  252.3554,  202.0293,\n",
       "        2997.4033,  197.2981,  434.3950,  293.5649,  237.2772,  224.1999,\n",
       "         457.6664, 2262.9783, 1693.0026, 2410.2734,  197.4115, 1592.4750,\n",
       "        1970.9547,  193.9722,  184.9067,  254.1237, 1633.4939, 2135.2590,\n",
       "        1954.0312,  143.6440, 1654.4922,  260.6284,  660.1451,  220.8467,\n",
       "         275.7413, 1656.5624,  326.6652, 2053.4548,  489.3335,  211.4370,\n",
       "         210.0995, 1600.3053, 1986.4924,  257.4280, 1656.0171,  221.8414,\n",
       "        1904.7816, 1942.3429,  350.0374, 1698.0880, 1608.9603,  170.6849,\n",
       "        1905.1019,  175.4389,  236.3952, 2042.0354,  180.6770,  276.5999,\n",
       "         210.3500, 1630.9027,  296.2735,  270.6233,  287.8549, 1930.0306,\n",
       "         179.7047, 1615.0706, 1913.7118,  220.5714, 1606.8412,  219.2022,\n",
       "         224.0030, 1612.9659, 1963.9802, 1995.6904,  341.5000, 1996.7992,\n",
       "         280.9182,  182.0666,  212.9470, 1999.7909, 2237.5674,  284.1943,\n",
       "         229.0126, 1615.1609,  352.6448,  231.7483, 1615.8104,  183.1380,\n",
       "        1903.6360,  198.7336,  239.4345, 2035.6760, 1948.4421,  201.7550,\n",
       "         195.5453,  252.0621, 1964.9448, 1969.8561, 1975.3533, 1573.4799,\n",
       "         278.8395,  160.1132,  234.5703,  255.2583, 1580.6890, 1598.9462,\n",
       "         216.5594,  281.7617,  300.2778,  310.9838,  201.7132, 2000.8759,\n",
       "         187.0771,  239.2932, 1633.9376, 2002.5046, 1924.4427, 2041.4528,\n",
       "        1674.7043, 1596.1301, 1971.5276, 1646.3850, 1068.6462,  499.2125,\n",
       "        1956.6387,  195.0397,  273.5725,  309.4285, 1932.1053, 1588.7468,\n",
       "        2145.7773, 2261.4785, 1608.4501,  236.5504, 1583.7577,  311.1363,\n",
       "        2049.3237, 2011.7802,  192.1308, 1921.7302,  268.8392, 1950.3091,\n",
       "         173.7306, 2005.2140,  206.0701, 1648.5768,  188.5606,  230.8860,\n",
       "        2000.9061, 1984.2583,  347.5899, 1988.8890, 1967.6396,  644.2937,\n",
       "         258.9025, 1613.5847, 1651.6487,  364.4552, 2047.6095, 1570.0747,\n",
       "        1587.5488, 1970.2157,  202.4970,  280.9392,  202.2704,  190.3976,\n",
       "         225.4185,  200.4203,  208.5917, 2009.9338,  224.4762, 4569.9067,\n",
       "         423.1777, 1644.3097, 1942.4427, 1955.7203, 1974.6141, 1796.5012,\n",
       "         248.9073,  488.0496, 1656.0861,  191.5478, 2042.2671,  240.9355,\n",
       "         186.1632, 1647.5021, 2260.1650, 1714.2384, 1575.4177,  183.9545,\n",
       "         192.3472,  200.6792,  166.9894, 2009.4886, 1627.3657, 2088.8611,\n",
       "         215.7912,  774.7803, 1598.7474, 1589.1320,  193.3688, 2024.5272,\n",
       "        2098.5830, 1585.9939,  397.1557,  432.8669, 1608.4352,  309.5633,\n",
       "         202.0742,  400.2130, 1620.9495, 1621.5957,  184.6101,  206.5536,\n",
       "         871.9304,  182.4277, 1666.3333,  199.0614, 1616.5613, 1556.1440,\n",
       "        1573.0159,  217.5089,  296.8964, 1590.5460, 1959.8009,  337.9868,\n",
       "        1604.2197,  243.6858, 1271.1904,  221.0852,  234.0467,  922.7005,\n",
       "         189.6839,  208.5311, 2032.6685,  199.8118,  255.8303, 1625.4421,\n",
       "        1595.7190,  264.0386, 1948.3800,  197.5587,  676.3924,  262.6884,\n",
       "         168.0467,  213.9640, 1909.7777, 1964.1355,  341.0035, 1673.7520,\n",
       "         279.3752,  226.8567, 2021.3323, 1938.8298, 1638.5282, 1598.3329,\n",
       "         195.7118, 1940.8397, 1613.6488, 1788.4526,  192.1172,  205.3209,\n",
       "         251.6318, 1701.4252, 1577.5911,  262.5567,  232.5106,  177.3625,\n",
       "         195.4280,  193.2348,  249.3349,  274.9368,  282.2879, 1604.0216,\n",
       "        1164.4341,  565.3531,  215.2836, 1601.9108,  384.2124,  218.2679,\n",
       "        1981.3826,  202.1303,  217.4909,  245.9351,  180.1619, 1735.5958,\n",
       "        1608.0222, 1957.9697, 1989.3956,  217.0219,  206.2852,  572.1429,\n",
       "        1949.5433,  230.8943, 1945.0614, 1578.7367,  228.0712,  237.0225,\n",
       "        1699.8555,  237.2258,  208.8014,  716.2084,  185.5689, 1583.0133,\n",
       "         210.2700,  197.6865,  186.6133,  216.6513,  202.8001, 2007.8718,\n",
       "         169.8273,  214.3681, 1576.4351,  747.1990,  187.3885, 1594.2982,\n",
       "         162.8309, 1832.7198, 1998.2679,  221.3087, 2120.2012,  318.1745,\n",
       "        1952.2078,  252.9600, 1624.9001,  336.4955, 2034.1910, 1918.5045,\n",
       "        1957.5343, 1587.2185, 2072.5522,  198.9888, 1655.5243, 1959.6846,\n",
       "        1984.4221,  492.6928, 1621.0078,  382.8004, 2007.0024,  192.6567,\n",
       "         244.5722,  248.8508,  228.8720, 2229.2964, 1608.3446, 1750.4524,\n",
       "        1954.3434, 2035.5227,  223.3970,  257.9302, 2102.2068, 1948.6073,\n",
       "        1582.8583, 2081.0557,  240.8204, 1981.9331,  168.1885, 1968.4082,\n",
       "        2084.1875,  192.1631,  300.5800, 1681.0970,  321.0082,  409.7813,\n",
       "         213.5170, 1627.8812, 1799.4857, 1649.5261, 2227.0337,  174.8162,\n",
       "        2361.0955, 2042.4928,  259.7658, 1614.0079,  202.4066, 1948.9478,\n",
       "         976.3595, 1148.4910, 1598.1044, 1908.5385, 1869.3066, 1628.8390,\n",
       "         236.7710, 1629.0590, 2080.3176,  308.9594, 1939.0974,  202.1614,\n",
       "        1622.5856, 1999.2720,  212.7152, 1600.1041,  143.3778, 1666.7505,\n",
       "         231.9697, 1988.7133, 2083.0850, 1673.0609, 1723.6432,  492.1842,\n",
       "        1959.5184,  398.2504, 1677.1144, 1612.9453, 1955.3766,  215.6329,\n",
       "         230.3894, 1571.2089,  218.8087,  216.5171,  251.5740, 1643.3228,\n",
       "        1677.5233,  380.0384, 1813.4005, 1727.1516,  230.0147, 1568.5699,\n",
       "        2024.5148, 2251.0034], device='cuda:0', grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# context_vec.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1172\n",
      "LOADED MODEL to cuda\n",
      "Running Batch 0, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.506558418273926\n",
      "Running Batch 1, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.6690030097961426\n",
      "Running Batch 2, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.5177550315856934\n",
      "Running Batch 3, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.6396701335906982\n",
      "Running Batch 4, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.5864717960357666\n",
      "Running Batch 5, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.5781874656677246\n",
      "Running Batch 6, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.533294677734375\n",
      "Running Batch 7, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.6249117851257324\n",
      "Running Batch 8, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.603182315826416\n",
      "Running Batch 9, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.6024012565612793\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 9, Loss: 2.6024012565612793\n",
      "Running Batch 10, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.5511460304260254\n",
      "Running Batch 11, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.5721981525421143\n",
      "Running Batch 12, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.714825391769409\n",
      "Running Batch 13, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.4616825580596924\n",
      "Running Batch 14, Epoch 0, Total Tokens: 293\n",
      "Loss: 2.465970993041992\n",
      "Running Batch 15, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.56864070892334\n",
      "Running Batch 16, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.458177328109741\n",
      "Running Batch 17, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.54524302482605\n",
      "Running Batch 18, Epoch 0, Total Tokens: 202\n",
      "Loss: 2.5198841094970703\n",
      "Running Batch 19, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.5101568698883057\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 19, Loss: 2.5101568698883057\n",
      "Running Batch 20, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.546635150909424\n",
      "Running Batch 21, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.530975103378296\n",
      "Running Batch 22, Epoch 0, Total Tokens: 418\n",
      "Loss: 2.4796273708343506\n",
      "Running Batch 23, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.4371731281280518\n",
      "Running Batch 24, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.516359567642212\n",
      "Running Batch 25, Epoch 0, Total Tokens: 106\n",
      "Loss: 2.5882554054260254\n",
      "Running Batch 26, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.5332188606262207\n",
      "Running Batch 27, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.6931886672973633\n",
      "Running Batch 28, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.5461552143096924\n",
      "Running Batch 29, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.535740375518799\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 29, Loss: 2.535740375518799\n",
      "Running Batch 30, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.5364062786102295\n",
      "Running Batch 31, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.4983510971069336\n",
      "Running Batch 32, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.5393736362457275\n",
      "Running Batch 33, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.5496861934661865\n",
      "Running Batch 34, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.5504658222198486\n",
      "Running Batch 35, Epoch 0, Total Tokens: 176\n",
      "Loss: 2.4973599910736084\n",
      "Running Batch 36, Epoch 0, Total Tokens: 251\n",
      "Loss: 2.5109505653381348\n",
      "Running Batch 37, Epoch 0, Total Tokens: 185\n",
      "Loss: 2.6377668380737305\n",
      "Running Batch 38, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.5366568565368652\n",
      "Running Batch 39, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.5911526679992676\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 39, Loss: 2.5911526679992676\n",
      "Running Batch 40, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.592773675918579\n",
      "Running Batch 41, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.6539831161499023\n",
      "Running Batch 42, Epoch 0, Total Tokens: 164\n",
      "Loss: 2.5787477493286133\n",
      "Running Batch 43, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.478283405303955\n",
      "Running Batch 44, Epoch 0, Total Tokens: 168\n",
      "Loss: 2.553297758102417\n",
      "Running Batch 45, Epoch 0, Total Tokens: 285\n",
      "Loss: 2.482922077178955\n",
      "Running Batch 46, Epoch 0, Total Tokens: 114\n",
      "Loss: 2.504676103591919\n",
      "Running Batch 47, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.5055389404296875\n",
      "Running Batch 48, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.547966718673706\n",
      "Running Batch 49, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.441380262374878\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 49, Loss: 2.441380262374878\n",
      "Running Batch 50, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.5516562461853027\n",
      "Running Batch 51, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.575113296508789\n",
      "Running Batch 52, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.5043954849243164\n",
      "Running Batch 53, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.5432863235473633\n",
      "Running Batch 54, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.4615566730499268\n",
      "Running Batch 55, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.5968563556671143\n",
      "Running Batch 56, Epoch 0, Total Tokens: 357\n",
      "Loss: 2.6187798976898193\n",
      "Running Batch 57, Epoch 0, Total Tokens: 114\n",
      "Loss: 2.4975085258483887\n",
      "Running Batch 58, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.654069423675537\n",
      "Running Batch 59, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.601539134979248\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 59, Loss: 2.601539134979248\n",
      "Running Batch 60, Epoch 0, Total Tokens: 179\n",
      "Loss: 2.603771924972534\n",
      "Running Batch 61, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.5365309715270996\n",
      "Running Batch 62, Epoch 0, Total Tokens: 224\n",
      "Loss: 2.4676146507263184\n",
      "Running Batch 63, Epoch 0, Total Tokens: 169\n",
      "Loss: 2.5391857624053955\n",
      "Running Batch 64, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.521097421646118\n",
      "Running Batch 65, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.499471426010132\n",
      "Running Batch 66, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.4902520179748535\n",
      "Running Batch 67, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.5538954734802246\n",
      "Running Batch 68, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.600017786026001\n",
      "Running Batch 69, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.5122780799865723\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 69, Loss: 2.5122780799865723\n",
      "Running Batch 70, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.649855136871338\n",
      "Running Batch 71, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.404470682144165\n",
      "Running Batch 72, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.586935043334961\n",
      "Running Batch 73, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.4789621829986572\n",
      "Running Batch 74, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.5188467502593994\n",
      "Running Batch 75, Epoch 0, Total Tokens: 572\n",
      "Loss: 2.4654648303985596\n",
      "Running Batch 76, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.4024341106414795\n",
      "Running Batch 77, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.5138847827911377\n",
      "Running Batch 78, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.4943008422851562\n",
      "Running Batch 79, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.583047389984131\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 79, Loss: 2.583047389984131\n",
      "Running Batch 80, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.5400617122650146\n",
      "Running Batch 81, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.509323835372925\n",
      "Running Batch 82, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.525226593017578\n",
      "Running Batch 83, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.526506185531616\n",
      "Running Batch 84, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.507822036743164\n",
      "Running Batch 85, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.4872751235961914\n",
      "Running Batch 86, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.4211807250976562\n",
      "Running Batch 87, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.5418155193328857\n",
      "Running Batch 88, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.570232629776001\n",
      "Running Batch 89, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.4772143363952637\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 89, Loss: 2.4772143363952637\n",
      "Running Batch 90, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.5403599739074707\n",
      "Running Batch 91, Epoch 0, Total Tokens: 183\n",
      "Loss: 2.4741928577423096\n",
      "Running Batch 92, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.4309139251708984\n",
      "Running Batch 93, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.4106051921844482\n",
      "Running Batch 94, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.5395684242248535\n",
      "Running Batch 95, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.4784679412841797\n",
      "Running Batch 96, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.4236605167388916\n",
      "Running Batch 97, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.499023675918579\n",
      "Running Batch 98, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.471343755722046\n",
      "Running Batch 99, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.5400075912475586\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 99, Loss: 2.5400075912475586\n",
      "Running Batch 100, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.464362859725952\n",
      "Running Batch 101, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.5261740684509277\n",
      "Running Batch 102, Epoch 0, Total Tokens: 187\n",
      "Loss: 2.459137201309204\n",
      "Running Batch 103, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.4896092414855957\n",
      "Running Batch 104, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.616825580596924\n",
      "Running Batch 105, Epoch 0, Total Tokens: 182\n",
      "Loss: 2.500323534011841\n",
      "Running Batch 106, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.4750759601593018\n",
      "Running Batch 107, Epoch 0, Total Tokens: 181\n",
      "Loss: 2.3589746952056885\n",
      "Running Batch 108, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.4099936485290527\n",
      "Running Batch 109, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.5176055431365967\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 109, Loss: 2.5176055431365967\n",
      "Running Batch 110, Epoch 0, Total Tokens: 183\n",
      "Loss: 2.471301555633545\n",
      "Running Batch 111, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.4050862789154053\n",
      "Running Batch 112, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.4600231647491455\n",
      "Running Batch 113, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.5913164615631104\n",
      "Running Batch 114, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.442671060562134\n",
      "Running Batch 115, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.5115251541137695\n",
      "Running Batch 116, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.561131238937378\n",
      "Running Batch 117, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.492255449295044\n",
      "Running Batch 118, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.5688886642456055\n",
      "Running Batch 119, Epoch 0, Total Tokens: 107\n",
      "Loss: 2.4344379901885986\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 119, Loss: 2.4344379901885986\n",
      "Running Batch 120, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.540238380432129\n",
      "Running Batch 121, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.5416717529296875\n",
      "Running Batch 122, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.471656084060669\n",
      "Running Batch 123, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.5270066261291504\n",
      "Running Batch 124, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.4440958499908447\n",
      "Running Batch 125, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.5174150466918945\n",
      "Running Batch 126, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.516695976257324\n",
      "Running Batch 127, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.4414002895355225\n",
      "Running Batch 128, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.454948902130127\n",
      "Running Batch 129, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.3732573986053467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 129, Loss: 2.3732573986053467\n",
      "Running Batch 130, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.4366002082824707\n",
      "Running Batch 131, Epoch 0, Total Tokens: 334\n",
      "Loss: 2.4316937923431396\n",
      "Running Batch 132, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.4841976165771484\n",
      "Running Batch 133, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.487091302871704\n",
      "Running Batch 134, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.362776041030884\n",
      "Running Batch 135, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.4399123191833496\n",
      "Running Batch 136, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.414639711380005\n",
      "Running Batch 137, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.4634432792663574\n",
      "Running Batch 138, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.4246134757995605\n",
      "Running Batch 139, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.494860887527466\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 139, Loss: 2.494860887527466\n",
      "Running Batch 140, Epoch 0, Total Tokens: 267\n",
      "Loss: 2.4624617099761963\n",
      "Running Batch 141, Epoch 0, Total Tokens: 103\n",
      "Loss: 2.3889143466949463\n",
      "Running Batch 142, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.5018696784973145\n",
      "Running Batch 143, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.458618402481079\n",
      "Running Batch 144, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.3408749103546143\n",
      "Running Batch 145, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.371419906616211\n",
      "Running Batch 146, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.4737303256988525\n",
      "Running Batch 147, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.4670257568359375\n",
      "Running Batch 148, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.422489881515503\n",
      "Running Batch 149, Epoch 0, Total Tokens: 322\n",
      "Loss: 2.4665167331695557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 149, Loss: 2.4665167331695557\n",
      "Running Batch 150, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.509032726287842\n",
      "Running Batch 151, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.4527649879455566\n",
      "Running Batch 152, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.4807958602905273\n",
      "Running Batch 153, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.4300761222839355\n",
      "Running Batch 154, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.3799562454223633\n",
      "Running Batch 155, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.5140421390533447\n",
      "Running Batch 156, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.473663806915283\n",
      "Running Batch 157, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.4130725860595703\n",
      "Running Batch 158, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.430225372314453\n",
      "Running Batch 159, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.476621627807617\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 159, Loss: 2.476621627807617\n",
      "Running Batch 160, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.3723578453063965\n",
      "Running Batch 161, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.3727524280548096\n",
      "Running Batch 162, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.3788001537323\n",
      "Running Batch 163, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.527707576751709\n",
      "Running Batch 164, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.4822702407836914\n",
      "Running Batch 165, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.4593167304992676\n",
      "Running Batch 166, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.4630746841430664\n",
      "Running Batch 167, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.5061099529266357\n",
      "Running Batch 168, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.524930000305176\n",
      "Running Batch 169, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.491079330444336\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 169, Loss: 2.491079330444336\n",
      "Running Batch 170, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.4086568355560303\n",
      "Running Batch 171, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.4383718967437744\n",
      "Running Batch 172, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.3734958171844482\n",
      "Running Batch 173, Epoch 0, Total Tokens: 209\n",
      "Loss: 2.4338996410369873\n",
      "Running Batch 174, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.4075658321380615\n",
      "Running Batch 175, Epoch 0, Total Tokens: 110\n",
      "Loss: 2.4214680194854736\n",
      "Running Batch 176, Epoch 0, Total Tokens: 199\n",
      "Loss: 2.4370059967041016\n",
      "Running Batch 177, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.4015791416168213\n",
      "Running Batch 178, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.4494173526763916\n",
      "Running Batch 179, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.417879343032837\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 179, Loss: 2.417879343032837\n",
      "Running Batch 180, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.554081916809082\n",
      "Running Batch 181, Epoch 0, Total Tokens: 178\n",
      "Loss: 2.4305357933044434\n",
      "Running Batch 182, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.412493944168091\n",
      "Running Batch 183, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.3989877700805664\n",
      "Running Batch 184, Epoch 0, Total Tokens: 174\n",
      "Loss: 2.4521820545196533\n",
      "Running Batch 185, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.340503692626953\n",
      "Running Batch 186, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.418815851211548\n",
      "Running Batch 187, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.352156162261963\n",
      "Running Batch 188, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.4505059719085693\n",
      "Running Batch 189, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.329845905303955\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 189, Loss: 2.329845905303955\n",
      "Running Batch 190, Epoch 0, Total Tokens: 169\n",
      "Loss: 2.47202730178833\n",
      "Running Batch 191, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.378249168395996\n",
      "Running Batch 192, Epoch 0, Total Tokens: 181\n",
      "Loss: 2.3278684616088867\n",
      "Running Batch 193, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.4394359588623047\n",
      "Running Batch 194, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.439509868621826\n",
      "Running Batch 195, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.485309362411499\n",
      "Running Batch 196, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.496610403060913\n",
      "Running Batch 197, Epoch 0, Total Tokens: 110\n",
      "Loss: 2.418490409851074\n",
      "Running Batch 198, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.448042392730713\n",
      "Running Batch 199, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.3896684646606445\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 199, Loss: 2.3896684646606445\n",
      "Running Batch 200, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.4491915702819824\n",
      "Running Batch 201, Epoch 0, Total Tokens: 199\n",
      "Loss: 2.3459315299987793\n",
      "Running Batch 202, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.351963520050049\n",
      "Running Batch 203, Epoch 0, Total Tokens: 170\n",
      "Loss: 2.4043657779693604\n",
      "Running Batch 204, Epoch 0, Total Tokens: 188\n",
      "Loss: 2.396216630935669\n",
      "Running Batch 205, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.40193247795105\n",
      "Running Batch 206, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.4527037143707275\n",
      "Running Batch 207, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.44040584564209\n",
      "Running Batch 208, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.4869771003723145\n",
      "Running Batch 209, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.472350835800171\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 209, Loss: 2.472350835800171\n",
      "Running Batch 210, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.4154114723205566\n",
      "Running Batch 211, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3796799182891846\n",
      "Running Batch 212, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.3464341163635254\n",
      "Running Batch 213, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.442336320877075\n",
      "Running Batch 214, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.3651833534240723\n",
      "Running Batch 215, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.4843993186950684\n",
      "Running Batch 216, Epoch 0, Total Tokens: 244\n",
      "Loss: 2.3864223957061768\n",
      "Running Batch 217, Epoch 0, Total Tokens: 196\n",
      "Loss: 2.3807201385498047\n",
      "Running Batch 218, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.416172981262207\n",
      "Running Batch 219, Epoch 0, Total Tokens: 299\n",
      "Loss: 2.3749356269836426\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 219, Loss: 2.3749356269836426\n",
      "Running Batch 220, Epoch 0, Total Tokens: 214\n",
      "Loss: 2.4122567176818848\n",
      "Running Batch 221, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.3221840858459473\n",
      "Running Batch 222, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.367562770843506\n",
      "Running Batch 223, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.3656015396118164\n",
      "Running Batch 224, Epoch 0, Total Tokens: 204\n",
      "Loss: 2.3581535816192627\n",
      "Running Batch 225, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.3653273582458496\n",
      "Running Batch 226, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.3520667552948\n",
      "Running Batch 227, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.3624582290649414\n",
      "Running Batch 228, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.4474105834960938\n",
      "Running Batch 229, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.3761887550354004\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 229, Loss: 2.3761887550354004\n",
      "Running Batch 230, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.4285361766815186\n",
      "Running Batch 231, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.3898258209228516\n",
      "Running Batch 232, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.490776300430298\n",
      "Running Batch 233, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.396271228790283\n",
      "Running Batch 234, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.359771728515625\n",
      "Running Batch 235, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.402803897857666\n",
      "Running Batch 236, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.35030198097229\n",
      "Running Batch 237, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.3042943477630615\n",
      "Running Batch 238, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.3535759449005127\n",
      "Running Batch 239, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.4383716583251953\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 239, Loss: 2.4383716583251953\n",
      "Running Batch 240, Epoch 0, Total Tokens: 179\n",
      "Loss: 2.519015312194824\n",
      "Running Batch 241, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.4415817260742188\n",
      "Running Batch 242, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.3831946849823\n",
      "Running Batch 243, Epoch 0, Total Tokens: 119\n",
      "Loss: 2.4150984287261963\n",
      "Running Batch 244, Epoch 0, Total Tokens: 180\n",
      "Loss: 2.373828411102295\n",
      "Running Batch 245, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.4505414962768555\n",
      "Running Batch 246, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.4566497802734375\n",
      "Running Batch 247, Epoch 0, Total Tokens: 195\n",
      "Loss: 2.399742603302002\n",
      "Running Batch 248, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.3734312057495117\n",
      "Running Batch 249, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.3855578899383545\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 249, Loss: 2.3855578899383545\n",
      "Running Batch 250, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.3755369186401367\n",
      "Running Batch 251, Epoch 0, Total Tokens: 201\n",
      "Loss: 2.414919376373291\n",
      "Running Batch 252, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.4961705207824707\n",
      "Running Batch 253, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.439509153366089\n",
      "Running Batch 254, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.446481227874756\n",
      "Running Batch 255, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.471571207046509\n",
      "Running Batch 256, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.324047327041626\n",
      "Running Batch 257, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.3994414806365967\n",
      "Running Batch 258, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.397244930267334\n",
      "Running Batch 259, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.3191099166870117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 259, Loss: 2.3191099166870117\n",
      "Running Batch 260, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.387770414352417\n",
      "Running Batch 261, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.3584656715393066\n",
      "Running Batch 262, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.459367513656616\n",
      "Running Batch 263, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2915306091308594\n",
      "Running Batch 264, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.381542205810547\n",
      "Running Batch 265, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.2696478366851807\n",
      "Running Batch 266, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.4249117374420166\n",
      "Running Batch 267, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.538442373275757\n",
      "Running Batch 268, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.371032953262329\n",
      "Running Batch 269, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.4790828227996826\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 269, Loss: 2.4790828227996826\n",
      "Running Batch 270, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.4340262413024902\n",
      "Running Batch 271, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.4278690814971924\n",
      "Running Batch 272, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.39106822013855\n",
      "Running Batch 273, Epoch 0, Total Tokens: 186\n",
      "Loss: 2.381357431411743\n",
      "Running Batch 274, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.368866205215454\n",
      "Running Batch 275, Epoch 0, Total Tokens: 367\n",
      "Loss: 2.3796935081481934\n",
      "Running Batch 276, Epoch 0, Total Tokens: 210\n",
      "Loss: 2.300626754760742\n",
      "Running Batch 277, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.2881321907043457\n",
      "Running Batch 278, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.4199941158294678\n",
      "Running Batch 279, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.380847692489624\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 279, Loss: 2.380847692489624\n",
      "Running Batch 280, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.200437545776367\n",
      "Running Batch 281, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.3607542514801025\n",
      "Running Batch 282, Epoch 0, Total Tokens: 428\n",
      "Loss: 2.3829164505004883\n",
      "Running Batch 283, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.4261021614074707\n",
      "Running Batch 284, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.47200870513916\n",
      "Running Batch 285, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.3389041423797607\n",
      "Running Batch 286, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.3068244457244873\n",
      "Running Batch 287, Epoch 0, Total Tokens: 267\n",
      "Loss: 2.3406131267547607\n",
      "Running Batch 288, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.4396917819976807\n",
      "Running Batch 289, Epoch 0, Total Tokens: 166\n",
      "Loss: 2.3882009983062744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 289, Loss: 2.3882009983062744\n",
      "Running Batch 290, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3610498905181885\n",
      "Running Batch 291, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.2752017974853516\n",
      "Running Batch 292, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.3990416526794434\n",
      "Running Batch 293, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.253359079360962\n",
      "Running Batch 294, Epoch 0, Total Tokens: 119\n",
      "Loss: 2.4714086055755615\n",
      "Running Batch 295, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2944467067718506\n",
      "Running Batch 296, Epoch 0, Total Tokens: 114\n",
      "Loss: 2.3659040927886963\n",
      "Running Batch 297, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.383552312850952\n",
      "Running Batch 298, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.386082887649536\n",
      "Running Batch 299, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.34761118888855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 299, Loss: 2.34761118888855\n",
      "Running Batch 300, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.301807165145874\n",
      "Running Batch 301, Epoch 0, Total Tokens: 274\n",
      "Loss: 2.3895723819732666\n",
      "Running Batch 302, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.3320906162261963\n",
      "Running Batch 303, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.4357688426971436\n",
      "Running Batch 304, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2898998260498047\n",
      "Running Batch 305, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.4514849185943604\n",
      "Running Batch 306, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.3339109420776367\n",
      "Running Batch 307, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.4041504859924316\n",
      "Running Batch 308, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.2489657402038574\n",
      "Running Batch 309, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.321284770965576\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 309, Loss: 2.321284770965576\n",
      "Running Batch 310, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.301612377166748\n",
      "Running Batch 311, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.327854633331299\n",
      "Running Batch 312, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.3471128940582275\n",
      "Running Batch 313, Epoch 0, Total Tokens: 206\n",
      "Loss: 2.306913375854492\n",
      "Running Batch 314, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.297475576400757\n",
      "Running Batch 315, Epoch 0, Total Tokens: 185\n",
      "Loss: 2.3487329483032227\n",
      "Running Batch 316, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.392075300216675\n",
      "Running Batch 317, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.379629373550415\n",
      "Running Batch 318, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.4216272830963135\n",
      "Running Batch 319, Epoch 0, Total Tokens: 225\n",
      "Loss: 2.3007242679595947\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 319, Loss: 2.3007242679595947\n",
      "Running Batch 320, Epoch 0, Total Tokens: 185\n",
      "Loss: 2.315269708633423\n",
      "Running Batch 321, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.26072359085083\n",
      "Running Batch 322, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.414118766784668\n",
      "Running Batch 323, Epoch 0, Total Tokens: 294\n",
      "Loss: 2.406916856765747\n",
      "Running Batch 324, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.3972620964050293\n",
      "Running Batch 325, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.4580345153808594\n",
      "Running Batch 326, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.326558828353882\n",
      "Running Batch 327, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.4282290935516357\n",
      "Running Batch 328, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3916168212890625\n",
      "Running Batch 329, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.3649468421936035\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 329, Loss: 2.3649468421936035\n",
      "Running Batch 330, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.3079159259796143\n",
      "Running Batch 331, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.406420946121216\n",
      "Running Batch 332, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.498154640197754\n",
      "Running Batch 333, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.3529200553894043\n",
      "Running Batch 334, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.303353786468506\n",
      "Running Batch 335, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.215810537338257\n",
      "Running Batch 336, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.336723804473877\n",
      "Running Batch 337, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.2407991886138916\n",
      "Running Batch 338, Epoch 0, Total Tokens: 163\n",
      "Loss: 2.295936346054077\n",
      "Running Batch 339, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.3113365173339844\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 339, Loss: 2.3113365173339844\n",
      "Running Batch 340, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.3959596157073975\n",
      "Running Batch 341, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.337095022201538\n",
      "Running Batch 342, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.399186611175537\n",
      "Running Batch 343, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.304452657699585\n",
      "Running Batch 344, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.388336181640625\n",
      "Running Batch 345, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.3385555744171143\n",
      "Running Batch 346, Epoch 0, Total Tokens: 211\n",
      "Loss: 2.3706166744232178\n",
      "Running Batch 347, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.3584847450256348\n",
      "Running Batch 348, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.368705987930298\n",
      "Running Batch 349, Epoch 0, Total Tokens: 184\n",
      "Loss: 2.407597064971924\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 349, Loss: 2.407597064971924\n",
      "Running Batch 350, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.362931489944458\n",
      "Running Batch 351, Epoch 0, Total Tokens: 258\n",
      "Loss: 2.3022942543029785\n",
      "Running Batch 352, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3936471939086914\n",
      "Running Batch 353, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.347374439239502\n",
      "Running Batch 354, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.3815340995788574\n",
      "Running Batch 355, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.440126419067383\n",
      "Running Batch 356, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.3425607681274414\n",
      "Running Batch 357, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.3553550243377686\n",
      "Running Batch 358, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.340075731277466\n",
      "Running Batch 359, Epoch 0, Total Tokens: 205\n",
      "Loss: 2.229065418243408\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 359, Loss: 2.229065418243408\n",
      "Running Batch 360, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.419637441635132\n",
      "Running Batch 361, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.3214187622070312\n",
      "Running Batch 362, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.284369468688965\n",
      "Running Batch 363, Epoch 0, Total Tokens: 111\n",
      "Loss: 2.337847948074341\n",
      "Running Batch 364, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.271273374557495\n",
      "Running Batch 365, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.391712188720703\n",
      "Running Batch 366, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.266594648361206\n",
      "Running Batch 367, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2998437881469727\n",
      "Running Batch 368, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.3956339359283447\n",
      "Running Batch 369, Epoch 0, Total Tokens: 166\n",
      "Loss: 2.2384941577911377\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 369, Loss: 2.2384941577911377\n",
      "Running Batch 370, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.254399299621582\n",
      "Running Batch 371, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.392536163330078\n",
      "Running Batch 372, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.3432064056396484\n",
      "Running Batch 373, Epoch 0, Total Tokens: 231\n",
      "Loss: 2.396530866622925\n",
      "Running Batch 374, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.335449695587158\n",
      "Running Batch 375, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.2797772884368896\n",
      "Running Batch 376, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2752959728240967\n",
      "Running Batch 377, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.290497303009033\n",
      "Running Batch 378, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.26910138130188\n",
      "Running Batch 379, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.2336130142211914\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 379, Loss: 2.2336130142211914\n",
      "Running Batch 380, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.300271511077881\n",
      "Running Batch 381, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.351200580596924\n",
      "Running Batch 382, Epoch 0, Total Tokens: 236\n",
      "Loss: 2.341797351837158\n",
      "Running Batch 383, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.29207444190979\n",
      "Running Batch 384, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.245561361312866\n",
      "Running Batch 385, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.3828234672546387\n",
      "Running Batch 386, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.2686526775360107\n",
      "Running Batch 387, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.3702433109283447\n",
      "Running Batch 388, Epoch 0, Total Tokens: 169\n",
      "Loss: 2.31868314743042\n",
      "Running Batch 389, Epoch 0, Total Tokens: 176\n",
      "Loss: 2.3554930686950684\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 389, Loss: 2.3554930686950684\n",
      "Running Batch 390, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.3130643367767334\n",
      "Running Batch 391, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.2828474044799805\n",
      "Running Batch 392, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.3330130577087402\n",
      "Running Batch 393, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2680132389068604\n",
      "Running Batch 394, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3641397953033447\n",
      "Running Batch 395, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.4152908325195312\n",
      "Running Batch 396, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2876009941101074\n",
      "Running Batch 397, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2393343448638916\n",
      "Running Batch 398, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2609901428222656\n",
      "Running Batch 399, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.2238082885742188\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 399, Loss: 2.2238082885742188\n",
      "Running Batch 400, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.303015947341919\n",
      "Running Batch 401, Epoch 0, Total Tokens: 182\n",
      "Loss: 2.3442764282226562\n",
      "Running Batch 402, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2934157848358154\n",
      "Running Batch 403, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.342466115951538\n",
      "Running Batch 404, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.2639830112457275\n",
      "Running Batch 405, Epoch 0, Total Tokens: 295\n",
      "Loss: 2.3128607273101807\n",
      "Running Batch 406, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.2402586936950684\n",
      "Running Batch 407, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.334360122680664\n",
      "Running Batch 408, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2814059257507324\n",
      "Running Batch 409, Epoch 0, Total Tokens: 262\n",
      "Loss: 2.352170705795288\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 409, Loss: 2.352170705795288\n",
      "Running Batch 410, Epoch 0, Total Tokens: 111\n",
      "Loss: 2.224992513656616\n",
      "Running Batch 411, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2876269817352295\n",
      "Running Batch 412, Epoch 0, Total Tokens: 356\n",
      "Loss: 2.324430227279663\n",
      "Running Batch 413, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.250692844390869\n",
      "Running Batch 414, Epoch 0, Total Tokens: 219\n",
      "Loss: 2.2535150051116943\n",
      "Running Batch 415, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.2618918418884277\n",
      "Running Batch 416, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.221282958984375\n",
      "Running Batch 417, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.342067241668701\n",
      "Running Batch 418, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2815322875976562\n",
      "Running Batch 419, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.245730400085449\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 419, Loss: 2.245730400085449\n",
      "Running Batch 420, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.3750150203704834\n",
      "Running Batch 421, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.2121689319610596\n",
      "Running Batch 422, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.301802635192871\n",
      "Running Batch 423, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.359739303588867\n",
      "Running Batch 424, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.2941372394561768\n",
      "Running Batch 425, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.2731716632843018\n",
      "Running Batch 426, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.2232680320739746\n",
      "Running Batch 427, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2835114002227783\n",
      "Running Batch 428, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.367743730545044\n",
      "Running Batch 429, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.275238037109375\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 429, Loss: 2.275238037109375\n",
      "Running Batch 430, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.3035404682159424\n",
      "Running Batch 431, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.325084924697876\n",
      "Running Batch 432, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.1903350353240967\n",
      "Running Batch 433, Epoch 0, Total Tokens: 190\n",
      "Loss: 2.3477025032043457\n",
      "Running Batch 434, Epoch 0, Total Tokens: 360\n",
      "Loss: 2.2980034351348877\n",
      "Running Batch 435, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.2538809776306152\n",
      "Running Batch 436, Epoch 0, Total Tokens: 109\n",
      "Loss: 2.3782825469970703\n",
      "Running Batch 437, Epoch 0, Total Tokens: 203\n",
      "Loss: 2.2573699951171875\n",
      "Running Batch 438, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.2543563842773438\n",
      "Running Batch 439, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.3438096046447754\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 439, Loss: 2.3438096046447754\n",
      "Running Batch 440, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.297233819961548\n",
      "Running Batch 441, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.1754047870635986\n",
      "Running Batch 442, Epoch 0, Total Tokens: 169\n",
      "Loss: 2.299990653991699\n",
      "Running Batch 443, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.209914207458496\n",
      "Running Batch 444, Epoch 0, Total Tokens: 223\n",
      "Loss: 2.2526893615722656\n",
      "Running Batch 445, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.384474277496338\n",
      "Running Batch 446, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.219822645187378\n",
      "Running Batch 447, Epoch 0, Total Tokens: 452\n",
      "Loss: 2.4550883769989014\n",
      "Running Batch 448, Epoch 0, Total Tokens: 202\n",
      "Loss: 2.3244948387145996\n",
      "Running Batch 449, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.4016973972320557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 449, Loss: 2.4016973972320557\n",
      "Running Batch 450, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.286665916442871\n",
      "Running Batch 451, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.27370285987854\n",
      "Running Batch 452, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.301356077194214\n",
      "Running Batch 453, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.3281567096710205\n",
      "Running Batch 454, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.3280019760131836\n",
      "Running Batch 455, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.210253953933716\n",
      "Running Batch 456, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.316136121749878\n",
      "Running Batch 457, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.3449385166168213\n",
      "Running Batch 458, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.3709704875946045\n",
      "Running Batch 459, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.391540288925171\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 459, Loss: 2.391540288925171\n",
      "Running Batch 460, Epoch 0, Total Tokens: 254\n",
      "Loss: 2.212130069732666\n",
      "Running Batch 461, Epoch 0, Total Tokens: 184\n",
      "Loss: 2.267475128173828\n",
      "Running Batch 462, Epoch 0, Total Tokens: 158\n",
      "Loss: 2.3846628665924072\n",
      "Running Batch 463, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.3523378372192383\n",
      "Running Batch 464, Epoch 0, Total Tokens: 254\n",
      "Loss: 2.1807634830474854\n",
      "Running Batch 465, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.348144292831421\n",
      "Running Batch 466, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1977062225341797\n",
      "Running Batch 467, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.227531671524048\n",
      "Running Batch 468, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.3025095462799072\n",
      "Running Batch 469, Epoch 0, Total Tokens: 261\n",
      "Loss: 2.365445613861084\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 469, Loss: 2.365445613861084\n",
      "Running Batch 470, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.3341848850250244\n",
      "Running Batch 471, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.2827391624450684\n",
      "Running Batch 472, Epoch 0, Total Tokens: 281\n",
      "Loss: 2.2905054092407227\n",
      "Running Batch 473, Epoch 0, Total Tokens: 109\n",
      "Loss: 2.319221019744873\n",
      "Running Batch 474, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.311898946762085\n",
      "Running Batch 475, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2499756813049316\n",
      "Running Batch 476, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.1211040019989014\n",
      "Running Batch 477, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.255842447280884\n",
      "Running Batch 478, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.313452959060669\n",
      "Running Batch 479, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.256680965423584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 479, Loss: 2.256680965423584\n",
      "Running Batch 480, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.2870047092437744\n",
      "Running Batch 481, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.2628276348114014\n",
      "Running Batch 482, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.2695398330688477\n",
      "Running Batch 483, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.3431971073150635\n",
      "Running Batch 484, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.326352834701538\n",
      "Running Batch 485, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.307544469833374\n",
      "Running Batch 486, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.299596071243286\n",
      "Running Batch 487, Epoch 0, Total Tokens: 191\n",
      "Loss: 2.3287229537963867\n",
      "Running Batch 488, Epoch 0, Total Tokens: 186\n",
      "Loss: 2.3238046169281006\n",
      "Running Batch 489, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.340517044067383\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 489, Loss: 2.340517044067383\n",
      "Running Batch 490, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.3029651641845703\n",
      "Running Batch 491, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.2139673233032227\n",
      "Running Batch 492, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.252251148223877\n",
      "Running Batch 493, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.2051730155944824\n",
      "Running Batch 494, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.3178467750549316\n",
      "Running Batch 495, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.268246650695801\n",
      "Running Batch 496, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.3102922439575195\n",
      "Running Batch 497, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2317628860473633\n",
      "Running Batch 498, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.4148013591766357\n",
      "Running Batch 499, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.189525842666626\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 499, Loss: 2.189525842666626\n",
      "Running Batch 500, Epoch 0, Total Tokens: 171\n",
      "Loss: 2.170705795288086\n",
      "Running Batch 501, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.210425853729248\n",
      "Running Batch 502, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.343252658843994\n",
      "Running Batch 503, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.293888807296753\n",
      "Running Batch 504, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.3363726139068604\n",
      "Running Batch 505, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.3391103744506836\n",
      "Running Batch 506, Epoch 0, Total Tokens: 175\n",
      "Loss: 2.303874969482422\n",
      "Running Batch 507, Epoch 0, Total Tokens: 241\n",
      "Loss: 2.1866097450256348\n",
      "Running Batch 508, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.2458765506744385\n",
      "Running Batch 509, Epoch 0, Total Tokens: 93\n",
      "Loss: 2.2564141750335693\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 509, Loss: 2.2564141750335693\n",
      "Running Batch 510, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.2286012172698975\n",
      "Running Batch 511, Epoch 0, Total Tokens: 111\n",
      "Loss: 2.218154191970825\n",
      "Running Batch 512, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.325070858001709\n",
      "Running Batch 513, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.1995646953582764\n",
      "Running Batch 514, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.3246185779571533\n",
      "Running Batch 515, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.306391477584839\n",
      "Running Batch 516, Epoch 0, Total Tokens: 206\n",
      "Loss: 2.2381255626678467\n",
      "Running Batch 517, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.279945135116577\n",
      "Running Batch 518, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.318375587463379\n",
      "Running Batch 519, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.302244186401367\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 519, Loss: 2.302244186401367\n",
      "Running Batch 520, Epoch 0, Total Tokens: 158\n",
      "Loss: 2.403899908065796\n",
      "Running Batch 521, Epoch 0, Total Tokens: 219\n",
      "Loss: 2.2556376457214355\n",
      "Running Batch 522, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.287391185760498\n",
      "Running Batch 523, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.260952949523926\n",
      "Running Batch 524, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.207594156265259\n",
      "Running Batch 525, Epoch 0, Total Tokens: 167\n",
      "Loss: 2.3794162273406982\n",
      "Running Batch 526, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.315347671508789\n",
      "Running Batch 527, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2700114250183105\n",
      "Running Batch 528, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.233926296234131\n",
      "Running Batch 529, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.155766725540161\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 529, Loss: 2.155766725540161\n",
      "Running Batch 530, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.2131659984588623\n",
      "Running Batch 531, Epoch 0, Total Tokens: 228\n",
      "Loss: 2.2566936016082764\n",
      "Running Batch 532, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.248173952102661\n",
      "Running Batch 533, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2975025177001953\n",
      "Running Batch 534, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.2806403636932373\n",
      "Running Batch 535, Epoch 0, Total Tokens: 187\n",
      "Loss: 2.2739930152893066\n",
      "Running Batch 536, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1611762046813965\n",
      "Running Batch 537, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.171769142150879\n",
      "Running Batch 538, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.2370636463165283\n",
      "Running Batch 539, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.259685754776001\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 539, Loss: 2.259685754776001\n",
      "Running Batch 540, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.22650146484375\n",
      "Running Batch 541, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.303234577178955\n",
      "Running Batch 542, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.172044038772583\n",
      "Running Batch 543, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.168972969055176\n",
      "Running Batch 544, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.1794826984405518\n",
      "Running Batch 545, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.274308919906616\n",
      "Running Batch 546, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1935811042785645\n",
      "Running Batch 547, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.142709732055664\n",
      "Running Batch 548, Epoch 0, Total Tokens: 231\n",
      "Loss: 2.2522642612457275\n",
      "Running Batch 549, Epoch 0, Total Tokens: 288\n",
      "Loss: 2.281965732574463\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 549, Loss: 2.281965732574463\n",
      "Running Batch 550, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2682855129241943\n",
      "Running Batch 551, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.212318181991577\n",
      "Running Batch 552, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2963316440582275\n",
      "Running Batch 553, Epoch 0, Total Tokens: 221\n",
      "Loss: 2.31132173538208\n",
      "Running Batch 554, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.17980694770813\n",
      "Running Batch 555, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.2293648719787598\n",
      "Running Batch 556, Epoch 0, Total Tokens: 181\n",
      "Loss: 2.2683427333831787\n",
      "Running Batch 557, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.3056318759918213\n",
      "Running Batch 558, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.1657369136810303\n",
      "Running Batch 559, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3706209659576416\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 559, Loss: 2.3706209659576416\n",
      "Running Batch 560, Epoch 0, Total Tokens: 361\n",
      "Loss: 2.2221646308898926\n",
      "Running Batch 561, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.3210043907165527\n",
      "Running Batch 562, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.2550272941589355\n",
      "Running Batch 563, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.2481529712677\n",
      "Running Batch 564, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.158874273300171\n",
      "Running Batch 565, Epoch 0, Total Tokens: 155\n",
      "Loss: 2.34702205657959\n",
      "Running Batch 566, Epoch 0, Total Tokens: 158\n",
      "Loss: 2.2226145267486572\n",
      "Running Batch 567, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.3158037662506104\n",
      "Running Batch 568, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.3989713191986084\n",
      "Running Batch 569, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.156238317489624\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 569, Loss: 2.156238317489624\n",
      "Running Batch 570, Epoch 0, Total Tokens: 199\n",
      "Loss: 2.1940486431121826\n",
      "Running Batch 571, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.2304272651672363\n",
      "Running Batch 572, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.264697551727295\n",
      "Running Batch 573, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.312474012374878\n",
      "Running Batch 574, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.2925655841827393\n",
      "Running Batch 575, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.1812336444854736\n",
      "Running Batch 576, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.198190450668335\n",
      "Running Batch 577, Epoch 0, Total Tokens: 178\n",
      "Loss: 2.214858293533325\n",
      "Running Batch 578, Epoch 0, Total Tokens: 179\n",
      "Loss: 2.2314400672912598\n",
      "Running Batch 579, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.172443389892578\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 579, Loss: 2.172443389892578\n",
      "Running Batch 580, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.2649331092834473\n",
      "Running Batch 581, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.262725830078125\n",
      "Running Batch 582, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.1671884059906006\n",
      "Running Batch 583, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.287454843521118\n",
      "Running Batch 584, Epoch 0, Total Tokens: 282\n",
      "Loss: 2.236607551574707\n",
      "Running Batch 585, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2842466831207275\n",
      "Running Batch 586, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.212247610092163\n",
      "Running Batch 587, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.1633102893829346\n",
      "Running Batch 588, Epoch 0, Total Tokens: 214\n",
      "Loss: 2.190181255340576\n",
      "Running Batch 589, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.270354986190796\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 589, Loss: 2.270354986190796\n",
      "Running Batch 590, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.32720685005188\n",
      "Running Batch 591, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.258295774459839\n",
      "Running Batch 592, Epoch 0, Total Tokens: 107\n",
      "Loss: 2.256333827972412\n",
      "Running Batch 593, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1754448413848877\n",
      "Running Batch 594, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.2401630878448486\n",
      "Running Batch 595, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.3071866035461426\n",
      "Running Batch 596, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.1865785121917725\n",
      "Running Batch 597, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.3592796325683594\n",
      "Running Batch 598, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.235273838043213\n",
      "Running Batch 599, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.3208963871002197\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 599, Loss: 2.3208963871002197\n",
      "Running Batch 600, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.223299264907837\n",
      "Running Batch 601, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.205350399017334\n",
      "Running Batch 602, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.34614896774292\n",
      "Running Batch 603, Epoch 0, Total Tokens: 337\n",
      "Loss: 2.1966164112091064\n",
      "Running Batch 604, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.2056143283843994\n",
      "Running Batch 605, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2249832153320312\n",
      "Running Batch 606, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.1844496726989746\n",
      "Running Batch 607, Epoch 0, Total Tokens: 178\n",
      "Loss: 2.3254685401916504\n",
      "Running Batch 608, Epoch 0, Total Tokens: 186\n",
      "Loss: 2.14621639251709\n",
      "Running Batch 609, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.192288637161255\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 609, Loss: 2.192288637161255\n",
      "Running Batch 610, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2000672817230225\n",
      "Running Batch 611, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.204503059387207\n",
      "Running Batch 612, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.100137948989868\n",
      "Running Batch 613, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2796547412872314\n",
      "Running Batch 614, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.2537357807159424\n",
      "Running Batch 615, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.193798065185547\n",
      "Running Batch 616, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.1093294620513916\n",
      "Running Batch 617, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.18605375289917\n",
      "Running Batch 618, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.2330174446105957\n",
      "Running Batch 619, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.167180299758911\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 619, Loss: 2.167180299758911\n",
      "Running Batch 620, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.297200918197632\n",
      "Running Batch 621, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.138688802719116\n",
      "Running Batch 622, Epoch 0, Total Tokens: 160\n",
      "Loss: 2.196115255355835\n",
      "Running Batch 623, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.155289649963379\n",
      "Running Batch 624, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.208379030227661\n",
      "Running Batch 625, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.2508411407470703\n",
      "Running Batch 626, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.233072280883789\n",
      "Running Batch 627, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.2390589714050293\n",
      "Running Batch 628, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.171163320541382\n",
      "Running Batch 629, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.2881174087524414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 629, Loss: 2.2881174087524414\n",
      "Running Batch 630, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.211359977722168\n",
      "Running Batch 631, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.267974376678467\n",
      "Running Batch 632, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.3099071979522705\n",
      "Running Batch 633, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2536346912384033\n",
      "Running Batch 634, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2359046936035156\n",
      "Running Batch 635, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.317711353302002\n",
      "Running Batch 636, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.181386709213257\n",
      "Running Batch 637, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.3004324436187744\n",
      "Running Batch 638, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.2360007762908936\n",
      "Running Batch 639, Epoch 0, Total Tokens: 372\n",
      "Loss: 2.1729698181152344\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 639, Loss: 2.1729698181152344\n",
      "Running Batch 640, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.1542954444885254\n",
      "Running Batch 641, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.231642961502075\n",
      "Running Batch 642, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.069587469100952\n",
      "Running Batch 643, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.204285144805908\n",
      "Running Batch 644, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.306929588317871\n",
      "Running Batch 645, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.286435842514038\n",
      "Running Batch 646, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2417500019073486\n",
      "Running Batch 647, Epoch 0, Total Tokens: 229\n",
      "Loss: 2.1881093978881836\n",
      "Running Batch 648, Epoch 0, Total Tokens: 266\n",
      "Loss: 2.154183864593506\n",
      "Running Batch 649, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.197237491607666\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 649, Loss: 2.197237491607666\n",
      "Running Batch 650, Epoch 0, Total Tokens: 326\n",
      "Loss: 2.21573543548584\n",
      "Running Batch 651, Epoch 0, Total Tokens: 237\n",
      "Loss: 2.1451330184936523\n",
      "Running Batch 652, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2173056602478027\n",
      "Running Batch 653, Epoch 0, Total Tokens: 108\n",
      "Loss: 2.268782377243042\n",
      "Running Batch 654, Epoch 0, Total Tokens: 624\n",
      "Loss: 2.2358763217926025\n",
      "Running Batch 655, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.174628496170044\n",
      "Running Batch 656, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.164156675338745\n",
      "Running Batch 657, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.215289354324341\n",
      "Running Batch 658, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.2411038875579834\n",
      "Running Batch 659, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.130523204803467\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 659, Loss: 2.130523204803467\n",
      "Running Batch 660, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.1412079334259033\n",
      "Running Batch 661, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.337118625640869\n",
      "Running Batch 662, Epoch 0, Total Tokens: 250\n",
      "Loss: 2.21282958984375\n",
      "Running Batch 663, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.339311122894287\n",
      "Running Batch 664, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.235438346862793\n",
      "Running Batch 665, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1834218502044678\n",
      "Running Batch 666, Epoch 0, Total Tokens: 197\n",
      "Loss: 2.1887025833129883\n",
      "Running Batch 667, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.2396886348724365\n",
      "Running Batch 668, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.2565054893493652\n",
      "Running Batch 669, Epoch 0, Total Tokens: 109\n",
      "Loss: 2.3647615909576416\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 669, Loss: 2.3647615909576416\n",
      "Running Batch 670, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.214639186859131\n",
      "Running Batch 671, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.2451329231262207\n",
      "Running Batch 672, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.1833300590515137\n",
      "Running Batch 673, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.294036865234375\n",
      "Running Batch 674, Epoch 0, Total Tokens: 244\n",
      "Loss: 2.196528434753418\n",
      "Running Batch 675, Epoch 0, Total Tokens: 99\n",
      "Loss: 2.2897489070892334\n",
      "Running Batch 676, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.1171317100524902\n",
      "Running Batch 677, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.218942165374756\n",
      "Running Batch 678, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.2254011631011963\n",
      "Running Batch 679, Epoch 0, Total Tokens: 228\n",
      "Loss: 2.2282824516296387\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 679, Loss: 2.2282824516296387\n",
      "Running Batch 680, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.229689836502075\n",
      "Running Batch 681, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.216977596282959\n",
      "Running Batch 682, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.202998638153076\n",
      "Running Batch 683, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.281071901321411\n",
      "Running Batch 684, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.255300998687744\n",
      "Running Batch 685, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.1738359928131104\n",
      "Running Batch 686, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.1562016010284424\n",
      "Running Batch 687, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.1335413455963135\n",
      "Running Batch 688, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.294506549835205\n",
      "Running Batch 689, Epoch 0, Total Tokens: 176\n",
      "Loss: 2.2283473014831543\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 689, Loss: 2.2283473014831543\n",
      "Running Batch 690, Epoch 0, Total Tokens: 108\n",
      "Loss: 2.2705466747283936\n",
      "Running Batch 691, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.0790908336639404\n",
      "Running Batch 692, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.27081036567688\n",
      "Running Batch 693, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.173731803894043\n",
      "Running Batch 694, Epoch 0, Total Tokens: 158\n",
      "Loss: 2.224494695663452\n",
      "Running Batch 695, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.197395086288452\n",
      "Running Batch 696, Epoch 0, Total Tokens: 174\n",
      "Loss: 2.2313497066497803\n",
      "Running Batch 697, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.23372220993042\n",
      "Running Batch 698, Epoch 0, Total Tokens: 190\n",
      "Loss: 2.1203293800354004\n",
      "Running Batch 699, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.267597198486328\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 699, Loss: 2.267597198486328\n",
      "Running Batch 700, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.27871036529541\n",
      "Running Batch 701, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.185734748840332\n",
      "Running Batch 702, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.2594006061553955\n",
      "Running Batch 703, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.1948792934417725\n",
      "Running Batch 704, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.2104880809783936\n",
      "Running Batch 705, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.176323175430298\n",
      "Running Batch 706, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.1742608547210693\n",
      "Running Batch 707, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2509379386901855\n",
      "Running Batch 708, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.190114736557007\n",
      "Running Batch 709, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.2061879634857178\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 709, Loss: 2.2061879634857178\n",
      "Running Batch 710, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2459466457366943\n",
      "Running Batch 711, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1338016986846924\n",
      "Running Batch 712, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.1719374656677246\n",
      "Running Batch 713, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1733438968658447\n",
      "Running Batch 714, Epoch 0, Total Tokens: 188\n",
      "Loss: 2.2508158683776855\n",
      "Running Batch 715, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.2094004154205322\n",
      "Running Batch 716, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.195728302001953\n",
      "Running Batch 717, Epoch 0, Total Tokens: 230\n",
      "Loss: 2.2289085388183594\n",
      "Running Batch 718, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1221225261688232\n",
      "Running Batch 719, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2406110763549805\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 719, Loss: 2.2406110763549805\n",
      "Running Batch 720, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.125593900680542\n",
      "Running Batch 721, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.135708808898926\n",
      "Running Batch 722, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.1356544494628906\n",
      "Running Batch 723, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.242597818374634\n",
      "Running Batch 724, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.13809871673584\n",
      "Running Batch 725, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.227293014526367\n",
      "Running Batch 726, Epoch 0, Total Tokens: 190\n",
      "Loss: 2.2082042694091797\n",
      "Running Batch 727, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.2590675354003906\n",
      "Running Batch 728, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.2197842597961426\n",
      "Running Batch 729, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.203130006790161\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 729, Loss: 2.203130006790161\n",
      "Running Batch 730, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.108582019805908\n",
      "Running Batch 731, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.185831069946289\n",
      "Running Batch 732, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.173074960708618\n",
      "Running Batch 733, Epoch 0, Total Tokens: 99\n",
      "Loss: 2.1194162368774414\n",
      "Running Batch 734, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.1608810424804688\n",
      "Running Batch 735, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.2130849361419678\n",
      "Running Batch 736, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.240018367767334\n",
      "Running Batch 737, Epoch 0, Total Tokens: 174\n",
      "Loss: 2.161576271057129\n",
      "Running Batch 738, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.208014965057373\n",
      "Running Batch 739, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.186469316482544\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 739, Loss: 2.186469316482544\n",
      "Running Batch 740, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.1617729663848877\n",
      "Running Batch 741, Epoch 0, Total Tokens: 285\n",
      "Loss: 2.1890292167663574\n",
      "Running Batch 742, Epoch 0, Total Tokens: 119\n",
      "Loss: 2.147890090942383\n",
      "Running Batch 743, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.242189407348633\n",
      "Running Batch 744, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.1688292026519775\n",
      "Running Batch 745, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.168570041656494\n",
      "Running Batch 746, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1697311401367188\n",
      "Running Batch 747, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.1819655895233154\n",
      "Running Batch 748, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.1633388996124268\n",
      "Running Batch 749, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.1544125080108643\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 749, Loss: 2.1544125080108643\n",
      "Running Batch 750, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.2772748470306396\n",
      "Running Batch 751, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.182612895965576\n",
      "Running Batch 752, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.202977418899536\n",
      "Running Batch 753, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.101088762283325\n",
      "Running Batch 754, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.3182311058044434\n",
      "Running Batch 755, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2836649417877197\n",
      "Running Batch 756, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.0346672534942627\n",
      "Running Batch 757, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.161045551300049\n",
      "Running Batch 758, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.226480722427368\n",
      "Running Batch 759, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.154181480407715\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 759, Loss: 2.154181480407715\n",
      "Running Batch 760, Epoch 0, Total Tokens: 114\n",
      "Loss: 2.1340301036834717\n",
      "Running Batch 761, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.1684389114379883\n",
      "Running Batch 762, Epoch 0, Total Tokens: 220\n",
      "Loss: 2.2751433849334717\n",
      "Running Batch 763, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.24481463432312\n",
      "Running Batch 764, Epoch 0, Total Tokens: 171\n",
      "Loss: 2.1722052097320557\n",
      "Running Batch 765, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.1800100803375244\n",
      "Running Batch 766, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.0743651390075684\n",
      "Running Batch 767, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.269822120666504\n",
      "Running Batch 768, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.197545289993286\n",
      "Running Batch 769, Epoch 0, Total Tokens: 237\n",
      "Loss: 2.121659994125366\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 769, Loss: 2.121659994125366\n",
      "Running Batch 770, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.181180238723755\n",
      "Running Batch 771, Epoch 0, Total Tokens: 188\n",
      "Loss: 2.1385133266448975\n",
      "Running Batch 772, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.118574380874634\n",
      "Running Batch 773, Epoch 0, Total Tokens: 170\n",
      "Loss: 2.2225756645202637\n",
      "Running Batch 774, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1670026779174805\n",
      "Running Batch 775, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.1438891887664795\n",
      "Running Batch 776, Epoch 0, Total Tokens: 257\n",
      "Loss: 2.1384787559509277\n",
      "Running Batch 777, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.110187292098999\n",
      "Running Batch 778, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.160123348236084\n",
      "Running Batch 779, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.1358184814453125\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 779, Loss: 2.1358184814453125\n",
      "Running Batch 780, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.1870977878570557\n",
      "Running Batch 781, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.084665536880493\n",
      "Running Batch 782, Epoch 0, Total Tokens: 165\n",
      "Loss: 2.14858341217041\n",
      "Running Batch 783, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.2204771041870117\n",
      "Running Batch 784, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.1897363662719727\n",
      "Running Batch 785, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.155729293823242\n",
      "Running Batch 786, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.247020959854126\n",
      "Running Batch 787, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.178732395172119\n",
      "Running Batch 788, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.2231507301330566\n",
      "Running Batch 789, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.0744407176971436\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 789, Loss: 2.0744407176971436\n",
      "Running Batch 790, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1531877517700195\n",
      "Running Batch 791, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.1397976875305176\n",
      "Running Batch 792, Epoch 0, Total Tokens: 299\n",
      "Loss: 2.2072594165802\n",
      "Running Batch 793, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.1759071350097656\n",
      "Running Batch 794, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.144451141357422\n",
      "Running Batch 795, Epoch 0, Total Tokens: 103\n",
      "Loss: 2.1971054077148438\n",
      "Running Batch 796, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1378793716430664\n",
      "Running Batch 797, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.07031512260437\n",
      "Running Batch 798, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.0520482063293457\n",
      "Running Batch 799, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.179415702819824\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 799, Loss: 2.179415702819824\n",
      "Running Batch 800, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1288886070251465\n",
      "Running Batch 801, Epoch 0, Total Tokens: 234\n",
      "Loss: 2.216327428817749\n",
      "Running Batch 802, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.091169834136963\n",
      "Running Batch 803, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1461446285247803\n",
      "Running Batch 804, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.0906999111175537\n",
      "Running Batch 805, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.243119478225708\n",
      "Running Batch 806, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.249034881591797\n",
      "Running Batch 807, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1247506141662598\n",
      "Running Batch 808, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1529769897460938\n",
      "Running Batch 809, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.097296714782715\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 809, Loss: 2.097296714782715\n",
      "Running Batch 810, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.1439852714538574\n",
      "Running Batch 811, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.164717197418213\n",
      "Running Batch 812, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.0937068462371826\n",
      "Running Batch 813, Epoch 0, Total Tokens: 182\n",
      "Loss: 2.0307984352111816\n",
      "Running Batch 814, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2190911769866943\n",
      "Running Batch 815, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.131817579269409\n",
      "Running Batch 816, Epoch 0, Total Tokens: 266\n",
      "Loss: 2.1289865970611572\n",
      "Running Batch 817, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.1677145957946777\n",
      "Running Batch 818, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.1663620471954346\n",
      "Running Batch 819, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.226905584335327\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 819, Loss: 2.226905584335327\n",
      "Running Batch 820, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.0943961143493652\n",
      "Running Batch 821, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.217003107070923\n",
      "Running Batch 822, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.1347172260284424\n",
      "Running Batch 823, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.166104793548584\n",
      "Running Batch 824, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.1513261795043945\n",
      "Running Batch 825, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1068835258483887\n",
      "Running Batch 826, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.1782777309417725\n",
      "Running Batch 827, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.2301743030548096\n",
      "Running Batch 828, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.2141332626342773\n",
      "Running Batch 829, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.2407474517822266\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 829, Loss: 2.2407474517822266\n",
      "Running Batch 830, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1196398735046387\n",
      "Running Batch 831, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.2128524780273438\n",
      "Running Batch 832, Epoch 0, Total Tokens: 112\n",
      "Loss: 2.169546127319336\n",
      "Running Batch 833, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.0838053226470947\n",
      "Running Batch 834, Epoch 0, Total Tokens: 163\n",
      "Loss: 2.2064642906188965\n",
      "Running Batch 835, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.1749653816223145\n",
      "Running Batch 836, Epoch 0, Total Tokens: 114\n",
      "Loss: 2.1752796173095703\n",
      "Running Batch 837, Epoch 0, Total Tokens: 111\n",
      "Loss: 2.1447980403900146\n",
      "Running Batch 838, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.068326950073242\n",
      "Running Batch 839, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.041922092437744\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 839, Loss: 2.041922092437744\n",
      "Running Batch 840, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.231428623199463\n",
      "Running Batch 841, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.0634541511535645\n",
      "Running Batch 842, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.150277614593506\n",
      "Running Batch 843, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.093618631362915\n",
      "Running Batch 844, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.0717132091522217\n",
      "Running Batch 845, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.1922974586486816\n",
      "Running Batch 846, Epoch 0, Total Tokens: 220\n",
      "Loss: 2.1622416973114014\n",
      "Running Batch 847, Epoch 0, Total Tokens: 170\n",
      "Loss: 2.149019718170166\n",
      "Running Batch 848, Epoch 0, Total Tokens: 174\n",
      "Loss: 2.1035521030426025\n",
      "Running Batch 849, Epoch 0, Total Tokens: 242\n",
      "Loss: 2.1326448917388916\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 849, Loss: 2.1326448917388916\n",
      "Running Batch 850, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.1558916568756104\n",
      "Running Batch 851, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.078460454940796\n",
      "Running Batch 852, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.2350947856903076\n",
      "Running Batch 853, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.0731611251831055\n",
      "Running Batch 854, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.2159006595611572\n",
      "Running Batch 855, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.19838285446167\n",
      "Running Batch 856, Epoch 0, Total Tokens: 286\n",
      "Loss: 2.157111406326294\n",
      "Running Batch 857, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1503334045410156\n",
      "Running Batch 858, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.155738353729248\n",
      "Running Batch 859, Epoch 0, Total Tokens: 171\n",
      "Loss: 2.1412904262542725\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 859, Loss: 2.1412904262542725\n",
      "Running Batch 860, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.1319987773895264\n",
      "Running Batch 861, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.2215805053710938\n",
      "Running Batch 862, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.113182544708252\n",
      "Running Batch 863, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.0931904315948486\n",
      "Running Batch 864, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.176680088043213\n",
      "Running Batch 865, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.060555934906006\n",
      "Running Batch 866, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1356000900268555\n",
      "Running Batch 867, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1236398220062256\n",
      "Running Batch 868, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.2134406566619873\n",
      "Running Batch 869, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.2046945095062256\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 869, Loss: 2.2046945095062256\n",
      "Running Batch 870, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.1581294536590576\n",
      "Running Batch 871, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.0844783782958984\n",
      "Running Batch 872, Epoch 0, Total Tokens: 171\n",
      "Loss: 2.0765326023101807\n",
      "Running Batch 873, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.1625382900238037\n",
      "Running Batch 874, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.2116761207580566\n",
      "Running Batch 875, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.150844097137451\n",
      "Running Batch 876, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.1670596599578857\n",
      "Running Batch 877, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.104795217514038\n",
      "Running Batch 878, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.09847354888916\n",
      "Running Batch 879, Epoch 0, Total Tokens: 142\n",
      "Loss: 1.984098196029663\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 879, Loss: 1.984098196029663\n",
      "Running Batch 880, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1154041290283203\n",
      "Running Batch 881, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.1552014350891113\n",
      "Running Batch 882, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.158384084701538\n",
      "Running Batch 883, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.1052451133728027\n",
      "Running Batch 884, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.1363251209259033\n",
      "Running Batch 885, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.04606556892395\n",
      "Running Batch 886, Epoch 0, Total Tokens: 173\n",
      "Loss: 2.114020824432373\n",
      "Running Batch 887, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.2298924922943115\n",
      "Running Batch 888, Epoch 0, Total Tokens: 192\n",
      "Loss: 2.1108295917510986\n",
      "Running Batch 889, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.170680046081543\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 889, Loss: 2.170680046081543\n",
      "Running Batch 890, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.131333589553833\n",
      "Running Batch 891, Epoch 0, Total Tokens: 287\n",
      "Loss: 2.1594085693359375\n",
      "Running Batch 892, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.202097177505493\n",
      "Running Batch 893, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.076007843017578\n",
      "Running Batch 894, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.126044273376465\n",
      "Running Batch 895, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.1497890949249268\n",
      "Running Batch 896, Epoch 0, Total Tokens: 527\n",
      "Loss: 2.2192280292510986\n",
      "Running Batch 897, Epoch 0, Total Tokens: 110\n",
      "Loss: 2.131272077560425\n",
      "Running Batch 898, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.191894769668579\n",
      "Running Batch 899, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.080430030822754\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 899, Loss: 2.080430030822754\n",
      "Running Batch 900, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1512246131896973\n",
      "Running Batch 901, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.051752805709839\n",
      "Running Batch 902, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.2135720252990723\n",
      "Running Batch 903, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.238898754119873\n",
      "Running Batch 904, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.0992190837860107\n",
      "Running Batch 905, Epoch 0, Total Tokens: 170\n",
      "Loss: 2.1318070888519287\n",
      "Running Batch 906, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.1882834434509277\n",
      "Running Batch 907, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.054866075515747\n",
      "Running Batch 908, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.1985862255096436\n",
      "Running Batch 909, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1534223556518555\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 909, Loss: 2.1534223556518555\n",
      "Running Batch 910, Epoch 0, Total Tokens: 220\n",
      "Loss: 2.108973979949951\n",
      "Running Batch 911, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.074317455291748\n",
      "Running Batch 912, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.10408091545105\n",
      "Running Batch 913, Epoch 0, Total Tokens: 273\n",
      "Loss: 2.150692939758301\n",
      "Running Batch 914, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.1406757831573486\n",
      "Running Batch 915, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.157829523086548\n",
      "Running Batch 916, Epoch 0, Total Tokens: 123\n",
      "Loss: 2.142491579055786\n",
      "Running Batch 917, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.086602210998535\n",
      "Running Batch 918, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1976213455200195\n",
      "Running Batch 919, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1257150173187256\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 919, Loss: 2.1257150173187256\n",
      "Running Batch 920, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.1161317825317383\n",
      "Running Batch 921, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.1317811012268066\n",
      "Running Batch 922, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.131241798400879\n",
      "Running Batch 923, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.063293933868408\n",
      "Running Batch 924, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.1458568572998047\n",
      "Running Batch 925, Epoch 0, Total Tokens: 116\n",
      "Loss: 2.030109405517578\n",
      "Running Batch 926, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.1955935955047607\n",
      "Running Batch 927, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.080007314682007\n",
      "Running Batch 928, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.127398729324341\n",
      "Running Batch 929, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.2111194133758545\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 929, Loss: 2.2111194133758545\n",
      "Running Batch 930, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.0943939685821533\n",
      "Running Batch 931, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.2283875942230225\n",
      "Running Batch 932, Epoch 0, Total Tokens: 249\n",
      "Loss: 2.127728223800659\n",
      "Running Batch 933, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.0691802501678467\n",
      "Running Batch 934, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.1028225421905518\n",
      "Running Batch 935, Epoch 0, Total Tokens: 351\n",
      "Loss: 2.1455860137939453\n",
      "Running Batch 936, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.120750904083252\n",
      "Running Batch 937, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.124443292617798\n",
      "Running Batch 938, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.111447334289551\n",
      "Running Batch 939, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.111438035964966\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 939, Loss: 2.111438035964966\n",
      "Running Batch 940, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.182713747024536\n",
      "Running Batch 941, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.0738003253936768\n",
      "Running Batch 942, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1471805572509766\n",
      "Running Batch 943, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.1806704998016357\n",
      "Running Batch 944, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.1219077110290527\n",
      "Running Batch 945, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.161574125289917\n",
      "Running Batch 946, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1797399520874023\n",
      "Running Batch 947, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.152127981185913\n",
      "Running Batch 948, Epoch 0, Total Tokens: 163\n",
      "Loss: 2.114711284637451\n",
      "Running Batch 949, Epoch 0, Total Tokens: 210\n",
      "Loss: 2.1098368167877197\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 949, Loss: 2.1098368167877197\n",
      "Running Batch 950, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.1226842403411865\n",
      "Running Batch 951, Epoch 0, Total Tokens: 384\n",
      "Loss: 2.1306369304656982\n",
      "Running Batch 952, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1135380268096924\n",
      "Running Batch 953, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.1063785552978516\n",
      "Running Batch 954, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.1965153217315674\n",
      "Running Batch 955, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.1843676567077637\n",
      "Running Batch 956, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.0652716159820557\n",
      "Running Batch 957, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.129354238510132\n",
      "Running Batch 958, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.1848440170288086\n",
      "Running Batch 959, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.062427520751953\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 959, Loss: 2.062427520751953\n",
      "Running Batch 960, Epoch 0, Total Tokens: 224\n",
      "Loss: 2.205824851989746\n",
      "Running Batch 961, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.1460702419281006\n",
      "Running Batch 962, Epoch 0, Total Tokens: 187\n",
      "Loss: 2.243671178817749\n",
      "Running Batch 963, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.1794583797454834\n",
      "Running Batch 964, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1382598876953125\n",
      "Running Batch 965, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.109422445297241\n",
      "Running Batch 966, Epoch 0, Total Tokens: 281\n",
      "Loss: 2.0735843181610107\n",
      "Running Batch 967, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.2248244285583496\n",
      "Running Batch 968, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.105138063430786\n",
      "Running Batch 969, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.094216823577881\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 969, Loss: 2.094216823577881\n",
      "Running Batch 970, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.172588586807251\n",
      "Running Batch 971, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.178471326828003\n",
      "Running Batch 972, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.1506478786468506\n",
      "Running Batch 973, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.056525468826294\n",
      "Running Batch 974, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.131247043609619\n",
      "Running Batch 975, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.148624897003174\n",
      "Running Batch 976, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.0445573329925537\n",
      "Running Batch 977, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.0416781902313232\n",
      "Running Batch 978, Epoch 0, Total Tokens: 169\n",
      "Loss: 2.146484136581421\n",
      "Running Batch 979, Epoch 0, Total Tokens: 167\n",
      "Loss: 2.152806043624878\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 979, Loss: 2.152806043624878\n",
      "Running Batch 980, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.106722354888916\n",
      "Running Batch 981, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.1259286403656006\n",
      "Running Batch 982, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.146587371826172\n",
      "Running Batch 983, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2425312995910645\n",
      "Running Batch 984, Epoch 0, Total Tokens: 178\n",
      "Loss: 2.1442325115203857\n",
      "Running Batch 985, Epoch 0, Total Tokens: 167\n",
      "Loss: 2.081723213195801\n",
      "Running Batch 986, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.0910863876342773\n",
      "Running Batch 987, Epoch 0, Total Tokens: 172\n",
      "Loss: 2.062828540802002\n",
      "Running Batch 988, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.1039528846740723\n",
      "Running Batch 989, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.003776788711548\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 989, Loss: 2.003776788711548\n",
      "Running Batch 990, Epoch 0, Total Tokens: 258\n",
      "Loss: 2.097463369369507\n",
      "Running Batch 991, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.1942527294158936\n",
      "Running Batch 992, Epoch 0, Total Tokens: 324\n",
      "Loss: 2.164642333984375\n",
      "Running Batch 993, Epoch 0, Total Tokens: 568\n",
      "Loss: 2.0210912227630615\n",
      "Running Batch 994, Epoch 0, Total Tokens: 103\n",
      "Loss: 2.1540956497192383\n",
      "Running Batch 995, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.1086602210998535\n",
      "Running Batch 996, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.106611490249634\n",
      "Running Batch 997, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.0728089809417725\n",
      "Running Batch 998, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.0320825576782227\n",
      "Running Batch 999, Epoch 0, Total Tokens: 109\n",
      "Loss: 2.178478479385376\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 999, Loss: 2.178478479385376\n",
      "Running Batch 1000, Epoch 0, Total Tokens: 149\n",
      "Loss: 2.088132619857788\n",
      "Running Batch 1001, Epoch 0, Total Tokens: 119\n",
      "Loss: 2.1038944721221924\n",
      "Running Batch 1002, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.1550846099853516\n",
      "Running Batch 1003, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.1003317832946777\n",
      "Running Batch 1004, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.1259377002716064\n",
      "Running Batch 1005, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.2354960441589355\n",
      "Running Batch 1006, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.11728572845459\n",
      "Running Batch 1007, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.172959804534912\n",
      "Running Batch 1008, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.099472761154175\n",
      "Running Batch 1009, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.9915187358856201\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1009, Loss: 1.9915187358856201\n",
      "Running Batch 1010, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.1573777198791504\n",
      "Running Batch 1011, Epoch 0, Total Tokens: 167\n",
      "Loss: 2.103022336959839\n",
      "Running Batch 1012, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.144101858139038\n",
      "Running Batch 1013, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.1417109966278076\n",
      "Running Batch 1014, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.268813133239746\n",
      "Running Batch 1015, Epoch 0, Total Tokens: 145\n",
      "Loss: 1.9829708337783813\n",
      "Running Batch 1016, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.089609384536743\n",
      "Running Batch 1017, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.0968077182769775\n",
      "Running Batch 1018, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.1416337490081787\n",
      "Running Batch 1019, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.098315715789795\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1019, Loss: 2.098315715789795\n",
      "Running Batch 1020, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.0688467025756836\n",
      "Running Batch 1021, Epoch 0, Total Tokens: 196\n",
      "Loss: 2.143165111541748\n",
      "Running Batch 1022, Epoch 0, Total Tokens: 187\n",
      "Loss: 2.1227924823760986\n",
      "Running Batch 1023, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.045973777770996\n",
      "Running Batch 1024, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.2099709510803223\n",
      "Running Batch 1025, Epoch 0, Total Tokens: 193\n",
      "Loss: 2.186276912689209\n",
      "Running Batch 1026, Epoch 0, Total Tokens: 157\n",
      "Loss: 2.0645596981048584\n",
      "Running Batch 1027, Epoch 0, Total Tokens: 190\n",
      "Loss: 2.073540449142456\n",
      "Running Batch 1028, Epoch 0, Total Tokens: 191\n",
      "Loss: 2.01904034614563\n",
      "Running Batch 1029, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1420722007751465\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1029, Loss: 2.1420722007751465\n",
      "Running Batch 1030, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.0674889087677\n",
      "Running Batch 1031, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.1923117637634277\n",
      "Running Batch 1032, Epoch 0, Total Tokens: 152\n",
      "Loss: 1.987615942955017\n",
      "Running Batch 1033, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.177917957305908\n",
      "Running Batch 1034, Epoch 0, Total Tokens: 125\n",
      "Loss: 2.085329294204712\n",
      "Running Batch 1035, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1116952896118164\n",
      "Running Batch 1036, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.143436908721924\n",
      "Running Batch 1037, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.039212942123413\n",
      "Running Batch 1038, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.122864246368408\n",
      "Running Batch 1039, Epoch 0, Total Tokens: 171\n",
      "Loss: 2.0991451740264893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1039, Loss: 2.0991451740264893\n",
      "Running Batch 1040, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1538124084472656\n",
      "Running Batch 1041, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.116785764694214\n",
      "Running Batch 1042, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.0856845378875732\n",
      "Running Batch 1043, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.1219747066497803\n",
      "Running Batch 1044, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.106041193008423\n",
      "Running Batch 1045, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.0843186378479004\n",
      "Running Batch 1046, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.183474063873291\n",
      "Running Batch 1047, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1197752952575684\n",
      "Running Batch 1048, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.177509307861328\n",
      "Running Batch 1049, Epoch 0, Total Tokens: 134\n",
      "Loss: 1.9727901220321655\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1049, Loss: 1.9727901220321655\n",
      "Running Batch 1050, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.0001652240753174\n",
      "Running Batch 1051, Epoch 0, Total Tokens: 145\n",
      "Loss: 2.084268808364868\n",
      "Running Batch 1052, Epoch 0, Total Tokens: 115\n",
      "Loss: 2.106006383895874\n",
      "Running Batch 1053, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.0017879009246826\n",
      "Running Batch 1054, Epoch 0, Total Tokens: 183\n",
      "Loss: 2.1476941108703613\n",
      "Running Batch 1055, Epoch 0, Total Tokens: 110\n",
      "Loss: 2.105881929397583\n",
      "Running Batch 1056, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.0687739849090576\n",
      "Running Batch 1057, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.0269052982330322\n",
      "Running Batch 1058, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.1473679542541504\n",
      "Running Batch 1059, Epoch 0, Total Tokens: 120\n",
      "Loss: 2.04516863822937\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1059, Loss: 2.04516863822937\n",
      "Running Batch 1060, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.0450453758239746\n",
      "Running Batch 1061, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.1083760261535645\n",
      "Running Batch 1062, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.060502052307129\n",
      "Running Batch 1063, Epoch 0, Total Tokens: 195\n",
      "Loss: 2.132506847381592\n",
      "Running Batch 1064, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.0571937561035156\n",
      "Running Batch 1065, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.147479772567749\n",
      "Running Batch 1066, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.096914052963257\n",
      "Running Batch 1067, Epoch 0, Total Tokens: 150\n",
      "Loss: 2.137892961502075\n",
      "Running Batch 1068, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.0838375091552734\n",
      "Running Batch 1069, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.1310994625091553\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1069, Loss: 2.1310994625091553\n",
      "Running Batch 1070, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.108574867248535\n",
      "Running Batch 1071, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.0977587699890137\n",
      "Running Batch 1072, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.0517537593841553\n",
      "Running Batch 1073, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.058773994445801\n",
      "Running Batch 1074, Epoch 0, Total Tokens: 128\n",
      "Loss: 2.127941846847534\n",
      "Running Batch 1075, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.0756659507751465\n",
      "Running Batch 1076, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.9897642135620117\n",
      "Running Batch 1077, Epoch 0, Total Tokens: 629\n",
      "Loss: 1.9977554082870483\n",
      "Running Batch 1078, Epoch 0, Total Tokens: 494\n",
      "Loss: 1.8860074281692505\n",
      "Running Batch 1079, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.2594568729400635\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1079, Loss: 2.2594568729400635\n",
      "Running Batch 1080, Epoch 0, Total Tokens: 151\n",
      "Loss: 2.1022536754608154\n",
      "Running Batch 1081, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.0377676486968994\n",
      "Running Batch 1082, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.050096035003662\n",
      "Running Batch 1083, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.0560426712036133\n",
      "Running Batch 1084, Epoch 0, Total Tokens: 164\n",
      "Loss: 2.2115390300750732\n",
      "Running Batch 1085, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.0938971042633057\n",
      "Running Batch 1086, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.0558414459228516\n",
      "Running Batch 1087, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.0825912952423096\n",
      "Running Batch 1088, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.103696584701538\n",
      "Running Batch 1089, Epoch 0, Total Tokens: 111\n",
      "Loss: 2.096652030944824\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1089, Loss: 2.096652030944824\n",
      "Running Batch 1090, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.1453678607940674\n",
      "Running Batch 1091, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.057333469390869\n",
      "Running Batch 1092, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.106546640396118\n",
      "Running Batch 1093, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.096627950668335\n",
      "Running Batch 1094, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1541478633880615\n",
      "Running Batch 1095, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.04443359375\n",
      "Running Batch 1096, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.059065341949463\n",
      "Running Batch 1097, Epoch 0, Total Tokens: 113\n",
      "Loss: 2.061915397644043\n",
      "Running Batch 1098, Epoch 0, Total Tokens: 117\n",
      "Loss: 2.0891196727752686\n",
      "Running Batch 1099, Epoch 0, Total Tokens: 154\n",
      "Loss: 2.109893798828125\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1099, Loss: 2.109893798828125\n",
      "Running Batch 1100, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.0196826457977295\n",
      "Running Batch 1101, Epoch 0, Total Tokens: 105\n",
      "Loss: 2.1138370037078857\n",
      "Running Batch 1102, Epoch 0, Total Tokens: 106\n",
      "Loss: 2.1067752838134766\n",
      "Running Batch 1103, Epoch 0, Total Tokens: 236\n",
      "Loss: 2.0503149032592773\n",
      "Running Batch 1104, Epoch 0, Total Tokens: 118\n",
      "Loss: 2.165430784225464\n",
      "Running Batch 1105, Epoch 0, Total Tokens: 102\n",
      "Loss: 2.112281084060669\n",
      "Running Batch 1106, Epoch 0, Total Tokens: 203\n",
      "Loss: 2.167238235473633\n",
      "Running Batch 1107, Epoch 0, Total Tokens: 192\n",
      "Loss: 2.1360883712768555\n",
      "Running Batch 1108, Epoch 0, Total Tokens: 148\n",
      "Loss: 2.036895751953125\n",
      "Running Batch 1109, Epoch 0, Total Tokens: 126\n",
      "Loss: 2.066148042678833\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1109, Loss: 2.066148042678833\n",
      "Running Batch 1110, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.089602470397949\n",
      "Running Batch 1111, Epoch 0, Total Tokens: 187\n",
      "Loss: 2.059998035430908\n",
      "Running Batch 1112, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.1167657375335693\n",
      "Running Batch 1113, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.0837972164154053\n",
      "Running Batch 1114, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.093209743499756\n",
      "Running Batch 1115, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.2479612827301025\n",
      "Running Batch 1116, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.1339480876922607\n",
      "Running Batch 1117, Epoch 0, Total Tokens: 296\n",
      "Loss: 2.0456199645996094\n",
      "Running Batch 1118, Epoch 0, Total Tokens: 156\n",
      "Loss: 2.0530929565429688\n",
      "Running Batch 1119, Epoch 0, Total Tokens: 140\n",
      "Loss: 2.0700173377990723\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1119, Loss: 2.0700173377990723\n",
      "Running Batch 1120, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.063969612121582\n",
      "Running Batch 1121, Epoch 0, Total Tokens: 132\n",
      "Loss: 2.055779457092285\n",
      "Running Batch 1122, Epoch 0, Total Tokens: 121\n",
      "Loss: 2.1083524227142334\n",
      "Running Batch 1123, Epoch 0, Total Tokens: 139\n",
      "Loss: 2.090003728866577\n",
      "Running Batch 1124, Epoch 0, Total Tokens: 234\n",
      "Loss: 2.04640793800354\n",
      "Running Batch 1125, Epoch 0, Total Tokens: 131\n",
      "Loss: 2.1301753520965576\n",
      "Running Batch 1126, Epoch 0, Total Tokens: 127\n",
      "Loss: 2.112154483795166\n",
      "Running Batch 1127, Epoch 0, Total Tokens: 340\n",
      "Loss: 2.06198787689209\n",
      "Running Batch 1128, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.0054924488067627\n",
      "Running Batch 1129, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.1611456871032715\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1129, Loss: 2.1611456871032715\n",
      "Running Batch 1130, Epoch 0, Total Tokens: 202\n",
      "Loss: 2.0788280963897705\n",
      "Running Batch 1131, Epoch 0, Total Tokens: 150\n",
      "Loss: 1.9572501182556152\n",
      "Running Batch 1132, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.116708517074585\n",
      "Running Batch 1133, Epoch 0, Total Tokens: 148\n",
      "Loss: 1.9707486629486084\n",
      "Running Batch 1134, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.1658337116241455\n",
      "Running Batch 1135, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.11486554145813\n",
      "Running Batch 1136, Epoch 0, Total Tokens: 137\n",
      "Loss: 2.071392059326172\n",
      "Running Batch 1137, Epoch 0, Total Tokens: 162\n",
      "Loss: 2.1560986042022705\n",
      "Running Batch 1138, Epoch 0, Total Tokens: 122\n",
      "Loss: 1.981544017791748\n",
      "Running Batch 1139, Epoch 0, Total Tokens: 124\n",
      "Loss: 2.027078866958618\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1139, Loss: 2.027078866958618\n",
      "Running Batch 1140, Epoch 0, Total Tokens: 147\n",
      "Loss: 2.1179966926574707\n",
      "Running Batch 1141, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.080044746398926\n",
      "Running Batch 1142, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.123933792114258\n",
      "Running Batch 1143, Epoch 0, Total Tokens: 142\n",
      "Loss: 2.0316433906555176\n",
      "Running Batch 1144, Epoch 0, Total Tokens: 135\n",
      "Loss: 2.088491439819336\n",
      "Running Batch 1145, Epoch 0, Total Tokens: 130\n",
      "Loss: 2.141753911972046\n",
      "Running Batch 1146, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.072382926940918\n",
      "Running Batch 1147, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.1058425903320312\n",
      "Running Batch 1148, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.078303575515747\n",
      "Running Batch 1149, Epoch 0, Total Tokens: 138\n",
      "Loss: 2.0774950981140137\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1149, Loss: 2.0774950981140137\n",
      "Running Batch 1150, Epoch 0, Total Tokens: 137\n",
      "Loss: 1.9966630935668945\n",
      "Running Batch 1151, Epoch 0, Total Tokens: 119\n",
      "Loss: 2.0990405082702637\n",
      "Running Batch 1152, Epoch 0, Total Tokens: 133\n",
      "Loss: 2.1535961627960205\n",
      "Running Batch 1153, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.059633493423462\n",
      "Running Batch 1154, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.1019105911254883\n",
      "Running Batch 1155, Epoch 0, Total Tokens: 141\n",
      "Loss: 2.0283639430999756\n",
      "Running Batch 1156, Epoch 0, Total Tokens: 159\n",
      "Loss: 2.128462791442871\n",
      "Running Batch 1157, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.061189889907837\n",
      "Running Batch 1158, Epoch 0, Total Tokens: 143\n",
      "Loss: 2.140617609024048\n",
      "Running Batch 1159, Epoch 0, Total Tokens: 153\n",
      "Loss: 2.085574150085449\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1159, Loss: 2.085574150085449\n",
      "Running Batch 1160, Epoch 0, Total Tokens: 146\n",
      "Loss: 2.0952413082122803\n",
      "Running Batch 1161, Epoch 0, Total Tokens: 199\n",
      "Loss: 2.067296028137207\n",
      "Running Batch 1162, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.078996419906616\n",
      "Running Batch 1163, Epoch 0, Total Tokens: 380\n",
      "Loss: 2.12477707862854\n",
      "Running Batch 1164, Epoch 0, Total Tokens: 134\n",
      "Loss: 2.024250030517578\n",
      "Running Batch 1165, Epoch 0, Total Tokens: 144\n",
      "Loss: 2.077094078063965\n",
      "Running Batch 1166, Epoch 0, Total Tokens: 161\n",
      "Loss: 2.0544052124023438\n",
      "Running Batch 1167, Epoch 0, Total Tokens: 152\n",
      "Loss: 2.083106517791748\n",
      "Running Batch 1168, Epoch 0, Total Tokens: 136\n",
      "Loss: 2.078075408935547\n",
      "Running Batch 1169, Epoch 0, Total Tokens: 129\n",
      "Loss: 2.0972847938537598\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 0, Batch: 1169, Loss: 2.0972847938537598\n",
      "Running Batch 1170, Epoch 0, Total Tokens: 122\n",
      "Loss: 2.035289764404297\n",
      "Running Batch 1171, Epoch 0, Total Tokens: 151\n",
      "Loss: 1.9658727645874023\n",
      "AVG LOSS: 2.2635620955517672, Epoch: 1\n",
      "Running Batch 0, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.0394060611724854\n",
      "Running Batch 1, Epoch 1, Total Tokens: 110\n",
      "Loss: 2.1513333320617676\n",
      "Running Batch 2, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.040677547454834\n",
      "Running Batch 3, Epoch 1, Total Tokens: 156\n",
      "Loss: 2.017260789871216\n",
      "Running Batch 4, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0593655109405518\n",
      "Running Batch 5, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0883452892303467\n",
      "Running Batch 6, Epoch 1, Total Tokens: 220\n",
      "Loss: 2.001887083053589\n",
      "Running Batch 7, Epoch 1, Total Tokens: 224\n",
      "Loss: 2.006404399871826\n",
      "Running Batch 8, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.003798007965088\n",
      "Running Batch 9, Epoch 1, Total Tokens: 217\n",
      "Loss: 2.0144996643066406\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 9, Loss: 2.0144996643066406\n",
      "Running Batch 10, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.0102055072784424\n",
      "Running Batch 11, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.0854389667510986\n",
      "Running Batch 12, Epoch 1, Total Tokens: 182\n",
      "Loss: 2.0426323413848877\n",
      "Running Batch 13, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.1231861114501953\n",
      "Running Batch 14, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.0005109310150146\n",
      "Running Batch 15, Epoch 1, Total Tokens: 181\n",
      "Loss: 2.1140565872192383\n",
      "Running Batch 16, Epoch 1, Total Tokens: 115\n",
      "Loss: 2.038520097732544\n",
      "Running Batch 17, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0711514949798584\n",
      "Running Batch 18, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.152557373046875\n",
      "Running Batch 19, Epoch 1, Total Tokens: 326\n",
      "Loss: 2.021869659423828\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 19, Loss: 2.021869659423828\n",
      "Running Batch 20, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.0892045497894287\n",
      "Running Batch 21, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.179054021835327\n",
      "Running Batch 22, Epoch 1, Total Tokens: 380\n",
      "Loss: 1.994836449623108\n",
      "Running Batch 23, Epoch 1, Total Tokens: 114\n",
      "Loss: 2.0678229331970215\n",
      "Running Batch 24, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.081312656402588\n",
      "Running Batch 25, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.0872480869293213\n",
      "Running Batch 26, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.1993446350097656\n",
      "Running Batch 27, Epoch 1, Total Tokens: 115\n",
      "Loss: 2.0609867572784424\n",
      "Running Batch 28, Epoch 1, Total Tokens: 568\n",
      "Loss: 2.106137275695801\n",
      "Running Batch 29, Epoch 1, Total Tokens: 125\n",
      "Loss: 2.0530285835266113\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 29, Loss: 2.0530285835266113\n",
      "Running Batch 30, Epoch 1, Total Tokens: 169\n",
      "Loss: 2.156085729598999\n",
      "Running Batch 31, Epoch 1, Total Tokens: 204\n",
      "Loss: 2.075085401535034\n",
      "Running Batch 32, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9789689779281616\n",
      "Running Batch 33, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0932276248931885\n",
      "Running Batch 34, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.1535656452178955\n",
      "Running Batch 35, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.927907943725586\n",
      "Running Batch 36, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.1041858196258545\n",
      "Running Batch 37, Epoch 1, Total Tokens: 168\n",
      "Loss: 2.0419702529907227\n",
      "Running Batch 38, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0670037269592285\n",
      "Running Batch 39, Epoch 1, Total Tokens: 197\n",
      "Loss: 2.0395827293395996\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 39, Loss: 2.0395827293395996\n",
      "Running Batch 40, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9839286804199219\n",
      "Running Batch 41, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.074887752532959\n",
      "Running Batch 42, Epoch 1, Total Tokens: 126\n",
      "Loss: 2.003122329711914\n",
      "Running Batch 43, Epoch 1, Total Tokens: 199\n",
      "Loss: 2.207159996032715\n",
      "Running Batch 44, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.1041018962860107\n",
      "Running Batch 45, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9626703262329102\n",
      "Running Batch 46, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.0252296924591064\n",
      "Running Batch 47, Epoch 1, Total Tokens: 357\n",
      "Loss: 2.1734607219696045\n",
      "Running Batch 48, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0195438861846924\n",
      "Running Batch 49, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.0394647121429443\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 49, Loss: 2.0394647121429443\n",
      "Running Batch 50, Epoch 1, Total Tokens: 124\n",
      "Loss: 2.0563530921936035\n",
      "Running Batch 51, Epoch 1, Total Tokens: 166\n",
      "Loss: 2.086002826690674\n",
      "Running Batch 52, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.151265859603882\n",
      "Running Batch 53, Epoch 1, Total Tokens: 142\n",
      "Loss: 2.131552219390869\n",
      "Running Batch 54, Epoch 1, Total Tokens: 337\n",
      "Loss: 2.016934871673584\n",
      "Running Batch 55, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.0989909172058105\n",
      "Running Batch 56, Epoch 1, Total Tokens: 261\n",
      "Loss: 2.0681354999542236\n",
      "Running Batch 57, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.044387102127075\n",
      "Running Batch 58, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.061082601547241\n",
      "Running Batch 59, Epoch 1, Total Tokens: 203\n",
      "Loss: 2.05415415763855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 59, Loss: 2.05415415763855\n",
      "Running Batch 60, Epoch 1, Total Tokens: 108\n",
      "Loss: 2.0088772773742676\n",
      "Running Batch 61, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.902252197265625\n",
      "Running Batch 62, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.111064910888672\n",
      "Running Batch 63, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0311076641082764\n",
      "Running Batch 64, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.9508001804351807\n",
      "Running Batch 65, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.1437666416168213\n",
      "Running Batch 66, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.080127000808716\n",
      "Running Batch 67, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0207130908966064\n",
      "Running Batch 68, Epoch 1, Total Tokens: 185\n",
      "Loss: 2.054070234298706\n",
      "Running Batch 69, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.0937306880950928\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 69, Loss: 2.0937306880950928\n",
      "Running Batch 70, Epoch 1, Total Tokens: 174\n",
      "Loss: 2.0630087852478027\n",
      "Running Batch 71, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.059633731842041\n",
      "Running Batch 72, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.174323797225952\n",
      "Running Batch 73, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.077115297317505\n",
      "Running Batch 74, Epoch 1, Total Tokens: 159\n",
      "Loss: 2.027374744415283\n",
      "Running Batch 75, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.987929344177246\n",
      "Running Batch 76, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9745049476623535\n",
      "Running Batch 77, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.9969627857208252\n",
      "Running Batch 78, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0532522201538086\n",
      "Running Batch 79, Epoch 1, Total Tokens: 127\n",
      "Loss: 2.0888378620147705\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 79, Loss: 2.0888378620147705\n",
      "Running Batch 80, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.9924554824829102\n",
      "Running Batch 81, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.0696730613708496\n",
      "Running Batch 82, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9779317378997803\n",
      "Running Batch 83, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9483730792999268\n",
      "Running Batch 84, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0533084869384766\n",
      "Running Batch 85, Epoch 1, Total Tokens: 231\n",
      "Loss: 2.0425729751586914\n",
      "Running Batch 86, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.092336654663086\n",
      "Running Batch 87, Epoch 1, Total Tokens: 120\n",
      "Loss: 2.0524511337280273\n",
      "Running Batch 88, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9330366849899292\n",
      "Running Batch 89, Epoch 1, Total Tokens: 180\n",
      "Loss: 2.0296568870544434\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 89, Loss: 2.0296568870544434\n",
      "Running Batch 90, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.0686304569244385\n",
      "Running Batch 91, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.0445775985717773\n",
      "Running Batch 92, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.1135499477386475\n",
      "Running Batch 93, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0620481967926025\n",
      "Running Batch 94, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0025081634521484\n",
      "Running Batch 95, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0272250175476074\n",
      "Running Batch 96, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9889367818832397\n",
      "Running Batch 97, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.152575731277466\n",
      "Running Batch 98, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.1038482189178467\n",
      "Running Batch 99, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.027855396270752\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 99, Loss: 2.027855396270752\n",
      "Running Batch 100, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.0347859859466553\n",
      "Running Batch 101, Epoch 1, Total Tokens: 527\n",
      "Loss: 2.091040849685669\n",
      "Running Batch 102, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.110504150390625\n",
      "Running Batch 103, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.0014309883117676\n",
      "Running Batch 104, Epoch 1, Total Tokens: 274\n",
      "Loss: 1.9623544216156006\n",
      "Running Batch 105, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.026918411254883\n",
      "Running Batch 106, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0268783569335938\n",
      "Running Batch 107, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0218505859375\n",
      "Running Batch 108, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.055370569229126\n",
      "Running Batch 109, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.047560691833496\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 109, Loss: 2.047560691833496\n",
      "Running Batch 110, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.9869022369384766\n",
      "Running Batch 111, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0351991653442383\n",
      "Running Batch 112, Epoch 1, Total Tokens: 115\n",
      "Loss: 2.081294298171997\n",
      "Running Batch 113, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.094119071960449\n",
      "Running Batch 114, Epoch 1, Total Tokens: 237\n",
      "Loss: 2.0564069747924805\n",
      "Running Batch 115, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0173392295837402\n",
      "Running Batch 116, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.0875213146209717\n",
      "Running Batch 117, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0556681156158447\n",
      "Running Batch 118, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9330050945281982\n",
      "Running Batch 119, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.060033082962036\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 119, Loss: 2.060033082962036\n",
      "Running Batch 120, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.070352554321289\n",
      "Running Batch 121, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.0188887119293213\n",
      "Running Batch 122, Epoch 1, Total Tokens: 178\n",
      "Loss: 2.042935848236084\n",
      "Running Batch 123, Epoch 1, Total Tokens: 237\n",
      "Loss: 2.013225555419922\n",
      "Running Batch 124, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.086493492126465\n",
      "Running Batch 125, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.9728100299835205\n",
      "Running Batch 126, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.0932910442352295\n",
      "Running Batch 127, Epoch 1, Total Tokens: 117\n",
      "Loss: 2.0935614109039307\n",
      "Running Batch 128, Epoch 1, Total Tokens: 119\n",
      "Loss: 2.0296506881713867\n",
      "Running Batch 129, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.0849850177764893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 129, Loss: 2.0849850177764893\n",
      "Running Batch 130, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9839059114456177\n",
      "Running Batch 131, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0106403827667236\n",
      "Running Batch 132, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.079697847366333\n",
      "Running Batch 133, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9630732536315918\n",
      "Running Batch 134, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.008270740509033\n",
      "Running Batch 135, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.0558249950408936\n",
      "Running Batch 136, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.9806487560272217\n",
      "Running Batch 137, Epoch 1, Total Tokens: 173\n",
      "Loss: 2.081907272338867\n",
      "Running Batch 138, Epoch 1, Total Tokens: 116\n",
      "Loss: 2.0106537342071533\n",
      "Running Batch 139, Epoch 1, Total Tokens: 169\n",
      "Loss: 2.0635488033294678\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 139, Loss: 2.0635488033294678\n",
      "Running Batch 140, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.1243743896484375\n",
      "Running Batch 141, Epoch 1, Total Tokens: 181\n",
      "Loss: 2.0106801986694336\n",
      "Running Batch 142, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.959646224975586\n",
      "Running Batch 143, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.0829994678497314\n",
      "Running Batch 144, Epoch 1, Total Tokens: 155\n",
      "Loss: 2.1220204830169678\n",
      "Running Batch 145, Epoch 1, Total Tokens: 202\n",
      "Loss: 1.9950090646743774\n",
      "Running Batch 146, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.024632692337036\n",
      "Running Batch 147, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.070070266723633\n",
      "Running Batch 148, Epoch 1, Total Tokens: 184\n",
      "Loss: 1.945818543434143\n",
      "Running Batch 149, Epoch 1, Total Tokens: 251\n",
      "Loss: 2.028841018676758\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 149, Loss: 2.028841018676758\n",
      "Running Batch 150, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.044842481613159\n",
      "Running Batch 151, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.063053607940674\n",
      "Running Batch 152, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.04707407951355\n",
      "Running Batch 153, Epoch 1, Total Tokens: 123\n",
      "Loss: 2.065650463104248\n",
      "Running Batch 154, Epoch 1, Total Tokens: 188\n",
      "Loss: 2.0981125831604004\n",
      "Running Batch 155, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.9911130666732788\n",
      "Running Batch 156, Epoch 1, Total Tokens: 126\n",
      "Loss: 2.0389177799224854\n",
      "Running Batch 157, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9202898740768433\n",
      "Running Batch 158, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.001667022705078\n",
      "Running Batch 159, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.1332030296325684\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 159, Loss: 2.1332030296325684\n",
      "Running Batch 160, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.059563636779785\n",
      "Running Batch 161, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0544307231903076\n",
      "Running Batch 162, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.0719923973083496\n",
      "Running Batch 163, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.98146390914917\n",
      "Running Batch 164, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.156468152999878\n",
      "Running Batch 165, Epoch 1, Total Tokens: 334\n",
      "Loss: 2.055633783340454\n",
      "Running Batch 166, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.068066358566284\n",
      "Running Batch 167, Epoch 1, Total Tokens: 157\n",
      "Loss: 2.1374073028564453\n",
      "Running Batch 168, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.175220489501953\n",
      "Running Batch 169, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9706090688705444\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 169, Loss: 1.9706090688705444\n",
      "Running Batch 170, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9864652156829834\n",
      "Running Batch 171, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9909876585006714\n",
      "Running Batch 172, Epoch 1, Total Tokens: 219\n",
      "Loss: 1.9971262216567993\n",
      "Running Batch 173, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0969419479370117\n",
      "Running Batch 174, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0149240493774414\n",
      "Running Batch 175, Epoch 1, Total Tokens: 123\n",
      "Loss: 2.0899360179901123\n",
      "Running Batch 176, Epoch 1, Total Tokens: 163\n",
      "Loss: 2.100999116897583\n",
      "Running Batch 177, Epoch 1, Total Tokens: 126\n",
      "Loss: 2.0143253803253174\n",
      "Running Batch 178, Epoch 1, Total Tokens: 202\n",
      "Loss: 2.0527544021606445\n",
      "Running Batch 179, Epoch 1, Total Tokens: 123\n",
      "Loss: 2.054896116256714\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 179, Loss: 2.054896116256714\n",
      "Running Batch 180, Epoch 1, Total Tokens: 124\n",
      "Loss: 2.0325756072998047\n",
      "Running Batch 181, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.039243459701538\n",
      "Running Batch 182, Epoch 1, Total Tokens: 143\n",
      "Loss: 2.072195529937744\n",
      "Running Batch 183, Epoch 1, Total Tokens: 174\n",
      "Loss: 2.0031771659851074\n",
      "Running Batch 184, Epoch 1, Total Tokens: 121\n",
      "Loss: 2.081041097640991\n",
      "Running Batch 185, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.0859313011169434\n",
      "Running Batch 186, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.0968127250671387\n",
      "Running Batch 187, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.0034303665161133\n",
      "Running Batch 188, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9272212982177734\n",
      "Running Batch 189, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.0852975845336914\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 189, Loss: 2.0852975845336914\n",
      "Running Batch 190, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.1504786014556885\n",
      "Running Batch 191, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.0702707767486572\n",
      "Running Batch 192, Epoch 1, Total Tokens: 159\n",
      "Loss: 2.1348302364349365\n",
      "Running Batch 193, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.039524793624878\n",
      "Running Batch 194, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9606326818466187\n",
      "Running Batch 195, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.120302200317383\n",
      "Running Batch 196, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.0648787021636963\n",
      "Running Batch 197, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.080537796020508\n",
      "Running Batch 198, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.006890058517456\n",
      "Running Batch 199, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9655264616012573\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 199, Loss: 1.9655264616012573\n",
      "Running Batch 200, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.0821211338043213\n",
      "Running Batch 201, Epoch 1, Total Tokens: 126\n",
      "Loss: 2.058401346206665\n",
      "Running Batch 202, Epoch 1, Total Tokens: 143\n",
      "Loss: 2.092073440551758\n",
      "Running Batch 203, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.945547342300415\n",
      "Running Batch 204, Epoch 1, Total Tokens: 124\n",
      "Loss: 2.0666611194610596\n",
      "Running Batch 205, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0045413970947266\n",
      "Running Batch 206, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0266060829162598\n",
      "Running Batch 207, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.943095088005066\n",
      "Running Batch 208, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9901646375656128\n",
      "Running Batch 209, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.1197381019592285\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 209, Loss: 2.1197381019592285\n",
      "Running Batch 210, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.028137445449829\n",
      "Running Batch 211, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.0565905570983887\n",
      "Running Batch 212, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9969555139541626\n",
      "Running Batch 213, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.028538465499878\n",
      "Running Batch 214, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.0117785930633545\n",
      "Running Batch 215, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9626367092132568\n",
      "Running Batch 216, Epoch 1, Total Tokens: 254\n",
      "Loss: 2.0197064876556396\n",
      "Running Batch 217, Epoch 1, Total Tokens: 203\n",
      "Loss: 2.117248773574829\n",
      "Running Batch 218, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.075535535812378\n",
      "Running Batch 219, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.0336833000183105\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 219, Loss: 2.0336833000183105\n",
      "Running Batch 220, Epoch 1, Total Tokens: 242\n",
      "Loss: 2.0428507328033447\n",
      "Running Batch 221, Epoch 1, Total Tokens: 167\n",
      "Loss: 2.03786563873291\n",
      "Running Batch 222, Epoch 1, Total Tokens: 127\n",
      "Loss: 2.0053372383117676\n",
      "Running Batch 223, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0023210048675537\n",
      "Running Batch 224, Epoch 1, Total Tokens: 172\n",
      "Loss: 2.0550804138183594\n",
      "Running Batch 225, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.0096185207366943\n",
      "Running Batch 226, Epoch 1, Total Tokens: 119\n",
      "Loss: 2.0445470809936523\n",
      "Running Batch 227, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.090459108352661\n",
      "Running Batch 228, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.0090174674987793\n",
      "Running Batch 229, Epoch 1, Total Tokens: 572\n",
      "Loss: 2.061492919921875\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 229, Loss: 2.061492919921875\n",
      "Running Batch 230, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0252649784088135\n",
      "Running Batch 231, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.0268714427948\n",
      "Running Batch 232, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9715096950531006\n",
      "Running Batch 233, Epoch 1, Total Tokens: 142\n",
      "Loss: 2.0967929363250732\n",
      "Running Batch 234, Epoch 1, Total Tokens: 186\n",
      "Loss: 2.0379505157470703\n",
      "Running Batch 235, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.0570363998413086\n",
      "Running Batch 236, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.013610363006592\n",
      "Running Batch 237, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.00593638420105\n",
      "Running Batch 238, Epoch 1, Total Tokens: 126\n",
      "Loss: 2.0645933151245117\n",
      "Running Batch 239, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9277292490005493\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 239, Loss: 1.9277292490005493\n",
      "Running Batch 240, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.1081581115722656\n",
      "Running Batch 241, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9948649406433105\n",
      "Running Batch 242, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.009031295776367\n",
      "Running Batch 243, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.009765863418579\n",
      "Running Batch 244, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.0179195404052734\n",
      "Running Batch 245, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.955962061882019\n",
      "Running Batch 246, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0557141304016113\n",
      "Running Batch 247, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9400771856307983\n",
      "Running Batch 248, Epoch 1, Total Tokens: 106\n",
      "Loss: 2.102842330932617\n",
      "Running Batch 249, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0217480659484863\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 249, Loss: 2.0217480659484863\n",
      "Running Batch 250, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9923282861709595\n",
      "Running Batch 251, Epoch 1, Total Tokens: 267\n",
      "Loss: 2.05647349357605\n",
      "Running Batch 252, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9968361854553223\n",
      "Running Batch 253, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9412957429885864\n",
      "Running Batch 254, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.127152681350708\n",
      "Running Batch 255, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9998987913131714\n",
      "Running Batch 256, Epoch 1, Total Tokens: 241\n",
      "Loss: 2.076462507247925\n",
      "Running Batch 257, Epoch 1, Total Tokens: 125\n",
      "Loss: 2.0551505088806152\n",
      "Running Batch 258, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.102003574371338\n",
      "Running Batch 259, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9798941612243652\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 259, Loss: 1.9798941612243652\n",
      "Running Batch 260, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0143840312957764\n",
      "Running Batch 261, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.9726814031600952\n",
      "Running Batch 262, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.0222153663635254\n",
      "Running Batch 263, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9887229204177856\n",
      "Running Batch 264, Epoch 1, Total Tokens: 210\n",
      "Loss: 1.9631510972976685\n",
      "Running Batch 265, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.9703905582427979\n",
      "Running Batch 266, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.077501058578491\n",
      "Running Batch 267, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.0769803524017334\n",
      "Running Batch 268, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.0396244525909424\n",
      "Running Batch 269, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.0708370208740234\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 269, Loss: 2.0708370208740234\n",
      "Running Batch 270, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.0481762886047363\n",
      "Running Batch 271, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.01619029045105\n",
      "Running Batch 272, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0622267723083496\n",
      "Running Batch 273, Epoch 1, Total Tokens: 120\n",
      "Loss: 2.0711183547973633\n",
      "Running Batch 274, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.946366548538208\n",
      "Running Batch 275, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.0238394737243652\n",
      "Running Batch 276, Epoch 1, Total Tokens: 287\n",
      "Loss: 1.9795629978179932\n",
      "Running Batch 277, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.989528775215149\n",
      "Running Batch 278, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.1091201305389404\n",
      "Running Batch 279, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.110630750656128\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 279, Loss: 2.110630750656128\n",
      "Running Batch 280, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.9675694704055786\n",
      "Running Batch 281, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0567290782928467\n",
      "Running Batch 282, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.995042324066162\n",
      "Running Batch 283, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.0106329917907715\n",
      "Running Batch 284, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.112445831298828\n",
      "Running Batch 285, Epoch 1, Total Tokens: 166\n",
      "Loss: 2.053791046142578\n",
      "Running Batch 286, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9918248653411865\n",
      "Running Batch 287, Epoch 1, Total Tokens: 156\n",
      "Loss: 2.1171512603759766\n",
      "Running Batch 288, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9837373495101929\n",
      "Running Batch 289, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.960513710975647\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 289, Loss: 1.960513710975647\n",
      "Running Batch 290, Epoch 1, Total Tokens: 167\n",
      "Loss: 2.077392339706421\n",
      "Running Batch 291, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9289602041244507\n",
      "Running Batch 292, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9516410827636719\n",
      "Running Batch 293, Epoch 1, Total Tokens: 295\n",
      "Loss: 1.9684603214263916\n",
      "Running Batch 294, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9954267740249634\n",
      "Running Batch 295, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.931234359741211\n",
      "Running Batch 296, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0343949794769287\n",
      "Running Batch 297, Epoch 1, Total Tokens: 367\n",
      "Loss: 2.007988452911377\n",
      "Running Batch 298, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0155622959136963\n",
      "Running Batch 299, Epoch 1, Total Tokens: 121\n",
      "Loss: 2.0796890258789062\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 299, Loss: 2.0796890258789062\n",
      "Running Batch 300, Epoch 1, Total Tokens: 262\n",
      "Loss: 2.0078012943267822\n",
      "Running Batch 301, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9426040649414062\n",
      "Running Batch 302, Epoch 1, Total Tokens: 122\n",
      "Loss: 2.0520741939544678\n",
      "Running Batch 303, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.114078998565674\n",
      "Running Batch 304, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.0382766723632812\n",
      "Running Batch 305, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9914209842681885\n",
      "Running Batch 306, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.066964626312256\n",
      "Running Batch 307, Epoch 1, Total Tokens: 116\n",
      "Loss: 2.0656349658966064\n",
      "Running Batch 308, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.012587785720825\n",
      "Running Batch 309, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.08811092376709\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 309, Loss: 2.08811092376709\n",
      "Running Batch 310, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.9982091188430786\n",
      "Running Batch 311, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.07043194770813\n",
      "Running Batch 312, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0350279808044434\n",
      "Running Batch 313, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9427796602249146\n",
      "Running Batch 314, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.003213882446289\n",
      "Running Batch 315, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0112996101379395\n",
      "Running Batch 316, Epoch 1, Total Tokens: 157\n",
      "Loss: 2.0394301414489746\n",
      "Running Batch 317, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.086714506149292\n",
      "Running Batch 318, Epoch 1, Total Tokens: 124\n",
      "Loss: 2.0050241947174072\n",
      "Running Batch 319, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.886307954788208\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 319, Loss: 1.886307954788208\n",
      "Running Batch 320, Epoch 1, Total Tokens: 183\n",
      "Loss: 2.0267746448516846\n",
      "Running Batch 321, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.025237560272217\n",
      "Running Batch 322, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.990591049194336\n",
      "Running Batch 323, Epoch 1, Total Tokens: 142\n",
      "Loss: 2.050523281097412\n",
      "Running Batch 324, Epoch 1, Total Tokens: 129\n",
      "Loss: 2.0101704597473145\n",
      "Running Batch 325, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.891762375831604\n",
      "Running Batch 326, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9361636638641357\n",
      "Running Batch 327, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0612943172454834\n",
      "Running Batch 328, Epoch 1, Total Tokens: 116\n",
      "Loss: 2.020914316177368\n",
      "Running Batch 329, Epoch 1, Total Tokens: 177\n",
      "Loss: 2.0419251918792725\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 329, Loss: 2.0419251918792725\n",
      "Running Batch 330, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.018296241760254\n",
      "Running Batch 331, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.026846170425415\n",
      "Running Batch 332, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.020673990249634\n",
      "Running Batch 333, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.046738386154175\n",
      "Running Batch 334, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0116069316864014\n",
      "Running Batch 335, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9880728721618652\n",
      "Running Batch 336, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.876203179359436\n",
      "Running Batch 337, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.9784235954284668\n",
      "Running Batch 338, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.101109504699707\n",
      "Running Batch 339, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9481598138809204\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 339, Loss: 1.9481598138809204\n",
      "Running Batch 340, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9375048875808716\n",
      "Running Batch 341, Epoch 1, Total Tokens: 254\n",
      "Loss: 1.9864153861999512\n",
      "Running Batch 342, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0169708728790283\n",
      "Running Batch 343, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.908210277557373\n",
      "Running Batch 344, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9822670221328735\n",
      "Running Batch 345, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.912768840789795\n",
      "Running Batch 346, Epoch 1, Total Tokens: 185\n",
      "Loss: 2.0054662227630615\n",
      "Running Batch 347, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.0056638717651367\n",
      "Running Batch 348, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.008788585662842\n",
      "Running Batch 349, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9997297525405884\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 349, Loss: 1.9997297525405884\n",
      "Running Batch 350, Epoch 1, Total Tokens: 155\n",
      "Loss: 2.007807731628418\n",
      "Running Batch 351, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9283864498138428\n",
      "Running Batch 352, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.9886834621429443\n",
      "Running Batch 353, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.9895384311676025\n",
      "Running Batch 354, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.0234363079071045\n",
      "Running Batch 355, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9981136322021484\n",
      "Running Batch 356, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9677000045776367\n",
      "Running Batch 357, Epoch 1, Total Tokens: 356\n",
      "Loss: 2.012897491455078\n",
      "Running Batch 358, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.973994493484497\n",
      "Running Batch 359, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.0218567848205566\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 359, Loss: 2.0218567848205566\n",
      "Running Batch 360, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9801088571548462\n",
      "Running Batch 361, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.9301599264144897\n",
      "Running Batch 362, Epoch 1, Total Tokens: 142\n",
      "Loss: 2.02018404006958\n",
      "Running Batch 363, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.9891924858093262\n",
      "Running Batch 364, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9589978456497192\n",
      "Running Batch 365, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.0038723945617676\n",
      "Running Batch 366, Epoch 1, Total Tokens: 113\n",
      "Loss: 2.0746657848358154\n",
      "Running Batch 367, Epoch 1, Total Tokens: 266\n",
      "Loss: 1.9925522804260254\n",
      "Running Batch 368, Epoch 1, Total Tokens: 159\n",
      "Loss: 2.011094570159912\n",
      "Running Batch 369, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.8869625329971313\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 369, Loss: 1.8869625329971313\n",
      "Running Batch 370, Epoch 1, Total Tokens: 170\n",
      "Loss: 2.181809902191162\n",
      "Running Batch 371, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.9762245416641235\n",
      "Running Batch 372, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.0109941959381104\n",
      "Running Batch 373, Epoch 1, Total Tokens: 134\n",
      "Loss: 2.1544957160949707\n",
      "Running Batch 374, Epoch 1, Total Tokens: 117\n",
      "Loss: 2.1243369579315186\n",
      "Running Batch 375, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0386645793914795\n",
      "Running Batch 376, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.9301390647888184\n",
      "Running Batch 377, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.098119020462036\n",
      "Running Batch 378, Epoch 1, Total Tokens: 166\n",
      "Loss: 2.1077864170074463\n",
      "Running Batch 379, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.068248987197876\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 379, Loss: 2.068248987197876\n",
      "Running Batch 380, Epoch 1, Total Tokens: 165\n",
      "Loss: 2.0553276538848877\n",
      "Running Batch 381, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9245738983154297\n",
      "Running Batch 382, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.978365421295166\n",
      "Running Batch 383, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0555477142333984\n",
      "Running Batch 384, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0247533321380615\n",
      "Running Batch 385, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.966363549232483\n",
      "Running Batch 386, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0761053562164307\n",
      "Running Batch 387, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.993230938911438\n",
      "Running Batch 388, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.052868127822876\n",
      "Running Batch 389, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9588077068328857\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 389, Loss: 1.9588077068328857\n",
      "Running Batch 390, Epoch 1, Total Tokens: 285\n",
      "Loss: 2.054659128189087\n",
      "Running Batch 391, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0291717052459717\n",
      "Running Batch 392, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.0078954696655273\n",
      "Running Batch 393, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8693511486053467\n",
      "Running Batch 394, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0007824897766113\n",
      "Running Batch 395, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.8944952487945557\n",
      "Running Batch 396, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.955622911453247\n",
      "Running Batch 397, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9017339944839478\n",
      "Running Batch 398, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9284687042236328\n",
      "Running Batch 399, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8789125680923462\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 399, Loss: 1.8789125680923462\n",
      "Running Batch 400, Epoch 1, Total Tokens: 108\n",
      "Loss: 2.0109689235687256\n",
      "Running Batch 401, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0738236904144287\n",
      "Running Batch 402, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.9717408418655396\n",
      "Running Batch 403, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0163822174072266\n",
      "Running Batch 404, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.9446766376495361\n",
      "Running Batch 405, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.059563398361206\n",
      "Running Batch 406, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.119706630706787\n",
      "Running Batch 407, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.8523664474487305\n",
      "Running Batch 408, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9533946514129639\n",
      "Running Batch 409, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9714617729187012\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 409, Loss: 1.9714617729187012\n",
      "Running Batch 410, Epoch 1, Total Tokens: 228\n",
      "Loss: 1.8911190032958984\n",
      "Running Batch 411, Epoch 1, Total Tokens: 294\n",
      "Loss: 2.0090436935424805\n",
      "Running Batch 412, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.000546932220459\n",
      "Running Batch 413, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.0006821155548096\n",
      "Running Batch 414, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0137457847595215\n",
      "Running Batch 415, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.006779909133911\n",
      "Running Batch 416, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.0442957878112793\n",
      "Running Batch 417, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.0693135261535645\n",
      "Running Batch 418, Epoch 1, Total Tokens: 159\n",
      "Loss: 2.0626511573791504\n",
      "Running Batch 419, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.9568586349487305\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 419, Loss: 1.9568586349487305\n",
      "Running Batch 420, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.024508237838745\n",
      "Running Batch 421, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0110671520233154\n",
      "Running Batch 422, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9335646629333496\n",
      "Running Batch 423, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9825611114501953\n",
      "Running Batch 424, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9645497798919678\n",
      "Running Batch 425, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.071019172668457\n",
      "Running Batch 426, Epoch 1, Total Tokens: 384\n",
      "Loss: 2.0037126541137695\n",
      "Running Batch 427, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9133169651031494\n",
      "Running Batch 428, Epoch 1, Total Tokens: 286\n",
      "Loss: 2.0229883193969727\n",
      "Running Batch 429, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.103701114654541\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 429, Loss: 2.103701114654541\n",
      "Running Batch 430, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.921366572380066\n",
      "Running Batch 431, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.019019842147827\n",
      "Running Batch 432, Epoch 1, Total Tokens: 106\n",
      "Loss: 1.9443893432617188\n",
      "Running Batch 433, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.005521297454834\n",
      "Running Batch 434, Epoch 1, Total Tokens: 163\n",
      "Loss: 2.1019465923309326\n",
      "Running Batch 435, Epoch 1, Total Tokens: 162\n",
      "Loss: 2.0764362812042236\n",
      "Running Batch 436, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9640791416168213\n",
      "Running Batch 437, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.00649094581604\n",
      "Running Batch 438, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8877367973327637\n",
      "Running Batch 439, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.965516448020935\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 439, Loss: 1.965516448020935\n",
      "Running Batch 440, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.963413119316101\n",
      "Running Batch 441, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9861356019973755\n",
      "Running Batch 442, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9186638593673706\n",
      "Running Batch 443, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9151268005371094\n",
      "Running Batch 444, Epoch 1, Total Tokens: 141\n",
      "Loss: 2.0388741493225098\n",
      "Running Batch 445, Epoch 1, Total Tokens: 258\n",
      "Loss: 2.0418925285339355\n",
      "Running Batch 446, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.9299120903015137\n",
      "Running Batch 447, Epoch 1, Total Tokens: 123\n",
      "Loss: 2.0165555477142334\n",
      "Running Batch 448, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.019181251525879\n",
      "Running Batch 449, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9902384281158447\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 449, Loss: 1.9902384281158447\n",
      "Running Batch 450, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.99753999710083\n",
      "Running Batch 451, Epoch 1, Total Tokens: 188\n",
      "Loss: 2.0258853435516357\n",
      "Running Batch 452, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9399464130401611\n",
      "Running Batch 453, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.0348424911499023\n",
      "Running Batch 454, Epoch 1, Total Tokens: 257\n",
      "Loss: 1.902719259262085\n",
      "Running Batch 455, Epoch 1, Total Tokens: 139\n",
      "Loss: 2.068960428237915\n",
      "Running Batch 456, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.8953202962875366\n",
      "Running Batch 457, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.9507774114608765\n",
      "Running Batch 458, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8728976249694824\n",
      "Running Batch 459, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.021538496017456\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 459, Loss: 2.021538496017456\n",
      "Running Batch 460, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9985915422439575\n",
      "Running Batch 461, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9380050897598267\n",
      "Running Batch 462, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9309574365615845\n",
      "Running Batch 463, Epoch 1, Total Tokens: 203\n",
      "Loss: 2.0175225734710693\n",
      "Running Batch 464, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.969179630279541\n",
      "Running Batch 465, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0523521900177\n",
      "Running Batch 466, Epoch 1, Total Tokens: 183\n",
      "Loss: 2.025336265563965\n",
      "Running Batch 467, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9773266315460205\n",
      "Running Batch 468, Epoch 1, Total Tokens: 163\n",
      "Loss: 1.9363110065460205\n",
      "Running Batch 469, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.995161533355713\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 469, Loss: 1.995161533355713\n",
      "Running Batch 470, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9846035242080688\n",
      "Running Batch 471, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8648266792297363\n",
      "Running Batch 472, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9668956995010376\n",
      "Running Batch 473, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.8655518293380737\n",
      "Running Batch 474, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.863822102546692\n",
      "Running Batch 475, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9694030284881592\n",
      "Running Batch 476, Epoch 1, Total Tokens: 220\n",
      "Loss: 1.9613012075424194\n",
      "Running Batch 477, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9564220905303955\n",
      "Running Batch 478, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9187992811203003\n",
      "Running Batch 479, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.9619331359863281\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 479, Loss: 1.9619331359863281\n",
      "Running Batch 480, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9256664514541626\n",
      "Running Batch 481, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.9732234477996826\n",
      "Running Batch 482, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.00168514251709\n",
      "Running Batch 483, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9880108833312988\n",
      "Running Batch 484, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9908496141433716\n",
      "Running Batch 485, Epoch 1, Total Tokens: 117\n",
      "Loss: 2.0144450664520264\n",
      "Running Batch 486, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.952027678489685\n",
      "Running Batch 487, Epoch 1, Total Tokens: 174\n",
      "Loss: 2.0370707511901855\n",
      "Running Batch 488, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9985027313232422\n",
      "Running Batch 489, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.988431692123413\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 489, Loss: 1.988431692123413\n",
      "Running Batch 490, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9532147645950317\n",
      "Running Batch 491, Epoch 1, Total Tokens: 137\n",
      "Loss: 2.011911153793335\n",
      "Running Batch 492, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9871547222137451\n",
      "Running Batch 493, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.9273204803466797\n",
      "Running Batch 494, Epoch 1, Total Tokens: 202\n",
      "Loss: 2.017969846725464\n",
      "Running Batch 495, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.937758445739746\n",
      "Running Batch 496, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0894880294799805\n",
      "Running Batch 497, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.9218189716339111\n",
      "Running Batch 498, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9541983604431152\n",
      "Running Batch 499, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.938233733177185\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 499, Loss: 1.938233733177185\n",
      "Running Batch 500, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9306564331054688\n",
      "Running Batch 501, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.971645474433899\n",
      "Running Batch 502, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.9898650646209717\n",
      "Running Batch 503, Epoch 1, Total Tokens: 196\n",
      "Loss: 2.026120662689209\n",
      "Running Batch 504, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9877195358276367\n",
      "Running Batch 505, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9558156728744507\n",
      "Running Batch 506, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.964850664138794\n",
      "Running Batch 507, Epoch 1, Total Tokens: 114\n",
      "Loss: 2.04656720161438\n",
      "Running Batch 508, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.9201385974884033\n",
      "Running Batch 509, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9551479816436768\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 509, Loss: 1.9551479816436768\n",
      "Running Batch 510, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.971095085144043\n",
      "Running Batch 511, Epoch 1, Total Tokens: 122\n",
      "Loss: 2.0727107524871826\n",
      "Running Batch 512, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.046919584274292\n",
      "Running Batch 513, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.8961412906646729\n",
      "Running Batch 514, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.9873785972595215\n",
      "Running Batch 515, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9461761713027954\n",
      "Running Batch 516, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9087337255477905\n",
      "Running Batch 517, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9158082008361816\n",
      "Running Batch 518, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.9866408109664917\n",
      "Running Batch 519, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9316344261169434\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 519, Loss: 1.9316344261169434\n",
      "Running Batch 520, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.9663037061691284\n",
      "Running Batch 521, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.9414719343185425\n",
      "Running Batch 522, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9221246242523193\n",
      "Running Batch 523, Epoch 1, Total Tokens: 273\n",
      "Loss: 1.9236518144607544\n",
      "Running Batch 524, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.0346810817718506\n",
      "Running Batch 525, Epoch 1, Total Tokens: 267\n",
      "Loss: 2.0296971797943115\n",
      "Running Batch 526, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.0334224700927734\n",
      "Running Batch 527, Epoch 1, Total Tokens: 372\n",
      "Loss: 1.9467012882232666\n",
      "Running Batch 528, Epoch 1, Total Tokens: 142\n",
      "Loss: 2.0502922534942627\n",
      "Running Batch 529, Epoch 1, Total Tokens: 151\n",
      "Loss: 2.032123327255249\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 529, Loss: 2.032123327255249\n",
      "Running Batch 530, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.0014994144439697\n",
      "Running Batch 531, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.9807441234588623\n",
      "Running Batch 532, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.019439458847046\n",
      "Running Batch 533, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0258800983428955\n",
      "Running Batch 534, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9484421014785767\n",
      "Running Batch 535, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.012873649597168\n",
      "Running Batch 536, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0906424522399902\n",
      "Running Batch 537, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9593770503997803\n",
      "Running Batch 538, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.9465636014938354\n",
      "Running Batch 539, Epoch 1, Total Tokens: 122\n",
      "Loss: 2.0463125705718994\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 539, Loss: 2.0463125705718994\n",
      "Running Batch 540, Epoch 1, Total Tokens: 244\n",
      "Loss: 1.9653990268707275\n",
      "Running Batch 541, Epoch 1, Total Tokens: 165\n",
      "Loss: 2.0122923851013184\n",
      "Running Batch 542, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.9673622846603394\n",
      "Running Batch 543, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9877724647521973\n",
      "Running Batch 544, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.95596444606781\n",
      "Running Batch 545, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.984190821647644\n",
      "Running Batch 546, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.8660897016525269\n",
      "Running Batch 547, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9908876419067383\n",
      "Running Batch 548, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9510393142700195\n",
      "Running Batch 549, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.9887744188308716\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 549, Loss: 1.9887744188308716\n",
      "Running Batch 550, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.8789702653884888\n",
      "Running Batch 551, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9848636388778687\n",
      "Running Batch 552, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.9852133989334106\n",
      "Running Batch 553, Epoch 1, Total Tokens: 152\n",
      "Loss: 2.0429112911224365\n",
      "Running Batch 554, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9692156314849854\n",
      "Running Batch 555, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.979211449623108\n",
      "Running Batch 556, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.9373571872711182\n",
      "Running Batch 557, Epoch 1, Total Tokens: 113\n",
      "Loss: 2.008267879486084\n",
      "Running Batch 558, Epoch 1, Total Tokens: 127\n",
      "Loss: 2.0182526111602783\n",
      "Running Batch 559, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8971980810165405\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 559, Loss: 1.8971980810165405\n",
      "Running Batch 560, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.946071743965149\n",
      "Running Batch 561, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.8480489253997803\n",
      "Running Batch 562, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.9843943119049072\n",
      "Running Batch 563, Epoch 1, Total Tokens: 228\n",
      "Loss: 2.0091216564178467\n",
      "Running Batch 564, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9595187902450562\n",
      "Running Batch 565, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9328211545944214\n",
      "Running Batch 566, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9192534685134888\n",
      "Running Batch 567, Epoch 1, Total Tokens: 162\n",
      "Loss: 2.0098092555999756\n",
      "Running Batch 568, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9388980865478516\n",
      "Running Batch 569, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.9655323028564453\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 569, Loss: 1.9655323028564453\n",
      "Running Batch 570, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9580222368240356\n",
      "Running Batch 571, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.0135884284973145\n",
      "Running Batch 572, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.9195853471755981\n",
      "Running Batch 573, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9307477474212646\n",
      "Running Batch 574, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.002225637435913\n",
      "Running Batch 575, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.020167589187622\n",
      "Running Batch 576, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9002269506454468\n",
      "Running Batch 577, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.9734058380126953\n",
      "Running Batch 578, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.0323543548583984\n",
      "Running Batch 579, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9666115045547485\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 579, Loss: 1.9666115045547485\n",
      "Running Batch 580, Epoch 1, Total Tokens: 281\n",
      "Loss: 1.8982365131378174\n",
      "Running Batch 581, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9797528982162476\n",
      "Running Batch 582, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.9430652856826782\n",
      "Running Batch 583, Epoch 1, Total Tokens: 140\n",
      "Loss: 2.0017151832580566\n",
      "Running Batch 584, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9190104007720947\n",
      "Running Batch 585, Epoch 1, Total Tokens: 185\n",
      "Loss: 1.9555690288543701\n",
      "Running Batch 586, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9673213958740234\n",
      "Running Batch 587, Epoch 1, Total Tokens: 147\n",
      "Loss: 2.0202486515045166\n",
      "Running Batch 588, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.8783234357833862\n",
      "Running Batch 589, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0305309295654297\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 589, Loss: 2.0305309295654297\n",
      "Running Batch 590, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.952942967414856\n",
      "Running Batch 591, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9480668306350708\n",
      "Running Batch 592, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.9476948976516724\n",
      "Running Batch 593, Epoch 1, Total Tokens: 143\n",
      "Loss: 2.0547354221343994\n",
      "Running Batch 594, Epoch 1, Total Tokens: 104\n",
      "Loss: 1.9660601615905762\n",
      "Running Batch 595, Epoch 1, Total Tokens: 110\n",
      "Loss: 1.9343230724334717\n",
      "Running Batch 596, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.9706372022628784\n",
      "Running Batch 597, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9976394176483154\n",
      "Running Batch 598, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.9835041761398315\n",
      "Running Batch 599, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9320011138916016\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 599, Loss: 1.9320011138916016\n",
      "Running Batch 600, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.9455254077911377\n",
      "Running Batch 601, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9745943546295166\n",
      "Running Batch 602, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.9472988843917847\n",
      "Running Batch 603, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9683897495269775\n",
      "Running Batch 604, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.9637728929519653\n",
      "Running Batch 605, Epoch 1, Total Tokens: 221\n",
      "Loss: 1.968343734741211\n",
      "Running Batch 606, Epoch 1, Total Tokens: 230\n",
      "Loss: 2.013739585876465\n",
      "Running Batch 607, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9702214002609253\n",
      "Running Batch 608, Epoch 1, Total Tokens: 214\n",
      "Loss: 1.940454363822937\n",
      "Running Batch 609, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.015967607498169\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 609, Loss: 2.015967607498169\n",
      "Running Batch 610, Epoch 1, Total Tokens: 117\n",
      "Loss: 2.007352113723755\n",
      "Running Batch 611, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.985918402671814\n",
      "Running Batch 612, Epoch 1, Total Tokens: 624\n",
      "Loss: 1.9222583770751953\n",
      "Running Batch 613, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.998769760131836\n",
      "Running Batch 614, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.8628815412521362\n",
      "Running Batch 615, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.027899742126465\n",
      "Running Batch 616, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.007401704788208\n",
      "Running Batch 617, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9950355291366577\n",
      "Running Batch 618, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9070193767547607\n",
      "Running Batch 619, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.8265916109085083\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 619, Loss: 1.8265916109085083\n",
      "Running Batch 620, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.020671844482422\n",
      "Running Batch 621, Epoch 1, Total Tokens: 250\n",
      "Loss: 1.9201295375823975\n",
      "Running Batch 622, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9214954376220703\n",
      "Running Batch 623, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.954964518547058\n",
      "Running Batch 624, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.024136543273926\n",
      "Running Batch 625, Epoch 1, Total Tokens: 629\n",
      "Loss: 1.9017986059188843\n",
      "Running Batch 626, Epoch 1, Total Tokens: 138\n",
      "Loss: 2.029811143875122\n",
      "Running Batch 627, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9001117944717407\n",
      "Running Batch 628, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.917588233947754\n",
      "Running Batch 629, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9471515417099\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 629, Loss: 1.9471515417099\n",
      "Running Batch 630, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.8895717859268188\n",
      "Running Batch 631, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9846388101577759\n",
      "Running Batch 632, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9178473949432373\n",
      "Running Batch 633, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9455033540725708\n",
      "Running Batch 634, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9946227073669434\n",
      "Running Batch 635, Epoch 1, Total Tokens: 340\n",
      "Loss: 2.0271384716033936\n",
      "Running Batch 636, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9040850400924683\n",
      "Running Batch 637, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.02285099029541\n",
      "Running Batch 638, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.9508122205734253\n",
      "Running Batch 639, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.916534423828125\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 639, Loss: 1.916534423828125\n",
      "Running Batch 640, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.894017219543457\n",
      "Running Batch 641, Epoch 1, Total Tokens: 107\n",
      "Loss: 1.8375972509384155\n",
      "Running Batch 642, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.9885849952697754\n",
      "Running Batch 643, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.9454715251922607\n",
      "Running Batch 644, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9994479417800903\n",
      "Running Batch 645, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9609295129776\n",
      "Running Batch 646, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8454750776290894\n",
      "Running Batch 647, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9791418313980103\n",
      "Running Batch 648, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9437931776046753\n",
      "Running Batch 649, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.950103759765625\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 649, Loss: 1.950103759765625\n",
      "Running Batch 650, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.8987369537353516\n",
      "Running Batch 651, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9252886772155762\n",
      "Running Batch 652, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0098214149475098\n",
      "Running Batch 653, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9208317995071411\n",
      "Running Batch 654, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0230026245117188\n",
      "Running Batch 655, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9841817617416382\n",
      "Running Batch 656, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9329583644866943\n",
      "Running Batch 657, Epoch 1, Total Tokens: 206\n",
      "Loss: 1.9483649730682373\n",
      "Running Batch 658, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9860548973083496\n",
      "Running Batch 659, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9584242105484009\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 659, Loss: 1.9584242105484009\n",
      "Running Batch 660, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.0638537406921387\n",
      "Running Batch 661, Epoch 1, Total Tokens: 234\n",
      "Loss: 1.8831076622009277\n",
      "Running Batch 662, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9675060510635376\n",
      "Running Batch 663, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.9181736707687378\n",
      "Running Batch 664, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.8991419076919556\n",
      "Running Batch 665, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.942566156387329\n",
      "Running Batch 666, Epoch 1, Total Tokens: 161\n",
      "Loss: 2.0114383697509766\n",
      "Running Batch 667, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.042689800262451\n",
      "Running Batch 668, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.9316738843917847\n",
      "Running Batch 669, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.8549985885620117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 669, Loss: 1.8549985885620117\n",
      "Running Batch 670, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.905684232711792\n",
      "Running Batch 671, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.9838446378707886\n",
      "Running Batch 672, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9471583366394043\n",
      "Running Batch 673, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.9801777601242065\n",
      "Running Batch 674, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9053212404251099\n",
      "Running Batch 675, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.9607627391815186\n",
      "Running Batch 676, Epoch 1, Total Tokens: 148\n",
      "Loss: 2.023841381072998\n",
      "Running Batch 677, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9896509647369385\n",
      "Running Batch 678, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.9647971391677856\n",
      "Running Batch 679, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.950195074081421\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 679, Loss: 1.950195074081421\n",
      "Running Batch 680, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.8793556690216064\n",
      "Running Batch 681, Epoch 1, Total Tokens: 156\n",
      "Loss: 2.0295863151550293\n",
      "Running Batch 682, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.9545196294784546\n",
      "Running Batch 683, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9509358406066895\n",
      "Running Batch 684, Epoch 1, Total Tokens: 109\n",
      "Loss: 1.9033854007720947\n",
      "Running Batch 685, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.8539713621139526\n",
      "Running Batch 686, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.884792685508728\n",
      "Running Batch 687, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9248355627059937\n",
      "Running Batch 688, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.9922679662704468\n",
      "Running Batch 689, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.008160352706909\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 689, Loss: 2.008160352706909\n",
      "Running Batch 690, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8751983642578125\n",
      "Running Batch 691, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.8756681680679321\n",
      "Running Batch 692, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.878693699836731\n",
      "Running Batch 693, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.96360445022583\n",
      "Running Batch 694, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9041786193847656\n",
      "Running Batch 695, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9879636764526367\n",
      "Running Batch 696, Epoch 1, Total Tokens: 133\n",
      "Loss: 2.0537304878234863\n",
      "Running Batch 697, Epoch 1, Total Tokens: 184\n",
      "Loss: 1.9926999807357788\n",
      "Running Batch 698, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9427213668823242\n",
      "Running Batch 699, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.9934494495391846\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 699, Loss: 1.9934494495391846\n",
      "Running Batch 700, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.8890446424484253\n",
      "Running Batch 701, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.0332508087158203\n",
      "Running Batch 702, Epoch 1, Total Tokens: 150\n",
      "Loss: 2.0216805934906006\n",
      "Running Batch 703, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9044373035430908\n",
      "Running Batch 704, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9590507745742798\n",
      "Running Batch 705, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.8950293064117432\n",
      "Running Batch 706, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.98604154586792\n",
      "Running Batch 707, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9263651371002197\n",
      "Running Batch 708, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9586563110351562\n",
      "Running Batch 709, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.856745719909668\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 709, Loss: 1.856745719909668\n",
      "Running Batch 710, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.932781457901001\n",
      "Running Batch 711, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9450701475143433\n",
      "Running Batch 712, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9195568561553955\n",
      "Running Batch 713, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9473286867141724\n",
      "Running Batch 714, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9411957263946533\n",
      "Running Batch 715, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.975295066833496\n",
      "Running Batch 716, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.9456568956375122\n",
      "Running Batch 717, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.064696788787842\n",
      "Running Batch 718, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.8543883562088013\n",
      "Running Batch 719, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.968919277191162\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 719, Loss: 1.968919277191162\n",
      "Running Batch 720, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9424018859863281\n",
      "Running Batch 721, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9565283060073853\n",
      "Running Batch 722, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9160186052322388\n",
      "Running Batch 723, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.898835301399231\n",
      "Running Batch 724, Epoch 1, Total Tokens: 158\n",
      "Loss: 2.0578272342681885\n",
      "Running Batch 725, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9222352504730225\n",
      "Running Batch 726, Epoch 1, Total Tokens: 145\n",
      "Loss: 2.000091075897217\n",
      "Running Batch 727, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.9014133214950562\n",
      "Running Batch 728, Epoch 1, Total Tokens: 191\n",
      "Loss: 1.8275972604751587\n",
      "Running Batch 729, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.929574966430664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 729, Loss: 1.929574966430664\n",
      "Running Batch 730, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.854044795036316\n",
      "Running Batch 731, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8545998334884644\n",
      "Running Batch 732, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.9560743570327759\n",
      "Running Batch 733, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9481616020202637\n",
      "Running Batch 734, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8720018863677979\n",
      "Running Batch 735, Epoch 1, Total Tokens: 172\n",
      "Loss: 2.02843976020813\n",
      "Running Batch 736, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.907623052597046\n",
      "Running Batch 737, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9621214866638184\n",
      "Running Batch 738, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9007453918457031\n",
      "Running Batch 739, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.9242513179779053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 739, Loss: 1.9242513179779053\n",
      "Running Batch 740, Epoch 1, Total Tokens: 281\n",
      "Loss: 1.9197864532470703\n",
      "Running Batch 741, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9068785905838013\n",
      "Running Batch 742, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9087469577789307\n",
      "Running Batch 743, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9235918521881104\n",
      "Running Batch 744, Epoch 1, Total Tokens: 157\n",
      "Loss: 1.9404542446136475\n",
      "Running Batch 745, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9140496253967285\n",
      "Running Batch 746, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9653239250183105\n",
      "Running Batch 747, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9585639238357544\n",
      "Running Batch 748, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9784334897994995\n",
      "Running Batch 749, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8981568813323975\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 749, Loss: 1.8981568813323975\n",
      "Running Batch 750, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9620823860168457\n",
      "Running Batch 751, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.905625820159912\n",
      "Running Batch 752, Epoch 1, Total Tokens: 110\n",
      "Loss: 1.9897054433822632\n",
      "Running Batch 753, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.93915855884552\n",
      "Running Batch 754, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.9735862016677856\n",
      "Running Batch 755, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8698841333389282\n",
      "Running Batch 756, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9221855401992798\n",
      "Running Batch 757, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.957340121269226\n",
      "Running Batch 758, Epoch 1, Total Tokens: 179\n",
      "Loss: 2.0486931800842285\n",
      "Running Batch 759, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.8848049640655518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 759, Loss: 1.8848049640655518\n",
      "Running Batch 760, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.932669758796692\n",
      "Running Batch 761, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9475884437561035\n",
      "Running Batch 762, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.9087820053100586\n",
      "Running Batch 763, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.8841665983200073\n",
      "Running Batch 764, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.001156806945801\n",
      "Running Batch 765, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8863446712493896\n",
      "Running Batch 766, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0268428325653076\n",
      "Running Batch 767, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.8931598663330078\n",
      "Running Batch 768, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.953847050666809\n",
      "Running Batch 769, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.907485842704773\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 769, Loss: 1.907485842704773\n",
      "Running Batch 770, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9047988653182983\n",
      "Running Batch 771, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.8858071565628052\n",
      "Running Batch 772, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9135075807571411\n",
      "Running Batch 773, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.8655304908752441\n",
      "Running Batch 774, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.8593741655349731\n",
      "Running Batch 775, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.949219822883606\n",
      "Running Batch 776, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9052395820617676\n",
      "Running Batch 777, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9411351680755615\n",
      "Running Batch 778, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.907085657119751\n",
      "Running Batch 779, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9082576036453247\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 779, Loss: 1.9082576036453247\n",
      "Running Batch 780, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9770501852035522\n",
      "Running Batch 781, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.032449245452881\n",
      "Running Batch 782, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.9847331047058105\n",
      "Running Batch 783, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.98561429977417\n",
      "Running Batch 784, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9562807083129883\n",
      "Running Batch 785, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9612336158752441\n",
      "Running Batch 786, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9607772827148438\n",
      "Running Batch 787, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9684882164001465\n",
      "Running Batch 788, Epoch 1, Total Tokens: 124\n",
      "Loss: 2.056318998336792\n",
      "Running Batch 789, Epoch 1, Total Tokens: 144\n",
      "Loss: 2.0001401901245117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 789, Loss: 2.0001401901245117\n",
      "Running Batch 790, Epoch 1, Total Tokens: 161\n",
      "Loss: 1.797054648399353\n",
      "Running Batch 791, Epoch 1, Total Tokens: 159\n",
      "Loss: 1.846203327178955\n",
      "Running Batch 792, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9880977869033813\n",
      "Running Batch 793, Epoch 1, Total Tokens: 322\n",
      "Loss: 1.9099414348602295\n",
      "Running Batch 794, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8476505279541016\n",
      "Running Batch 795, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.935091495513916\n",
      "Running Batch 796, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9412559270858765\n",
      "Running Batch 797, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9109441041946411\n",
      "Running Batch 798, Epoch 1, Total Tokens: 324\n",
      "Loss: 1.8832091093063354\n",
      "Running Batch 799, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9713748693466187\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 799, Loss: 1.9713748693466187\n",
      "Running Batch 800, Epoch 1, Total Tokens: 234\n",
      "Loss: 1.974223017692566\n",
      "Running Batch 801, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.8646936416625977\n",
      "Running Batch 802, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9941730499267578\n",
      "Running Batch 803, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.9938336610794067\n",
      "Running Batch 804, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9738818407058716\n",
      "Running Batch 805, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.962864875793457\n",
      "Running Batch 806, Epoch 1, Total Tokens: 167\n",
      "Loss: 1.9842798709869385\n",
      "Running Batch 807, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.950454831123352\n",
      "Running Batch 808, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.8781893253326416\n",
      "Running Batch 809, Epoch 1, Total Tokens: 168\n",
      "Loss: 1.9118305444717407\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 809, Loss: 1.9118305444717407\n",
      "Running Batch 810, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.9478099346160889\n",
      "Running Batch 811, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.956956148147583\n",
      "Running Batch 812, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8054503202438354\n",
      "Running Batch 813, Epoch 1, Total Tokens: 282\n",
      "Loss: 1.8918076753616333\n",
      "Running Batch 814, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.8796674013137817\n",
      "Running Batch 815, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8740934133529663\n",
      "Running Batch 816, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9012900590896606\n",
      "Running Batch 817, Epoch 1, Total Tokens: 123\n",
      "Loss: 1.9253056049346924\n",
      "Running Batch 818, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.8450721502304077\n",
      "Running Batch 819, Epoch 1, Total Tokens: 154\n",
      "Loss: 2.0104498863220215\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 819, Loss: 2.0104498863220215\n",
      "Running Batch 820, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8557690382003784\n",
      "Running Batch 821, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8881707191467285\n",
      "Running Batch 822, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9544156789779663\n",
      "Running Batch 823, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.927147626876831\n",
      "Running Batch 824, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9261161088943481\n",
      "Running Batch 825, Epoch 1, Total Tokens: 175\n",
      "Loss: 1.8583176136016846\n",
      "Running Batch 826, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.9359385967254639\n",
      "Running Batch 827, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.8861348628997803\n",
      "Running Batch 828, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.9187268018722534\n",
      "Running Batch 829, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9780406951904297\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 829, Loss: 1.9780406951904297\n",
      "Running Batch 830, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9459999799728394\n",
      "Running Batch 831, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.916875958442688\n",
      "Running Batch 832, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.937417984008789\n",
      "Running Batch 833, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.9766148328781128\n",
      "Running Batch 834, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.9763351678848267\n",
      "Running Batch 835, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.8618777990341187\n",
      "Running Batch 836, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0095551013946533\n",
      "Running Batch 837, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.9343808889389038\n",
      "Running Batch 838, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9113686084747314\n",
      "Running Batch 839, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8694028854370117\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 839, Loss: 1.8694028854370117\n",
      "Running Batch 840, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.8442225456237793\n",
      "Running Batch 841, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.872904896736145\n",
      "Running Batch 842, Epoch 1, Total Tokens: 211\n",
      "Loss: 1.9257745742797852\n",
      "Running Batch 843, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9061142206192017\n",
      "Running Batch 844, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.922843098640442\n",
      "Running Batch 845, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9023261070251465\n",
      "Running Batch 846, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9404555559158325\n",
      "Running Batch 847, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9707705974578857\n",
      "Running Batch 848, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9198788404464722\n",
      "Running Batch 849, Epoch 1, Total Tokens: 123\n",
      "Loss: 2.0094316005706787\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 849, Loss: 2.0094316005706787\n",
      "Running Batch 850, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.9857277870178223\n",
      "Running Batch 851, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9458168745040894\n",
      "Running Batch 852, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.8964155912399292\n",
      "Running Batch 853, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.9374109506607056\n",
      "Running Batch 854, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.910544991493225\n",
      "Running Batch 855, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9227752685546875\n",
      "Running Batch 856, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9781066179275513\n",
      "Running Batch 857, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.8847978115081787\n",
      "Running Batch 858, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.8746901750564575\n",
      "Running Batch 859, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.9379886388778687\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 859, Loss: 1.9379886388778687\n",
      "Running Batch 860, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9199848175048828\n",
      "Running Batch 861, Epoch 1, Total Tokens: 159\n",
      "Loss: 2.00199818611145\n",
      "Running Batch 862, Epoch 1, Total Tokens: 210\n",
      "Loss: 1.9202589988708496\n",
      "Running Batch 863, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9072169065475464\n",
      "Running Batch 864, Epoch 1, Total Tokens: 214\n",
      "Loss: 2.0812265872955322\n",
      "Running Batch 865, Epoch 1, Total Tokens: 118\n",
      "Loss: 2.0155835151672363\n",
      "Running Batch 866, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9786523580551147\n",
      "Running Batch 867, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.9147796630859375\n",
      "Running Batch 868, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.914237380027771\n",
      "Running Batch 869, Epoch 1, Total Tokens: 146\n",
      "Loss: 2.0759241580963135\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 869, Loss: 2.0759241580963135\n",
      "Running Batch 870, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9039337635040283\n",
      "Running Batch 871, Epoch 1, Total Tokens: 106\n",
      "Loss: 1.902357816696167\n",
      "Running Batch 872, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.881205677986145\n",
      "Running Batch 873, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8694782257080078\n",
      "Running Batch 874, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9144439697265625\n",
      "Running Batch 875, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9011578559875488\n",
      "Running Batch 876, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.950724720954895\n",
      "Running Batch 877, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9053484201431274\n",
      "Running Batch 878, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.847825050354004\n",
      "Running Batch 879, Epoch 1, Total Tokens: 114\n",
      "Loss: 1.8881255388259888\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 879, Loss: 1.8881255388259888\n",
      "Running Batch 880, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.8793061971664429\n",
      "Running Batch 881, Epoch 1, Total Tokens: 249\n",
      "Loss: 1.8990079164505005\n",
      "Running Batch 882, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.8154516220092773\n",
      "Running Batch 883, Epoch 1, Total Tokens: 236\n",
      "Loss: 1.953932523727417\n",
      "Running Batch 884, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9003874063491821\n",
      "Running Batch 885, Epoch 1, Total Tokens: 182\n",
      "Loss: 1.9478676319122314\n",
      "Running Batch 886, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9510698318481445\n",
      "Running Batch 887, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9188753366470337\n",
      "Running Batch 888, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.8391528129577637\n",
      "Running Batch 889, Epoch 1, Total Tokens: 136\n",
      "Loss: 2.011883020401001\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 889, Loss: 2.011883020401001\n",
      "Running Batch 890, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8891077041625977\n",
      "Running Batch 891, Epoch 1, Total Tokens: 111\n",
      "Loss: 1.9324679374694824\n",
      "Running Batch 892, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8852217197418213\n",
      "Running Batch 893, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9009320735931396\n",
      "Running Batch 894, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9077293872833252\n",
      "Running Batch 895, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.8787968158721924\n",
      "Running Batch 896, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.8708112239837646\n",
      "Running Batch 897, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8446319103240967\n",
      "Running Batch 898, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9187071323394775\n",
      "Running Batch 899, Epoch 1, Total Tokens: 285\n",
      "Loss: 1.901029109954834\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 899, Loss: 1.901029109954834\n",
      "Running Batch 900, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.846765160560608\n",
      "Running Batch 901, Epoch 1, Total Tokens: 130\n",
      "Loss: 2.054816722869873\n",
      "Running Batch 902, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9229844808578491\n",
      "Running Batch 903, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.9465230703353882\n",
      "Running Batch 904, Epoch 1, Total Tokens: 205\n",
      "Loss: 1.9749881029129028\n",
      "Running Batch 905, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.947393774986267\n",
      "Running Batch 906, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.964055061340332\n",
      "Running Batch 907, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.887747883796692\n",
      "Running Batch 908, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8592779636383057\n",
      "Running Batch 909, Epoch 1, Total Tokens: 119\n",
      "Loss: 1.9023672342300415\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 909, Loss: 1.9023672342300415\n",
      "Running Batch 910, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.872959852218628\n",
      "Running Batch 911, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.8704848289489746\n",
      "Running Batch 912, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.0220437049865723\n",
      "Running Batch 913, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.8960025310516357\n",
      "Running Batch 914, Epoch 1, Total Tokens: 158\n",
      "Loss: 2.0778088569641113\n",
      "Running Batch 915, Epoch 1, Total Tokens: 220\n",
      "Loss: 1.9211461544036865\n",
      "Running Batch 916, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9859566688537598\n",
      "Running Batch 917, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.8837848901748657\n",
      "Running Batch 918, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9090771675109863\n",
      "Running Batch 919, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9514583349227905\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 919, Loss: 1.9514583349227905\n",
      "Running Batch 920, Epoch 1, Total Tokens: 452\n",
      "Loss: 2.083503484725952\n",
      "Running Batch 921, Epoch 1, Total Tokens: 190\n",
      "Loss: 1.9564368724822998\n",
      "Running Batch 922, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9651752710342407\n",
      "Running Batch 923, Epoch 1, Total Tokens: 131\n",
      "Loss: 2.0245437622070312\n",
      "Running Batch 924, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8593729734420776\n",
      "Running Batch 925, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.8803093433380127\n",
      "Running Batch 926, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.9556529521942139\n",
      "Running Batch 927, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9054434299468994\n",
      "Running Batch 928, Epoch 1, Total Tokens: 223\n",
      "Loss: 1.8295612335205078\n",
      "Running Batch 929, Epoch 1, Total Tokens: 288\n",
      "Loss: 2.007603168487549\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 929, Loss: 2.007603168487549\n",
      "Running Batch 930, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8085429668426514\n",
      "Running Batch 931, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9830565452575684\n",
      "Running Batch 932, Epoch 1, Total Tokens: 103\n",
      "Loss: 1.953741431236267\n",
      "Running Batch 933, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.8796534538269043\n",
      "Running Batch 934, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.906821846961975\n",
      "Running Batch 935, Epoch 1, Total Tokens: 164\n",
      "Loss: 1.8619884252548218\n",
      "Running Batch 936, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.965617060661316\n",
      "Running Batch 937, Epoch 1, Total Tokens: 149\n",
      "Loss: 2.013223648071289\n",
      "Running Batch 938, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.8985971212387085\n",
      "Running Batch 939, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.85642409324646\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 939, Loss: 1.85642409324646\n",
      "Running Batch 940, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9058185815811157\n",
      "Running Batch 941, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.846834421157837\n",
      "Running Batch 942, Epoch 1, Total Tokens: 183\n",
      "Loss: 1.9516377449035645\n",
      "Running Batch 943, Epoch 1, Total Tokens: 191\n",
      "Loss: 1.8900225162506104\n",
      "Running Batch 944, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.8351852893829346\n",
      "Running Batch 945, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.9280813932418823\n",
      "Running Batch 946, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.9417580366134644\n",
      "Running Batch 947, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.9655691385269165\n",
      "Running Batch 948, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8926161527633667\n",
      "Running Batch 949, Epoch 1, Total Tokens: 127\n",
      "Loss: 1.900526523590088\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 949, Loss: 1.900526523590088\n",
      "Running Batch 950, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.8093993663787842\n",
      "Running Batch 951, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.914695382118225\n",
      "Running Batch 952, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.8787728548049927\n",
      "Running Batch 953, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.9534622430801392\n",
      "Running Batch 954, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9205843210220337\n",
      "Running Batch 955, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.8434085845947266\n",
      "Running Batch 956, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8927719593048096\n",
      "Running Batch 957, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.8699790239334106\n",
      "Running Batch 958, Epoch 1, Total Tokens: 179\n",
      "Loss: 1.895050287246704\n",
      "Running Batch 959, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.876431941986084\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 959, Loss: 1.876431941986084\n",
      "Running Batch 960, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8698090314865112\n",
      "Running Batch 961, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.8788139820098877\n",
      "Running Batch 962, Epoch 1, Total Tokens: 205\n",
      "Loss: 1.9191378355026245\n",
      "Running Batch 963, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.8734729290008545\n",
      "Running Batch 964, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9324767589569092\n",
      "Running Batch 965, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9780081510543823\n",
      "Running Batch 966, Epoch 1, Total Tokens: 128\n",
      "Loss: 2.034496545791626\n",
      "Running Batch 967, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.9339852333068848\n",
      "Running Batch 968, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.9240639209747314\n",
      "Running Batch 969, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9071755409240723\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 969, Loss: 1.9071755409240723\n",
      "Running Batch 970, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.91655695438385\n",
      "Running Batch 971, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.9860882759094238\n",
      "Running Batch 972, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9117156267166138\n",
      "Running Batch 973, Epoch 1, Total Tokens: 188\n",
      "Loss: 1.8928213119506836\n",
      "Running Batch 974, Epoch 1, Total Tokens: 124\n",
      "Loss: 1.923438310623169\n",
      "Running Batch 975, Epoch 1, Total Tokens: 132\n",
      "Loss: 2.0258007049560547\n",
      "Running Batch 976, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.920492172241211\n",
      "Running Batch 977, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.9528868198394775\n",
      "Running Batch 978, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.968969702720642\n",
      "Running Batch 979, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8505576848983765\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 979, Loss: 1.8505576848983765\n",
      "Running Batch 980, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9069995880126953\n",
      "Running Batch 981, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9125336408615112\n",
      "Running Batch 982, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9512977600097656\n",
      "Running Batch 983, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8753293752670288\n",
      "Running Batch 984, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.907899260520935\n",
      "Running Batch 985, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.9786916971206665\n",
      "Running Batch 986, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8326830863952637\n",
      "Running Batch 987, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8108407258987427\n",
      "Running Batch 988, Epoch 1, Total Tokens: 225\n",
      "Loss: 2.015774726867676\n",
      "Running Batch 989, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9156558513641357\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 989, Loss: 1.9156558513641357\n",
      "Running Batch 990, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.8755229711532593\n",
      "Running Batch 991, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.8970061540603638\n",
      "Running Batch 992, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.9271692037582397\n",
      "Running Batch 993, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.9636216163635254\n",
      "Running Batch 994, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.8895407915115356\n",
      "Running Batch 995, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.901908278465271\n",
      "Running Batch 996, Epoch 1, Total Tokens: 153\n",
      "Loss: 2.04634690284729\n",
      "Running Batch 997, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.901914358139038\n",
      "Running Batch 998, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.924804449081421\n",
      "Running Batch 999, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.9620392322540283\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 999, Loss: 1.9620392322540283\n",
      "Running Batch 1000, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9166297912597656\n",
      "Running Batch 1001, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.872894525527954\n",
      "Running Batch 1002, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.93478262424469\n",
      "Running Batch 1003, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.9729785919189453\n",
      "Running Batch 1004, Epoch 1, Total Tokens: 494\n",
      "Loss: 1.6585259437561035\n",
      "Running Batch 1005, Epoch 1, Total Tokens: 266\n",
      "Loss: 1.8491878509521484\n",
      "Running Batch 1006, Epoch 1, Total Tokens: 201\n",
      "Loss: 1.8766684532165527\n",
      "Running Batch 1007, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.954468846321106\n",
      "Running Batch 1008, Epoch 1, Total Tokens: 187\n",
      "Loss: 1.959494709968567\n",
      "Running Batch 1009, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9320968389511108\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1009, Loss: 1.9320968389511108\n",
      "Running Batch 1010, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.9106645584106445\n",
      "Running Batch 1011, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9178941249847412\n",
      "Running Batch 1012, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.872458577156067\n",
      "Running Batch 1013, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.867134690284729\n",
      "Running Batch 1014, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.92621910572052\n",
      "Running Batch 1015, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9451706409454346\n",
      "Running Batch 1016, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9295275211334229\n",
      "Running Batch 1017, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.805619478225708\n",
      "Running Batch 1018, Epoch 1, Total Tokens: 120\n",
      "Loss: 1.8654171228408813\n",
      "Running Batch 1019, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.936033010482788\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1019, Loss: 1.936033010482788\n",
      "Running Batch 1020, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.8740228414535522\n",
      "Running Batch 1021, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.9057385921478271\n",
      "Running Batch 1022, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9190168380737305\n",
      "Running Batch 1023, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.973726749420166\n",
      "Running Batch 1024, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.8679203987121582\n",
      "Running Batch 1025, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.8721377849578857\n",
      "Running Batch 1026, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.8921481370925903\n",
      "Running Batch 1027, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.8077828884124756\n",
      "Running Batch 1028, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8600221872329712\n",
      "Running Batch 1029, Epoch 1, Total Tokens: 296\n",
      "Loss: 1.827257752418518\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1029, Loss: 1.827257752418518\n",
      "Running Batch 1030, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.8897942304611206\n",
      "Running Batch 1031, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.8584072589874268\n",
      "Running Batch 1032, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.8397382497787476\n",
      "Running Batch 1033, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.89588463306427\n",
      "Running Batch 1034, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.8984941244125366\n",
      "Running Batch 1035, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.945244550704956\n",
      "Running Batch 1036, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9027788639068604\n",
      "Running Batch 1037, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.9236081838607788\n",
      "Running Batch 1038, Epoch 1, Total Tokens: 160\n",
      "Loss: 1.93070650100708\n",
      "Running Batch 1039, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.9303531646728516\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1039, Loss: 1.9303531646728516\n",
      "Running Batch 1040, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8998181819915771\n",
      "Running Batch 1041, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9106590747833252\n",
      "Running Batch 1042, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9141440391540527\n",
      "Running Batch 1043, Epoch 1, Total Tokens: 108\n",
      "Loss: 1.899367332458496\n",
      "Running Batch 1044, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9480561017990112\n",
      "Running Batch 1045, Epoch 1, Total Tokens: 172\n",
      "Loss: 1.8891292810440063\n",
      "Running Batch 1046, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9050878286361694\n",
      "Running Batch 1047, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.9839262962341309\n",
      "Running Batch 1048, Epoch 1, Total Tokens: 166\n",
      "Loss: 1.853871464729309\n",
      "Running Batch 1049, Epoch 1, Total Tokens: 146\n",
      "Loss: 1.8892130851745605\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1049, Loss: 1.8892130851745605\n",
      "Running Batch 1050, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.804770827293396\n",
      "Running Batch 1051, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.877621054649353\n",
      "Running Batch 1052, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.96035897731781\n",
      "Running Batch 1053, Epoch 1, Total Tokens: 428\n",
      "Loss: 1.810211181640625\n",
      "Running Batch 1054, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.7804453372955322\n",
      "Running Batch 1055, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.907467246055603\n",
      "Running Batch 1056, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.8021200895309448\n",
      "Running Batch 1057, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.8958756923675537\n",
      "Running Batch 1058, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9609849452972412\n",
      "Running Batch 1059, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9995512962341309\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1059, Loss: 1.9995512962341309\n",
      "Running Batch 1060, Epoch 1, Total Tokens: 112\n",
      "Loss: 1.869560956954956\n",
      "Running Batch 1061, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.905748963356018\n",
      "Running Batch 1062, Epoch 1, Total Tokens: 132\n",
      "Loss: 1.8963512182235718\n",
      "Running Batch 1063, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.9122532606124878\n",
      "Running Batch 1064, Epoch 1, Total Tokens: 195\n",
      "Loss: 1.9462385177612305\n",
      "Running Batch 1065, Epoch 1, Total Tokens: 361\n",
      "Loss: 1.9647560119628906\n",
      "Running Batch 1066, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.8970372676849365\n",
      "Running Batch 1067, Epoch 1, Total Tokens: 113\n",
      "Loss: 1.8268113136291504\n",
      "Running Batch 1068, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.9187501668930054\n",
      "Running Batch 1069, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.947197675704956\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1069, Loss: 1.947197675704956\n",
      "Running Batch 1070, Epoch 1, Total Tokens: 193\n",
      "Loss: 1.933609127998352\n",
      "Running Batch 1071, Epoch 1, Total Tokens: 181\n",
      "Loss: 1.897445797920227\n",
      "Running Batch 1072, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.9774754047393799\n",
      "Running Batch 1073, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.9580615758895874\n",
      "Running Batch 1074, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9480633735656738\n",
      "Running Batch 1075, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.8883200883865356\n",
      "Running Batch 1076, Epoch 1, Total Tokens: 299\n",
      "Loss: 1.895358920097351\n",
      "Running Batch 1077, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.8889497518539429\n",
      "Running Batch 1078, Epoch 1, Total Tokens: 224\n",
      "Loss: 1.9022859334945679\n",
      "Running Batch 1079, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.912684679031372\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1079, Loss: 1.912684679031372\n",
      "Running Batch 1080, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.8336334228515625\n",
      "Running Batch 1081, Epoch 1, Total Tokens: 284\n",
      "Loss: 1.9495302438735962\n",
      "Running Batch 1082, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.924172282218933\n",
      "Running Batch 1083, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.936232566833496\n",
      "Running Batch 1084, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.9644949436187744\n",
      "Running Batch 1085, Epoch 1, Total Tokens: 140\n",
      "Loss: 1.8485835790634155\n",
      "Running Batch 1086, Epoch 1, Total Tokens: 145\n",
      "Loss: 1.7986053228378296\n",
      "Running Batch 1087, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.839125394821167\n",
      "Running Batch 1088, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.9121367931365967\n",
      "Running Batch 1089, Epoch 1, Total Tokens: 125\n",
      "Loss: 1.9252890348434448\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1089, Loss: 1.9252890348434448\n",
      "Running Batch 1090, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.865377426147461\n",
      "Running Batch 1091, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8835904598236084\n",
      "Running Batch 1092, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.7999320030212402\n",
      "Running Batch 1093, Epoch 1, Total Tokens: 258\n",
      "Loss: 1.909744143486023\n",
      "Running Batch 1094, Epoch 1, Total Tokens: 152\n",
      "Loss: 1.8838813304901123\n",
      "Running Batch 1095, Epoch 1, Total Tokens: 135\n",
      "Loss: 2.0081658363342285\n",
      "Running Batch 1096, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.9346493482589722\n",
      "Running Batch 1097, Epoch 1, Total Tokens: 192\n",
      "Loss: 1.9349479675292969\n",
      "Running Batch 1098, Epoch 1, Total Tokens: 118\n",
      "Loss: 1.9468941688537598\n",
      "Running Batch 1099, Epoch 1, Total Tokens: 170\n",
      "Loss: 1.886117935180664\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1099, Loss: 1.886117935180664\n",
      "Running Batch 1100, Epoch 1, Total Tokens: 135\n",
      "Loss: 1.8508985042572021\n",
      "Running Batch 1101, Epoch 1, Total Tokens: 129\n",
      "Loss: 1.9198369979858398\n",
      "Running Batch 1102, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.942041039466858\n",
      "Running Batch 1103, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.9621083736419678\n",
      "Running Batch 1104, Epoch 1, Total Tokens: 133\n",
      "Loss: 1.9175732135772705\n",
      "Running Batch 1105, Epoch 1, Total Tokens: 122\n",
      "Loss: 1.8502812385559082\n",
      "Running Batch 1106, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.8441417217254639\n",
      "Running Batch 1107, Epoch 1, Total Tokens: 178\n",
      "Loss: 1.8662693500518799\n",
      "Running Batch 1108, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.9647443294525146\n",
      "Running Batch 1109, Epoch 1, Total Tokens: 109\n",
      "Loss: 1.9128090143203735\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1109, Loss: 1.9128090143203735\n",
      "Running Batch 1110, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.925149917602539\n",
      "Running Batch 1111, Epoch 1, Total Tokens: 418\n",
      "Loss: 1.929638385772705\n",
      "Running Batch 1112, Epoch 1, Total Tokens: 236\n",
      "Loss: 1.8479266166687012\n",
      "Running Batch 1113, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.908571481704712\n",
      "Running Batch 1114, Epoch 1, Total Tokens: 142\n",
      "Loss: 1.9454494714736938\n",
      "Running Batch 1115, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.9614566564559937\n",
      "Running Batch 1116, Epoch 1, Total Tokens: 148\n",
      "Loss: 1.8898528814315796\n",
      "Running Batch 1117, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.899639368057251\n",
      "Running Batch 1118, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.8188369274139404\n",
      "Running Batch 1119, Epoch 1, Total Tokens: 151\n",
      "Loss: 1.8321270942687988\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1119, Loss: 1.8321270942687988\n",
      "Running Batch 1120, Epoch 1, Total Tokens: 130\n",
      "Loss: 1.8032194375991821\n",
      "Running Batch 1121, Epoch 1, Total Tokens: 351\n",
      "Loss: 1.8985981941223145\n",
      "Running Batch 1122, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.956642508506775\n",
      "Running Batch 1123, Epoch 1, Total Tokens: 136\n",
      "Loss: 1.7986730337142944\n",
      "Running Batch 1124, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.8832125663757324\n",
      "Running Batch 1125, Epoch 1, Total Tokens: 115\n",
      "Loss: 1.8952269554138184\n",
      "Running Batch 1126, Epoch 1, Total Tokens: 171\n",
      "Loss: 1.9251753091812134\n",
      "Running Batch 1127, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.963133454322815\n",
      "Running Batch 1128, Epoch 1, Total Tokens: 173\n",
      "Loss: 1.8839898109436035\n",
      "Running Batch 1129, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.898849606513977\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1129, Loss: 1.898849606513977\n",
      "Running Batch 1130, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.9078155755996704\n",
      "Running Batch 1131, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.8675611019134521\n",
      "Running Batch 1132, Epoch 1, Total Tokens: 104\n",
      "Loss: 1.8650071620941162\n",
      "Running Batch 1133, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.8704534769058228\n",
      "Running Batch 1134, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.8721201419830322\n",
      "Running Batch 1135, Epoch 1, Total Tokens: 131\n",
      "Loss: 1.9297422170639038\n",
      "Running Batch 1136, Epoch 1, Total Tokens: 134\n",
      "Loss: 1.8853895664215088\n",
      "Running Batch 1137, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.8311285972595215\n",
      "Running Batch 1138, Epoch 1, Total Tokens: 174\n",
      "Loss: 1.8788282871246338\n",
      "Running Batch 1139, Epoch 1, Total Tokens: 155\n",
      "Loss: 1.7986928224563599\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1139, Loss: 1.7986928224563599\n",
      "Running Batch 1140, Epoch 1, Total Tokens: 199\n",
      "Loss: 1.9284411668777466\n",
      "Running Batch 1141, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.8382245302200317\n",
      "Running Batch 1142, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.824813723564148\n",
      "Running Batch 1143, Epoch 1, Total Tokens: 196\n",
      "Loss: 1.8656041622161865\n",
      "Running Batch 1144, Epoch 1, Total Tokens: 149\n",
      "Loss: 1.894402265548706\n",
      "Running Batch 1145, Epoch 1, Total Tokens: 121\n",
      "Loss: 1.9882621765136719\n",
      "Running Batch 1146, Epoch 1, Total Tokens: 139\n",
      "Loss: 1.9467017650604248\n",
      "Running Batch 1147, Epoch 1, Total Tokens: 128\n",
      "Loss: 1.891097903251648\n",
      "Running Batch 1148, Epoch 1, Total Tokens: 116\n",
      "Loss: 1.89626944065094\n",
      "Running Batch 1149, Epoch 1, Total Tokens: 141\n",
      "Loss: 1.863040804862976\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1149, Loss: 1.863040804862976\n",
      "Running Batch 1150, Epoch 1, Total Tokens: 158\n",
      "Loss: 1.8125255107879639\n",
      "Running Batch 1151, Epoch 1, Total Tokens: 117\n",
      "Loss: 1.9218528270721436\n",
      "Running Batch 1152, Epoch 1, Total Tokens: 144\n",
      "Loss: 1.9635159969329834\n",
      "Running Batch 1153, Epoch 1, Total Tokens: 176\n",
      "Loss: 1.836714506149292\n",
      "Running Batch 1154, Epoch 1, Total Tokens: 169\n",
      "Loss: 1.920546531677246\n",
      "Running Batch 1155, Epoch 1, Total Tokens: 293\n",
      "Loss: 1.907138705253601\n",
      "Running Batch 1156, Epoch 1, Total Tokens: 153\n",
      "Loss: 1.9463874101638794\n",
      "Running Batch 1157, Epoch 1, Total Tokens: 231\n",
      "Loss: 2.027883529663086\n",
      "Running Batch 1158, Epoch 1, Total Tokens: 156\n",
      "Loss: 1.8869699239730835\n",
      "Running Batch 1159, Epoch 1, Total Tokens: 137\n",
      "Loss: 1.780741810798645\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1159, Loss: 1.780741810798645\n",
      "Running Batch 1160, Epoch 1, Total Tokens: 126\n",
      "Loss: 1.9342817068099976\n",
      "Running Batch 1161, Epoch 1, Total Tokens: 150\n",
      "Loss: 1.8935638666152954\n",
      "Running Batch 1162, Epoch 1, Total Tokens: 162\n",
      "Loss: 1.9057761430740356\n",
      "Running Batch 1163, Epoch 1, Total Tokens: 360\n",
      "Loss: 1.9257946014404297\n",
      "Running Batch 1164, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.96245539188385\n",
      "Running Batch 1165, Epoch 1, Total Tokens: 154\n",
      "Loss: 1.883114218711853\n",
      "Running Batch 1166, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9121440649032593\n",
      "Running Batch 1167, Epoch 1, Total Tokens: 143\n",
      "Loss: 1.8553069829940796\n",
      "Running Batch 1168, Epoch 1, Total Tokens: 165\n",
      "Loss: 1.9106879234313965\n",
      "Running Batch 1169, Epoch 1, Total Tokens: 299\n",
      "Loss: 1.897569179534912\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 1, Batch: 1169, Loss: 1.897569179534912\n",
      "Running Batch 1170, Epoch 1, Total Tokens: 138\n",
      "Loss: 1.842867136001587\n",
      "Running Batch 1171, Epoch 1, Total Tokens: 147\n",
      "Loss: 1.9778834581375122\n",
      "AVG LOSS: 1.9693494891754189, Epoch: 2\n",
      "Running Batch 0, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.956751823425293\n",
      "Running Batch 1, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.9211875200271606\n",
      "Running Batch 2, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.9084560871124268\n",
      "Running Batch 3, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.892642617225647\n",
      "Running Batch 4, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.868751049041748\n",
      "Running Batch 5, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8150784969329834\n",
      "Running Batch 6, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.8584874868392944\n",
      "Running Batch 7, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.934139370918274\n",
      "Running Batch 8, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8206102848052979\n",
      "Running Batch 9, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8781136274337769\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 9, Loss: 1.8781136274337769\n",
      "Running Batch 10, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8175151348114014\n",
      "Running Batch 11, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7820017337799072\n",
      "Running Batch 12, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8869283199310303\n",
      "Running Batch 13, Epoch 2, Total Tokens: 175\n",
      "Loss: 1.8337185382843018\n",
      "Running Batch 14, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7908639907836914\n",
      "Running Batch 15, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.9999196529388428\n",
      "Running Batch 16, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8303687572479248\n",
      "Running Batch 17, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.8111381530761719\n",
      "Running Batch 18, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8722585439682007\n",
      "Running Batch 19, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.833878755569458\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 19, Loss: 1.833878755569458\n",
      "Running Batch 20, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.8850562572479248\n",
      "Running Batch 21, Epoch 2, Total Tokens: 418\n",
      "Loss: 1.7398966550827026\n",
      "Running Batch 22, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8282177448272705\n",
      "Running Batch 23, Epoch 2, Total Tokens: 273\n",
      "Loss: 1.9410536289215088\n",
      "Running Batch 24, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.805779218673706\n",
      "Running Batch 25, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8514161109924316\n",
      "Running Batch 26, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.9396109580993652\n",
      "Running Batch 27, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.9033832550048828\n",
      "Running Batch 28, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8213622570037842\n",
      "Running Batch 29, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.7945719957351685\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 29, Loss: 1.7945719957351685\n",
      "Running Batch 30, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.909442663192749\n",
      "Running Batch 31, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.9238784313201904\n",
      "Running Batch 32, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.944139003753662\n",
      "Running Batch 33, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.9139182567596436\n",
      "Running Batch 34, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.897889256477356\n",
      "Running Batch 35, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.906398892402649\n",
      "Running Batch 36, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.915652871131897\n",
      "Running Batch 37, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.841482162475586\n",
      "Running Batch 38, Epoch 2, Total Tokens: 267\n",
      "Loss: 1.8647428750991821\n",
      "Running Batch 39, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.8857275247573853\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 39, Loss: 1.8857275247573853\n",
      "Running Batch 40, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.92689847946167\n",
      "Running Batch 41, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8041515350341797\n",
      "Running Batch 42, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.8456851243972778\n",
      "Running Batch 43, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.9211305379867554\n",
      "Running Batch 44, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8396180868148804\n",
      "Running Batch 45, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.8670363426208496\n",
      "Running Batch 46, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8481773138046265\n",
      "Running Batch 47, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.769662618637085\n",
      "Running Batch 48, Epoch 2, Total Tokens: 322\n",
      "Loss: 1.7803947925567627\n",
      "Running Batch 49, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8770350217819214\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 49, Loss: 1.8770350217819214\n",
      "Running Batch 50, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.850485920906067\n",
      "Running Batch 51, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7654083967208862\n",
      "Running Batch 52, Epoch 2, Total Tokens: 201\n",
      "Loss: 1.7604900598526\n",
      "Running Batch 53, Epoch 2, Total Tokens: 192\n",
      "Loss: 1.8435661792755127\n",
      "Running Batch 54, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.9195506572723389\n",
      "Running Batch 55, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.884106159210205\n",
      "Running Batch 56, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8968147039413452\n",
      "Running Batch 57, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8573379516601562\n",
      "Running Batch 58, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.8436518907546997\n",
      "Running Batch 59, Epoch 2, Total Tokens: 138\n",
      "Loss: 2.0131022930145264\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 59, Loss: 2.0131022930145264\n",
      "Running Batch 60, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.832101583480835\n",
      "Running Batch 61, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8682469129562378\n",
      "Running Batch 62, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.8720194101333618\n",
      "Running Batch 63, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.9305509328842163\n",
      "Running Batch 64, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.9412267208099365\n",
      "Running Batch 65, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8879987001419067\n",
      "Running Batch 66, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.888132095336914\n",
      "Running Batch 67, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.9203572273254395\n",
      "Running Batch 68, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.908216118812561\n",
      "Running Batch 69, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8599010705947876\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 69, Loss: 1.8599010705947876\n",
      "Running Batch 70, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.8334604501724243\n",
      "Running Batch 71, Epoch 2, Total Tokens: 177\n",
      "Loss: 1.8727755546569824\n",
      "Running Batch 72, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.9685235023498535\n",
      "Running Batch 73, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.9449527263641357\n",
      "Running Batch 74, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8387030363082886\n",
      "Running Batch 75, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8216274976730347\n",
      "Running Batch 76, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.9693843126296997\n",
      "Running Batch 77, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.9214439392089844\n",
      "Running Batch 78, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8508625030517578\n",
      "Running Batch 79, Epoch 2, Total Tokens: 237\n",
      "Loss: 1.8026108741760254\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 79, Loss: 1.8026108741760254\n",
      "Running Batch 80, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.9866563081741333\n",
      "Running Batch 81, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8898676633834839\n",
      "Running Batch 82, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.9143588542938232\n",
      "Running Batch 83, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8326598405838013\n",
      "Running Batch 84, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.7592192888259888\n",
      "Running Batch 85, Epoch 2, Total Tokens: 217\n",
      "Loss: 1.8353760242462158\n",
      "Running Batch 86, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.743300437927246\n",
      "Running Batch 87, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.851879358291626\n",
      "Running Batch 88, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.924792766571045\n",
      "Running Batch 89, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.9345463514328003\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 89, Loss: 1.9345463514328003\n",
      "Running Batch 90, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8250343799591064\n",
      "Running Batch 91, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8720221519470215\n",
      "Running Batch 92, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8713315725326538\n",
      "Running Batch 93, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.7900949716567993\n",
      "Running Batch 94, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8424797058105469\n",
      "Running Batch 95, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.9543064832687378\n",
      "Running Batch 96, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.8993269205093384\n",
      "Running Batch 97, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.9241389036178589\n",
      "Running Batch 98, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8765450716018677\n",
      "Running Batch 99, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8070876598358154\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 99, Loss: 1.8070876598358154\n",
      "Running Batch 100, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.835862398147583\n",
      "Running Batch 101, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.9326467514038086\n",
      "Running Batch 102, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.833825707435608\n",
      "Running Batch 103, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.9946943521499634\n",
      "Running Batch 104, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8895697593688965\n",
      "Running Batch 105, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.8364211320877075\n",
      "Running Batch 106, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8760230541229248\n",
      "Running Batch 107, Epoch 2, Total Tokens: 210\n",
      "Loss: 1.7463819980621338\n",
      "Running Batch 108, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8337442874908447\n",
      "Running Batch 109, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.7647565603256226\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 109, Loss: 1.7647565603256226\n",
      "Running Batch 110, Epoch 2, Total Tokens: 110\n",
      "Loss: 1.9612880945205688\n",
      "Running Batch 111, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8039194345474243\n",
      "Running Batch 112, Epoch 2, Total Tokens: 367\n",
      "Loss: 1.858775019645691\n",
      "Running Batch 113, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.9042003154754639\n",
      "Running Batch 114, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8787691593170166\n",
      "Running Batch 115, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8328346014022827\n",
      "Running Batch 116, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.9285855293273926\n",
      "Running Batch 117, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.915402889251709\n",
      "Running Batch 118, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.8188068866729736\n",
      "Running Batch 119, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8186644315719604\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 119, Loss: 1.8186644315719604\n",
      "Running Batch 120, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.9321385622024536\n",
      "Running Batch 121, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8748584985733032\n",
      "Running Batch 122, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.8694201707839966\n",
      "Running Batch 123, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.9100031852722168\n",
      "Running Batch 124, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8946306705474854\n",
      "Running Batch 125, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.797159194946289\n",
      "Running Batch 126, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8921509981155396\n",
      "Running Batch 127, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.918610692024231\n",
      "Running Batch 128, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8324084281921387\n",
      "Running Batch 129, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8847576379776\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 129, Loss: 1.8847576379776\n",
      "Running Batch 130, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.9029184579849243\n",
      "Running Batch 131, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.86165452003479\n",
      "Running Batch 132, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.839169979095459\n",
      "Running Batch 133, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8692373037338257\n",
      "Running Batch 134, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.9072654247283936\n",
      "Running Batch 135, Epoch 2, Total Tokens: 244\n",
      "Loss: 1.8198086023330688\n",
      "Running Batch 136, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.838584303855896\n",
      "Running Batch 137, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.787716269493103\n",
      "Running Batch 138, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.766087532043457\n",
      "Running Batch 139, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8106355667114258\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 139, Loss: 1.8106355667114258\n",
      "Running Batch 140, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8392401933670044\n",
      "Running Batch 141, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8221122026443481\n",
      "Running Batch 142, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8334475755691528\n",
      "Running Batch 143, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.880427598953247\n",
      "Running Batch 144, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8212394714355469\n",
      "Running Batch 145, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.9095114469528198\n",
      "Running Batch 146, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.9015114307403564\n",
      "Running Batch 147, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.95732843875885\n",
      "Running Batch 148, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.9658528566360474\n",
      "Running Batch 149, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7766282558441162\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 149, Loss: 1.7766282558441162\n",
      "Running Batch 150, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8638556003570557\n",
      "Running Batch 151, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8957453966140747\n",
      "Running Batch 152, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.8605018854141235\n",
      "Running Batch 153, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8023884296417236\n",
      "Running Batch 154, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8423782587051392\n",
      "Running Batch 155, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.831703543663025\n",
      "Running Batch 156, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.9379487037658691\n",
      "Running Batch 157, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8790903091430664\n",
      "Running Batch 158, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.8045631647109985\n",
      "Running Batch 159, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.803362488746643\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 159, Loss: 1.803362488746643\n",
      "Running Batch 160, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8859444856643677\n",
      "Running Batch 161, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.8705151081085205\n",
      "Running Batch 162, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.782413363456726\n",
      "Running Batch 163, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8197499513626099\n",
      "Running Batch 164, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.8387380838394165\n",
      "Running Batch 165, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8034980297088623\n",
      "Running Batch 166, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.9022865295410156\n",
      "Running Batch 167, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.9484049081802368\n",
      "Running Batch 168, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.9253268241882324\n",
      "Running Batch 169, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8823118209838867\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 169, Loss: 1.8823118209838867\n",
      "Running Batch 170, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.8530609607696533\n",
      "Running Batch 171, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8635541200637817\n",
      "Running Batch 172, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8930988311767578\n",
      "Running Batch 173, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.8664429187774658\n",
      "Running Batch 174, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.795196294784546\n",
      "Running Batch 175, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8975398540496826\n",
      "Running Batch 176, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.8221240043640137\n",
      "Running Batch 177, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8096109628677368\n",
      "Running Batch 178, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.9382785558700562\n",
      "Running Batch 179, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.8514271974563599\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 179, Loss: 1.8514271974563599\n",
      "Running Batch 180, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.856823444366455\n",
      "Running Batch 181, Epoch 2, Total Tokens: 219\n",
      "Loss: 1.7642210721969604\n",
      "Running Batch 182, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.7261141538619995\n",
      "Running Batch 183, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.871683120727539\n",
      "Running Batch 184, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.8140045404434204\n",
      "Running Batch 185, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.9430838823318481\n",
      "Running Batch 186, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.7828783988952637\n",
      "Running Batch 187, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.8527053594589233\n",
      "Running Batch 188, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.9287928342819214\n",
      "Running Batch 189, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.869524359703064\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 189, Loss: 1.869524359703064\n",
      "Running Batch 190, Epoch 2, Total Tokens: 191\n",
      "Loss: 1.8419400453567505\n",
      "Running Batch 191, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.81295645236969\n",
      "Running Batch 192, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.8903119564056396\n",
      "Running Batch 193, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.8828872442245483\n",
      "Running Batch 194, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8024872541427612\n",
      "Running Batch 195, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.802565574645996\n",
      "Running Batch 196, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7732678651809692\n",
      "Running Batch 197, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.7604819536209106\n",
      "Running Batch 198, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8221898078918457\n",
      "Running Batch 199, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.8579626083374023\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 199, Loss: 1.8579626083374023\n",
      "Running Batch 200, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8699429035186768\n",
      "Running Batch 201, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.850586175918579\n",
      "Running Batch 202, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7632498741149902\n",
      "Running Batch 203, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7952553033828735\n",
      "Running Batch 204, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7976980209350586\n",
      "Running Batch 205, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7864303588867188\n",
      "Running Batch 206, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8218700885772705\n",
      "Running Batch 207, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.7953953742980957\n",
      "Running Batch 208, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8499127626419067\n",
      "Running Batch 209, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.827430248260498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 209, Loss: 1.827430248260498\n",
      "Running Batch 210, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.8553130626678467\n",
      "Running Batch 211, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.8966741561889648\n",
      "Running Batch 212, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.9096755981445312\n",
      "Running Batch 213, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.9130234718322754\n",
      "Running Batch 214, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.8015352487564087\n",
      "Running Batch 215, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.839139461517334\n",
      "Running Batch 216, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8034921884536743\n",
      "Running Batch 217, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8078380823135376\n",
      "Running Batch 218, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8160496950149536\n",
      "Running Batch 219, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8169974088668823\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 219, Loss: 1.8169974088668823\n",
      "Running Batch 220, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8772263526916504\n",
      "Running Batch 221, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.8788007497787476\n",
      "Running Batch 222, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.835145354270935\n",
      "Running Batch 223, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8747940063476562\n",
      "Running Batch 224, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.7469676733016968\n",
      "Running Batch 225, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8851346969604492\n",
      "Running Batch 226, Epoch 2, Total Tokens: 452\n",
      "Loss: 1.9170809984207153\n",
      "Running Batch 227, Epoch 2, Total Tokens: 186\n",
      "Loss: 1.8671395778656006\n",
      "Running Batch 228, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8974337577819824\n",
      "Running Batch 229, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8510655164718628\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 229, Loss: 1.8510655164718628\n",
      "Running Batch 230, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7706245183944702\n",
      "Running Batch 231, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7624794244766235\n",
      "Running Batch 232, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8304743766784668\n",
      "Running Batch 233, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8097474575042725\n",
      "Running Batch 234, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.7406818866729736\n",
      "Running Batch 235, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8096766471862793\n",
      "Running Batch 236, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8884979486465454\n",
      "Running Batch 237, Epoch 2, Total Tokens: 527\n",
      "Loss: 1.8903374671936035\n",
      "Running Batch 238, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.926051139831543\n",
      "Running Batch 239, Epoch 2, Total Tokens: 184\n",
      "Loss: 1.8302571773529053\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 239, Loss: 1.8302571773529053\n",
      "Running Batch 240, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7931809425354004\n",
      "Running Batch 241, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8667359352111816\n",
      "Running Batch 242, Epoch 2, Total Tokens: 237\n",
      "Loss: 1.9197003841400146\n",
      "Running Batch 243, Epoch 2, Total Tokens: 105\n",
      "Loss: 1.819635033607483\n",
      "Running Batch 244, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7712961435317993\n",
      "Running Batch 245, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8447076082229614\n",
      "Running Batch 246, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.943131923675537\n",
      "Running Batch 247, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.8793578147888184\n",
      "Running Batch 248, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.869078278541565\n",
      "Running Batch 249, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8701890707015991\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 249, Loss: 1.8701890707015991\n",
      "Running Batch 250, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.89984929561615\n",
      "Running Batch 251, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.7714680433273315\n",
      "Running Batch 252, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8289955854415894\n",
      "Running Batch 253, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8732179403305054\n",
      "Running Batch 254, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.825125813484192\n",
      "Running Batch 255, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.9101426601409912\n",
      "Running Batch 256, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8461326360702515\n",
      "Running Batch 257, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.8577204942703247\n",
      "Running Batch 258, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8860867023468018\n",
      "Running Batch 259, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8389052152633667\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 259, Loss: 1.8389052152633667\n",
      "Running Batch 260, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8267015218734741\n",
      "Running Batch 261, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8983010053634644\n",
      "Running Batch 262, Epoch 2, Total Tokens: 221\n",
      "Loss: 1.7658780813217163\n",
      "Running Batch 263, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8132826089859009\n",
      "Running Batch 264, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.9319136142730713\n",
      "Running Batch 265, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.8197665214538574\n",
      "Running Batch 266, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8637795448303223\n",
      "Running Batch 267, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8419536352157593\n",
      "Running Batch 268, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.9201315641403198\n",
      "Running Batch 269, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.8035598993301392\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 269, Loss: 1.8035598993301392\n",
      "Running Batch 270, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.8133900165557861\n",
      "Running Batch 271, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8974415063858032\n",
      "Running Batch 272, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8774971961975098\n",
      "Running Batch 273, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.893895149230957\n",
      "Running Batch 274, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.888569951057434\n",
      "Running Batch 275, Epoch 2, Total Tokens: 281\n",
      "Loss: 1.8463729619979858\n",
      "Running Batch 276, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8497114181518555\n",
      "Running Batch 277, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.852565050125122\n",
      "Running Batch 278, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8308109045028687\n",
      "Running Batch 279, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.824393630027771\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 279, Loss: 1.824393630027771\n",
      "Running Batch 280, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.8597289323806763\n",
      "Running Batch 281, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8990468978881836\n",
      "Running Batch 282, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.84130859375\n",
      "Running Batch 283, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8227455615997314\n",
      "Running Batch 284, Epoch 2, Total Tokens: 195\n",
      "Loss: 1.8472319841384888\n",
      "Running Batch 285, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.8985538482666016\n",
      "Running Batch 286, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.9163175821304321\n",
      "Running Batch 287, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8992077112197876\n",
      "Running Batch 288, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7853153944015503\n",
      "Running Batch 289, Epoch 2, Total Tokens: 111\n",
      "Loss: 1.7780417203903198\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 289, Loss: 1.7780417203903198\n",
      "Running Batch 290, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7796810865402222\n",
      "Running Batch 291, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.9272572994232178\n",
      "Running Batch 292, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.7942333221435547\n",
      "Running Batch 293, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8687258958816528\n",
      "Running Batch 294, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8713536262512207\n",
      "Running Batch 295, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.8928437232971191\n",
      "Running Batch 296, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8415815830230713\n",
      "Running Batch 297, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8729121685028076\n",
      "Running Batch 298, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8376067876815796\n",
      "Running Batch 299, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8378278017044067\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 299, Loss: 1.8378278017044067\n",
      "Running Batch 300, Epoch 2, Total Tokens: 168\n",
      "Loss: 1.8182334899902344\n",
      "Running Batch 301, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8104811906814575\n",
      "Running Batch 302, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.83954656124115\n",
      "Running Batch 303, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.9318093061447144\n",
      "Running Batch 304, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7436351776123047\n",
      "Running Batch 305, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8767600059509277\n",
      "Running Batch 306, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.7628222703933716\n",
      "Running Batch 307, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8790768384933472\n",
      "Running Batch 308, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8344688415527344\n",
      "Running Batch 309, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7372528314590454\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 309, Loss: 1.7372528314590454\n",
      "Running Batch 310, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.7813129425048828\n",
      "Running Batch 311, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.9038575887680054\n",
      "Running Batch 312, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7950111627578735\n",
      "Running Batch 313, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.8312181234359741\n",
      "Running Batch 314, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.924095869064331\n",
      "Running Batch 315, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8398256301879883\n",
      "Running Batch 316, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8324825763702393\n",
      "Running Batch 317, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8270996809005737\n",
      "Running Batch 318, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.839643120765686\n",
      "Running Batch 319, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.85336434841156\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 319, Loss: 1.85336434841156\n",
      "Running Batch 320, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7959446907043457\n",
      "Running Batch 321, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.893190860748291\n",
      "Running Batch 322, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.7963008880615234\n",
      "Running Batch 323, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8976067304611206\n",
      "Running Batch 324, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7139546871185303\n",
      "Running Batch 325, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8320802450180054\n",
      "Running Batch 326, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8904246091842651\n",
      "Running Batch 327, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.9090349674224854\n",
      "Running Batch 328, Epoch 2, Total Tokens: 258\n",
      "Loss: 1.7716526985168457\n",
      "Running Batch 329, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8008252382278442\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 329, Loss: 1.8008252382278442\n",
      "Running Batch 330, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.819217324256897\n",
      "Running Batch 331, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8508996963500977\n",
      "Running Batch 332, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.876516580581665\n",
      "Running Batch 333, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.818260908126831\n",
      "Running Batch 334, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8387079238891602\n",
      "Running Batch 335, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.9251279830932617\n",
      "Running Batch 336, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.810777187347412\n",
      "Running Batch 337, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7365466356277466\n",
      "Running Batch 338, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8355422019958496\n",
      "Running Batch 339, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8268401622772217\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 339, Loss: 1.8268401622772217\n",
      "Running Batch 340, Epoch 2, Total Tokens: 192\n",
      "Loss: 1.7848353385925293\n",
      "Running Batch 341, Epoch 2, Total Tokens: 299\n",
      "Loss: 1.840844750404358\n",
      "Running Batch 342, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.888438105583191\n",
      "Running Batch 343, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.822234869003296\n",
      "Running Batch 344, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.9472092390060425\n",
      "Running Batch 345, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.76303231716156\n",
      "Running Batch 346, Epoch 2, Total Tokens: 179\n",
      "Loss: 1.8258893489837646\n",
      "Running Batch 347, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.8336135149002075\n",
      "Running Batch 348, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8588426113128662\n",
      "Running Batch 349, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8611191511154175\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 349, Loss: 1.8611191511154175\n",
      "Running Batch 350, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8798530101776123\n",
      "Running Batch 351, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8704270124435425\n",
      "Running Batch 352, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.9303480386734009\n",
      "Running Batch 353, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8490805625915527\n",
      "Running Batch 354, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7807847261428833\n",
      "Running Batch 355, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.917005181312561\n",
      "Running Batch 356, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7919062376022339\n",
      "Running Batch 357, Epoch 2, Total Tokens: 257\n",
      "Loss: 1.792657494544983\n",
      "Running Batch 358, Epoch 2, Total Tokens: 223\n",
      "Loss: 1.8868502378463745\n",
      "Running Batch 359, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8171526193618774\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 359, Loss: 1.8171526193618774\n",
      "Running Batch 360, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.9305826425552368\n",
      "Running Batch 361, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8894535303115845\n",
      "Running Batch 362, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.9208825826644897\n",
      "Running Batch 363, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.818914532661438\n",
      "Running Batch 364, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8223364353179932\n",
      "Running Batch 365, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.9211649894714355\n",
      "Running Batch 366, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8387113809585571\n",
      "Running Batch 367, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.9097856283187866\n",
      "Running Batch 368, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.9121359586715698\n",
      "Running Batch 369, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7688442468643188\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 369, Loss: 1.7688442468643188\n",
      "Running Batch 370, Epoch 2, Total Tokens: 231\n",
      "Loss: 1.8787583112716675\n",
      "Running Batch 371, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.874866247177124\n",
      "Running Batch 372, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.76260507106781\n",
      "Running Batch 373, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8403596878051758\n",
      "Running Batch 374, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8049836158752441\n",
      "Running Batch 375, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8395063877105713\n",
      "Running Batch 376, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.836584210395813\n",
      "Running Batch 377, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.8614380359649658\n",
      "Running Batch 378, Epoch 2, Total Tokens: 294\n",
      "Loss: 1.9216127395629883\n",
      "Running Batch 379, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.8091615438461304\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 379, Loss: 1.8091615438461304\n",
      "Running Batch 380, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8873814344406128\n",
      "Running Batch 381, Epoch 2, Total Tokens: 211\n",
      "Loss: 1.7677890062332153\n",
      "Running Batch 382, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8840250968933105\n",
      "Running Batch 383, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.815637469291687\n",
      "Running Batch 384, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8953014612197876\n",
      "Running Batch 385, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.7347939014434814\n",
      "Running Batch 386, Epoch 2, Total Tokens: 209\n",
      "Loss: 1.8212569952011108\n",
      "Running Batch 387, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.800737738609314\n",
      "Running Batch 388, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.9393749237060547\n",
      "Running Batch 389, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7566545009613037\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 389, Loss: 1.7566545009613037\n",
      "Running Batch 390, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.8508660793304443\n",
      "Running Batch 391, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8719584941864014\n",
      "Running Batch 392, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.792722463607788\n",
      "Running Batch 393, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8137611150741577\n",
      "Running Batch 394, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.7795400619506836\n",
      "Running Batch 395, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8375717401504517\n",
      "Running Batch 396, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8239173889160156\n",
      "Running Batch 397, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.845481038093567\n",
      "Running Batch 398, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8614263534545898\n",
      "Running Batch 399, Epoch 2, Total Tokens: 170\n",
      "Loss: 1.7634841203689575\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 399, Loss: 1.7634841203689575\n",
      "Running Batch 400, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.8062220811843872\n",
      "Running Batch 401, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8622491359710693\n",
      "Running Batch 402, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.8818176984786987\n",
      "Running Batch 403, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8032326698303223\n",
      "Running Batch 404, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7486385107040405\n",
      "Running Batch 405, Epoch 2, Total Tokens: 202\n",
      "Loss: 1.8879029750823975\n",
      "Running Batch 406, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7639890909194946\n",
      "Running Batch 407, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8945331573486328\n",
      "Running Batch 408, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.796243667602539\n",
      "Running Batch 409, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.8955211639404297\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 409, Loss: 1.8955211639404297\n",
      "Running Batch 410, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.8541451692581177\n",
      "Running Batch 411, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.811145305633545\n",
      "Running Batch 412, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.982919692993164\n",
      "Running Batch 413, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.7362226247787476\n",
      "Running Batch 414, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8122278451919556\n",
      "Running Batch 415, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.882239580154419\n",
      "Running Batch 416, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.88690984249115\n",
      "Running Batch 417, Epoch 2, Total Tokens: 295\n",
      "Loss: 1.859385371208191\n",
      "Running Batch 418, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.8724415302276611\n",
      "Running Batch 419, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8184123039245605\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 419, Loss: 1.8184123039245605\n",
      "Running Batch 420, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7940328121185303\n",
      "Running Batch 421, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.7981189489364624\n",
      "Running Batch 422, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6801421642303467\n",
      "Running Batch 423, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8597561120986938\n",
      "Running Batch 424, Epoch 2, Total Tokens: 293\n",
      "Loss: 1.7880939245224\n",
      "Running Batch 425, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8028137683868408\n",
      "Running Batch 426, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.859043002128601\n",
      "Running Batch 427, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8098945617675781\n",
      "Running Batch 428, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.909286618232727\n",
      "Running Batch 429, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8253744840621948\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 429, Loss: 1.8253744840621948\n",
      "Running Batch 430, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.8118609189987183\n",
      "Running Batch 431, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8227920532226562\n",
      "Running Batch 432, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.866085171699524\n",
      "Running Batch 433, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.7851946353912354\n",
      "Running Batch 434, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8050674200057983\n",
      "Running Batch 435, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.917886734008789\n",
      "Running Batch 436, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.902131199836731\n",
      "Running Batch 437, Epoch 2, Total Tokens: 236\n",
      "Loss: 1.8353928327560425\n",
      "Running Batch 438, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8659114837646484\n",
      "Running Batch 439, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8085756301879883\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 439, Loss: 1.8085756301879883\n",
      "Running Batch 440, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.8448835611343384\n",
      "Running Batch 441, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.8710461854934692\n",
      "Running Batch 442, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8448973894119263\n",
      "Running Batch 443, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8434480428695679\n",
      "Running Batch 444, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8266181945800781\n",
      "Running Batch 445, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.805806279182434\n",
      "Running Batch 446, Epoch 2, Total Tokens: 266\n",
      "Loss: 1.8280048370361328\n",
      "Running Batch 447, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.9385722875595093\n",
      "Running Batch 448, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.9147448539733887\n",
      "Running Batch 449, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.8439533710479736\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 449, Loss: 1.8439533710479736\n",
      "Running Batch 450, Epoch 2, Total Tokens: 629\n",
      "Loss: 1.7709494829177856\n",
      "Running Batch 451, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.9134455919265747\n",
      "Running Batch 452, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.829167127609253\n",
      "Running Batch 453, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8790392875671387\n",
      "Running Batch 454, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.804916501045227\n",
      "Running Batch 455, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.804642915725708\n",
      "Running Batch 456, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.836540699005127\n",
      "Running Batch 457, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.9607572555541992\n",
      "Running Batch 458, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8839447498321533\n",
      "Running Batch 459, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.9089082479476929\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 459, Loss: 1.9089082479476929\n",
      "Running Batch 460, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8825289011001587\n",
      "Running Batch 461, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8226675987243652\n",
      "Running Batch 462, Epoch 2, Total Tokens: 106\n",
      "Loss: 1.828108310699463\n",
      "Running Batch 463, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.7956645488739014\n",
      "Running Batch 464, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8433523178100586\n",
      "Running Batch 465, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.730631947517395\n",
      "Running Batch 466, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7966006994247437\n",
      "Running Batch 467, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.884941577911377\n",
      "Running Batch 468, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7819322347640991\n",
      "Running Batch 469, Epoch 2, Total Tokens: 284\n",
      "Loss: 1.8336358070373535\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 469, Loss: 1.8336358070373535\n",
      "Running Batch 470, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8477882146835327\n",
      "Running Batch 471, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8411582708358765\n",
      "Running Batch 472, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.826230525970459\n",
      "Running Batch 473, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.7451516389846802\n",
      "Running Batch 474, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8600467443466187\n",
      "Running Batch 475, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.9138497114181519\n",
      "Running Batch 476, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7896147966384888\n",
      "Running Batch 477, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7854907512664795\n",
      "Running Batch 478, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8455893993377686\n",
      "Running Batch 479, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8557926416397095\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 479, Loss: 1.8557926416397095\n",
      "Running Batch 480, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.9174724817276\n",
      "Running Batch 481, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7633415460586548\n",
      "Running Batch 482, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.715867280960083\n",
      "Running Batch 483, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8275856971740723\n",
      "Running Batch 484, Epoch 2, Total Tokens: 111\n",
      "Loss: 1.776554822921753\n",
      "Running Batch 485, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8765822649002075\n",
      "Running Batch 486, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.9004918336868286\n",
      "Running Batch 487, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.8768757581710815\n",
      "Running Batch 488, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.83345627784729\n",
      "Running Batch 489, Epoch 2, Total Tokens: 262\n",
      "Loss: 1.8482873439788818\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 489, Loss: 1.8482873439788818\n",
      "Running Batch 490, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8073196411132812\n",
      "Running Batch 491, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.7737630605697632\n",
      "Running Batch 492, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.830145239830017\n",
      "Running Batch 493, Epoch 2, Total Tokens: 228\n",
      "Loss: 1.805011510848999\n",
      "Running Batch 494, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.9215338230133057\n",
      "Running Batch 495, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8452274799346924\n",
      "Running Batch 496, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.7705564498901367\n",
      "Running Batch 497, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8019468784332275\n",
      "Running Batch 498, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7940884828567505\n",
      "Running Batch 499, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8916162252426147\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 499, Loss: 1.8916162252426147\n",
      "Running Batch 500, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8550019264221191\n",
      "Running Batch 501, Epoch 2, Total Tokens: 163\n",
      "Loss: 1.8484866619110107\n",
      "Running Batch 502, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.8784730434417725\n",
      "Running Batch 503, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.9749921560287476\n",
      "Running Batch 504, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8602113723754883\n",
      "Running Batch 505, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8640856742858887\n",
      "Running Batch 506, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.797191858291626\n",
      "Running Batch 507, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7308180332183838\n",
      "Running Batch 508, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.759461522102356\n",
      "Running Batch 509, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.876737356185913\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 509, Loss: 1.876737356185913\n",
      "Running Batch 510, Epoch 2, Total Tokens: 254\n",
      "Loss: 1.8003803491592407\n",
      "Running Batch 511, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8429676294326782\n",
      "Running Batch 512, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8335607051849365\n",
      "Running Batch 513, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8055768013000488\n",
      "Running Batch 514, Epoch 2, Total Tokens: 357\n",
      "Loss: 1.9638081789016724\n",
      "Running Batch 515, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.7772759199142456\n",
      "Running Batch 516, Epoch 2, Total Tokens: 196\n",
      "Loss: 1.8101575374603271\n",
      "Running Batch 517, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.810279369354248\n",
      "Running Batch 518, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7833707332611084\n",
      "Running Batch 519, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8596419095993042\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 519, Loss: 1.8596419095993042\n",
      "Running Batch 520, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.7886933088302612\n",
      "Running Batch 521, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.832605004310608\n",
      "Running Batch 522, Epoch 2, Total Tokens: 219\n",
      "Loss: 1.8231303691864014\n",
      "Running Batch 523, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.940266489982605\n",
      "Running Batch 524, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.868579626083374\n",
      "Running Batch 525, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.817240834236145\n",
      "Running Batch 526, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7930054664611816\n",
      "Running Batch 527, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7333828210830688\n",
      "Running Batch 528, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.9174646139144897\n",
      "Running Batch 529, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7986960411071777\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 529, Loss: 1.7986960411071777\n",
      "Running Batch 530, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8180749416351318\n",
      "Running Batch 531, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8338398933410645\n",
      "Running Batch 532, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.9178117513656616\n",
      "Running Batch 533, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7635858058929443\n",
      "Running Batch 534, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8034825325012207\n",
      "Running Batch 535, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7250263690948486\n",
      "Running Batch 536, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.828094244003296\n",
      "Running Batch 537, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8461241722106934\n",
      "Running Batch 538, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.8646184206008911\n",
      "Running Batch 539, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.84373939037323\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 539, Loss: 1.84373939037323\n",
      "Running Batch 540, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7963383197784424\n",
      "Running Batch 541, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7016545534133911\n",
      "Running Batch 542, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7815643548965454\n",
      "Running Batch 543, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.8947486877441406\n",
      "Running Batch 544, Epoch 2, Total Tokens: 193\n",
      "Loss: 1.7876702547073364\n",
      "Running Batch 545, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8159393072128296\n",
      "Running Batch 546, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.9082549810409546\n",
      "Running Batch 547, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7877362966537476\n",
      "Running Batch 548, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.825751781463623\n",
      "Running Batch 549, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8474829196929932\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 549, Loss: 1.8474829196929932\n",
      "Running Batch 550, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.784447193145752\n",
      "Running Batch 551, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8320622444152832\n",
      "Running Batch 552, Epoch 2, Total Tokens: 428\n",
      "Loss: 1.7771011590957642\n",
      "Running Batch 553, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.837713360786438\n",
      "Running Batch 554, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.8151471614837646\n",
      "Running Batch 555, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.8047778606414795\n",
      "Running Batch 556, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7870948314666748\n",
      "Running Batch 557, Epoch 2, Total Tokens: 205\n",
      "Loss: 1.9216642379760742\n",
      "Running Batch 558, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.827195167541504\n",
      "Running Batch 559, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.869319200515747\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 559, Loss: 1.869319200515747\n",
      "Running Batch 560, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.877241849899292\n",
      "Running Batch 561, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7446928024291992\n",
      "Running Batch 562, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.7895761728286743\n",
      "Running Batch 563, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8894171714782715\n",
      "Running Batch 564, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8995170593261719\n",
      "Running Batch 565, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.9117261171340942\n",
      "Running Batch 566, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.9132065773010254\n",
      "Running Batch 567, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.8849341869354248\n",
      "Running Batch 568, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.83873450756073\n",
      "Running Batch 569, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.8636341094970703\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 569, Loss: 1.8636341094970703\n",
      "Running Batch 570, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8434183597564697\n",
      "Running Batch 571, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8914821147918701\n",
      "Running Batch 572, Epoch 2, Total Tokens: 494\n",
      "Loss: 1.7371970415115356\n",
      "Running Batch 573, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7356613874435425\n",
      "Running Batch 574, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7768754959106445\n",
      "Running Batch 575, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8555867671966553\n",
      "Running Batch 576, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.8179044723510742\n",
      "Running Batch 577, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7840747833251953\n",
      "Running Batch 578, Epoch 2, Total Tokens: 287\n",
      "Loss: 1.8733999729156494\n",
      "Running Batch 579, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8518527746200562\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 579, Loss: 1.8518527746200562\n",
      "Running Batch 580, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8214670419692993\n",
      "Running Batch 581, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.8177275657653809\n",
      "Running Batch 582, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.9022564888000488\n",
      "Running Batch 583, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8157516717910767\n",
      "Running Batch 584, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8027141094207764\n",
      "Running Batch 585, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8348437547683716\n",
      "Running Batch 586, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.9086452722549438\n",
      "Running Batch 587, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8845857381820679\n",
      "Running Batch 588, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.8637993335723877\n",
      "Running Batch 589, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.9195289611816406\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 589, Loss: 1.9195289611816406\n",
      "Running Batch 590, Epoch 2, Total Tokens: 228\n",
      "Loss: 1.7736129760742188\n",
      "Running Batch 591, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.7833795547485352\n",
      "Running Batch 592, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8911062479019165\n",
      "Running Batch 593, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.8587239980697632\n",
      "Running Batch 594, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8600876331329346\n",
      "Running Batch 595, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.7962309122085571\n",
      "Running Batch 596, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.689860463142395\n",
      "Running Batch 597, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7850676774978638\n",
      "Running Batch 598, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.8234450817108154\n",
      "Running Batch 599, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.9295762777328491\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 599, Loss: 1.9295762777328491\n",
      "Running Batch 600, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.781850814819336\n",
      "Running Batch 601, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7784439325332642\n",
      "Running Batch 602, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7820385694503784\n",
      "Running Batch 603, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.9267643690109253\n",
      "Running Batch 604, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7991095781326294\n",
      "Running Batch 605, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8537851572036743\n",
      "Running Batch 606, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7723851203918457\n",
      "Running Batch 607, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.9608089923858643\n",
      "Running Batch 608, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8639230728149414\n",
      "Running Batch 609, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.817319631576538\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 609, Loss: 1.817319631576538\n",
      "Running Batch 610, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.946224570274353\n",
      "Running Batch 611, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.838068962097168\n",
      "Running Batch 612, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.8269902467727661\n",
      "Running Batch 613, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.8110517263412476\n",
      "Running Batch 614, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.8591822385787964\n",
      "Running Batch 615, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7836341857910156\n",
      "Running Batch 616, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.7996697425842285\n",
      "Running Batch 617, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.769286870956421\n",
      "Running Batch 618, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7584631443023682\n",
      "Running Batch 619, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.7476402521133423\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 619, Loss: 1.7476402521133423\n",
      "Running Batch 620, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.823325276374817\n",
      "Running Batch 621, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.7730222940444946\n",
      "Running Batch 622, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7758831977844238\n",
      "Running Batch 623, Epoch 2, Total Tokens: 230\n",
      "Loss: 1.7744462490081787\n",
      "Running Batch 624, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7418855428695679\n",
      "Running Batch 625, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8335062265396118\n",
      "Running Batch 626, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8544766902923584\n",
      "Running Batch 627, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.8345813751220703\n",
      "Running Batch 628, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7831356525421143\n",
      "Running Batch 629, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.8246604204177856\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 629, Loss: 1.8246604204177856\n",
      "Running Batch 630, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.7580620050430298\n",
      "Running Batch 631, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8391350507736206\n",
      "Running Batch 632, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.9672795534133911\n",
      "Running Batch 633, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.8025168180465698\n",
      "Running Batch 634, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7812328338623047\n",
      "Running Batch 635, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8853404521942139\n",
      "Running Batch 636, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.829452395439148\n",
      "Running Batch 637, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7854351997375488\n",
      "Running Batch 638, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8246601819992065\n",
      "Running Batch 639, Epoch 2, Total Tokens: 116\n",
      "Loss: 1.8702348470687866\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 639, Loss: 1.8702348470687866\n",
      "Running Batch 640, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.891361117362976\n",
      "Running Batch 641, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.741127610206604\n",
      "Running Batch 642, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.8754734992980957\n",
      "Running Batch 643, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.821272850036621\n",
      "Running Batch 644, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.820069670677185\n",
      "Running Batch 645, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8816940784454346\n",
      "Running Batch 646, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.7168848514556885\n",
      "Running Batch 647, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8899660110473633\n",
      "Running Batch 648, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8129761219024658\n",
      "Running Batch 649, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.7759733200073242\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 649, Loss: 1.7759733200073242\n",
      "Running Batch 650, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8713808059692383\n",
      "Running Batch 651, Epoch 2, Total Tokens: 210\n",
      "Loss: 1.8926478624343872\n",
      "Running Batch 652, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7471758127212524\n",
      "Running Batch 653, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.840336561203003\n",
      "Running Batch 654, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8038043975830078\n",
      "Running Batch 655, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7680513858795166\n",
      "Running Batch 656, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.775628685951233\n",
      "Running Batch 657, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8360275030136108\n",
      "Running Batch 658, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7668280601501465\n",
      "Running Batch 659, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7881720066070557\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 659, Loss: 1.7881720066070557\n",
      "Running Batch 660, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8089113235473633\n",
      "Running Batch 661, Epoch 2, Total Tokens: 351\n",
      "Loss: 1.9132128953933716\n",
      "Running Batch 662, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7877126932144165\n",
      "Running Batch 663, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7519183158874512\n",
      "Running Batch 664, Epoch 2, Total Tokens: 96\n",
      "Loss: 1.8699203729629517\n",
      "Running Batch 665, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8288756608963013\n",
      "Running Batch 666, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.9330825805664062\n",
      "Running Batch 667, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8444262742996216\n",
      "Running Batch 668, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7644966840744019\n",
      "Running Batch 669, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.797614574432373\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 669, Loss: 1.797614574432373\n",
      "Running Batch 670, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8475558757781982\n",
      "Running Batch 671, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7372623682022095\n",
      "Running Batch 672, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8829842805862427\n",
      "Running Batch 673, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8492618799209595\n",
      "Running Batch 674, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7174276113510132\n",
      "Running Batch 675, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7789392471313477\n",
      "Running Batch 676, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.9323590993881226\n",
      "Running Batch 677, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.8598779439926147\n",
      "Running Batch 678, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.6980894804000854\n",
      "Running Batch 679, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.7576457262039185\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 679, Loss: 1.7576457262039185\n",
      "Running Batch 680, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.8821738958358765\n",
      "Running Batch 681, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.7584344148635864\n",
      "Running Batch 682, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8086920976638794\n",
      "Running Batch 683, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.878578543663025\n",
      "Running Batch 684, Epoch 2, Total Tokens: 106\n",
      "Loss: 1.798890233039856\n",
      "Running Batch 685, Epoch 2, Total Tokens: 121\n",
      "Loss: 1.7204493284225464\n",
      "Running Batch 686, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.851171612739563\n",
      "Running Batch 687, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.847151756286621\n",
      "Running Batch 688, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.856457233428955\n",
      "Running Batch 689, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.7916351556777954\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 689, Loss: 1.7916351556777954\n",
      "Running Batch 690, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.872110366821289\n",
      "Running Batch 691, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.7670642137527466\n",
      "Running Batch 692, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7921069860458374\n",
      "Running Batch 693, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7312771081924438\n",
      "Running Batch 694, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8175369501113892\n",
      "Running Batch 695, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8156708478927612\n",
      "Running Batch 696, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.7181109189987183\n",
      "Running Batch 697, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8584893941879272\n",
      "Running Batch 698, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7489244937896729\n",
      "Running Batch 699, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7781782150268555\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 699, Loss: 1.7781782150268555\n",
      "Running Batch 700, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8806195259094238\n",
      "Running Batch 701, Epoch 2, Total Tokens: 108\n",
      "Loss: 1.824366569519043\n",
      "Running Batch 702, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.766858458518982\n",
      "Running Batch 703, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.832331657409668\n",
      "Running Batch 704, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8676788806915283\n",
      "Running Batch 705, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7404084205627441\n",
      "Running Batch 706, Epoch 2, Total Tokens: 214\n",
      "Loss: 1.7784862518310547\n",
      "Running Batch 707, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.834852695465088\n",
      "Running Batch 708, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7580375671386719\n",
      "Running Batch 709, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7291978597640991\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 709, Loss: 1.7291978597640991\n",
      "Running Batch 710, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8082832098007202\n",
      "Running Batch 711, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.7711867094039917\n",
      "Running Batch 712, Epoch 2, Total Tokens: 176\n",
      "Loss: 1.7361506223678589\n",
      "Running Batch 713, Epoch 2, Total Tokens: 241\n",
      "Loss: 1.82500159740448\n",
      "Running Batch 714, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8184558153152466\n",
      "Running Batch 715, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8194048404693604\n",
      "Running Batch 716, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.7194064855575562\n",
      "Running Batch 717, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8752970695495605\n",
      "Running Batch 718, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8079257011413574\n",
      "Running Batch 719, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7711951732635498\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 719, Loss: 1.7711951732635498\n",
      "Running Batch 720, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8868463039398193\n",
      "Running Batch 721, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.8070608377456665\n",
      "Running Batch 722, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8862502574920654\n",
      "Running Batch 723, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.774924874305725\n",
      "Running Batch 724, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.9172210693359375\n",
      "Running Batch 725, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7943931818008423\n",
      "Running Batch 726, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8213304281234741\n",
      "Running Batch 727, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.8822005987167358\n",
      "Running Batch 728, Epoch 2, Total Tokens: 242\n",
      "Loss: 1.9252288341522217\n",
      "Running Batch 729, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.9200063943862915\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 729, Loss: 1.9200063943862915\n",
      "Running Batch 730, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8179740905761719\n",
      "Running Batch 731, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7092814445495605\n",
      "Running Batch 732, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.867626428604126\n",
      "Running Batch 733, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8138951063156128\n",
      "Running Batch 734, Epoch 2, Total Tokens: 197\n",
      "Loss: 1.8530395030975342\n",
      "Running Batch 735, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7891124486923218\n",
      "Running Batch 736, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.853895902633667\n",
      "Running Batch 737, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8727346658706665\n",
      "Running Batch 738, Epoch 2, Total Tokens: 161\n",
      "Loss: 1.7794959545135498\n",
      "Running Batch 739, Epoch 2, Total Tokens: 214\n",
      "Loss: 1.7203953266143799\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 739, Loss: 1.7203953266143799\n",
      "Running Batch 740, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8490008115768433\n",
      "Running Batch 741, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7900992631912231\n",
      "Running Batch 742, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8028111457824707\n",
      "Running Batch 743, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.855653166770935\n",
      "Running Batch 744, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.741300344467163\n",
      "Running Batch 745, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.7669087648391724\n",
      "Running Batch 746, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7012218236923218\n",
      "Running Batch 747, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.792362093925476\n",
      "Running Batch 748, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.9051270484924316\n",
      "Running Batch 749, Epoch 2, Total Tokens: 288\n",
      "Loss: 1.8719478845596313\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 749, Loss: 1.8719478845596313\n",
      "Running Batch 750, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7777012586593628\n",
      "Running Batch 751, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8703075647354126\n",
      "Running Batch 752, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.904889464378357\n",
      "Running Batch 753, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8304469585418701\n",
      "Running Batch 754, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7039591073989868\n",
      "Running Batch 755, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.6971904039382935\n",
      "Running Batch 756, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.802390217781067\n",
      "Running Batch 757, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7435075044631958\n",
      "Running Batch 758, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.9664677381515503\n",
      "Running Batch 759, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.767439842224121\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 759, Loss: 1.767439842224121\n",
      "Running Batch 760, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8890589475631714\n",
      "Running Batch 761, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7897212505340576\n",
      "Running Batch 762, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.786876916885376\n",
      "Running Batch 763, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.804133415222168\n",
      "Running Batch 764, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.805582046508789\n",
      "Running Batch 765, Epoch 2, Total Tokens: 165\n",
      "Loss: 1.7100244760513306\n",
      "Running Batch 766, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8535405397415161\n",
      "Running Batch 767, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8981553316116333\n",
      "Running Batch 768, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8389012813568115\n",
      "Running Batch 769, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.812100887298584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 769, Loss: 1.812100887298584\n",
      "Running Batch 770, Epoch 2, Total Tokens: 274\n",
      "Loss: 1.768498420715332\n",
      "Running Batch 771, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.7922102212905884\n",
      "Running Batch 772, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7534403800964355\n",
      "Running Batch 773, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.9648940563201904\n",
      "Running Batch 774, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8302439451217651\n",
      "Running Batch 775, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.8007217645645142\n",
      "Running Batch 776, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.767515778541565\n",
      "Running Batch 777, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8659749031066895\n",
      "Running Batch 778, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.7544212341308594\n",
      "Running Batch 779, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8254623413085938\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 779, Loss: 1.8254623413085938\n",
      "Running Batch 780, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.808186411857605\n",
      "Running Batch 781, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.780436635017395\n",
      "Running Batch 782, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8198201656341553\n",
      "Running Batch 783, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.7549488544464111\n",
      "Running Batch 784, Epoch 2, Total Tokens: 360\n",
      "Loss: 1.7188704013824463\n",
      "Running Batch 785, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.661726474761963\n",
      "Running Batch 786, Epoch 2, Total Tokens: 324\n",
      "Loss: 1.8875056505203247\n",
      "Running Batch 787, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.8749048709869385\n",
      "Running Batch 788, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7285146713256836\n",
      "Running Batch 789, Epoch 2, Total Tokens: 199\n",
      "Loss: 1.6931447982788086\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 789, Loss: 1.6931447982788086\n",
      "Running Batch 790, Epoch 2, Total Tokens: 185\n",
      "Loss: 1.7944011688232422\n",
      "Running Batch 791, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.7497161626815796\n",
      "Running Batch 792, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.714195728302002\n",
      "Running Batch 793, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.7991716861724854\n",
      "Running Batch 794, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.7732720375061035\n",
      "Running Batch 795, Epoch 2, Total Tokens: 568\n",
      "Loss: 1.7695555686950684\n",
      "Running Batch 796, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7886525392532349\n",
      "Running Batch 797, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7693116664886475\n",
      "Running Batch 798, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.848770260810852\n",
      "Running Batch 799, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.812680959701538\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 799, Loss: 1.812680959701538\n",
      "Running Batch 800, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.815186858177185\n",
      "Running Batch 801, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.8417174816131592\n",
      "Running Batch 802, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.755635380744934\n",
      "Running Batch 803, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8368421792984009\n",
      "Running Batch 804, Epoch 2, Total Tokens: 103\n",
      "Loss: 1.7420397996902466\n",
      "Running Batch 805, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.6954017877578735\n",
      "Running Batch 806, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7886662483215332\n",
      "Running Batch 807, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7644364833831787\n",
      "Running Batch 808, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.801588773727417\n",
      "Running Batch 809, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7311452627182007\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 809, Loss: 1.7311452627182007\n",
      "Running Batch 810, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8741317987442017\n",
      "Running Batch 811, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8480124473571777\n",
      "Running Batch 812, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.7803629636764526\n",
      "Running Batch 813, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.903842568397522\n",
      "Running Batch 814, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.8243491649627686\n",
      "Running Batch 815, Epoch 2, Total Tokens: 220\n",
      "Loss: 1.8297319412231445\n",
      "Running Batch 816, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8061211109161377\n",
      "Running Batch 817, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.866115927696228\n",
      "Running Batch 818, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.7655688524246216\n",
      "Running Batch 819, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.8533906936645508\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 819, Loss: 1.8533906936645508\n",
      "Running Batch 820, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7547537088394165\n",
      "Running Batch 821, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.7600512504577637\n",
      "Running Batch 822, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7399511337280273\n",
      "Running Batch 823, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8235913515090942\n",
      "Running Batch 824, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.757697582244873\n",
      "Running Batch 825, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8307658433914185\n",
      "Running Batch 826, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7817476987838745\n",
      "Running Batch 827, Epoch 2, Total Tokens: 326\n",
      "Loss: 1.7518630027770996\n",
      "Running Batch 828, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8016951084136963\n",
      "Running Batch 829, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.7669219970703125\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 829, Loss: 1.7669219970703125\n",
      "Running Batch 830, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8369883298873901\n",
      "Running Batch 831, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8774663209915161\n",
      "Running Batch 832, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.7588430643081665\n",
      "Running Batch 833, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8015531301498413\n",
      "Running Batch 834, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7549012899398804\n",
      "Running Batch 835, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8032997846603394\n",
      "Running Batch 836, Epoch 2, Total Tokens: 164\n",
      "Loss: 1.7145994901657104\n",
      "Running Batch 837, Epoch 2, Total Tokens: 337\n",
      "Loss: 1.780281662940979\n",
      "Running Batch 838, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.902494192123413\n",
      "Running Batch 839, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.8731045722961426\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 839, Loss: 1.8731045722961426\n",
      "Running Batch 840, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.803576946258545\n",
      "Running Batch 841, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.8271386623382568\n",
      "Running Batch 842, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.7575328350067139\n",
      "Running Batch 843, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7950987815856934\n",
      "Running Batch 844, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7356855869293213\n",
      "Running Batch 845, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8086776733398438\n",
      "Running Batch 846, Epoch 2, Total Tokens: 340\n",
      "Loss: 1.700942039489746\n",
      "Running Batch 847, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.840919017791748\n",
      "Running Batch 848, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.833448052406311\n",
      "Running Batch 849, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7772220373153687\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 849, Loss: 1.7772220373153687\n",
      "Running Batch 850, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.9020745754241943\n",
      "Running Batch 851, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7822786569595337\n",
      "Running Batch 852, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.8819416761398315\n",
      "Running Batch 853, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8238794803619385\n",
      "Running Batch 854, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7469139099121094\n",
      "Running Batch 855, Epoch 2, Total Tokens: 234\n",
      "Loss: 1.809730052947998\n",
      "Running Batch 856, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.773372769355774\n",
      "Running Batch 857, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8001989126205444\n",
      "Running Batch 858, Epoch 2, Total Tokens: 155\n",
      "Loss: 1.7765625715255737\n",
      "Running Batch 859, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.886054515838623\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 859, Loss: 1.886054515838623\n",
      "Running Batch 860, Epoch 2, Total Tokens: 334\n",
      "Loss: 1.7986682653427124\n",
      "Running Batch 861, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8819243907928467\n",
      "Running Batch 862, Epoch 2, Total Tokens: 168\n",
      "Loss: 1.7325581312179565\n",
      "Running Batch 863, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.823162317276001\n",
      "Running Batch 864, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.7470389604568481\n",
      "Running Batch 865, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.9124447107315063\n",
      "Running Batch 866, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.7825491428375244\n",
      "Running Batch 867, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.812586784362793\n",
      "Running Batch 868, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.9192285537719727\n",
      "Running Batch 869, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.9063913822174072\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 869, Loss: 1.9063913822174072\n",
      "Running Batch 870, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7886288166046143\n",
      "Running Batch 871, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.725319266319275\n",
      "Running Batch 872, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.836394190788269\n",
      "Running Batch 873, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.828786015510559\n",
      "Running Batch 874, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.8154174089431763\n",
      "Running Batch 875, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.8405070304870605\n",
      "Running Batch 876, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.751266598701477\n",
      "Running Batch 877, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7526863813400269\n",
      "Running Batch 878, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.730314016342163\n",
      "Running Batch 879, Epoch 2, Total Tokens: 119\n",
      "Loss: 1.7242934703826904\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 879, Loss: 1.7242934703826904\n",
      "Running Batch 880, Epoch 2, Total Tokens: 160\n",
      "Loss: 1.8226574659347534\n",
      "Running Batch 881, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7897924184799194\n",
      "Running Batch 882, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7717273235321045\n",
      "Running Batch 883, Epoch 2, Total Tokens: 384\n",
      "Loss: 1.8223936557769775\n",
      "Running Batch 884, Epoch 2, Total Tokens: 117\n",
      "Loss: 1.7788022756576538\n",
      "Running Batch 885, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.8578273057937622\n",
      "Running Batch 886, Epoch 2, Total Tokens: 361\n",
      "Loss: 1.8334988355636597\n",
      "Running Batch 887, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7525392770767212\n",
      "Running Batch 888, Epoch 2, Total Tokens: 261\n",
      "Loss: 1.8106751441955566\n",
      "Running Batch 889, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8092783689498901\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 889, Loss: 1.8092783689498901\n",
      "Running Batch 890, Epoch 2, Total Tokens: 156\n",
      "Loss: 1.7687764167785645\n",
      "Running Batch 891, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8167848587036133\n",
      "Running Batch 892, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.7250323295593262\n",
      "Running Batch 893, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7673028707504272\n",
      "Running Batch 894, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.829877495765686\n",
      "Running Batch 895, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.7443794012069702\n",
      "Running Batch 896, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8332549333572388\n",
      "Running Batch 897, Epoch 2, Total Tokens: 102\n",
      "Loss: 1.7549054622650146\n",
      "Running Batch 898, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.8447113037109375\n",
      "Running Batch 899, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7835146188735962\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 899, Loss: 1.7835146188735962\n",
      "Running Batch 900, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8078949451446533\n",
      "Running Batch 901, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.868284821510315\n",
      "Running Batch 902, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8459036350250244\n",
      "Running Batch 903, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8663774728775024\n",
      "Running Batch 904, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7453362941741943\n",
      "Running Batch 905, Epoch 2, Total Tokens: 166\n",
      "Loss: 1.7644379138946533\n",
      "Running Batch 906, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.8058183193206787\n",
      "Running Batch 907, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.794572353363037\n",
      "Running Batch 908, Epoch 2, Total Tokens: 244\n",
      "Loss: 1.8148044347763062\n",
      "Running Batch 909, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8044648170471191\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 909, Loss: 1.8044648170471191\n",
      "Running Batch 910, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.865237832069397\n",
      "Running Batch 911, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7487928867340088\n",
      "Running Batch 912, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7738200426101685\n",
      "Running Batch 913, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.745218276977539\n",
      "Running Batch 914, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.768892526626587\n",
      "Running Batch 915, Epoch 2, Total Tokens: 229\n",
      "Loss: 1.7186825275421143\n",
      "Running Batch 916, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8249367475509644\n",
      "Running Batch 917, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.752750277519226\n",
      "Running Batch 918, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7957812547683716\n",
      "Running Batch 919, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7788004875183105\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 919, Loss: 1.7788004875183105\n",
      "Running Batch 920, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7525324821472168\n",
      "Running Batch 921, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8595161437988281\n",
      "Running Batch 922, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8483951091766357\n",
      "Running Batch 923, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7982449531555176\n",
      "Running Batch 924, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.8228920698165894\n",
      "Running Batch 925, Epoch 2, Total Tokens: 251\n",
      "Loss: 1.7783684730529785\n",
      "Running Batch 926, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.8089596033096313\n",
      "Running Batch 927, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.718736171722412\n",
      "Running Batch 928, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7978897094726562\n",
      "Running Batch 929, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.8179899454116821\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 929, Loss: 1.8179899454116821\n",
      "Running Batch 930, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.765932559967041\n",
      "Running Batch 931, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8211679458618164\n",
      "Running Batch 932, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8940021991729736\n",
      "Running Batch 933, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.8719505071640015\n",
      "Running Batch 934, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.8412997722625732\n",
      "Running Batch 935, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7824206352233887\n",
      "Running Batch 936, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8397526741027832\n",
      "Running Batch 937, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.815646767616272\n",
      "Running Batch 938, Epoch 2, Total Tokens: 182\n",
      "Loss: 1.7035088539123535\n",
      "Running Batch 939, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8551321029663086\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 939, Loss: 1.8551321029663086\n",
      "Running Batch 940, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.761601448059082\n",
      "Running Batch 941, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7409383058547974\n",
      "Running Batch 942, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8890502452850342\n",
      "Running Batch 943, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7763277292251587\n",
      "Running Batch 944, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.8385177850723267\n",
      "Running Batch 945, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.7229905128479004\n",
      "Running Batch 946, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.9020885229110718\n",
      "Running Batch 947, Epoch 2, Total Tokens: 250\n",
      "Loss: 1.7266863584518433\n",
      "Running Batch 948, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8536778688430786\n",
      "Running Batch 949, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8139926195144653\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 949, Loss: 1.8139926195144653\n",
      "Running Batch 950, Epoch 2, Total Tokens: 624\n",
      "Loss: 1.8028018474578857\n",
      "Running Batch 951, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.831026554107666\n",
      "Running Batch 952, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7947189807891846\n",
      "Running Batch 953, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8102613687515259\n",
      "Running Batch 954, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.7410122156143188\n",
      "Running Batch 955, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7414684295654297\n",
      "Running Batch 956, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8078666925430298\n",
      "Running Batch 957, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7300755977630615\n",
      "Running Batch 958, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.741054654121399\n",
      "Running Batch 959, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.827080488204956\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 959, Loss: 1.827080488204956\n",
      "Running Batch 960, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8256895542144775\n",
      "Running Batch 961, Epoch 2, Total Tokens: 299\n",
      "Loss: 1.8594367504119873\n",
      "Running Batch 962, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.7398964166641235\n",
      "Running Batch 963, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.7877206802368164\n",
      "Running Batch 964, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.7681118249893188\n",
      "Running Batch 965, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8558571338653564\n",
      "Running Batch 966, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7464483976364136\n",
      "Running Batch 967, Epoch 2, Total Tokens: 380\n",
      "Loss: 1.7287640571594238\n",
      "Running Batch 968, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.786993145942688\n",
      "Running Batch 969, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8199677467346191\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 969, Loss: 1.8199677467346191\n",
      "Running Batch 970, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.893506407737732\n",
      "Running Batch 971, Epoch 2, Total Tokens: 254\n",
      "Loss: 1.8613917827606201\n",
      "Running Batch 972, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.788709044456482\n",
      "Running Batch 973, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.682315468788147\n",
      "Running Batch 974, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7922452688217163\n",
      "Running Batch 975, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.7636666297912598\n",
      "Running Batch 976, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.837680459022522\n",
      "Running Batch 977, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.8582532405853271\n",
      "Running Batch 978, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.9163450002670288\n",
      "Running Batch 979, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.758462905883789\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 979, Loss: 1.758462905883789\n",
      "Running Batch 980, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.709837794303894\n",
      "Running Batch 981, Epoch 2, Total Tokens: 181\n",
      "Loss: 1.8049002885818481\n",
      "Running Batch 982, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8055810928344727\n",
      "Running Batch 983, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8175314664840698\n",
      "Running Batch 984, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.80029296875\n",
      "Running Batch 985, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.8034507036209106\n",
      "Running Batch 986, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8161393404006958\n",
      "Running Batch 987, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8441787958145142\n",
      "Running Batch 988, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8639379739761353\n",
      "Running Batch 989, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8150131702423096\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 989, Loss: 1.8150131702423096\n",
      "Running Batch 990, Epoch 2, Total Tokens: 282\n",
      "Loss: 1.7712832689285278\n",
      "Running Batch 991, Epoch 2, Total Tokens: 112\n",
      "Loss: 1.8254871368408203\n",
      "Running Batch 992, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8092631101608276\n",
      "Running Batch 993, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7103848457336426\n",
      "Running Batch 994, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8566473722457886\n",
      "Running Batch 995, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.7297652959823608\n",
      "Running Batch 996, Epoch 2, Total Tokens: 158\n",
      "Loss: 1.8185553550720215\n",
      "Running Batch 997, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.8345743417739868\n",
      "Running Batch 998, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.7554787397384644\n",
      "Running Batch 999, Epoch 2, Total Tokens: 281\n",
      "Loss: 1.8077657222747803\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 999, Loss: 1.8077657222747803\n",
      "Running Batch 1000, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.8129132986068726\n",
      "Running Batch 1001, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7360591888427734\n",
      "Running Batch 1002, Epoch 2, Total Tokens: 266\n",
      "Loss: 1.8392059803009033\n",
      "Running Batch 1003, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.753499150276184\n",
      "Running Batch 1004, Epoch 2, Total Tokens: 249\n",
      "Loss: 1.7407716512680054\n",
      "Running Batch 1005, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8280093669891357\n",
      "Running Batch 1006, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8010704517364502\n",
      "Running Batch 1007, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.867932915687561\n",
      "Running Batch 1008, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.7790383100509644\n",
      "Running Batch 1009, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7772959470748901\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1009, Loss: 1.7772959470748901\n",
      "Running Batch 1010, Epoch 2, Total Tokens: 183\n",
      "Loss: 1.720747947692871\n",
      "Running Batch 1011, Epoch 2, Total Tokens: 285\n",
      "Loss: 1.6707500219345093\n",
      "Running Batch 1012, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7048583030700684\n",
      "Running Batch 1013, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.737931728363037\n",
      "Running Batch 1014, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7205400466918945\n",
      "Running Batch 1015, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.7210252285003662\n",
      "Running Batch 1016, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.802208423614502\n",
      "Running Batch 1017, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.8271633386611938\n",
      "Running Batch 1018, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8137105703353882\n",
      "Running Batch 1019, Epoch 2, Total Tokens: 225\n",
      "Loss: 1.8478450775146484\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1019, Loss: 1.8478450775146484\n",
      "Running Batch 1020, Epoch 2, Total Tokens: 125\n",
      "Loss: 1.693679690361023\n",
      "Running Batch 1021, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.836781620979309\n",
      "Running Batch 1022, Epoch 2, Total Tokens: 130\n",
      "Loss: 1.7614777088165283\n",
      "Running Batch 1023, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7568022012710571\n",
      "Running Batch 1024, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.816560983657837\n",
      "Running Batch 1025, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.8231101036071777\n",
      "Running Batch 1026, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.8157154321670532\n",
      "Running Batch 1027, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.8320330381393433\n",
      "Running Batch 1028, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7864264249801636\n",
      "Running Batch 1029, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7985442876815796\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1029, Loss: 1.7985442876815796\n",
      "Running Batch 1030, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7743045091629028\n",
      "Running Batch 1031, Epoch 2, Total Tokens: 169\n",
      "Loss: 1.756824016571045\n",
      "Running Batch 1032, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.8500467538833618\n",
      "Running Batch 1033, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7245875597000122\n",
      "Running Batch 1034, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7250052690505981\n",
      "Running Batch 1035, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7410552501678467\n",
      "Running Batch 1036, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.835523247718811\n",
      "Running Batch 1037, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7864147424697876\n",
      "Running Batch 1038, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.8164033889770508\n",
      "Running Batch 1039, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.9172033071517944\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1039, Loss: 1.9172033071517944\n",
      "Running Batch 1040, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8083487749099731\n",
      "Running Batch 1041, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8528584241867065\n",
      "Running Batch 1042, Epoch 2, Total Tokens: 206\n",
      "Loss: 1.854986548423767\n",
      "Running Batch 1043, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7632949352264404\n",
      "Running Batch 1044, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7759613990783691\n",
      "Running Batch 1045, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7938379049301147\n",
      "Running Batch 1046, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8400681018829346\n",
      "Running Batch 1047, Epoch 2, Total Tokens: 187\n",
      "Loss: 1.6851576566696167\n",
      "Running Batch 1048, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7414882183074951\n",
      "Running Batch 1049, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.722450852394104\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1049, Loss: 1.722450852394104\n",
      "Running Batch 1050, Epoch 2, Total Tokens: 173\n",
      "Loss: 1.747841715812683\n",
      "Running Batch 1051, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.914801001548767\n",
      "Running Batch 1052, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.752357840538025\n",
      "Running Batch 1053, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.7673046588897705\n",
      "Running Batch 1054, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.7353405952453613\n",
      "Running Batch 1055, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.8008995056152344\n",
      "Running Batch 1056, Epoch 2, Total Tokens: 203\n",
      "Loss: 1.7845401763916016\n",
      "Running Batch 1057, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.7940945625305176\n",
      "Running Batch 1058, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7955312728881836\n",
      "Running Batch 1059, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8015817403793335\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1059, Loss: 1.8015817403793335\n",
      "Running Batch 1060, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7442286014556885\n",
      "Running Batch 1061, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.8716952800750732\n",
      "Running Batch 1062, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.753788709640503\n",
      "Running Batch 1063, Epoch 2, Total Tokens: 141\n",
      "Loss: 1.7608389854431152\n",
      "Running Batch 1064, Epoch 2, Total Tokens: 174\n",
      "Loss: 1.7755457162857056\n",
      "Running Batch 1065, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.815975546836853\n",
      "Running Batch 1066, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7732646465301514\n",
      "Running Batch 1067, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7752670049667358\n",
      "Running Batch 1068, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.728448748588562\n",
      "Running Batch 1069, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7618536949157715\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1069, Loss: 1.7618536949157715\n",
      "Running Batch 1070, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.803551197052002\n",
      "Running Batch 1071, Epoch 2, Total Tokens: 135\n",
      "Loss: 1.7189314365386963\n",
      "Running Batch 1072, Epoch 2, Total Tokens: 188\n",
      "Loss: 1.8149079084396362\n",
      "Running Batch 1073, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8067270517349243\n",
      "Running Batch 1074, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7898799180984497\n",
      "Running Batch 1075, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7745434045791626\n",
      "Running Batch 1076, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8053840398788452\n",
      "Running Batch 1077, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.7850871086120605\n",
      "Running Batch 1078, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.8826428651809692\n",
      "Running Batch 1079, Epoch 2, Total Tokens: 128\n",
      "Loss: 1.6800349950790405\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1079, Loss: 1.6800349950790405\n",
      "Running Batch 1080, Epoch 2, Total Tokens: 148\n",
      "Loss: 1.8033933639526367\n",
      "Running Batch 1081, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.8139517307281494\n",
      "Running Batch 1082, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.7609264850616455\n",
      "Running Batch 1083, Epoch 2, Total Tokens: 172\n",
      "Loss: 1.7439473867416382\n",
      "Running Batch 1084, Epoch 2, Total Tokens: 153\n",
      "Loss: 1.7651302814483643\n",
      "Running Batch 1085, Epoch 2, Total Tokens: 286\n",
      "Loss: 1.8761541843414307\n",
      "Running Batch 1086, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7083848714828491\n",
      "Running Batch 1087, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.7421239614486694\n",
      "Running Batch 1088, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.787255048751831\n",
      "Running Batch 1089, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7729116678237915\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1089, Loss: 1.7729116678237915\n",
      "Running Batch 1090, Epoch 2, Total Tokens: 178\n",
      "Loss: 1.852194905281067\n",
      "Running Batch 1091, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.7673691511154175\n",
      "Running Batch 1092, Epoch 2, Total Tokens: 184\n",
      "Loss: 1.818971037864685\n",
      "Running Batch 1093, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.8246614933013916\n",
      "Running Batch 1094, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.7462713718414307\n",
      "Running Batch 1095, Epoch 2, Total Tokens: 190\n",
      "Loss: 1.7740739583969116\n",
      "Running Batch 1096, Epoch 2, Total Tokens: 157\n",
      "Loss: 1.8160192966461182\n",
      "Running Batch 1097, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8581950664520264\n",
      "Running Batch 1098, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7356964349746704\n",
      "Running Batch 1099, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.7468883991241455\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1099, Loss: 1.7468883991241455\n",
      "Running Batch 1100, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.7171452045440674\n",
      "Running Batch 1101, Epoch 2, Total Tokens: 132\n",
      "Loss: 1.8452056646347046\n",
      "Running Batch 1102, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.82377290725708\n",
      "Running Batch 1103, Epoch 2, Total Tokens: 131\n",
      "Loss: 1.8408918380737305\n",
      "Running Batch 1104, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.8036128282546997\n",
      "Running Batch 1105, Epoch 2, Total Tokens: 145\n",
      "Loss: 1.870129108428955\n",
      "Running Batch 1106, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7005101442337036\n",
      "Running Batch 1107, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.743219017982483\n",
      "Running Batch 1108, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.7594002485275269\n",
      "Running Batch 1109, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.6521830558776855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1109, Loss: 1.6521830558776855\n",
      "Running Batch 1110, Epoch 2, Total Tokens: 136\n",
      "Loss: 1.8013149499893188\n",
      "Running Batch 1111, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7946778535842896\n",
      "Running Batch 1112, Epoch 2, Total Tokens: 150\n",
      "Loss: 1.7147231101989746\n",
      "Running Batch 1113, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7868715524673462\n",
      "Running Batch 1114, Epoch 2, Total Tokens: 372\n",
      "Loss: 1.8102548122406006\n",
      "Running Batch 1115, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.6882494688034058\n",
      "Running Batch 1116, Epoch 2, Total Tokens: 122\n",
      "Loss: 1.8155970573425293\n",
      "Running Batch 1117, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.724043369293213\n",
      "Running Batch 1118, Epoch 2, Total Tokens: 572\n",
      "Loss: 1.8336752653121948\n",
      "Running Batch 1119, Epoch 2, Total Tokens: 105\n",
      "Loss: 1.8212614059448242\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1119, Loss: 1.8212614059448242\n",
      "Running Batch 1120, Epoch 2, Total Tokens: 149\n",
      "Loss: 1.8198966979980469\n",
      "Running Batch 1121, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.6785717010498047\n",
      "Running Batch 1122, Epoch 2, Total Tokens: 139\n",
      "Loss: 1.7141834497451782\n",
      "Running Batch 1123, Epoch 2, Total Tokens: 134\n",
      "Loss: 1.8140658140182495\n",
      "Running Batch 1124, Epoch 2, Total Tokens: 137\n",
      "Loss: 1.7467464208602905\n",
      "Running Batch 1125, Epoch 2, Total Tokens: 100\n",
      "Loss: 1.7656214237213135\n",
      "Running Batch 1126, Epoch 2, Total Tokens: 133\n",
      "Loss: 1.6948965787887573\n",
      "Running Batch 1127, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.8556545972824097\n",
      "Running Batch 1128, Epoch 2, Total Tokens: 231\n",
      "Loss: 1.6840810775756836\n",
      "Running Batch 1129, Epoch 2, Total Tokens: 115\n",
      "Loss: 1.7687281370162964\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1129, Loss: 1.7687281370162964\n",
      "Running Batch 1130, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.737404465675354\n",
      "Running Batch 1131, Epoch 2, Total Tokens: 224\n",
      "Loss: 1.7821606397628784\n",
      "Running Batch 1132, Epoch 2, Total Tokens: 285\n",
      "Loss: 1.7178078889846802\n",
      "Running Batch 1133, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.7908915281295776\n",
      "Running Batch 1134, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.717527985572815\n",
      "Running Batch 1135, Epoch 2, Total Tokens: 120\n",
      "Loss: 1.7501344680786133\n",
      "Running Batch 1136, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.7352631092071533\n",
      "Running Batch 1137, Epoch 2, Total Tokens: 127\n",
      "Loss: 1.8427073955535889\n",
      "Running Batch 1138, Epoch 2, Total Tokens: 159\n",
      "Loss: 1.8544179201126099\n",
      "Running Batch 1139, Epoch 2, Total Tokens: 267\n",
      "Loss: 1.7519396543502808\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1139, Loss: 1.7519396543502808\n",
      "Running Batch 1140, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7181401252746582\n",
      "Running Batch 1141, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.761718511581421\n",
      "Running Batch 1142, Epoch 2, Total Tokens: 123\n",
      "Loss: 1.8739063739776611\n",
      "Running Batch 1143, Epoch 2, Total Tokens: 124\n",
      "Loss: 1.7915623188018799\n",
      "Running Batch 1144, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.8625690937042236\n",
      "Running Batch 1145, Epoch 2, Total Tokens: 154\n",
      "Loss: 1.7228776216506958\n",
      "Running Batch 1146, Epoch 2, Total Tokens: 138\n",
      "Loss: 1.7346525192260742\n",
      "Running Batch 1147, Epoch 2, Total Tokens: 191\n",
      "Loss: 1.7895011901855469\n",
      "Running Batch 1148, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.9014735221862793\n",
      "Running Batch 1149, Epoch 2, Total Tokens: 171\n",
      "Loss: 1.8101633787155151\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1149, Loss: 1.8101633787155151\n",
      "Running Batch 1150, Epoch 2, Total Tokens: 147\n",
      "Loss: 1.9620774984359741\n",
      "Running Batch 1151, Epoch 2, Total Tokens: 356\n",
      "Loss: 1.8211320638656616\n",
      "Running Batch 1152, Epoch 2, Total Tokens: 162\n",
      "Loss: 1.7994859218597412\n",
      "Running Batch 1153, Epoch 2, Total Tokens: 143\n",
      "Loss: 1.7983049154281616\n",
      "Running Batch 1154, Epoch 2, Total Tokens: 146\n",
      "Loss: 1.6754155158996582\n",
      "Running Batch 1155, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7812403440475464\n",
      "Running Batch 1156, Epoch 2, Total Tokens: 140\n",
      "Loss: 1.7344130277633667\n",
      "Running Batch 1157, Epoch 2, Total Tokens: 99\n",
      "Loss: 1.7815940380096436\n",
      "Running Batch 1158, Epoch 2, Total Tokens: 113\n",
      "Loss: 1.784364938735962\n",
      "Running Batch 1159, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.8218920230865479\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1159, Loss: 1.8218920230865479\n",
      "Running Batch 1160, Epoch 2, Total Tokens: 236\n",
      "Loss: 1.8532805442810059\n",
      "Running Batch 1161, Epoch 2, Total Tokens: 211\n",
      "Loss: 1.7360992431640625\n",
      "Running Batch 1162, Epoch 2, Total Tokens: 142\n",
      "Loss: 1.6723796129226685\n",
      "Running Batch 1163, Epoch 2, Total Tokens: 118\n",
      "Loss: 1.7670962810516357\n",
      "Running Batch 1164, Epoch 2, Total Tokens: 151\n",
      "Loss: 1.7454367876052856\n",
      "Running Batch 1165, Epoch 2, Total Tokens: 126\n",
      "Loss: 1.8094316720962524\n",
      "Running Batch 1166, Epoch 2, Total Tokens: 129\n",
      "Loss: 1.7885208129882812\n",
      "Running Batch 1167, Epoch 2, Total Tokens: 152\n",
      "Loss: 1.7639448642730713\n",
      "Running Batch 1168, Epoch 2, Total Tokens: 144\n",
      "Loss: 1.7730430364608765\n",
      "Running Batch 1169, Epoch 2, Total Tokens: 114\n",
      "Loss: 1.7629287242889404\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 2, Batch: 1169, Loss: 1.7629287242889404\n",
      "Running Batch 1170, Epoch 2, Total Tokens: 167\n",
      "Loss: 1.7651711702346802\n",
      "Running Batch 1171, Epoch 2, Total Tokens: 196\n",
      "Loss: 1.8185510635375977\n",
      "AVG LOSS: 1.8233307231815195, Epoch: 3\n",
      "Running Batch 0, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7272543907165527\n",
      "Running Batch 1, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.7395706176757812\n",
      "Running Batch 2, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7271366119384766\n",
      "Running Batch 3, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7522993087768555\n",
      "Running Batch 4, Epoch 3, Total Tokens: 206\n",
      "Loss: 1.7084509134292603\n",
      "Running Batch 5, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.843273639678955\n",
      "Running Batch 6, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7434909343719482\n",
      "Running Batch 7, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.787093162536621\n",
      "Running Batch 8, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.7683314085006714\n",
      "Running Batch 9, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7208319902420044\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 9, Loss: 1.7208319902420044\n",
      "Running Batch 10, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7786386013031006\n",
      "Running Batch 11, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7455588579177856\n",
      "Running Batch 12, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.801680326461792\n",
      "Running Batch 13, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7797527313232422\n",
      "Running Batch 14, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7141517400741577\n",
      "Running Batch 15, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.6817196607589722\n",
      "Running Batch 16, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.752255916595459\n",
      "Running Batch 17, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7480438947677612\n",
      "Running Batch 18, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.7423839569091797\n",
      "Running Batch 19, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.676496148109436\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 19, Loss: 1.676496148109436\n",
      "Running Batch 20, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.8230810165405273\n",
      "Running Batch 21, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.7125115394592285\n",
      "Running Batch 22, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7186051607131958\n",
      "Running Batch 23, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6736961603164673\n",
      "Running Batch 24, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7162529230117798\n",
      "Running Batch 25, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7615681886672974\n",
      "Running Batch 26, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.783200979232788\n",
      "Running Batch 27, Epoch 3, Total Tokens: 326\n",
      "Loss: 1.6727843284606934\n",
      "Running Batch 28, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6784964799880981\n",
      "Running Batch 29, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.7335747480392456\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 29, Loss: 1.7335747480392456\n",
      "Running Batch 30, Epoch 3, Total Tokens: 180\n",
      "Loss: 1.7949200868606567\n",
      "Running Batch 31, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7333006858825684\n",
      "Running Batch 32, Epoch 3, Total Tokens: 224\n",
      "Loss: 1.7746278047561646\n",
      "Running Batch 33, Epoch 3, Total Tokens: 249\n",
      "Loss: 1.73170804977417\n",
      "Running Batch 34, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7555588483810425\n",
      "Running Batch 35, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.725245475769043\n",
      "Running Batch 36, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7288662195205688\n",
      "Running Batch 37, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7324594259262085\n",
      "Running Batch 38, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.7270182371139526\n",
      "Running Batch 39, Epoch 3, Total Tokens: 202\n",
      "Loss: 1.8001600503921509\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 39, Loss: 1.8001600503921509\n",
      "Running Batch 40, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7793850898742676\n",
      "Running Batch 41, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7756227254867554\n",
      "Running Batch 42, Epoch 3, Total Tokens: 108\n",
      "Loss: 1.778480052947998\n",
      "Running Batch 43, Epoch 3, Total Tokens: 193\n",
      "Loss: 1.686498999595642\n",
      "Running Batch 44, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7893967628479004\n",
      "Running Batch 45, Epoch 3, Total Tokens: 229\n",
      "Loss: 1.766260027885437\n",
      "Running Batch 46, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7590596675872803\n",
      "Running Batch 47, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.720454454421997\n",
      "Running Batch 48, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6701583862304688\n",
      "Running Batch 49, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7809531688690186\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 49, Loss: 1.7809531688690186\n",
      "Running Batch 50, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6723989248275757\n",
      "Running Batch 51, Epoch 3, Total Tokens: 183\n",
      "Loss: 1.6481730937957764\n",
      "Running Batch 52, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.70866858959198\n",
      "Running Batch 53, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7575942277908325\n",
      "Running Batch 54, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7917070388793945\n",
      "Running Batch 55, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.8155800104141235\n",
      "Running Batch 56, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6651694774627686\n",
      "Running Batch 57, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7785282135009766\n",
      "Running Batch 58, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.8728504180908203\n",
      "Running Batch 59, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.753675103187561\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 59, Loss: 1.753675103187561\n",
      "Running Batch 60, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.8251932859420776\n",
      "Running Batch 61, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7425596714019775\n",
      "Running Batch 62, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.729362964630127\n",
      "Running Batch 63, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7701663970947266\n",
      "Running Batch 64, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.8653467893600464\n",
      "Running Batch 65, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7876189947128296\n",
      "Running Batch 66, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.776293158531189\n",
      "Running Batch 67, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.8352288007736206\n",
      "Running Batch 68, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.76070237159729\n",
      "Running Batch 69, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.643094778060913\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 69, Loss: 1.643094778060913\n",
      "Running Batch 70, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7364201545715332\n",
      "Running Batch 71, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6721628904342651\n",
      "Running Batch 72, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7634022235870361\n",
      "Running Batch 73, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6478967666625977\n",
      "Running Batch 74, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.8393486738204956\n",
      "Running Batch 75, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7441942691802979\n",
      "Running Batch 76, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7245999574661255\n",
      "Running Batch 77, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.8043997287750244\n",
      "Running Batch 78, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.7942503690719604\n",
      "Running Batch 79, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.638733983039856\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 79, Loss: 1.638733983039856\n",
      "Running Batch 80, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7830876111984253\n",
      "Running Batch 81, Epoch 3, Total Tokens: 266\n",
      "Loss: 1.7216635942459106\n",
      "Running Batch 82, Epoch 3, Total Tokens: 361\n",
      "Loss: 1.7491540908813477\n",
      "Running Batch 83, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.711868405342102\n",
      "Running Batch 84, Epoch 3, Total Tokens: 281\n",
      "Loss: 1.6844942569732666\n",
      "Running Batch 85, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7241246700286865\n",
      "Running Batch 86, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7193089723587036\n",
      "Running Batch 87, Epoch 3, Total Tokens: 273\n",
      "Loss: 1.7764729261398315\n",
      "Running Batch 88, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.762650728225708\n",
      "Running Batch 89, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.730667233467102\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 89, Loss: 1.730667233467102\n",
      "Running Batch 90, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.7816656827926636\n",
      "Running Batch 91, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.8860057592391968\n",
      "Running Batch 92, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7008671760559082\n",
      "Running Batch 93, Epoch 3, Total Tokens: 236\n",
      "Loss: 1.7293555736541748\n",
      "Running Batch 94, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.803803563117981\n",
      "Running Batch 95, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7636418342590332\n",
      "Running Batch 96, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7168188095092773\n",
      "Running Batch 97, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7165279388427734\n",
      "Running Batch 98, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7897984981536865\n",
      "Running Batch 99, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.781883716583252\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 99, Loss: 1.781883716583252\n",
      "Running Batch 100, Epoch 3, Total Tokens: 296\n",
      "Loss: 1.7535114288330078\n",
      "Running Batch 101, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.7716939449310303\n",
      "Running Batch 102, Epoch 3, Total Tokens: 572\n",
      "Loss: 1.7362898588180542\n",
      "Running Batch 103, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7102017402648926\n",
      "Running Batch 104, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7729114294052124\n",
      "Running Batch 105, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7493481636047363\n",
      "Running Batch 106, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.8284339904785156\n",
      "Running Batch 107, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6859289407730103\n",
      "Running Batch 108, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7741267681121826\n",
      "Running Batch 109, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7581002712249756\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 109, Loss: 1.7581002712249756\n",
      "Running Batch 110, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7610957622528076\n",
      "Running Batch 111, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.8307760953903198\n",
      "Running Batch 112, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.737628698348999\n",
      "Running Batch 113, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7957192659378052\n",
      "Running Batch 114, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.8095663785934448\n",
      "Running Batch 115, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.6687984466552734\n",
      "Running Batch 116, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.8403875827789307\n",
      "Running Batch 117, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.790941596031189\n",
      "Running Batch 118, Epoch 3, Total Tokens: 285\n",
      "Loss: 1.6849007606506348\n",
      "Running Batch 119, Epoch 3, Total Tokens: 202\n",
      "Loss: 1.8035094738006592\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 119, Loss: 1.8035094738006592\n",
      "Running Batch 120, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6843293905258179\n",
      "Running Batch 121, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6903806924819946\n",
      "Running Batch 122, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7305150032043457\n",
      "Running Batch 123, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7061035633087158\n",
      "Running Batch 124, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.697521448135376\n",
      "Running Batch 125, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.7635432481765747\n",
      "Running Batch 126, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7871469259262085\n",
      "Running Batch 127, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.726199746131897\n",
      "Running Batch 128, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.73677396774292\n",
      "Running Batch 129, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.735080361366272\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 129, Loss: 1.735080361366272\n",
      "Running Batch 130, Epoch 3, Total Tokens: 171\n",
      "Loss: 1.7888110876083374\n",
      "Running Batch 131, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.7925498485565186\n",
      "Running Batch 132, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.8519799709320068\n",
      "Running Batch 133, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.686297059059143\n",
      "Running Batch 134, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7529687881469727\n",
      "Running Batch 135, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.838107943534851\n",
      "Running Batch 136, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7678442001342773\n",
      "Running Batch 137, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.8923065662384033\n",
      "Running Batch 138, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7416341304779053\n",
      "Running Batch 139, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7382874488830566\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 139, Loss: 1.7382874488830566\n",
      "Running Batch 140, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6972721815109253\n",
      "Running Batch 141, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.8647807836532593\n",
      "Running Batch 142, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.8093870878219604\n",
      "Running Batch 143, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7247072458267212\n",
      "Running Batch 144, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.8293275833129883\n",
      "Running Batch 145, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6853547096252441\n",
      "Running Batch 146, Epoch 3, Total Tokens: 186\n",
      "Loss: 1.7703040838241577\n",
      "Running Batch 147, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6183055639266968\n",
      "Running Batch 148, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.7564138174057007\n",
      "Running Batch 149, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.7071751356124878\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 149, Loss: 1.7071751356124878\n",
      "Running Batch 150, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.682827353477478\n",
      "Running Batch 151, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7478052377700806\n",
      "Running Batch 152, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7630258798599243\n",
      "Running Batch 153, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7617433071136475\n",
      "Running Batch 154, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.768323540687561\n",
      "Running Batch 155, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.741932988166809\n",
      "Running Batch 156, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7568618059158325\n",
      "Running Batch 157, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7372221946716309\n",
      "Running Batch 158, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.8108799457550049\n",
      "Running Batch 159, Epoch 3, Total Tokens: 230\n",
      "Loss: 1.7928658723831177\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 159, Loss: 1.7928658723831177\n",
      "Running Batch 160, Epoch 3, Total Tokens: 191\n",
      "Loss: 1.7951370477676392\n",
      "Running Batch 161, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6877301931381226\n",
      "Running Batch 162, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.81257963180542\n",
      "Running Batch 163, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7641518115997314\n",
      "Running Batch 164, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7358754873275757\n",
      "Running Batch 165, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7454673051834106\n",
      "Running Batch 166, Epoch 3, Total Tokens: 211\n",
      "Loss: 1.7038835287094116\n",
      "Running Batch 167, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.7528218030929565\n",
      "Running Batch 168, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7184499502182007\n",
      "Running Batch 169, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.8239580392837524\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 169, Loss: 1.8239580392837524\n",
      "Running Batch 170, Epoch 3, Total Tokens: 187\n",
      "Loss: 1.7128037214279175\n",
      "Running Batch 171, Epoch 3, Total Tokens: 185\n",
      "Loss: 1.781109094619751\n",
      "Running Batch 172, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7365106344223022\n",
      "Running Batch 173, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7859559059143066\n",
      "Running Batch 174, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.8198374509811401\n",
      "Running Batch 175, Epoch 3, Total Tokens: 167\n",
      "Loss: 1.7174714803695679\n",
      "Running Batch 176, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.676544189453125\n",
      "Running Batch 177, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7648048400878906\n",
      "Running Batch 178, Epoch 3, Total Tokens: 231\n",
      "Loss: 1.8173518180847168\n",
      "Running Batch 179, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6784456968307495\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 179, Loss: 1.6784456968307495\n",
      "Running Batch 180, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.704644799232483\n",
      "Running Batch 181, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7934789657592773\n",
      "Running Batch 182, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.680071234703064\n",
      "Running Batch 183, Epoch 3, Total Tokens: 295\n",
      "Loss: 1.707364559173584\n",
      "Running Batch 184, Epoch 3, Total Tokens: 274\n",
      "Loss: 1.7500247955322266\n",
      "Running Batch 185, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.734924077987671\n",
      "Running Batch 186, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.7210476398468018\n",
      "Running Batch 187, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.788225531578064\n",
      "Running Batch 188, Epoch 3, Total Tokens: 629\n",
      "Loss: 1.6221349239349365\n",
      "Running Batch 189, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.7422857284545898\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 189, Loss: 1.7422857284545898\n",
      "Running Batch 190, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7613424062728882\n",
      "Running Batch 191, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6604359149932861\n",
      "Running Batch 192, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.681579828262329\n",
      "Running Batch 193, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.877060055732727\n",
      "Running Batch 194, Epoch 3, Total Tokens: 201\n",
      "Loss: 1.6407394409179688\n",
      "Running Batch 195, Epoch 3, Total Tokens: 191\n",
      "Loss: 1.7111024856567383\n",
      "Running Batch 196, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7355645895004272\n",
      "Running Batch 197, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6483004093170166\n",
      "Running Batch 198, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.884031057357788\n",
      "Running Batch 199, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7535384893417358\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 199, Loss: 1.7535384893417358\n",
      "Running Batch 200, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.728327989578247\n",
      "Running Batch 201, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7911577224731445\n",
      "Running Batch 202, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6831011772155762\n",
      "Running Batch 203, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.7208290100097656\n",
      "Running Batch 204, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.718714714050293\n",
      "Running Batch 205, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7857706546783447\n",
      "Running Batch 206, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7762187719345093\n",
      "Running Batch 207, Epoch 3, Total Tokens: 257\n",
      "Loss: 1.6626014709472656\n",
      "Running Batch 208, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.8698052167892456\n",
      "Running Batch 209, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7208731174468994\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 209, Loss: 1.7208731174468994\n",
      "Running Batch 210, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7761669158935547\n",
      "Running Batch 211, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.7470719814300537\n",
      "Running Batch 212, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.681318759918213\n",
      "Running Batch 213, Epoch 3, Total Tokens: 254\n",
      "Loss: 1.7531622648239136\n",
      "Running Batch 214, Epoch 3, Total Tokens: 108\n",
      "Loss: 1.7213106155395508\n",
      "Running Batch 215, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7355241775512695\n",
      "Running Batch 216, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.822641372680664\n",
      "Running Batch 217, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.7460355758666992\n",
      "Running Batch 218, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.753639817237854\n",
      "Running Batch 219, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7640153169631958\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 219, Loss: 1.7640153169631958\n",
      "Running Batch 220, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.7048667669296265\n",
      "Running Batch 221, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.800805926322937\n",
      "Running Batch 222, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7281748056411743\n",
      "Running Batch 223, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.8189772367477417\n",
      "Running Batch 224, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7562810182571411\n",
      "Running Batch 225, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7061847448349\n",
      "Running Batch 226, Epoch 3, Total Tokens: 197\n",
      "Loss: 1.7271361351013184\n",
      "Running Batch 227, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7798539400100708\n",
      "Running Batch 228, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.722112774848938\n",
      "Running Batch 229, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7208800315856934\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 229, Loss: 1.7208800315856934\n",
      "Running Batch 230, Epoch 3, Total Tokens: 196\n",
      "Loss: 1.7907230854034424\n",
      "Running Batch 231, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.7739945650100708\n",
      "Running Batch 232, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7208902835845947\n",
      "Running Batch 233, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7502626180648804\n",
      "Running Batch 234, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7030175924301147\n",
      "Running Batch 235, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.7125704288482666\n",
      "Running Batch 236, Epoch 3, Total Tokens: 100\n",
      "Loss: 1.7789826393127441\n",
      "Running Batch 237, Epoch 3, Total Tokens: 242\n",
      "Loss: 1.7320128679275513\n",
      "Running Batch 238, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.8256410360336304\n",
      "Running Batch 239, Epoch 3, Total Tokens: 182\n",
      "Loss: 1.748967170715332\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 239, Loss: 1.748967170715332\n",
      "Running Batch 240, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7094818353652954\n",
      "Running Batch 241, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.8570443391799927\n",
      "Running Batch 242, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7555749416351318\n",
      "Running Batch 243, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7574288845062256\n",
      "Running Batch 244, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.6952691078186035\n",
      "Running Batch 245, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.768802523612976\n",
      "Running Batch 246, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.8027218580245972\n",
      "Running Batch 247, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.8073785305023193\n",
      "Running Batch 248, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.704930305480957\n",
      "Running Batch 249, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6695719957351685\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 249, Loss: 1.6695719957351685\n",
      "Running Batch 250, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7185331583023071\n",
      "Running Batch 251, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.764774203300476\n",
      "Running Batch 252, Epoch 3, Total Tokens: 244\n",
      "Loss: 1.7007355690002441\n",
      "Running Batch 253, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.854495644569397\n",
      "Running Batch 254, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7633190155029297\n",
      "Running Batch 255, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7126550674438477\n",
      "Running Batch 256, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.6988301277160645\n",
      "Running Batch 257, Epoch 3, Total Tokens: 170\n",
      "Loss: 1.7890704870224\n",
      "Running Batch 258, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.80243980884552\n",
      "Running Batch 259, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.752787709236145\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 259, Loss: 1.752787709236145\n",
      "Running Batch 260, Epoch 3, Total Tokens: 205\n",
      "Loss: 1.7273858785629272\n",
      "Running Batch 261, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6981831789016724\n",
      "Running Batch 262, Epoch 3, Total Tokens: 220\n",
      "Loss: 1.764474630355835\n",
      "Running Batch 263, Epoch 3, Total Tokens: 206\n",
      "Loss: 1.712143898010254\n",
      "Running Batch 264, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.7875239849090576\n",
      "Running Batch 265, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7053815126419067\n",
      "Running Batch 266, Epoch 3, Total Tokens: 217\n",
      "Loss: 1.7376803159713745\n",
      "Running Batch 267, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.72552490234375\n",
      "Running Batch 268, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7114689350128174\n",
      "Running Batch 269, Epoch 3, Total Tokens: 105\n",
      "Loss: 1.709559679031372\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 269, Loss: 1.709559679031372\n",
      "Running Batch 270, Epoch 3, Total Tokens: 187\n",
      "Loss: 1.7657926082611084\n",
      "Running Batch 271, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7567044496536255\n",
      "Running Batch 272, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.8241995573043823\n",
      "Running Batch 273, Epoch 3, Total Tokens: 109\n",
      "Loss: 1.8053861856460571\n",
      "Running Batch 274, Epoch 3, Total Tokens: 188\n",
      "Loss: 1.7269351482391357\n",
      "Running Batch 275, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.8279370069503784\n",
      "Running Batch 276, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7304595708847046\n",
      "Running Batch 277, Epoch 3, Total Tokens: 209\n",
      "Loss: 1.7716065645217896\n",
      "Running Batch 278, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.7418948411941528\n",
      "Running Batch 279, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7097620964050293\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 279, Loss: 1.7097620964050293\n",
      "Running Batch 280, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7205158472061157\n",
      "Running Batch 281, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7946752309799194\n",
      "Running Batch 282, Epoch 3, Total Tokens: 111\n",
      "Loss: 1.6871168613433838\n",
      "Running Batch 283, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.7624222040176392\n",
      "Running Batch 284, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.806645393371582\n",
      "Running Batch 285, Epoch 3, Total Tokens: 192\n",
      "Loss: 1.7536910772323608\n",
      "Running Batch 286, Epoch 3, Total Tokens: 210\n",
      "Loss: 1.8005027770996094\n",
      "Running Batch 287, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.737886667251587\n",
      "Running Batch 288, Epoch 3, Total Tokens: 384\n",
      "Loss: 1.7168749570846558\n",
      "Running Batch 289, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7307735681533813\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 289, Loss: 1.7307735681533813\n",
      "Running Batch 290, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7569372653961182\n",
      "Running Batch 291, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6861871480941772\n",
      "Running Batch 292, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6561992168426514\n",
      "Running Batch 293, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.760918378829956\n",
      "Running Batch 294, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.763195514678955\n",
      "Running Batch 295, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.882195234298706\n",
      "Running Batch 296, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.7305608987808228\n",
      "Running Batch 297, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7941651344299316\n",
      "Running Batch 298, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7143491506576538\n",
      "Running Batch 299, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7313449382781982\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 299, Loss: 1.7313449382781982\n",
      "Running Batch 300, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7787188291549683\n",
      "Running Batch 301, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6792924404144287\n",
      "Running Batch 302, Epoch 3, Total Tokens: 228\n",
      "Loss: 1.8647197484970093\n",
      "Running Batch 303, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7182343006134033\n",
      "Running Batch 304, Epoch 3, Total Tokens: 262\n",
      "Loss: 1.786659836769104\n",
      "Running Batch 305, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6539539098739624\n",
      "Running Batch 306, Epoch 3, Total Tokens: 452\n",
      "Loss: 1.8792827129364014\n",
      "Running Batch 307, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.782404899597168\n",
      "Running Batch 308, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7400637865066528\n",
      "Running Batch 309, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.7989097833633423\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 309, Loss: 1.7989097833633423\n",
      "Running Batch 310, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6423749923706055\n",
      "Running Batch 311, Epoch 3, Total Tokens: 167\n",
      "Loss: 1.655029535293579\n",
      "Running Batch 312, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7244917154312134\n",
      "Running Batch 313, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7724800109863281\n",
      "Running Batch 314, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7714704275131226\n",
      "Running Batch 315, Epoch 3, Total Tokens: 299\n",
      "Loss: 1.7410269975662231\n",
      "Running Batch 316, Epoch 3, Total Tokens: 494\n",
      "Loss: 1.6224461793899536\n",
      "Running Batch 317, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.692786455154419\n",
      "Running Batch 318, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7454519271850586\n",
      "Running Batch 319, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.713962435722351\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 319, Loss: 1.713962435722351\n",
      "Running Batch 320, Epoch 3, Total Tokens: 175\n",
      "Loss: 1.7210417985916138\n",
      "Running Batch 321, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.8285415172576904\n",
      "Running Batch 322, Epoch 3, Total Tokens: 251\n",
      "Loss: 1.8595175743103027\n",
      "Running Batch 323, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.784208059310913\n",
      "Running Batch 324, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.690946340560913\n",
      "Running Batch 325, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7883418798446655\n",
      "Running Batch 326, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7011873722076416\n",
      "Running Batch 327, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7760907411575317\n",
      "Running Batch 328, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7369905710220337\n",
      "Running Batch 329, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6751068830490112\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 329, Loss: 1.6751068830490112\n",
      "Running Batch 330, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.726047158241272\n",
      "Running Batch 331, Epoch 3, Total Tokens: 166\n",
      "Loss: 1.759831428527832\n",
      "Running Batch 332, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.8556370735168457\n",
      "Running Batch 333, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.7782115936279297\n",
      "Running Batch 334, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6560648679733276\n",
      "Running Batch 335, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7567626237869263\n",
      "Running Batch 336, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.648302435874939\n",
      "Running Batch 337, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6963179111480713\n",
      "Running Batch 338, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.741312026977539\n",
      "Running Batch 339, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6232078075408936\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 339, Loss: 1.6232078075408936\n",
      "Running Batch 340, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.666018009185791\n",
      "Running Batch 341, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.775610327720642\n",
      "Running Batch 342, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7136424779891968\n",
      "Running Batch 343, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6512656211853027\n",
      "Running Batch 344, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6965079307556152\n",
      "Running Batch 345, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7176953554153442\n",
      "Running Batch 346, Epoch 3, Total Tokens: 261\n",
      "Loss: 1.7847074270248413\n",
      "Running Batch 347, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7774372100830078\n",
      "Running Batch 348, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7440845966339111\n",
      "Running Batch 349, Epoch 3, Total Tokens: 237\n",
      "Loss: 1.6882857084274292\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 349, Loss: 1.6882857084274292\n",
      "Running Batch 350, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7791723012924194\n",
      "Running Batch 351, Epoch 3, Total Tokens: 104\n",
      "Loss: 1.6948318481445312\n",
      "Running Batch 352, Epoch 3, Total Tokens: 111\n",
      "Loss: 1.6633554697036743\n",
      "Running Batch 353, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.741210699081421\n",
      "Running Batch 354, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7544374465942383\n",
      "Running Batch 355, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6816662549972534\n",
      "Running Batch 356, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.696143627166748\n",
      "Running Batch 357, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.742635726928711\n",
      "Running Batch 358, Epoch 3, Total Tokens: 163\n",
      "Loss: 1.658065915107727\n",
      "Running Batch 359, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7758848667144775\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 359, Loss: 1.7758848667144775\n",
      "Running Batch 360, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7244722843170166\n",
      "Running Batch 361, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.8207080364227295\n",
      "Running Batch 362, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.8701871633529663\n",
      "Running Batch 363, Epoch 3, Total Tokens: 107\n",
      "Loss: 1.737902283668518\n",
      "Running Batch 364, Epoch 3, Total Tokens: 334\n",
      "Loss: 1.7439489364624023\n",
      "Running Batch 365, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.719521164894104\n",
      "Running Batch 366, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.8044341802597046\n",
      "Running Batch 367, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6633338928222656\n",
      "Running Batch 368, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6633846759796143\n",
      "Running Batch 369, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6365858316421509\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 369, Loss: 1.6365858316421509\n",
      "Running Batch 370, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.719444990158081\n",
      "Running Batch 371, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6947928667068481\n",
      "Running Batch 372, Epoch 3, Total Tokens: 340\n",
      "Loss: 1.7044163942337036\n",
      "Running Batch 373, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6719127893447876\n",
      "Running Batch 374, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6857202053070068\n",
      "Running Batch 375, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.5807013511657715\n",
      "Running Batch 376, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.681291937828064\n",
      "Running Batch 377, Epoch 3, Total Tokens: 163\n",
      "Loss: 1.7612744569778442\n",
      "Running Batch 378, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7391786575317383\n",
      "Running Batch 379, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7131719589233398\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 379, Loss: 1.7131719589233398\n",
      "Running Batch 380, Epoch 3, Total Tokens: 224\n",
      "Loss: 1.7496989965438843\n",
      "Running Batch 381, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7419904470443726\n",
      "Running Batch 382, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.6930992603302002\n",
      "Running Batch 383, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.7342876195907593\n",
      "Running Batch 384, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7795050144195557\n",
      "Running Batch 385, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6712478399276733\n",
      "Running Batch 386, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.7650279998779297\n",
      "Running Batch 387, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7552286386489868\n",
      "Running Batch 388, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7315670251846313\n",
      "Running Batch 389, Epoch 3, Total Tokens: 428\n",
      "Loss: 1.7382997274398804\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 389, Loss: 1.7382997274398804\n",
      "Running Batch 390, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7624508142471313\n",
      "Running Batch 391, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.72791588306427\n",
      "Running Batch 392, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7117687463760376\n",
      "Running Batch 393, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7420891523361206\n",
      "Running Batch 394, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.7511749267578125\n",
      "Running Batch 395, Epoch 3, Total Tokens: 195\n",
      "Loss: 1.7545613050460815\n",
      "Running Batch 396, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7514768838882446\n",
      "Running Batch 397, Epoch 3, Total Tokens: 360\n",
      "Loss: 1.7134621143341064\n",
      "Running Batch 398, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7140156030654907\n",
      "Running Batch 399, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7784359455108643\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 399, Loss: 1.7784359455108643\n",
      "Running Batch 400, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.7117544412612915\n",
      "Running Batch 401, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.78874933719635\n",
      "Running Batch 402, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7640275955200195\n",
      "Running Batch 403, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.7862924337387085\n",
      "Running Batch 404, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7341804504394531\n",
      "Running Batch 405, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7044168710708618\n",
      "Running Batch 406, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7496064901351929\n",
      "Running Batch 407, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.822702407836914\n",
      "Running Batch 408, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6990307569503784\n",
      "Running Batch 409, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7371028661727905\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 409, Loss: 1.7371028661727905\n",
      "Running Batch 410, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.7171075344085693\n",
      "Running Batch 411, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.679350733757019\n",
      "Running Batch 412, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6706218719482422\n",
      "Running Batch 413, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.7249515056610107\n",
      "Running Batch 414, Epoch 3, Total Tokens: 228\n",
      "Loss: 1.6738694906234741\n",
      "Running Batch 415, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.7584408521652222\n",
      "Running Batch 416, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6435232162475586\n",
      "Running Batch 417, Epoch 3, Total Tokens: 109\n",
      "Loss: 1.7611140012741089\n",
      "Running Batch 418, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.7524622678756714\n",
      "Running Batch 419, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.743364930152893\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 419, Loss: 1.743364930152893\n",
      "Running Batch 420, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7396126985549927\n",
      "Running Batch 421, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6780281066894531\n",
      "Running Batch 422, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.750409722328186\n",
      "Running Batch 423, Epoch 3, Total Tokens: 210\n",
      "Loss: 1.7511881589889526\n",
      "Running Batch 424, Epoch 3, Total Tokens: 195\n",
      "Loss: 1.7795600891113281\n",
      "Running Batch 425, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.7222998142242432\n",
      "Running Batch 426, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7739180326461792\n",
      "Running Batch 427, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7243517637252808\n",
      "Running Batch 428, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.721815824508667\n",
      "Running Batch 429, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.7632603645324707\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 429, Loss: 1.7632603645324707\n",
      "Running Batch 430, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6446688175201416\n",
      "Running Batch 431, Epoch 3, Total Tokens: 527\n",
      "Loss: 1.7581546306610107\n",
      "Running Batch 432, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7214274406433105\n",
      "Running Batch 433, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7377005815505981\n",
      "Running Batch 434, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7064586877822876\n",
      "Running Batch 435, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6949516534805298\n",
      "Running Batch 436, Epoch 3, Total Tokens: 219\n",
      "Loss: 1.6931757926940918\n",
      "Running Batch 437, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7331472635269165\n",
      "Running Batch 438, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6447817087173462\n",
      "Running Batch 439, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.69694983959198\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 439, Loss: 1.69694983959198\n",
      "Running Batch 440, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.726636290550232\n",
      "Running Batch 441, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.8039309978485107\n",
      "Running Batch 442, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.751326322555542\n",
      "Running Batch 443, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7925686836242676\n",
      "Running Batch 444, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.754266381263733\n",
      "Running Batch 445, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7225061655044556\n",
      "Running Batch 446, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7481176853179932\n",
      "Running Batch 447, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6587297916412354\n",
      "Running Batch 448, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.868434190750122\n",
      "Running Batch 449, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7528843879699707\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 449, Loss: 1.7528843879699707\n",
      "Running Batch 450, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7646781206130981\n",
      "Running Batch 451, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.8074780702590942\n",
      "Running Batch 452, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7284190654754639\n",
      "Running Batch 453, Epoch 3, Total Tokens: 568\n",
      "Loss: 1.7376948595046997\n",
      "Running Batch 454, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6886636018753052\n",
      "Running Batch 455, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7897611856460571\n",
      "Running Batch 456, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.727098822593689\n",
      "Running Batch 457, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7697778940200806\n",
      "Running Batch 458, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6717579364776611\n",
      "Running Batch 459, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7328909635543823\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 459, Loss: 1.7328909635543823\n",
      "Running Batch 460, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7365528345108032\n",
      "Running Batch 461, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6547363996505737\n",
      "Running Batch 462, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7937394380569458\n",
      "Running Batch 463, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7288051843643188\n",
      "Running Batch 464, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.762056827545166\n",
      "Running Batch 465, Epoch 3, Total Tokens: 99\n",
      "Loss: 1.757360577583313\n",
      "Running Batch 466, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7252402305603027\n",
      "Running Batch 467, Epoch 3, Total Tokens: 220\n",
      "Loss: 1.7368677854537964\n",
      "Running Batch 468, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.6982864141464233\n",
      "Running Batch 469, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.8056334257125854\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 469, Loss: 1.8056334257125854\n",
      "Running Batch 470, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7272745370864868\n",
      "Running Batch 471, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.751530647277832\n",
      "Running Batch 472, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.7897552251815796\n",
      "Running Batch 473, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.6943864822387695\n",
      "Running Batch 474, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7102590799331665\n",
      "Running Batch 475, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.7779841423034668\n",
      "Running Batch 476, Epoch 3, Total Tokens: 258\n",
      "Loss: 1.7421201467514038\n",
      "Running Batch 477, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.664462685585022\n",
      "Running Batch 478, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7494841814041138\n",
      "Running Batch 479, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.6056876182556152\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 479, Loss: 1.6056876182556152\n",
      "Running Batch 480, Epoch 3, Total Tokens: 188\n",
      "Loss: 1.7077218294143677\n",
      "Running Batch 481, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7271827459335327\n",
      "Running Batch 482, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7938014268875122\n",
      "Running Batch 483, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.7957788705825806\n",
      "Running Batch 484, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.631792426109314\n",
      "Running Batch 485, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6317081451416016\n",
      "Running Batch 486, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7598199844360352\n",
      "Running Batch 487, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.713827133178711\n",
      "Running Batch 488, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7995611429214478\n",
      "Running Batch 489, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7556668519973755\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 489, Loss: 1.7556668519973755\n",
      "Running Batch 490, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7944769859313965\n",
      "Running Batch 491, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7788623571395874\n",
      "Running Batch 492, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6910722255706787\n",
      "Running Batch 493, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6612277030944824\n",
      "Running Batch 494, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6750138998031616\n",
      "Running Batch 495, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7114304304122925\n",
      "Running Batch 496, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.661726474761963\n",
      "Running Batch 497, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.746812343597412\n",
      "Running Batch 498, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7228047847747803\n",
      "Running Batch 499, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7370903491973877\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 499, Loss: 1.7370903491973877\n",
      "Running Batch 500, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7660998106002808\n",
      "Running Batch 501, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.8185553550720215\n",
      "Running Batch 502, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.771191954612732\n",
      "Running Batch 503, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7743862867355347\n",
      "Running Batch 504, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7187528610229492\n",
      "Running Batch 505, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7277333736419678\n",
      "Running Batch 506, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7978882789611816\n",
      "Running Batch 507, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7690043449401855\n",
      "Running Batch 508, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7688214778900146\n",
      "Running Batch 509, Epoch 3, Total Tokens: 196\n",
      "Loss: 1.6416246891021729\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 509, Loss: 1.6416246891021729\n",
      "Running Batch 510, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.7878390550613403\n",
      "Running Batch 511, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7624902725219727\n",
      "Running Batch 512, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.718211054801941\n",
      "Running Batch 513, Epoch 3, Total Tokens: 166\n",
      "Loss: 1.7378668785095215\n",
      "Running Batch 514, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7023555040359497\n",
      "Running Batch 515, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6290769577026367\n",
      "Running Batch 516, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7301709651947021\n",
      "Running Batch 517, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.669925332069397\n",
      "Running Batch 518, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.660766363143921\n",
      "Running Batch 519, Epoch 3, Total Tokens: 111\n",
      "Loss: 1.7619296312332153\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 519, Loss: 1.7619296312332153\n",
      "Running Batch 520, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.690565586090088\n",
      "Running Batch 521, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7419322729110718\n",
      "Running Batch 522, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7829387187957764\n",
      "Running Batch 523, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6660780906677246\n",
      "Running Batch 524, Epoch 3, Total Tokens: 202\n",
      "Loss: 1.7226076126098633\n",
      "Running Batch 525, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.8326233625411987\n",
      "Running Batch 526, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7792145013809204\n",
      "Running Batch 527, Epoch 3, Total Tokens: 285\n",
      "Loss: 1.7721821069717407\n",
      "Running Batch 528, Epoch 3, Total Tokens: 293\n",
      "Loss: 1.7143431901931763\n",
      "Running Batch 529, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6768994331359863\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 529, Loss: 1.6768994331359863\n",
      "Running Batch 530, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6508501768112183\n",
      "Running Batch 531, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.738165259361267\n",
      "Running Batch 532, Epoch 3, Total Tokens: 168\n",
      "Loss: 1.742887258529663\n",
      "Running Batch 533, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6708296537399292\n",
      "Running Batch 534, Epoch 3, Total Tokens: 337\n",
      "Loss: 1.742440938949585\n",
      "Running Batch 535, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7314788103103638\n",
      "Running Batch 536, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.760141372680664\n",
      "Running Batch 537, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7947938442230225\n",
      "Running Batch 538, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6894384622573853\n",
      "Running Batch 539, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6993029117584229\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 539, Loss: 1.6993029117584229\n",
      "Running Batch 540, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.716911792755127\n",
      "Running Batch 541, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6758742332458496\n",
      "Running Batch 542, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.769624948501587\n",
      "Running Batch 543, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.7281973361968994\n",
      "Running Batch 544, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.7209022045135498\n",
      "Running Batch 545, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7541424036026\n",
      "Running Batch 546, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6605143547058105\n",
      "Running Batch 547, Epoch 3, Total Tokens: 182\n",
      "Loss: 1.6711660623550415\n",
      "Running Batch 548, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7373065948486328\n",
      "Running Batch 549, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7346628904342651\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 549, Loss: 1.7346628904342651\n",
      "Running Batch 550, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7607595920562744\n",
      "Running Batch 551, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.7088253498077393\n",
      "Running Batch 552, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7794520854949951\n",
      "Running Batch 553, Epoch 3, Total Tokens: 188\n",
      "Loss: 1.7975291013717651\n",
      "Running Batch 554, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7585010528564453\n",
      "Running Batch 555, Epoch 3, Total Tokens: 166\n",
      "Loss: 1.7527475357055664\n",
      "Running Batch 556, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7772470712661743\n",
      "Running Batch 557, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6234890222549438\n",
      "Running Batch 558, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7272592782974243\n",
      "Running Batch 559, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.719513177871704\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 559, Loss: 1.719513177871704\n",
      "Running Batch 560, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.7362500429153442\n",
      "Running Batch 561, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7626042366027832\n",
      "Running Batch 562, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7205069065093994\n",
      "Running Batch 563, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7273095846176147\n",
      "Running Batch 564, Epoch 3, Total Tokens: 186\n",
      "Loss: 1.7737261056900024\n",
      "Running Batch 565, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.6879326105117798\n",
      "Running Batch 566, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6653504371643066\n",
      "Running Batch 567, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.637946605682373\n",
      "Running Batch 568, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7919834852218628\n",
      "Running Batch 569, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7405003309249878\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 569, Loss: 1.7405003309249878\n",
      "Running Batch 570, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.613067388534546\n",
      "Running Batch 571, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.715257167816162\n",
      "Running Batch 572, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.657967209815979\n",
      "Running Batch 573, Epoch 3, Total Tokens: 225\n",
      "Loss: 1.7581019401550293\n",
      "Running Batch 574, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.753414511680603\n",
      "Running Batch 575, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6606183052062988\n",
      "Running Batch 576, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.7848392724990845\n",
      "Running Batch 577, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7029247283935547\n",
      "Running Batch 578, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.723599910736084\n",
      "Running Batch 579, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6855846643447876\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 579, Loss: 1.6855846643447876\n",
      "Running Batch 580, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6943968534469604\n",
      "Running Batch 581, Epoch 3, Total Tokens: 106\n",
      "Loss: 1.7113820314407349\n",
      "Running Batch 582, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6754056215286255\n",
      "Running Batch 583, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.7219915390014648\n",
      "Running Batch 584, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.7386409044265747\n",
      "Running Batch 585, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.718313455581665\n",
      "Running Batch 586, Epoch 3, Total Tokens: 357\n",
      "Loss: 1.8511693477630615\n",
      "Running Batch 587, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6796398162841797\n",
      "Running Batch 588, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7510056495666504\n",
      "Running Batch 589, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7631033658981323\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 589, Loss: 1.7631033658981323\n",
      "Running Batch 590, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6788322925567627\n",
      "Running Batch 591, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.718741536140442\n",
      "Running Batch 592, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7232791185379028\n",
      "Running Batch 593, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.811148762702942\n",
      "Running Batch 594, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.67337965965271\n",
      "Running Batch 595, Epoch 3, Total Tokens: 418\n",
      "Loss: 1.7306917905807495\n",
      "Running Batch 596, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.697129487991333\n",
      "Running Batch 597, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7655755281448364\n",
      "Running Batch 598, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6833614110946655\n",
      "Running Batch 599, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7120945453643799\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 599, Loss: 1.7120945453643799\n",
      "Running Batch 600, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6900475025177002\n",
      "Running Batch 601, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.687315583229065\n",
      "Running Batch 602, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6807663440704346\n",
      "Running Batch 603, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7716878652572632\n",
      "Running Batch 604, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.790732502937317\n",
      "Running Batch 605, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6990697383880615\n",
      "Running Batch 606, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.7561378479003906\n",
      "Running Batch 607, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.72343909740448\n",
      "Running Batch 608, Epoch 3, Total Tokens: 624\n",
      "Loss: 1.7688519954681396\n",
      "Running Batch 609, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7374945878982544\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 609, Loss: 1.7374945878982544\n",
      "Running Batch 610, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7661223411560059\n",
      "Running Batch 611, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.8143562078475952\n",
      "Running Batch 612, Epoch 3, Total Tokens: 224\n",
      "Loss: 1.7525780200958252\n",
      "Running Batch 613, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7079626321792603\n",
      "Running Batch 614, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7903364896774292\n",
      "Running Batch 615, Epoch 3, Total Tokens: 185\n",
      "Loss: 1.8332871198654175\n",
      "Running Batch 616, Epoch 3, Total Tokens: 170\n",
      "Loss: 1.6567350625991821\n",
      "Running Batch 617, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.7013579607009888\n",
      "Running Batch 618, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7365086078643799\n",
      "Running Batch 619, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7308787107467651\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 619, Loss: 1.7308787107467651\n",
      "Running Batch 620, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6398675441741943\n",
      "Running Batch 621, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.677896499633789\n",
      "Running Batch 622, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7890021800994873\n",
      "Running Batch 623, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6748400926589966\n",
      "Running Batch 624, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.8050799369812012\n",
      "Running Batch 625, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.7258728742599487\n",
      "Running Batch 626, Epoch 3, Total Tokens: 223\n",
      "Loss: 1.7458480596542358\n",
      "Running Batch 627, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.73187255859375\n",
      "Running Batch 628, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6566375494003296\n",
      "Running Batch 629, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.6254315376281738\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 629, Loss: 1.6254315376281738\n",
      "Running Batch 630, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6876633167266846\n",
      "Running Batch 631, Epoch 3, Total Tokens: 234\n",
      "Loss: 1.7786489725112915\n",
      "Running Batch 632, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7659634351730347\n",
      "Running Batch 633, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.721665382385254\n",
      "Running Batch 634, Epoch 3, Total Tokens: 380\n",
      "Loss: 1.6772873401641846\n",
      "Running Batch 635, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7093477249145508\n",
      "Running Batch 636, Epoch 3, Total Tokens: 266\n",
      "Loss: 1.709271788597107\n",
      "Running Batch 637, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6979832649230957\n",
      "Running Batch 638, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.761137843132019\n",
      "Running Batch 639, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7043771743774414\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 639, Loss: 1.7043771743774414\n",
      "Running Batch 640, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6273906230926514\n",
      "Running Batch 641, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.676888346672058\n",
      "Running Batch 642, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7439343929290771\n",
      "Running Batch 643, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6540471315383911\n",
      "Running Batch 644, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7170926332473755\n",
      "Running Batch 645, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7632472515106201\n",
      "Running Batch 646, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.733289122581482\n",
      "Running Batch 647, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6748137474060059\n",
      "Running Batch 648, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.692150592803955\n",
      "Running Batch 649, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.770573616027832\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 649, Loss: 1.770573616027832\n",
      "Running Batch 650, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6430227756500244\n",
      "Running Batch 651, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.7853821516036987\n",
      "Running Batch 652, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.787126064300537\n",
      "Running Batch 653, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7109630107879639\n",
      "Running Batch 654, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.716072678565979\n",
      "Running Batch 655, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.7581063508987427\n",
      "Running Batch 656, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6867873668670654\n",
      "Running Batch 657, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7413995265960693\n",
      "Running Batch 658, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7131198644638062\n",
      "Running Batch 659, Epoch 3, Total Tokens: 170\n",
      "Loss: 1.6641212701797485\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 659, Loss: 1.6641212701797485\n",
      "Running Batch 660, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.7356703281402588\n",
      "Running Batch 661, Epoch 3, Total Tokens: 177\n",
      "Loss: 1.6784865856170654\n",
      "Running Batch 662, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.664293885231018\n",
      "Running Batch 663, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7242552042007446\n",
      "Running Batch 664, Epoch 3, Total Tokens: 185\n",
      "Loss: 1.7038086652755737\n",
      "Running Batch 665, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.675815463066101\n",
      "Running Batch 666, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.7043826580047607\n",
      "Running Batch 667, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6502482891082764\n",
      "Running Batch 668, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6512185335159302\n",
      "Running Batch 669, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.6638720035552979\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 669, Loss: 1.6638720035552979\n",
      "Running Batch 670, Epoch 3, Total Tokens: 107\n",
      "Loss: 1.6842060089111328\n",
      "Running Batch 671, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.653788685798645\n",
      "Running Batch 672, Epoch 3, Total Tokens: 372\n",
      "Loss: 1.6722899675369263\n",
      "Running Batch 673, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6344656944274902\n",
      "Running Batch 674, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.8425110578536987\n",
      "Running Batch 675, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.635077714920044\n",
      "Running Batch 676, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7202757596969604\n",
      "Running Batch 677, Epoch 3, Total Tokens: 160\n",
      "Loss: 1.6298761367797852\n",
      "Running Batch 678, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.6798624992370605\n",
      "Running Batch 679, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6095588207244873\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 679, Loss: 1.6095588207244873\n",
      "Running Batch 680, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6773631572723389\n",
      "Running Batch 681, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6795824766159058\n",
      "Running Batch 682, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.8034794330596924\n",
      "Running Batch 683, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7039847373962402\n",
      "Running Batch 684, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6535441875457764\n",
      "Running Batch 685, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.7445260286331177\n",
      "Running Batch 686, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.694706916809082\n",
      "Running Batch 687, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7171846628189087\n",
      "Running Batch 688, Epoch 3, Total Tokens: 214\n",
      "Loss: 1.6993839740753174\n",
      "Running Batch 689, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6870263814926147\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 689, Loss: 1.6870263814926147\n",
      "Running Batch 690, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.6820634603500366\n",
      "Running Batch 691, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7034647464752197\n",
      "Running Batch 692, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7393007278442383\n",
      "Running Batch 693, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.703674554824829\n",
      "Running Batch 694, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.6889389753341675\n",
      "Running Batch 695, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.8355094194412231\n",
      "Running Batch 696, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6806964874267578\n",
      "Running Batch 697, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7589027881622314\n",
      "Running Batch 698, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.7410621643066406\n",
      "Running Batch 699, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.766707420349121\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 699, Loss: 1.766707420349121\n",
      "Running Batch 700, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7781563997268677\n",
      "Running Batch 701, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.6417715549468994\n",
      "Running Batch 702, Epoch 3, Total Tokens: 167\n",
      "Loss: 1.684665322303772\n",
      "Running Batch 703, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6922533512115479\n",
      "Running Batch 704, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7152799367904663\n",
      "Running Batch 705, Epoch 3, Total Tokens: 205\n",
      "Loss: 1.7618731260299683\n",
      "Running Batch 706, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7206363677978516\n",
      "Running Batch 707, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6589897871017456\n",
      "Running Batch 708, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.729745864868164\n",
      "Running Batch 709, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6888000965118408\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 709, Loss: 1.6888000965118408\n",
      "Running Batch 710, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6660038232803345\n",
      "Running Batch 711, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.684408187866211\n",
      "Running Batch 712, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.6909279823303223\n",
      "Running Batch 713, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.68095862865448\n",
      "Running Batch 714, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.6608099937438965\n",
      "Running Batch 715, Epoch 3, Total Tokens: 220\n",
      "Loss: 1.6976619958877563\n",
      "Running Batch 716, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7664377689361572\n",
      "Running Batch 717, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.7086093425750732\n",
      "Running Batch 718, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.8193573951721191\n",
      "Running Batch 719, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6774729490280151\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 719, Loss: 1.6774729490280151\n",
      "Running Batch 720, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6764394044876099\n",
      "Running Batch 721, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.62534761428833\n",
      "Running Batch 722, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.8182685375213623\n",
      "Running Batch 723, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6720231771469116\n",
      "Running Batch 724, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.750057578086853\n",
      "Running Batch 725, Epoch 3, Total Tokens: 294\n",
      "Loss: 1.7208889722824097\n",
      "Running Batch 726, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6870981454849243\n",
      "Running Batch 727, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7299772500991821\n",
      "Running Batch 728, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6932517290115356\n",
      "Running Batch 729, Epoch 3, Total Tokens: 267\n",
      "Loss: 1.6910358667373657\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 729, Loss: 1.6910358667373657\n",
      "Running Batch 730, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.670642375946045\n",
      "Running Batch 731, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7940720319747925\n",
      "Running Batch 732, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6843959093093872\n",
      "Running Batch 733, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7315465211868286\n",
      "Running Batch 734, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.793874740600586\n",
      "Running Batch 735, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6379399299621582\n",
      "Running Batch 736, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.8102920055389404\n",
      "Running Batch 737, Epoch 3, Total Tokens: 237\n",
      "Loss: 1.8046672344207764\n",
      "Running Batch 738, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.7319836616516113\n",
      "Running Batch 739, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7258110046386719\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 739, Loss: 1.7258110046386719\n",
      "Running Batch 740, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.6370658874511719\n",
      "Running Batch 741, Epoch 3, Total Tokens: 166\n",
      "Loss: 1.707095742225647\n",
      "Running Batch 742, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.701735019683838\n",
      "Running Batch 743, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.7017964124679565\n",
      "Running Batch 744, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7705318927764893\n",
      "Running Batch 745, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6434556245803833\n",
      "Running Batch 746, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7627352476119995\n",
      "Running Batch 747, Epoch 3, Total Tokens: 187\n",
      "Loss: 1.7992334365844727\n",
      "Running Batch 748, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.6774781942367554\n",
      "Running Batch 749, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6846394538879395\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 749, Loss: 1.6846394538879395\n",
      "Running Batch 750, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.767103672027588\n",
      "Running Batch 751, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6951349973678589\n",
      "Running Batch 752, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7170701026916504\n",
      "Running Batch 753, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.751369595527649\n",
      "Running Batch 754, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6919242143630981\n",
      "Running Batch 755, Epoch 3, Total Tokens: 112\n",
      "Loss: 1.82707679271698\n",
      "Running Batch 756, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7012975215911865\n",
      "Running Batch 757, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.786963701248169\n",
      "Running Batch 758, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.7244020700454712\n",
      "Running Batch 759, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7192853689193726\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 759, Loss: 1.7192853689193726\n",
      "Running Batch 760, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7044801712036133\n",
      "Running Batch 761, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7397081851959229\n",
      "Running Batch 762, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7547380924224854\n",
      "Running Batch 763, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6236590147018433\n",
      "Running Batch 764, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7286094427108765\n",
      "Running Batch 765, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6777750253677368\n",
      "Running Batch 766, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6717137098312378\n",
      "Running Batch 767, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.804701566696167\n",
      "Running Batch 768, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6828889846801758\n",
      "Running Batch 769, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7407252788543701\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 769, Loss: 1.7407252788543701\n",
      "Running Batch 770, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7756435871124268\n",
      "Running Batch 771, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7688766717910767\n",
      "Running Batch 772, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7219568490982056\n",
      "Running Batch 773, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.7294524908065796\n",
      "Running Batch 774, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.6141761541366577\n",
      "Running Batch 775, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7366665601730347\n",
      "Running Batch 776, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6044631004333496\n",
      "Running Batch 777, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.6746455430984497\n",
      "Running Batch 778, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7137682437896729\n",
      "Running Batch 779, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.67214834690094\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 779, Loss: 1.67214834690094\n",
      "Running Batch 780, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.5933811664581299\n",
      "Running Batch 781, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6678060293197632\n",
      "Running Batch 782, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7524334192276\n",
      "Running Batch 783, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.7306756973266602\n",
      "Running Batch 784, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7089415788650513\n",
      "Running Batch 785, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.837996006011963\n",
      "Running Batch 786, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.7336009740829468\n",
      "Running Batch 787, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.693591833114624\n",
      "Running Batch 788, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.684482455253601\n",
      "Running Batch 789, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.669237494468689\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 789, Loss: 1.669237494468689\n",
      "Running Batch 790, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7104195356369019\n",
      "Running Batch 791, Epoch 3, Total Tokens: 104\n",
      "Loss: 1.6278327703475952\n",
      "Running Batch 792, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7842110395431519\n",
      "Running Batch 793, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.6724729537963867\n",
      "Running Batch 794, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7870428562164307\n",
      "Running Batch 795, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6667102575302124\n",
      "Running Batch 796, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.673656940460205\n",
      "Running Batch 797, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6629990339279175\n",
      "Running Batch 798, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7368495464324951\n",
      "Running Batch 799, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6673741340637207\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 799, Loss: 1.6673741340637207\n",
      "Running Batch 800, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6852394342422485\n",
      "Running Batch 801, Epoch 3, Total Tokens: 164\n",
      "Loss: 1.8078460693359375\n",
      "Running Batch 802, Epoch 3, Total Tokens: 121\n",
      "Loss: 1.6775696277618408\n",
      "Running Batch 803, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6343718767166138\n",
      "Running Batch 804, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7169737815856934\n",
      "Running Batch 805, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6604472398757935\n",
      "Running Batch 806, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7125540971755981\n",
      "Running Batch 807, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.8479951620101929\n",
      "Running Batch 808, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.738661766052246\n",
      "Running Batch 809, Epoch 3, Total Tokens: 286\n",
      "Loss: 1.7521781921386719\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 809, Loss: 1.7521781921386719\n",
      "Running Batch 810, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.7464724779129028\n",
      "Running Batch 811, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7957303524017334\n",
      "Running Batch 812, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.615233302116394\n",
      "Running Batch 813, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7859917879104614\n",
      "Running Batch 814, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.724913477897644\n",
      "Running Batch 815, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.7137672901153564\n",
      "Running Batch 816, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.689151644706726\n",
      "Running Batch 817, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.701231837272644\n",
      "Running Batch 818, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7298073768615723\n",
      "Running Batch 819, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7739231586456299\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 819, Loss: 1.7739231586456299\n",
      "Running Batch 820, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.7754688262939453\n",
      "Running Batch 821, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7065622806549072\n",
      "Running Batch 822, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.8033602237701416\n",
      "Running Batch 823, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.8051453828811646\n",
      "Running Batch 824, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7207146883010864\n",
      "Running Batch 825, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6857649087905884\n",
      "Running Batch 826, Epoch 3, Total Tokens: 157\n",
      "Loss: 1.615073323249817\n",
      "Running Batch 827, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.8246166706085205\n",
      "Running Batch 828, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7275928258895874\n",
      "Running Batch 829, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6942973136901855\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 829, Loss: 1.6942973136901855\n",
      "Running Batch 830, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.6482508182525635\n",
      "Running Batch 831, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7614431381225586\n",
      "Running Batch 832, Epoch 3, Total Tokens: 178\n",
      "Loss: 1.6545921564102173\n",
      "Running Batch 833, Epoch 3, Total Tokens: 187\n",
      "Loss: 1.6804240942001343\n",
      "Running Batch 834, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.5573644638061523\n",
      "Running Batch 835, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.8003451824188232\n",
      "Running Batch 836, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7383356094360352\n",
      "Running Batch 837, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7214878797531128\n",
      "Running Batch 838, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7294758558273315\n",
      "Running Batch 839, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7058606147766113\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 839, Loss: 1.7058606147766113\n",
      "Running Batch 840, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6512205600738525\n",
      "Running Batch 841, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.6704448461532593\n",
      "Running Batch 842, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.6152678728103638\n",
      "Running Batch 843, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6926428079605103\n",
      "Running Batch 844, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.729534387588501\n",
      "Running Batch 845, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7148051261901855\n",
      "Running Batch 846, Epoch 3, Total Tokens: 179\n",
      "Loss: 1.5984755754470825\n",
      "Running Batch 847, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7625114917755127\n",
      "Running Batch 848, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.6935611963272095\n",
      "Running Batch 849, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7683091163635254\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 849, Loss: 1.7683091163635254\n",
      "Running Batch 850, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.6786085367202759\n",
      "Running Batch 851, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6564797163009644\n",
      "Running Batch 852, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6516196727752686\n",
      "Running Batch 853, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.8307652473449707\n",
      "Running Batch 854, Epoch 3, Total Tokens: 356\n",
      "Loss: 1.730741024017334\n",
      "Running Batch 855, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6789517402648926\n",
      "Running Batch 856, Epoch 3, Total Tokens: 287\n",
      "Loss: 1.7203670740127563\n",
      "Running Batch 857, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7642258405685425\n",
      "Running Batch 858, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7901438474655151\n",
      "Running Batch 859, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6768995523452759\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 859, Loss: 1.6768995523452759\n",
      "Running Batch 860, Epoch 3, Total Tokens: 110\n",
      "Loss: 1.8099086284637451\n",
      "Running Batch 861, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.69874107837677\n",
      "Running Batch 862, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6709843873977661\n",
      "Running Batch 863, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6241987943649292\n",
      "Running Batch 864, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.7082257270812988\n",
      "Running Batch 865, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.6950829029083252\n",
      "Running Batch 866, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6333352327346802\n",
      "Running Batch 867, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7382855415344238\n",
      "Running Batch 868, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7302794456481934\n",
      "Running Batch 869, Epoch 3, Total Tokens: 170\n",
      "Loss: 1.6141650676727295\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 869, Loss: 1.6141650676727295\n",
      "Running Batch 870, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6721949577331543\n",
      "Running Batch 871, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6441258192062378\n",
      "Running Batch 872, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.717057704925537\n",
      "Running Batch 873, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6197736263275146\n",
      "Running Batch 874, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6091874837875366\n",
      "Running Batch 875, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.735020399093628\n",
      "Running Batch 876, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7157667875289917\n",
      "Running Batch 877, Epoch 3, Total Tokens: 163\n",
      "Loss: 1.7637118101119995\n",
      "Running Batch 878, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.69089674949646\n",
      "Running Batch 879, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6838122606277466\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 879, Loss: 1.6838122606277466\n",
      "Running Batch 880, Epoch 3, Total Tokens: 282\n",
      "Loss: 1.6423046588897705\n",
      "Running Batch 881, Epoch 3, Total Tokens: 244\n",
      "Loss: 1.62888765335083\n",
      "Running Batch 882, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7321501970291138\n",
      "Running Batch 883, Epoch 3, Total Tokens: 109\n",
      "Loss: 1.5844134092330933\n",
      "Running Batch 884, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.8311938047409058\n",
      "Running Batch 885, Epoch 3, Total Tokens: 158\n",
      "Loss: 1.7498748302459717\n",
      "Running Batch 886, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.669413447380066\n",
      "Running Batch 887, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6934596300125122\n",
      "Running Batch 888, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7501288652420044\n",
      "Running Batch 889, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.8019373416900635\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 889, Loss: 1.8019373416900635\n",
      "Running Batch 890, Epoch 3, Total Tokens: 250\n",
      "Loss: 1.6741092205047607\n",
      "Running Batch 891, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7396571636199951\n",
      "Running Batch 892, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6474324464797974\n",
      "Running Batch 893, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6917294263839722\n",
      "Running Batch 894, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7503432035446167\n",
      "Running Batch 895, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.5911818742752075\n",
      "Running Batch 896, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.682616949081421\n",
      "Running Batch 897, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7579644918441772\n",
      "Running Batch 898, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6827465295791626\n",
      "Running Batch 899, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.8360596895217896\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 899, Loss: 1.8360596895217896\n",
      "Running Batch 900, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6407667398452759\n",
      "Running Batch 901, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6150513887405396\n",
      "Running Batch 902, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7387855052947998\n",
      "Running Batch 903, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6885356903076172\n",
      "Running Batch 904, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6149803400039673\n",
      "Running Batch 905, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6398252248764038\n",
      "Running Batch 906, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.6796042919158936\n",
      "Running Batch 907, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.7183384895324707\n",
      "Running Batch 908, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7090214490890503\n",
      "Running Batch 909, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7067052125930786\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 909, Loss: 1.7067052125930786\n",
      "Running Batch 910, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.677695393562317\n",
      "Running Batch 911, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.725361943244934\n",
      "Running Batch 912, Epoch 3, Total Tokens: 219\n",
      "Loss: 1.7976490259170532\n",
      "Running Batch 913, Epoch 3, Total Tokens: 324\n",
      "Loss: 1.6621730327606201\n",
      "Running Batch 914, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7060102224349976\n",
      "Running Batch 915, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.6263892650604248\n",
      "Running Batch 916, Epoch 3, Total Tokens: 168\n",
      "Loss: 1.7507660388946533\n",
      "Running Batch 917, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.695023536682129\n",
      "Running Batch 918, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7619857788085938\n",
      "Running Batch 919, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7453008890151978\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 919, Loss: 1.7453008890151978\n",
      "Running Batch 920, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6789098978042603\n",
      "Running Batch 921, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.5740691423416138\n",
      "Running Batch 922, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.6746156215667725\n",
      "Running Batch 923, Epoch 3, Total Tokens: 254\n",
      "Loss: 1.7299463748931885\n",
      "Running Batch 924, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.670647382736206\n",
      "Running Batch 925, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.7972825765609741\n",
      "Running Batch 926, Epoch 3, Total Tokens: 299\n",
      "Loss: 1.6919395923614502\n",
      "Running Batch 927, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.748024821281433\n",
      "Running Batch 928, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.56895911693573\n",
      "Running Batch 929, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.7470353841781616\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 929, Loss: 1.7470353841781616\n",
      "Running Batch 930, Epoch 3, Total Tokens: 117\n",
      "Loss: 1.6348013877868652\n",
      "Running Batch 931, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7464972734451294\n",
      "Running Batch 932, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.657470703125\n",
      "Running Batch 933, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6450239419937134\n",
      "Running Batch 934, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6588406562805176\n",
      "Running Batch 935, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.6823172569274902\n",
      "Running Batch 936, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.6320170164108276\n",
      "Running Batch 937, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.728252649307251\n",
      "Running Batch 938, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7235145568847656\n",
      "Running Batch 939, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6706534624099731\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 939, Loss: 1.6706534624099731\n",
      "Running Batch 940, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6462557315826416\n",
      "Running Batch 941, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6959933042526245\n",
      "Running Batch 942, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.5995081663131714\n",
      "Running Batch 943, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6693370342254639\n",
      "Running Batch 944, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6439498662948608\n",
      "Running Batch 945, Epoch 3, Total Tokens: 155\n",
      "Loss: 1.764532208442688\n",
      "Running Batch 946, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7003278732299805\n",
      "Running Batch 947, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.798811435699463\n",
      "Running Batch 948, Epoch 3, Total Tokens: 204\n",
      "Loss: 1.651010274887085\n",
      "Running Batch 949, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6796228885650635\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 949, Loss: 1.6796228885650635\n",
      "Running Batch 950, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7388486862182617\n",
      "Running Batch 951, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6948187351226807\n",
      "Running Batch 952, Epoch 3, Total Tokens: 236\n",
      "Loss: 1.701066255569458\n",
      "Running Batch 953, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.6770095825195312\n",
      "Running Batch 954, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.702470302581787\n",
      "Running Batch 955, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7981208562850952\n",
      "Running Batch 956, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6701247692108154\n",
      "Running Batch 957, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.616455316543579\n",
      "Running Batch 958, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6761136054992676\n",
      "Running Batch 959, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.689786434173584\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 959, Loss: 1.689786434173584\n",
      "Running Batch 960, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7198245525360107\n",
      "Running Batch 961, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7215487957000732\n",
      "Running Batch 962, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.7194530963897705\n",
      "Running Batch 963, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.6832127571105957\n",
      "Running Batch 964, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6052545309066772\n",
      "Running Batch 965, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6561082601547241\n",
      "Running Batch 966, Epoch 3, Total Tokens: 195\n",
      "Loss: 1.6976150274276733\n",
      "Running Batch 967, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.7534087896347046\n",
      "Running Batch 968, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.662664771080017\n",
      "Running Batch 969, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6960591077804565\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 969, Loss: 1.6960591077804565\n",
      "Running Batch 970, Epoch 3, Total Tokens: 192\n",
      "Loss: 1.7709978818893433\n",
      "Running Batch 971, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6370981931686401\n",
      "Running Batch 972, Epoch 3, Total Tokens: 184\n",
      "Loss: 1.7666141986846924\n",
      "Running Batch 973, Epoch 3, Total Tokens: 234\n",
      "Loss: 1.7130486965179443\n",
      "Running Batch 974, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.64909029006958\n",
      "Running Batch 975, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7156827449798584\n",
      "Running Batch 976, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7287142276763916\n",
      "Running Batch 977, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.7446720600128174\n",
      "Running Batch 978, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.6574506759643555\n",
      "Running Batch 979, Epoch 3, Total Tokens: 186\n",
      "Loss: 1.6760777235031128\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 979, Loss: 1.6760777235031128\n",
      "Running Batch 980, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6420334577560425\n",
      "Running Batch 981, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.7591758966445923\n",
      "Running Batch 982, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.6541415452957153\n",
      "Running Batch 983, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.7266539335250854\n",
      "Running Batch 984, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.780530333518982\n",
      "Running Batch 985, Epoch 3, Total Tokens: 165\n",
      "Loss: 1.716448187828064\n",
      "Running Batch 986, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.66378915309906\n",
      "Running Batch 987, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.640830636024475\n",
      "Running Batch 988, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7014297246932983\n",
      "Running Batch 989, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6519804000854492\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 989, Loss: 1.6519804000854492\n",
      "Running Batch 990, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.697253942489624\n",
      "Running Batch 991, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6820142269134521\n",
      "Running Batch 992, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.7297807931900024\n",
      "Running Batch 993, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.6583443880081177\n",
      "Running Batch 994, Epoch 3, Total Tokens: 171\n",
      "Loss: 1.692160964012146\n",
      "Running Batch 995, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.753432035446167\n",
      "Running Batch 996, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7972068786621094\n",
      "Running Batch 997, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.677517294883728\n",
      "Running Batch 998, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.716036081314087\n",
      "Running Batch 999, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7802813053131104\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 999, Loss: 1.7802813053131104\n",
      "Running Batch 1000, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.7564712762832642\n",
      "Running Batch 1001, Epoch 3, Total Tokens: 188\n",
      "Loss: 1.6353418827056885\n",
      "Running Batch 1002, Epoch 3, Total Tokens: 181\n",
      "Loss: 1.7430603504180908\n",
      "Running Batch 1003, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6626086235046387\n",
      "Running Batch 1004, Epoch 3, Total Tokens: 288\n",
      "Loss: 1.7095165252685547\n",
      "Running Batch 1005, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.7339218854904175\n",
      "Running Batch 1006, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6856305599212646\n",
      "Running Batch 1007, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.7691965103149414\n",
      "Running Batch 1008, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.7932742834091187\n",
      "Running Batch 1009, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7051383256912231\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1009, Loss: 1.7051383256912231\n",
      "Running Batch 1010, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.7652333974838257\n",
      "Running Batch 1011, Epoch 3, Total Tokens: 114\n",
      "Loss: 1.659065842628479\n",
      "Running Batch 1012, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.7594852447509766\n",
      "Running Batch 1013, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.615617036819458\n",
      "Running Batch 1014, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.6999095678329468\n",
      "Running Batch 1015, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.740549921989441\n",
      "Running Batch 1016, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.693777084350586\n",
      "Running Batch 1017, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.658605694770813\n",
      "Running Batch 1018, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.726738452911377\n",
      "Running Batch 1019, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.632188081741333\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1019, Loss: 1.632188081741333\n",
      "Running Batch 1020, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.6346205472946167\n",
      "Running Batch 1021, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6406935453414917\n",
      "Running Batch 1022, Epoch 3, Total Tokens: 367\n",
      "Loss: 1.6478970050811768\n",
      "Running Batch 1023, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.6925222873687744\n",
      "Running Batch 1024, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.711272954940796\n",
      "Running Batch 1025, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.642248272895813\n",
      "Running Batch 1026, Epoch 3, Total Tokens: 107\n",
      "Loss: 1.7920900583267212\n",
      "Running Batch 1027, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.764688491821289\n",
      "Running Batch 1028, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6142137050628662\n",
      "Running Batch 1029, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.5979816913604736\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1029, Loss: 1.5979816913604736\n",
      "Running Batch 1030, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7157950401306152\n",
      "Running Batch 1031, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6742830276489258\n",
      "Running Batch 1032, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6632598638534546\n",
      "Running Batch 1033, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7116458415985107\n",
      "Running Batch 1034, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6812347173690796\n",
      "Running Batch 1035, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6975160837173462\n",
      "Running Batch 1036, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.7206782102584839\n",
      "Running Batch 1037, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6861807107925415\n",
      "Running Batch 1038, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7483539581298828\n",
      "Running Batch 1039, Epoch 3, Total Tokens: 118\n",
      "Loss: 1.626621961593628\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1039, Loss: 1.626621961593628\n",
      "Running Batch 1040, Epoch 3, Total Tokens: 156\n",
      "Loss: 1.7636219263076782\n",
      "Running Batch 1041, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.7881462574005127\n",
      "Running Batch 1042, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.734253168106079\n",
      "Running Batch 1043, Epoch 3, Total Tokens: 146\n",
      "Loss: 1.6815873384475708\n",
      "Running Batch 1044, Epoch 3, Total Tokens: 351\n",
      "Loss: 1.6991868019104004\n",
      "Running Batch 1045, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.684082269668579\n",
      "Running Batch 1046, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6735223531723022\n",
      "Running Batch 1047, Epoch 3, Total Tokens: 108\n",
      "Loss: 1.725770115852356\n",
      "Running Batch 1048, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.6985344886779785\n",
      "Running Batch 1049, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.6859114170074463\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1049, Loss: 1.6859114170074463\n",
      "Running Batch 1050, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7000592947006226\n",
      "Running Batch 1051, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6031028032302856\n",
      "Running Batch 1052, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6172218322753906\n",
      "Running Batch 1053, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6586834192276\n",
      "Running Batch 1054, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6392040252685547\n",
      "Running Batch 1055, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7597724199295044\n",
      "Running Batch 1056, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.7221580743789673\n",
      "Running Batch 1057, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6502004861831665\n",
      "Running Batch 1058, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6994194984436035\n",
      "Running Batch 1059, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.70754873752594\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1059, Loss: 1.70754873752594\n",
      "Running Batch 1060, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.7179783582687378\n",
      "Running Batch 1061, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.738358497619629\n",
      "Running Batch 1062, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6103520393371582\n",
      "Running Batch 1063, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7025847434997559\n",
      "Running Batch 1064, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6740165948867798\n",
      "Running Batch 1065, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.6186648607254028\n",
      "Running Batch 1066, Epoch 3, Total Tokens: 221\n",
      "Loss: 1.6448862552642822\n",
      "Running Batch 1067, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.6713964939117432\n",
      "Running Batch 1068, Epoch 3, Total Tokens: 143\n",
      "Loss: 1.6441766023635864\n",
      "Running Batch 1069, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.7458555698394775\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1069, Loss: 1.7458555698394775\n",
      "Running Batch 1070, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.7824807167053223\n",
      "Running Batch 1071, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7068264484405518\n",
      "Running Batch 1072, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.6414533853530884\n",
      "Running Batch 1073, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.724674940109253\n",
      "Running Batch 1074, Epoch 3, Total Tokens: 113\n",
      "Loss: 1.5951120853424072\n",
      "Running Batch 1075, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.647458553314209\n",
      "Running Batch 1076, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.699731469154358\n",
      "Running Batch 1077, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.7708988189697266\n",
      "Running Batch 1078, Epoch 3, Total Tokens: 98\n",
      "Loss: 1.745736002922058\n",
      "Running Batch 1079, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.764850378036499\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1079, Loss: 1.764850378036499\n",
      "Running Batch 1080, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.698000192642212\n",
      "Running Batch 1081, Epoch 3, Total Tokens: 115\n",
      "Loss: 1.7163714170455933\n",
      "Running Batch 1082, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6605910062789917\n",
      "Running Batch 1083, Epoch 3, Total Tokens: 267\n",
      "Loss: 1.6736209392547607\n",
      "Running Batch 1084, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.5838724374771118\n",
      "Running Batch 1085, Epoch 3, Total Tokens: 154\n",
      "Loss: 1.687837839126587\n",
      "Running Batch 1086, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.645877718925476\n",
      "Running Batch 1087, Epoch 3, Total Tokens: 199\n",
      "Loss: 1.7225407361984253\n",
      "Running Batch 1088, Epoch 3, Total Tokens: 123\n",
      "Loss: 1.7134795188903809\n",
      "Running Batch 1089, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6595940589904785\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1089, Loss: 1.6595940589904785\n",
      "Running Batch 1090, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6848969459533691\n",
      "Running Batch 1091, Epoch 3, Total Tokens: 125\n",
      "Loss: 1.6846710443496704\n",
      "Running Batch 1092, Epoch 3, Total Tokens: 148\n",
      "Loss: 1.6676030158996582\n",
      "Running Batch 1093, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7377909421920776\n",
      "Running Batch 1094, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.706558108329773\n",
      "Running Batch 1095, Epoch 3, Total Tokens: 174\n",
      "Loss: 1.693560004234314\n",
      "Running Batch 1096, Epoch 3, Total Tokens: 231\n",
      "Loss: 1.7293065786361694\n",
      "Running Batch 1097, Epoch 3, Total Tokens: 281\n",
      "Loss: 1.6443781852722168\n",
      "Running Batch 1098, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7349196672439575\n",
      "Running Batch 1099, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.72207510471344\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1099, Loss: 1.72207510471344\n",
      "Running Batch 1100, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.6712117195129395\n",
      "Running Batch 1101, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.7360738515853882\n",
      "Running Batch 1102, Epoch 3, Total Tokens: 127\n",
      "Loss: 1.6563447713851929\n",
      "Running Batch 1103, Epoch 3, Total Tokens: 133\n",
      "Loss: 1.7486658096313477\n",
      "Running Batch 1104, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6384997367858887\n",
      "Running Batch 1105, Epoch 3, Total Tokens: 149\n",
      "Loss: 1.6755928993225098\n",
      "Running Batch 1106, Epoch 3, Total Tokens: 107\n",
      "Loss: 1.6359272003173828\n",
      "Running Batch 1107, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6991795301437378\n",
      "Running Batch 1108, Epoch 3, Total Tokens: 138\n",
      "Loss: 1.7030638456344604\n",
      "Running Batch 1109, Epoch 3, Total Tokens: 169\n",
      "Loss: 1.6680097579956055\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1109, Loss: 1.6680097579956055\n",
      "Running Batch 1110, Epoch 3, Total Tokens: 183\n",
      "Loss: 1.7040187120437622\n",
      "Running Batch 1111, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7690407037734985\n",
      "Running Batch 1112, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6983883380889893\n",
      "Running Batch 1113, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.6992098093032837\n",
      "Running Batch 1114, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.7066632509231567\n",
      "Running Batch 1115, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.7648370265960693\n",
      "Running Batch 1116, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.7977139949798584\n",
      "Running Batch 1117, Epoch 3, Total Tokens: 162\n",
      "Loss: 1.6022675037384033\n",
      "Running Batch 1118, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.7921301126480103\n",
      "Running Batch 1119, Epoch 3, Total Tokens: 109\n",
      "Loss: 1.7212941646575928\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1119, Loss: 1.7212941646575928\n",
      "Running Batch 1120, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.69919753074646\n",
      "Running Batch 1121, Epoch 3, Total Tokens: 176\n",
      "Loss: 1.6806119680404663\n",
      "Running Batch 1122, Epoch 3, Total Tokens: 172\n",
      "Loss: 1.6818829774856567\n",
      "Running Batch 1123, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.658487319946289\n",
      "Running Batch 1124, Epoch 3, Total Tokens: 136\n",
      "Loss: 1.6570545434951782\n",
      "Running Batch 1125, Epoch 3, Total Tokens: 167\n",
      "Loss: 1.7756236791610718\n",
      "Running Batch 1126, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.6918797492980957\n",
      "Running Batch 1127, Epoch 3, Total Tokens: 119\n",
      "Loss: 1.7055139541625977\n",
      "Running Batch 1128, Epoch 3, Total Tokens: 141\n",
      "Loss: 1.6359124183654785\n",
      "Running Batch 1129, Epoch 3, Total Tokens: 134\n",
      "Loss: 1.689883828163147\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1129, Loss: 1.689883828163147\n",
      "Running Batch 1130, Epoch 3, Total Tokens: 173\n",
      "Loss: 1.651370644569397\n",
      "Running Batch 1131, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.715987205505371\n",
      "Running Batch 1132, Epoch 3, Total Tokens: 147\n",
      "Loss: 1.6993132829666138\n",
      "Running Batch 1133, Epoch 3, Total Tokens: 254\n",
      "Loss: 1.7667574882507324\n",
      "Running Batch 1134, Epoch 3, Total Tokens: 131\n",
      "Loss: 1.731382131576538\n",
      "Running Batch 1135, Epoch 3, Total Tokens: 135\n",
      "Loss: 1.6420402526855469\n",
      "Running Batch 1136, Epoch 3, Total Tokens: 124\n",
      "Loss: 1.7159531116485596\n",
      "Running Batch 1137, Epoch 3, Total Tokens: 120\n",
      "Loss: 1.6167066097259521\n",
      "Running Batch 1138, Epoch 3, Total Tokens: 322\n",
      "Loss: 1.6893525123596191\n",
      "Running Batch 1139, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6738146543502808\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1139, Loss: 1.6738146543502808\n",
      "Running Batch 1140, Epoch 3, Total Tokens: 128\n",
      "Loss: 1.6778039932250977\n",
      "Running Batch 1141, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7382105588912964\n",
      "Running Batch 1142, Epoch 3, Total Tokens: 258\n",
      "Loss: 1.662797212600708\n",
      "Running Batch 1143, Epoch 3, Total Tokens: 151\n",
      "Loss: 1.6171983480453491\n",
      "Running Batch 1144, Epoch 3, Total Tokens: 130\n",
      "Loss: 1.6910851001739502\n",
      "Running Batch 1145, Epoch 3, Total Tokens: 144\n",
      "Loss: 1.6507389545440674\n",
      "Running Batch 1146, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.5946155786514282\n",
      "Running Batch 1147, Epoch 3, Total Tokens: 126\n",
      "Loss: 1.712425708770752\n",
      "Running Batch 1148, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.7102336883544922\n",
      "Running Batch 1149, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6500111818313599\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1149, Loss: 1.6500111818313599\n",
      "Running Batch 1150, Epoch 3, Total Tokens: 116\n",
      "Loss: 1.707736611366272\n",
      "Running Batch 1151, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.6529287099838257\n",
      "Running Batch 1152, Epoch 3, Total Tokens: 132\n",
      "Loss: 1.7699840068817139\n",
      "Running Batch 1153, Epoch 3, Total Tokens: 122\n",
      "Loss: 1.7076115608215332\n",
      "Running Batch 1154, Epoch 3, Total Tokens: 129\n",
      "Loss: 1.657954216003418\n",
      "Running Batch 1155, Epoch 3, Total Tokens: 139\n",
      "Loss: 1.6129957437515259\n",
      "Running Batch 1156, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6668987274169922\n",
      "Running Batch 1157, Epoch 3, Total Tokens: 152\n",
      "Loss: 1.6500811576843262\n",
      "Running Batch 1158, Epoch 3, Total Tokens: 183\n",
      "Loss: 1.5836588144302368\n",
      "Running Batch 1159, Epoch 3, Total Tokens: 145\n",
      "Loss: 1.6899809837341309\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1159, Loss: 1.6899809837341309\n",
      "Running Batch 1160, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.6509288549423218\n",
      "Running Batch 1161, Epoch 3, Total Tokens: 140\n",
      "Loss: 1.6194484233856201\n",
      "Running Batch 1162, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6566776037216187\n",
      "Running Batch 1163, Epoch 3, Total Tokens: 153\n",
      "Loss: 1.6263459920883179\n",
      "Running Batch 1164, Epoch 3, Total Tokens: 161\n",
      "Loss: 1.6874802112579346\n",
      "Running Batch 1165, Epoch 3, Total Tokens: 159\n",
      "Loss: 1.6793224811553955\n",
      "Running Batch 1166, Epoch 3, Total Tokens: 187\n",
      "Loss: 1.6623551845550537\n",
      "Running Batch 1167, Epoch 3, Total Tokens: 150\n",
      "Loss: 1.7216413021087646\n",
      "Running Batch 1168, Epoch 3, Total Tokens: 190\n",
      "Loss: 1.7588083744049072\n",
      "Running Batch 1169, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.693109154701233\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 3, Batch: 1169, Loss: 1.693109154701233\n",
      "Running Batch 1170, Epoch 3, Total Tokens: 137\n",
      "Loss: 1.6101423501968384\n",
      "Running Batch 1171, Epoch 3, Total Tokens: 142\n",
      "Loss: 1.572378158569336\n",
      "AVG LOSS: 1.7211277085156165, Epoch: 4\n",
      "Running Batch 0, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.6841298341751099\n",
      "Running Batch 1, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6767065525054932\n",
      "Running Batch 2, Epoch 4, Total Tokens: 131\n",
      "Loss: 1.651397705078125\n",
      "Running Batch 3, Epoch 4, Total Tokens: 131\n",
      "Loss: 1.7536097764968872\n",
      "Running Batch 4, Epoch 4, Total Tokens: 203\n",
      "Loss: 1.7028107643127441\n",
      "Running Batch 5, Epoch 4, Total Tokens: 141\n",
      "Loss: 1.69693922996521\n",
      "Running Batch 6, Epoch 4, Total Tokens: 326\n",
      "Loss: 1.6897302865982056\n",
      "Running Batch 7, Epoch 4, Total Tokens: 117\n",
      "Loss: 1.6326230764389038\n",
      "Running Batch 8, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.6814686059951782\n",
      "Running Batch 9, Epoch 4, Total Tokens: 127\n",
      "Loss: 1.7940784692764282\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 9, Loss: 1.7940784692764282\n",
      "Running Batch 10, Epoch 4, Total Tokens: 196\n",
      "Loss: 1.618489146232605\n",
      "Running Batch 11, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.7300770282745361\n",
      "Running Batch 12, Epoch 4, Total Tokens: 126\n",
      "Loss: 1.7041209936141968\n",
      "Running Batch 13, Epoch 4, Total Tokens: 117\n",
      "Loss: 1.6370774507522583\n",
      "Running Batch 14, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6423083543777466\n",
      "Running Batch 15, Epoch 4, Total Tokens: 129\n",
      "Loss: 1.5649930238723755\n",
      "Running Batch 16, Epoch 4, Total Tokens: 110\n",
      "Loss: 1.7272095680236816\n",
      "Running Batch 17, Epoch 4, Total Tokens: 131\n",
      "Loss: 1.6912997961044312\n",
      "Running Batch 18, Epoch 4, Total Tokens: 134\n",
      "Loss: 1.626076579093933\n",
      "Running Batch 19, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.6696840524673462\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 19, Loss: 1.6696840524673462\n",
      "Running Batch 20, Epoch 4, Total Tokens: 136\n",
      "Loss: 1.6834208965301514\n",
      "Running Batch 21, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.675480842590332\n",
      "Running Batch 22, Epoch 4, Total Tokens: 121\n",
      "Loss: 1.6561384201049805\n",
      "Running Batch 23, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.6330500841140747\n",
      "Running Batch 24, Epoch 4, Total Tokens: 181\n",
      "Loss: 1.7429122924804688\n",
      "Running Batch 25, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.7060117721557617\n",
      "Running Batch 26, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.6197985410690308\n",
      "Running Batch 27, Epoch 4, Total Tokens: 157\n",
      "Loss: 1.7351570129394531\n",
      "Running Batch 28, Epoch 4, Total Tokens: 151\n",
      "Loss: 1.6918458938598633\n",
      "Running Batch 29, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.6623852252960205\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 29, Loss: 1.6623852252960205\n",
      "Running Batch 30, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5909658670425415\n",
      "Running Batch 31, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.645895004272461\n",
      "Running Batch 32, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.6133509874343872\n",
      "Running Batch 33, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.6089191436767578\n",
      "Running Batch 34, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.710412621498108\n",
      "Running Batch 35, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6177953481674194\n",
      "Running Batch 36, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.6353074312210083\n",
      "Running Batch 37, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.7083125114440918\n",
      "Running Batch 38, Epoch 4, Total Tokens: 148\n",
      "Loss: 1.588479995727539\n",
      "Running Batch 39, Epoch 4, Total Tokens: 121\n",
      "Loss: 1.6806849241256714\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 39, Loss: 1.6806849241256714\n",
      "Running Batch 40, Epoch 4, Total Tokens: 112\n",
      "Loss: 1.7548906803131104\n",
      "Running Batch 41, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6719478368759155\n",
      "Running Batch 42, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6938867568969727\n",
      "Running Batch 43, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.6967145204544067\n",
      "Running Batch 44, Epoch 4, Total Tokens: 192\n",
      "Loss: 1.6969749927520752\n",
      "Running Batch 45, Epoch 4, Total Tokens: 137\n",
      "Loss: 1.6222872734069824\n",
      "Running Batch 46, Epoch 4, Total Tokens: 122\n",
      "Loss: 1.6804291009902954\n",
      "Running Batch 47, Epoch 4, Total Tokens: 135\n",
      "Loss: 1.6560330390930176\n",
      "Running Batch 48, Epoch 4, Total Tokens: 130\n",
      "Loss: 1.6887668371200562\n",
      "Running Batch 49, Epoch 4, Total Tokens: 135\n",
      "Loss: 1.6616532802581787\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 49, Loss: 1.6616532802581787\n",
      "Running Batch 50, Epoch 4, Total Tokens: 205\n",
      "Loss: 1.6620068550109863\n",
      "Running Batch 51, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.5894434452056885\n",
      "Running Batch 52, Epoch 4, Total Tokens: 115\n",
      "Loss: 1.7193835973739624\n",
      "Running Batch 53, Epoch 4, Total Tokens: 142\n",
      "Loss: 1.6807036399841309\n",
      "Running Batch 54, Epoch 4, Total Tokens: 121\n",
      "Loss: 1.755818247795105\n",
      "Running Batch 55, Epoch 4, Total Tokens: 127\n",
      "Loss: 1.640408992767334\n",
      "Running Batch 56, Epoch 4, Total Tokens: 119\n",
      "Loss: 1.6779307126998901\n",
      "Running Batch 57, Epoch 4, Total Tokens: 188\n",
      "Loss: 1.7003709077835083\n",
      "Running Batch 58, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.5610754489898682\n",
      "Running Batch 59, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.7382889986038208\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 59, Loss: 1.7382889986038208\n",
      "Running Batch 60, Epoch 4, Total Tokens: 190\n",
      "Loss: 1.6628965139389038\n",
      "Running Batch 61, Epoch 4, Total Tokens: 161\n",
      "Loss: 1.6278146505355835\n",
      "Running Batch 62, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.5726591348648071\n",
      "Running Batch 63, Epoch 4, Total Tokens: 112\n",
      "Loss: 1.7244244813919067\n",
      "Running Batch 64, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.64418363571167\n",
      "Running Batch 65, Epoch 4, Total Tokens: 137\n",
      "Loss: 1.6192771196365356\n",
      "Running Batch 66, Epoch 4, Total Tokens: 224\n",
      "Loss: 1.6023107767105103\n",
      "Running Batch 67, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.6271371841430664\n",
      "Running Batch 68, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.6437008380889893\n",
      "Running Batch 69, Epoch 4, Total Tokens: 124\n",
      "Loss: 1.6731464862823486\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 69, Loss: 1.6731464862823486\n",
      "Running Batch 70, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6125990152359009\n",
      "Running Batch 71, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.6010236740112305\n",
      "Running Batch 72, Epoch 4, Total Tokens: 124\n",
      "Loss: 1.6877034902572632\n",
      "Running Batch 73, Epoch 4, Total Tokens: 186\n",
      "Loss: 1.597967267036438\n",
      "Running Batch 74, Epoch 4, Total Tokens: 137\n",
      "Loss: 1.635589361190796\n",
      "Running Batch 75, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.7259706258773804\n",
      "Running Batch 76, Epoch 4, Total Tokens: 152\n",
      "Loss: 1.7876628637313843\n",
      "Running Batch 77, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.7421875\n",
      "Running Batch 78, Epoch 4, Total Tokens: 127\n",
      "Loss: 1.6773618459701538\n",
      "Running Batch 79, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.7525798082351685\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 79, Loss: 1.7525798082351685\n",
      "Running Batch 80, Epoch 4, Total Tokens: 123\n",
      "Loss: 1.6511913537979126\n",
      "Running Batch 81, Epoch 4, Total Tokens: 133\n",
      "Loss: 1.5915918350219727\n",
      "Running Batch 82, Epoch 4, Total Tokens: 151\n",
      "Loss: 1.7037383317947388\n",
      "Running Batch 83, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.6934738159179688\n",
      "Running Batch 84, Epoch 4, Total Tokens: 116\n",
      "Loss: 1.6593570709228516\n",
      "Running Batch 85, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6765847206115723\n",
      "Running Batch 86, Epoch 4, Total Tokens: 136\n",
      "Loss: 1.5801596641540527\n",
      "Running Batch 87, Epoch 4, Total Tokens: 129\n",
      "Loss: 1.6849853992462158\n",
      "Running Batch 88, Epoch 4, Total Tokens: 130\n",
      "Loss: 1.7098233699798584\n",
      "Running Batch 89, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.611130714416504\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 89, Loss: 1.611130714416504\n",
      "Running Batch 90, Epoch 4, Total Tokens: 128\n",
      "Loss: 1.6884199380874634\n",
      "Running Batch 91, Epoch 4, Total Tokens: 155\n",
      "Loss: 1.7553365230560303\n",
      "Running Batch 92, Epoch 4, Total Tokens: 125\n",
      "Loss: 1.613267421722412\n",
      "Running Batch 93, Epoch 4, Total Tokens: 121\n",
      "Loss: 1.6559221744537354\n",
      "Running Batch 94, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.6011812686920166\n",
      "Running Batch 95, Epoch 4, Total Tokens: 126\n",
      "Loss: 1.5976852178573608\n",
      "Running Batch 96, Epoch 4, Total Tokens: 244\n",
      "Loss: 1.6482610702514648\n",
      "Running Batch 97, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.6801882982254028\n",
      "Running Batch 98, Epoch 4, Total Tokens: 199\n",
      "Loss: 1.7391177415847778\n",
      "Running Batch 99, Epoch 4, Total Tokens: 428\n",
      "Loss: 1.602141261100769\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 99, Loss: 1.602141261100769\n",
      "Running Batch 100, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.7047022581100464\n",
      "Running Batch 101, Epoch 4, Total Tokens: 236\n",
      "Loss: 1.6384552717208862\n",
      "Running Batch 102, Epoch 4, Total Tokens: 117\n",
      "Loss: 1.6284077167510986\n",
      "Running Batch 103, Epoch 4, Total Tokens: 136\n",
      "Loss: 1.7352380752563477\n",
      "Running Batch 104, Epoch 4, Total Tokens: 150\n",
      "Loss: 1.6545089483261108\n",
      "Running Batch 105, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.5829304456710815\n",
      "Running Batch 106, Epoch 4, Total Tokens: 111\n",
      "Loss: 1.618360996246338\n",
      "Running Batch 107, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.6309900283813477\n",
      "Running Batch 108, Epoch 4, Total Tokens: 126\n",
      "Loss: 1.5936436653137207\n",
      "Running Batch 109, Epoch 4, Total Tokens: 361\n",
      "Loss: 1.6105318069458008\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 109, Loss: 1.6105318069458008\n",
      "Running Batch 110, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6534967422485352\n",
      "Running Batch 111, Epoch 4, Total Tokens: 112\n",
      "Loss: 1.6034080982208252\n",
      "Running Batch 112, Epoch 4, Total Tokens: 139\n",
      "Loss: 1.70942223072052\n",
      "Running Batch 113, Epoch 4, Total Tokens: 124\n",
      "Loss: 1.6203676462173462\n",
      "Running Batch 114, Epoch 4, Total Tokens: 165\n",
      "Loss: 1.6405341625213623\n",
      "Running Batch 115, Epoch 4, Total Tokens: 182\n",
      "Loss: 1.7091431617736816\n",
      "Running Batch 116, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.614147424697876\n",
      "Running Batch 117, Epoch 4, Total Tokens: 118\n",
      "Loss: 1.75592839717865\n",
      "Running Batch 118, Epoch 4, Total Tokens: 135\n",
      "Loss: 1.7060145139694214\n",
      "Running Batch 119, Epoch 4, Total Tokens: 360\n",
      "Loss: 1.7035237550735474\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 119, Loss: 1.7035237550735474\n",
      "Running Batch 120, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.6392935514450073\n",
      "Running Batch 121, Epoch 4, Total Tokens: 163\n",
      "Loss: 1.6331316232681274\n",
      "Running Batch 122, Epoch 4, Total Tokens: 157\n",
      "Loss: 1.652008056640625\n",
      "Running Batch 123, Epoch 4, Total Tokens: 351\n",
      "Loss: 1.7201857566833496\n",
      "Running Batch 124, Epoch 4, Total Tokens: 220\n",
      "Loss: 1.5834856033325195\n",
      "Running Batch 125, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.6417226791381836\n",
      "Running Batch 126, Epoch 4, Total Tokens: 166\n",
      "Loss: 1.6789982318878174\n",
      "Running Batch 127, Epoch 4, Total Tokens: 146\n",
      "Loss: 1.6222399473190308\n",
      "Running Batch 128, Epoch 4, Total Tokens: 169\n",
      "Loss: 1.6945613622665405\n",
      "Running Batch 129, Epoch 4, Total Tokens: 144\n",
      "Loss: 1.6173601150512695\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 129, Loss: 1.6173601150512695\n",
      "Running Batch 130, Epoch 4, Total Tokens: 169\n",
      "Loss: 1.6628193855285645\n",
      "Running Batch 131, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.5754472017288208\n",
      "Running Batch 132, Epoch 4, Total Tokens: 145\n",
      "Loss: 1.6746479272842407\n",
      "Running Batch 133, Epoch 4, Total Tokens: 140\n",
      "Loss: 1.6135050058364868\n",
      "Running Batch 134, Epoch 4, Total Tokens: 114\n",
      "Loss: 1.6459324359893799\n",
      "Running Batch 135, Epoch 4, Total Tokens: 171\n",
      "Loss: 1.6265987157821655\n",
      "Running Batch 136, Epoch 4, Total Tokens: 188\n",
      "Loss: 1.6070960760116577\n",
      "Running Batch 137, Epoch 4, Total Tokens: 322\n",
      "Loss: 1.5463112592697144\n",
      "Running Batch 138, Epoch 4, Total Tokens: 149\n",
      "Loss: 1.6885907649993896\n",
      "Running Batch 139, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.6449416875839233\n",
      "SAVING MODEL to ./models/model.pt\n",
      "SAVED MODEL\n",
      "Epoch: 4, Batch: 139, Loss: 1.6449416875839233\n",
      "Running Batch 140, Epoch 4, Total Tokens: 151\n",
      "Loss: 1.6936343908309937\n",
      "Running Batch 141, Epoch 4, Total Tokens: 122\n",
      "Loss: 1.6844816207885742\n",
      "Running Batch 142, Epoch 4, Total Tokens: 153\n",
      "Loss: 1.642021894454956\n",
      "Running Batch 143, Epoch 4, Total Tokens: 124\n",
      "Loss: 1.6164562702178955\n",
      "Running Batch 144, Epoch 4, Total Tokens: 125\n",
      "Loss: 1.685081124305725\n",
      "Running Batch 145, Epoch 4, Total Tokens: 154\n",
      "Loss: 1.654404878616333\n",
      "Running Batch 146, Epoch 4, Total Tokens: 147\n",
      "Loss: 1.6364933252334595\n",
      "Running Batch 147, Epoch 4, Total Tokens: 156\n",
      "Loss: 1.6921473741531372\n",
      "Running Batch 148, Epoch 4, Total Tokens: 188\n",
      "Loss: 1.7625982761383057\n",
      "Running Batch 149, Epoch 4, Total Tokens: 122\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# print(f\"Longest formula in training: {max([len(formula) for formula in dataset.data_frame['IndexList']])}\")\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "PAD_IDX = dataset.token_to_idx[PAD]\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "def remove_trailing_pads(labels):\n",
    "   # Clip trailing PAD on labels\n",
    "   non_pad_cols = (labels != PAD_IDX).sum(dim=0)\n",
    "   non_pad_cols = non_pad_cols[non_pad_cols > 0]\n",
    "\n",
    "   return labels[:, :len(non_pad_cols)]\n",
    "\n",
    "loader = data.DataLoader(dataset, batch_size = enc.hp[\"batch_size\"], shuffle = True)\n",
    "print(len(loader))\n",
    "model_path = \"./models/model.pt\"\n",
    "model_backup_path = \"./models/model_backup.pt\"\n",
    "current_params_path = \"./models/current_params.txt\" \n",
    "\n",
    "state_dict = torch.load(model_path)\n",
    "torch.save((state_dict), model_backup_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.train()\n",
    "print(f\"LOADED MODEL to {device}\")\n",
    "\n",
    "prev_loss = 100\n",
    "for epoch in range(100):\n",
    "    curr_loss = 0\n",
    "    for bidx, batch in enumerate(loader):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        labels = remove_trailing_pads(labels)\n",
    "        context_vec = model.encoder(images).squeeze()\n",
    "\n",
    "        inputs = torch.cat([context_vec.unsqueeze(1).repeat(1, labels.shape[1], 1), model.decoder.embedding(labels)], dim=2)\n",
    "        print(f\"Running Batch {bidx}, Epoch {epoch}, Total Tokens: {labels.shape[1]}\")\n",
    "        output, _ = model.decoder(inputs, None)\n",
    "\n",
    "        # output[labels == PAD_IDX] = 0\n",
    "        # output = F.normalize(output, dim=2, p=1)\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "        target = nn.functional.one_hot(labels[:,1:], num_classes=len(dataset.tokens)).float().to(device)\n",
    "        # target[labels == PAD_IDX] = 0\n",
    "        \n",
    "        # print(f\"Output shape: {output.shape}, Labels shape: {labels.shape}, Target shape: {target.shape}\")\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output.transpose(1, 2), target.transpose(1, 2))\n",
    "        loss = loss[labels[:,1:] != PAD_IDX].mean()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # for name, param in model.named_parameters():\n",
    "        #     if param.requires_grad:\n",
    "        #         print(f\"Layer: {name}, Mean: {param.grad.mean()}, Std: {param.grad.std()}\")\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item()}\")\n",
    "        curr_loss += loss.item()\n",
    "        if bidx % 10 == 9:\n",
    "            print(f\"SAVING MODEL to {model_path}\")\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(\"SAVED MODEL\")\n",
    "            print(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            try:\n",
    "                with open(current_params_path, 'w') as f:\n",
    "                    f.write(f\"Epoch: {epoch}, Batch: {bidx}, Loss: {loss.item()}\")\n",
    "            except:\n",
    "                print(\"\\n Could not write to file \\n\")\n",
    "    print(f\"AVG LOSS: {(curr_loss)/len(loader)}, Epoch: {epoch+1}\")\n",
    "    prev_loss = curr_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
