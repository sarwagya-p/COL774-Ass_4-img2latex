{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7400e06",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-01T16:50:09.066101Z",
     "iopub.status.busy": "2023-11-01T16:50:09.065356Z",
     "iopub.status.idle": "2023-11-01T16:50:11.166235Z",
     "shell.execute_reply": "2023-11-01T16:50:11.164541Z"
    },
    "papermill": {
     "duration": 2.108331,
     "end_time": "2023-11-01T16:50:11.169131",
     "exception": false,
     "start_time": "2023-11-01T16:50:09.060800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "\n",
    "\n",
    "class BLEU(object):\n",
    "    @staticmethod\n",
    "    def compute(candidate, references, weights):\n",
    "        candidate = [c.lower() for c in candidate]\n",
    "        references = [[r.lower() for r in reference] for reference in references]\n",
    "\n",
    "        p_ns = (BLEU.modified_precision(candidate, references, i) for i, _ in enumerate(weights, start=1))\n",
    "        s = math.fsum(w * math.log(p_n) for w, p_n in zip(weights, p_ns) if p_n)\n",
    "\n",
    "        bp = BLEU.brevity_penalty(candidate, references)\n",
    "        return bp * math.exp(s)\n",
    "\n",
    "    @staticmethod\n",
    "    def modified_precision(candidate, references, n):\n",
    "        counts = Counter(ngrams(candidate, n))\n",
    "\n",
    "        if not counts:\n",
    "            return 0\n",
    "\n",
    "        max_counts = {}\n",
    "        for reference in references:\n",
    "            reference_counts = Counter(ngrams(reference, n))\n",
    "            for ngram in counts:\n",
    "                max_counts[ngram] = max(max_counts.get(ngram, 0), reference_counts[ngram])\n",
    "\n",
    "        clipped_counts = dict((ngram, min(count, max_counts[ngram])) for ngram, count in counts.items())\n",
    "\n",
    "        return sum(clipped_counts.values()) / sum(counts.values())\n",
    "    \n",
    "    @staticmethod\n",
    "    def brevity_penalty(candidate, references):\n",
    "        c = len(candidate)\n",
    "        # r = min(abs(len(r) - c) for r in references)\n",
    "        r = min(len(r) for r in references)\n",
    "\n",
    "        if c > r:\n",
    "            return 1\n",
    "        else:\n",
    "            return math.exp(1 - r / c)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d12eba",
   "metadata": {
    "papermill": {
     "duration": 0.001949,
     "end_time": "2023-11-01T16:50:11.192378",
     "exception": false,
     "start_time": "2023-11-01T16:50:11.190429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from EncoderDecoder import EncoderDecoder, EncoderCNN, DecoderRNN\n",
    "from data_utils import Img2LatexDataset, load_img\n",
    "from train_model import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = load_model(\"./models/part1a.pt\")\n",
    "model.eval()\n",
    "\n",
    "dataset = Img2LatexDataset(\"../data/SyntheticData/images/\", \"../data/SyntheticData/test.csv\")\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(f\"Images shape: {batch[0].shape}, formulas shape: {batch[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = 0\n",
    "\n",
    "counted = 1\n",
    "\n",
    "for batch in loader:\n",
    "    imgs, labels = batch\n",
    "    preds = []\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        preds.append(\" \".join(model(imgs[i])))\n",
    "        counted += 1\n",
    "        \n",
    "    ground_truths = [\" \".join([model.decoder.vocab[tok] for tok in labels[i]]) for i in range(len(labels))]\n",
    "    for gt, pred in zip(ground_truths, preds):\n",
    "        gt = gt.split()\n",
    "        pred = pred.split()\n",
    "        overall += BLEU.compute(pred,[gt], weights=[1/4, 1/4, 1/4, 1/4])\n",
    "\n",
    "    if counted % 10 == 1:\n",
    "        print(f\"Out of {counted}, BLEU score: {overall/counted}\")\n",
    "\n",
    "print(\"Macro Bleu : \", overall/counted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.465098,
   "end_time": "2023-11-01T16:50:11.714543",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-01T16:50:05.249445",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
